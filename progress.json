[
  {
    "id": "44209833",
    "title": "Hate Radio",
    "url": "https://rwandanstories.org/genocide/hate_radio.html",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "仇恨电台",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44210736",
    "title": "The Homelessness Experiment – or how to AI-proof your life",
    "url": "https://corentin.trebaol.com/Blog/8.+The+Homelessness+Experiment",
    "summary": "\"The Homelessness Experiment – or how to AI-proof your life\" focuses on Corentin Trebaol's journey and insights gained from simulating homelessness. The article highlights the increasing automation and AI taking over various jobs, leading to potential widespread unemployment and a need to \"AI-proof\" one's life.\n\nTrebaol's experiment provided him with a stark understanding of the challenges faced by the homeless, including resource scarcity, vulnerability, and the constant struggle for survival. Beyond empathy, the experiment underscored the importance of adaptable skills and resilience in a rapidly changing job market.\n\nThe article emphasizes that traditional career paths and skillsets might become obsolete. Instead, individuals need to cultivate skills that AI struggles to replicate, such as creativity, complex problem-solving, critical thinking, emotional intelligence, and interpersonal communication. These \"human skills\" are presented as crucial for navigating a future dominated by automation.\n\nFurthermore, the article suggests diversifying income streams and developing a mindset of continuous learning and adaptation. By focusing on skills that are difficult to automate and embracing a flexible approach to work, individuals can better prepare themselves for the potential displacement caused by advancements in artificial intelligence. The \"homelessness experiment\" serves as a wake-up call to proactively adapt and develop skills that will remain valuable in an AI-driven world.\n",
    "chinese_title": "无家可归实验——或如何用人工智能保护你的生活",
    "chinese_summary": "无家可归实验——或如何让你的生活不受人工智能影响"
  },
  {
    "id": "44210606",
    "title": "Bill Atkinson has passed away",
    "url": "https://m.facebook.com/story.php?story_fbid=10238073579963378&id=1378467145",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "比尔·阿特金森去世了。",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44208968",
    "title": "Why We're Moving on from Nix",
    "url": "https://blog.railway.com/p/introducing-railpack",
    "summary": "Railway is replacing Nixpacks, their existing build system, with a new system called Railpack. While Nixpacks worked well for many users, limitations hindered scaling the platform to a larger user base.\n\nThe primary issue with Nixpacks was its reliance on Nix's commit-based package versioning. This made granular version control difficult and led to unpredictable build failures when package versions updated. Image sizes were also excessively large due to Nix's monolithic dependency structure, hindering caching efficiency.\n\nRailpack addresses these issues with a completely new architecture. Key benefits include:\n\n*   **Granular Versioning:** Supports specific major.minor.patch versions of packages.\n*   **Smaller Builds:** Reduced image sizes by 38-77% compared to Nixpacks.\n*   **Better Caching:** Direct integration with BuildKit provides more precise layer and filesystem control, leading to improved cache hit rates.\n*   **Locked Dependencies:** Dependencies are locked after a successful build, preventing unexpected failures from version updates.\n\nRailpack leverages a custom BuildKit LLB + Frontend for fine-grained image construction and uses Mise for version resolution and package installation. The build process is split into Analyze, Plan, and Generate phases, enabling highly parallel builds and precise layer control.\n\nRailpack is currently in beta and supports Node, Python, Go, PHP, and Static HTML deployments, with built-in support for popular static site generators like Vite, Astro, CRA, and Angular. Railway aims to focus on providing deeper support for popular languages. Railpack is open source.\n",
    "chinese_title": "我们为何放弃Nix",
    "chinese_summary": "Railway正在用名为Railpack的新系统取代其现有的构建系统Nixpacks。虽然Nixpacks对许多用户来说运行良好，但其局限性阻碍了平台扩展到更大的用户群。\n\nNixpacks的主要问题在于其依赖于Nix基于提交的软件包版本控制。这使得细粒度的版本控制变得困难，并导致软件包版本更新时出现不可预测的构建失败。由于Nix的单体依赖结构，镜像尺寸也过大，阻碍了缓存效率。\n\nRailpack通过一个全新的架构解决了这些问题。主要优势包括：\n\n*   **细粒度的版本控制：** 支持软件包的特定major.minor.patch版本。\n*   **更小的构建：** 与Nixpacks相比，镜像尺寸减少了38-77%。\n*   **更好的缓存：** 与BuildKit的直接集成提供了更精确的层和文件系统控制，从而提高了缓存命中率。\n*   **锁定的依赖项：** 依赖项在成功构建后被锁定，防止版本更新导致意外失败。\n\nRailpack利用定制的BuildKit LLB + Frontend进行细粒度的镜像构建，并使用Mise进行版本解析和软件包安装。构建过程分为分析、计划和生成阶段，从而实现高度并行的构建和精确的层控制。\n\nRailpack目前处于测试阶段，支持Node、Python、Go、PHP和静态HTML部署，并内置支持Vite、Astro、CRA和Angular等流行的静态站点生成器。Railway的目标是专注于为流行的语言提供更深层次的支持。Railpack是开源的。"
  },
  {
    "id": "44208060",
    "title": "Low-Level Optimization with Zig",
    "url": "https://alloc.dev/2025/06/07/zig_optimization",
    "summary": "This article champions Zig as a language well-suited for low-level optimization due to its verbosity and powerful compile-time execution (comptime). While compilers are generally good at optimization, they sometimes miss opportunities, especially in high-level languages due to lack of intent. Zig's verbosity allows developers to express more intent, providing the compiler with critical information like alignment, aliasing, and sizes, leading to better code generation.\n\nComptime is Zig's secret weapon, enabling code generation at compile time, replacing the need for traditional macros, templates, and generics. It allows for the inspection, reflection, and generation of types. Unlike macros, comptime code is just regular Zig code running at compile time without side effects.\n\nThe article showcases the benefits of comptime with a string comparison example. A naive string comparison approach is contrasted with a comptime version, which optimizes code based on knowing one of the strings at compile time, leading to significantly improved assembly. It further demonstrates how to optimize this comptime comparison, comparing larger chunks using SIMD registers.\n\nFinally, the article highlights comptime's utility beyond compile-time constants, showing how it can be used for runtime dispatch based on compile-time generated procedures. The author concludes by praising Zig's ability to make writing performant code easier and encourages readers to move beyond language wars, embracing the power of Turing completeness while still having favorite languages.\n",
    "chinese_title": "使用 Zig 进行底层优化",
    "chinese_summary": "本文推崇 Zig 语言，认为它因其详尽的表达能力和强大的编译时执行 (comptime) 功能，非常适合底层优化。虽然编译器通常擅长优化，但由于缺乏意图，它们有时会错过机会，尤其是在高级语言中。Zig 的详尽表达能力允许开发者表达更多意图，为编译器提供关键信息，如对齐、别名和大小，从而实现更好的代码生成。\n\nComptime 是 Zig 的秘密武器，它能够在编译时生成代码，取代了对传统宏、模板和泛型的需求。它允许对类型进行检查、反射和生成。与宏不同，comptime 代码只是在编译时运行的常规 Zig 代码，没有副作用。\n\n本文通过一个字符串比较的例子展示了 comptime 的优势。一个简单的字符串比较方法与一个 comptime 版本进行了对比，comptime 版本通过在编译时知道其中一个字符串来优化代码，从而显著改进了汇编代码。文章进一步展示了如何优化这种 comptime 比较，使用 SIMD 寄存器比较更大的块。\n\n最后，文章强调了 comptime 的实用性不仅限于编译时常量，还展示了如何将其用于基于编译时生成过程的运行时调度。作者最后赞扬了 Zig 使编写高性能代码变得更容易的能力，并鼓励读者超越语言之争，拥抱图灵完备性的力量，同时仍然拥有自己喜欢的语言。"
  },
  {
    "id": "44209497",
    "title": "What was Radiant AI, anyway?",
    "url": "https://blog.paavo.me/radiant-ai/",
    "summary": "This article delves into the truth behind Bethesda's \"Radiant AI,\" a promised feature of The Elder Scrolls IV: Oblivion that many believe never fully materialized. The resurgence of interest following the Oblivion Remastered prompted the author to investigate what Radiant AI was intended to be, what it actually was, and its legacy in later Bethesda titles.\n\nThe article explores pre-release hype, focusing on a GameInformer cover story and the E3 2005 demo. These sources promised dynamic NPC behavior, with characters autonomously fulfilling needs like eating, working, and even committing crimes, all independent of player interaction. Todd Howard's demo showcased a shopkeeper independently practicing archery and using potions, further fueling expectations.\n\nThe author examines Bethesda's own statements through fan interviews, revealing their goal of creating a world where NPC actions felt natural and unscripted, similar to a quest in Morrowind. However, it also highlights the challenges of making these independent behaviors meaningful and perceptible to the player.\n\nThe article suggests that while the ambition was high, the reality may have fallen short. It sets the stage for further exploration of Radiant AI's mechanics, debunking myths, and examining its presence (or absence) in subsequent games like Fallout 3, Skyrim, and Starfield. The central question remains: was Radiant AI a revolutionary system, a marketing exaggeration, or something in between?\n",
    "chinese_title": "Radiant AI 到底是什么？",
    "chinese_summary": "本文深入探讨了Bethesda公司《上古卷轴IV：湮灭》中“Radiant AI”背后的真相。许多人认为这个承诺的功能从未完全实现。在《湮灭》重制版重新引发人们的兴趣后，作者开始调查Radiant AI最初的设想、实际效果以及它在Bethesda后续作品中的遗产。\n\n文章探讨了发布前的宣传，重点关注GameInformer的封面故事和2005年E3展会的演示。这些来源承诺了动态的NPC行为，角色可以自主地满足吃饭、工作甚至犯罪等需求，所有这些都独立于玩家的互动。Todd Howard的演示展示了一个店主独立练习射箭和使用药水，进一步激发了人们的期望。\n\n作者通过粉丝访谈来考察Bethesda自己的声明，揭示了他们创造一个NPC行为感觉自然且非脚本化的世界的意图，类似于《晨风》中的任务。然而，它也强调了使这些独立行为对玩家来说有意义且可感知的挑战。\n\n文章认为，虽然雄心勃勃，但现实可能并未达到预期。它为进一步探索Radiant AI的机制、揭穿神话以及考察其在后续游戏（如《辐射3》、《天际》和《星空》）中的存在（或缺失）奠定了基础。核心问题仍然是：Radiant AI是一个革命性的系统，一个营销夸张，还是介于两者之间？"
  },
  {
    "id": "44210895",
    "title": "OneText (YC W23) Is Hiring a DevOps/DBA Lead Engineer",
    "url": "https://jobs.ashbyhq.com/one-text/b95952a2-9bc2-4c3a-9da1-3dcc157b4a27",
    "summary": "The provided text snippet announces that OneText (YC W23) is hiring a DevOps/DBA Lead Engineer. The text itself is very short and primarily serves as a title or heading for a job posting. It also notes that Javascript is required to run the relevant application, likely the platform where the job is listed.\n\nIn essence: OneText, a company that participated in the Y Combinator Winter 2023 program (YC W23), is looking for a lead engineer specializing in DevOps and database administration (DBA). JavaScript is required to access the full job posting details.\n",
    "chinese_title": "OneText (YC W23) 招聘 DevOps/DBA 首席工程师",
    "chinese_summary": "OneText (YC W23) 招聘 DevOps/DBA 首席工程师。需要 JavaScript 运行应用。"
  },
  {
    "id": "44180533",
    "title": "The time bomb in the tax code that's fueling mass tech layoffs",
    "url": "https://qz.com/tech-layoffs-tax-code-trump-section-174-microsoft-meta-1851783502",
    "summary": "This Quartz article argues that a little-noticed change to Section 174 of the U.S. tax code, buried within the 2017 Tax Cuts and Jobs Act (TCJA), is a key factor contributing to mass tech layoffs since 2023. For almost 70 years, companies could immediately deduct 100% of R&D spending, incentivizing domestic innovation. The TCJA slashed corporate tax rates but included a delayed provision to offset costs: the change to Section 174.\n\nBeginning in 2022, companies could no longer immediately expense R&D; instead, they had to amortize it over five to fifteen years. This increased tax burdens and decreased cash flow, particularly impacting companies that relied on R&D write-offs to minimize taxable income.\n\nThe article connects this change to layoffs at major tech companies like Meta, Microsoft, Amazon, Salesforce, and smaller firms. While companies publicly cited over-hiring and AI as reasons, the article contends the tax change played a significant, yet less acknowledged, role. It forced companies to cut headcount, the largest R&D expense, to manage increased tax liabilities.\n\nThe effect extended beyond tech, impacting any company relying on in-house development and innovation. The article highlights that this policy, aimed at short-term revenue, has inadvertently harmed American competitiveness and economic growth by disincentivizing R&D investment. While there are bipartisan efforts to repeal the change, it may be too late for many already laid off. The article warns that Washington is poised to pass a second Trump tax bill with more obscure provisions, and it comes as analysts are only just beginning to understand the real-world effects of the last round.\n",
    "chinese_title": "引发大规模科技裁员的税法定时炸弹",
    "chinese_summary": "石英财经一篇报道指出，美国税法第174条中一项鲜为人知的变更——深藏于2017年《减税与就业法案》(TCJA)之中——是导致自2023年以来大规模科技裁员的一个关键因素。 近70年来，公司可以立即扣除100%的研发支出，从而激励国内创新。 TCJA大幅降低了公司税率，但也包含一项延迟生效的条款来抵消成本：即对第174条的修改。\n\n从2022年开始，公司不再能够立即将研发费用列为支出； 相反，他们必须在五年到十五年内分期摊销。 这增加了税收负担，减少了现金流，尤其影响了那些依赖研发注销来减少应纳税收入的公司。\n\n该文章将这一变化与Meta、微软、亚马逊、Salesforce等大型科技公司以及规模较小的公司发生的裁员联系起来。 尽管公司公开声称过度招聘和人工智能是原因，但该文章认为，税收变化起到了重要但未被充分重视的作用。 它迫使公司削减员工数量（最大的研发支出）以应对增加的税务责任。\n\n这种影响超出了科技行业，影响了任何依赖内部开发和创新的公司。 该文章强调，这项旨在实现短期收入的政策，通过抑制研发投资，无意中损害了美国的竞争力和经济增长。 尽管两党都在努力废除这一变更，但对于许多已经失业的人来说，可能为时已晚。 该文章警告说，华盛顿正准备通过第二项特朗普税收法案，其中包含更多晦涩的条款，而分析师们才刚刚开始了解上一轮税改的实际影响。"
  },
  {
    "id": "44208283",
    "title": "A tool for burning visible pictures on a compact disc surface",
    "url": "https://github.com/arduinocelentano/cdimage",
    "summary": "This document describes CDImage, a tool for burning visible pictures onto the surface of a compact disc. The project was inspired by earlier attempts by others and builds upon their work, particularly in coordinate conversion. The author created a GUI with visual preview but ultimately abandoned the project in 2008 due to calibration difficulties across different CD brands and types.\n\nNow, the author has revived and shared the code as a tribute to the CD era, porting it to Qt6 and fixing some bugs. Building CDImage requires the Qt 6 library. A Windows binary build is also provided but is not thoroughly tested.\n\nA crucial aspect of the tool is accurate CD geometry, as slight variations significantly impact image calculation. The tool includes parameters for some CD models, and manual input is possible, but calibration is complex and requires experimentation. The process involves generating a large audio track (around 800MB) that encodes the image data, which can then be burned using standard CD burning software in Audio CD mode.\n\nThe document delves into the challenges of calibration, presenting it as a bi-criteria optimization problem requiring expert feedback. The author discusses existing calibration methods, their limitations, and potential improvements using seek time delays or AI-powered image recognition. The author also encourages sharing of new ideas regarding the calibration process. Finally, the document points to further readings including the \"Red Book\" and other projects.\n",
    "chinese_title": "在光盘表面刻录可见图片的工具",
    "chinese_summary": "本文档介绍了CDImage，一个将可见图片刻录到光盘表面的工具。该项目受到早期其他尝试的启发，并基于他们的工作，特别是在坐标转换方面。作者创建了一个带有视觉预览的GUI，但由于不同光盘品牌和类型之间的校准困难，最终在2008年放弃了该项目。\n\n现在，作者重新启动并共享了该代码，以此致敬CD时代，将其移植到Qt6并修复了一些错误。构建CDImage需要Qt 6库。 还提供了一个Windows二进制版本，但未经彻底测试。\n\n该工具的一个关键方面是精确的光盘几何形状，因为细微的变化会显著影响图像计算。该工具包含一些光盘型号的参数，并且可以手动输入，但校准很复杂且需要实验。该过程涉及生成一个大的音频轨道（约800MB），该轨道编码图像数据，然后可以使用标准的CD刻录软件以音频CD模式刻录。\n\n本文档深入探讨了校准的挑战，将其呈现为一个需要专家反馈的双准则优化问题。作者讨论了现有的校准方法、它们的局限性以及使用寻道时间延迟或人工智能图像识别进行潜在改进的方法。作者还鼓励分享有关校准过程的新想法。最后，本文档指向了包括“红皮书”和其他项目的进一步阅读材料。"
  },
  {
    "id": "44209665",
    "title": "If it works, it's not AI: a commercial look at AI startups (1999)",
    "url": "https://dspace.mit.edu/handle/1721.1/80558",
    "summary": "Eve M. Phillips' 1999 MIT thesis, \"If it works, it's not AI: a commercial look at artificial intelligence startups,\" explores the commercial aspects of AI startups. The title itself hints at a central theme: as AI technology matures and becomes practically applicable, it often loses its \"AI\" label and is simply considered standard software or engineering.\n\nThe thesis likely investigates how AI startups navigate the challenges of defining and marketing their products in a landscape where successful AI solutions are often reclassified as something else. It probably examines the difficulty in differentiating true AI innovation from more traditional software solutions and how this impacts funding, market perception, and overall business strategy.\n\nThe research was advised by Patrick Winston and likely delves into real-world examples and case studies of AI startups. The inclusion of a bibliography suggests a thorough exploration of existing literature on AI and its commercial applications. The metadata confirms the thesis was submitted to the Department of Electrical Engineering and Computer Science at MIT. The full printable version being available implies a detailed study with likely both theoretical background and practical examples.\n",
    "chinese_title": "如果有效，那就不是人工智能：人工智能创业公司的商业视角（1999）",
    "chinese_summary": "夏娃·M·菲利普斯1999年麻省理工学院论文《如果有效，就不是人工智能：人工智能创业公司的商业视角》探讨了人工智能创业公司的商业层面。标题本身暗示了一个中心主题：随着人工智能技术成熟并变得实际可行，它通常会失去其“人工智能”的标签，而被简单地视为标准软件或工程。\n\n该论文可能探讨了人工智能创业公司如何在定义和营销其产品方面应对挑战，因为成功的AI解决方案经常被重新归类为其他东西。它可能考察了区分真正的人工智能创新与更传统的软件解决方案的难度，以及这如何影响资金、市场认知和整体商业策略。\n\n该研究由帕特里克·温斯顿指导，可能深入研究了人工智能创业公司的真实案例和案例研究。参考文献的存在表明对人工智能及其商业应用的现有文献进行了彻底的探索。元数据证实该论文已提交给麻省理工学院电气工程与计算机科学系。可打印的完整版本意味着一项详细的研究，可能包括理论背景和实际例子。"
  },
  {
    "id": "44205282",
    "title": "Researchers develop ‘transparent paper’ as alternative to plastics",
    "url": "https://japannews.yomiuri.co.jp/science-nature/technology/20250605-259501/",
    "summary": "Japanese researchers at JAMSTEC have developed a biodegradable \"transparent paper\" from cellulose as a potential replacement for plastics. The paper is made from cellulose powder derived from cotton seed fibers, dissolved in a lithium bromide-water solution, heated into a gel, shaped, and dried. The resulting material is as strong as polycarbonate plastic, allowing for the creation of items like cups and straws.\n\nThe transparency arises from densely packed nanometer-scale fibers that allow light to pass through without diffusion, enabling clear visibility through even thick sheets. The researchers found that the material biodegraded in seawater within four months, even at deep-sea levels, although the process was slower at greater depths due to fewer microbes.\n\nWhile paper packs are currently the most common alternative to plastic containers, consumers often prefer to see the product. Transparent paper solves this problem but will require factories to mass-produce it.\n\nAccording to JAMSTEC, producing the transparent paper would cost about three times as much as ordinary paper, but would reduce CO2 emissions by about half compared to plastic production. An expert noted that, unlike previous transparent papers, this new material has been proven biodegradable in the deep sea.\n",
    "chinese_title": "研究人员开发“透明纸”作为塑料替代品",
    "chinese_summary": "日本海洋研究开发机构（JAMSTEC）的研究人员开发出一种由纤维素制成的可生物降解的“透明纸”，有望取代塑料。这种纸由棉籽纤维提取的纤维素粉末制成，溶解在溴化锂水溶液中，加热成凝胶，塑形并干燥。所得材料强度与聚碳酸酯塑料相当，可用于制造杯子和吸管等物品。\n\n透明度源于致密堆积的纳米级纤维，它们允许光线通过而不发生漫射，从而即使是厚片也能清晰可见。研究人员发现，该材料在海水中四个月内即可生物降解，即使在深海中也是如此，但由于微生物较少，降解过程在较深处较慢。\n\n虽然纸质包装目前是塑料容器最常见的替代品，但消费者通常更喜欢看到产品。透明纸解决了这个问题，但需要工厂进行大规模生产。\n\n据 JAMSTEC 称，生产这种透明纸的成本约为普通纸的三倍，但与塑料生产相比，可以减少约一半的二氧化碳排放。一位专家指出，与之前的透明纸不同，这种新材料已被证明可以在深海中生物降解。"
  },
  {
    "id": "44207503",
    "title": "The FAIR Package Manager: Decentralized WordPress infrastructure",
    "url": "https://joost.blog/path-forward-for-wordpress/",
    "summary": "This article announces FAIR (Federated and Independent Repositories), a new initiative aimed at decentralizing WordPress infrastructure and establishing more accountable governance. Born from concerns about centralized control within the WordPress ecosystem, FAIR is a technical project under the Linux Foundation that aims to provide an alternative distribution layer for WordPress plugins and themes.\n\nThe project arose from several parallel efforts, including the creation of AspirePress, a community-run mirror of WordPress.org repositories, and an open letter from core contributors advocating for governance reform. FAIR leverages existing tools like Composer and Linux package managers to create a user-friendly system for managing WordPress installations.\n\nKey features of FAIR include a decentralized package management system, federation-ready mirrors, support for commercial plugins, and cryptographic signing. It's designed to be compatible with the current WordPress core while removing bottlenecks caused by centralization and offering an independently governed system.\n\nFAIR is not intended to fork WordPress or create a separate platform, but rather to offer a new distribution path. Users will still be able to install WordPress from WordPress.org. However, FAIR provides an option for more control over plugin delivery and a decentralized system. The author emphasizes that FAIR is a contribution toward better infrastructure and governance for WordPress and invites others to join the effort.\n",
    "chinese_title": "公平软件包管理器：去中心化的WordPress基础设施",
    "chinese_summary": "本文宣布“FAIR”（联邦式独立代码库）计划，这是一项旨在分散WordPress基础设施并建立更负责任治理的新举措。FAIR源于对WordPress生态系统中中心化控制的担忧，是由Linux基金会支持的技术项目，旨在为WordPress插件和主题提供替代分发层。\n\n该项目由多个并行工作推动产生，包括创建AspirePress（WordPress.org代码库的社区运营镜像）以及核心贡献者倡导治理改革的公开信。FAIR利用Composer和Linux软件包管理器等现有工具，创建了一个用户友好的WordPress安装管理系统。\n\nFAIR的主要功能包括去中心化的软件包管理系统、支持联邦的镜像、对商业插件的支持以及密码签名。它旨在与当前的WordPress核心兼容，同时消除中心化造成的瓶颈，并提供一个独立管理的系统。\n\nFAIR并非旨在分叉WordPress或创建一个独立的平台，而是提供一种新的分发途径。用户仍然可以从WordPress.org安装WordPress。但是，FAIR提供了一个选项，可以更好地控制插件交付并建立一个去中心化的系统。作者强调，FAIR是对WordPress更好的基础设施和治理的贡献，并邀请其他人加入这项工作。"
  },
  {
    "id": "44210557",
    "title": "After Pornhub left France, this VPN saw a 1,000% surge in signups in 30 minutes",
    "url": "https://mashable.com/article/proton-vpn-pornhub-france",
    "summary": "Following Pornhub's decision to block access in France due to a new age-verification law, Proton VPN reported a massive 1,000% surge in registrations within just 30 minutes. This spike surpasses even the increase seen when TikTok faced a potential ban in the U.S.\n\nPornhub exited France, its second-largest market, rather than comply with the new French law requiring age verification using methods like facial recognition or government IDs. While VPNs are generally used to protect online privacy and circumvent censorship, this incident highlights their use in bypassing geographic restrictions to access content.\n\nProton VPN acknowledges this use, stating that while facilitating access to porn wasn't their original intention, VPNs can be utilized for such purposes. The company also shares concerns about age-verification laws, emphasizing that they impact everyone and could lead to the creation of databases of personal IDs susceptible to misuse. They suggest content controls on personal devices as a more effective and less privacy-invasive solution.\n\nProton VPN, a Swiss-based company founded in 2014, provides a range of privacy-focused services. Their VPN service, launched in 2017, boasts a vast network of over 13,000 servers in 117 countries. The service has received a Mashable Choice Award.\n",
    "chinese_title": "Pornhub离开法国后，该VPN在30分钟内注册量激增1000%",
    "chinese_summary": "鉴于一项新的年龄验证法，Pornhub决定封锁在法国的访问。此后，Proton VPN报告称，仅仅30分钟内注册量激增1000%。这一增长幅度甚至超过了TikTok在美国面临潜在禁令时所见的增幅。\n\nPornhub宁愿退出其第二大市场法国，也不愿遵守法国新的年龄验证法，该法律要求使用面部识别或政府身份证等方法进行年龄验证。虽然VPN通常用于保护在线隐私和规避审查，但此次事件突显了它们在绕过地域限制以访问内容方面的用途。\n\nProton VPN承认了这种用途，并表示虽然促进对色情内容的访问并非其最初的意图，但VPN可以被用于此类目的。该公司还对年龄验证法表示担忧，强调它们会影响到每个人，并可能导致创建易被滥用的个人身份数据库。他们建议在个人设备上进行内容控制，认为这是更有效且侵犯隐私较少的解决方案。\n\nProton VPN是一家总部位于瑞士的公司，成立于2014年，提供一系列以隐私为中心的服务。其VPN服务于2017年推出，拥有庞大的网络，在117个国家/地区拥有超过13,000台服务器。该服务曾获得Mashable Choice Award。"
  },
  {
    "id": "44210441",
    "title": "EFF to the FTC: DMCA Section 1201 Creates Anti-Competitive Regulatory Barriers",
    "url": "https://www.eff.org/deeplinks/2025/06/eff-files-comments-ftc-regarding-reducing-anti-competitive-regulatory-barriers",
    "summary": "The Electronic Frontier Foundation (EFF), in collaboration with Authors Alliance, has urged the Federal Trade Commission (FTC) to recognize Section 1201 of the Digital Millennium Copyright Act (DMCA) and its triennial exemption process as anti-competitive regulations. The EFF argues that Section 1201, designed to prevent circumvention of technological protection measures on copyrighted works, effectively restricts fair use by preventing access to content for legitimate purposes like research, education, and repair.\n\nWhile Congress created a triennial exemption process managed by the Library of Congress as a safety valve, the EFF contends that this process is overly burdensome and time-consuming, acting as a chokepoint instead. This hinders individuals and organizations from exercising their fair use rights, ultimately thwarting the public interest that copyright law is intended to serve.\n\nThe EFF acknowledges the FTC's limited direct control over Congress and the Library of Congress but hopes the FTC's investigation will highlight the negative impact of Section 1201 and the ineffectiveness of the exemption process. The EFF urges the FTC to recommend that Congress either repeal or reform Section 1201. Failing that, the EFF advocates for significant revisions to the Library of Congress's triennial rulemaking process, starting with the 2026 review, to ensure copyright law supports, rather than inhibits, competition and independent innovation.\n",
    "chinese_title": "电子前哨基金会致函联邦贸易委员会：数字千年版权法第1201条制造反竞争监管壁垒",
    "chinese_summary": "电子前哨基金会 (EFF) 与作家联盟合作，已敦促联邦贸易委员会 (FTC) 承认《数字千年版权法案》(DMCA) 第 1201 条及其三年一次的豁免程序属于反竞争法规。EFF 认为，旨在防止规避受版权保护作品技术保护措施的第 1201 条，实际上通过阻止出于研究、教育和维修等合法目的访问内容，从而限制了合理使用。\n\n虽然国会设立了由国会图书馆管理的三年一次的豁免程序作为安全阀，但 EFF 认为该程序过于繁琐和耗时，反而成为了一个瓶颈。这阻碍了个人和组织行使其合理使用权，最终阻碍了版权法旨在服务的公共利益。\n\nEFF 承认联邦贸易委员会对国会和国会图书馆的直接控制有限，但希望联邦贸易委员会的调查能够突出第 1201 条的负面影响以及豁免程序的无效性。EFF 敦促联邦贸易委员会建议国会废除或改革第 1201 条。如果做不到这一点，EFF 倡导对国会图书馆三年一次的规则制定程序进行重大修订，从 2026 年的审查开始，以确保版权法支持而非抑制竞争和独立创新。"
  },
  {
    "id": "44201975",
    "title": "How we decreased GitLab repo backup times from 48 hours to 41 minutes",
    "url": "https://about.gitlab.com/blog/2025/06/05/how-we-decreased-gitlab-repo-backup-times-from-48-hours-to-41-minutes/",
    "summary": "GitLab significantly reduced repository backup times, from 48 hours to 41 minutes, by addressing a Git scalability issue related to reference count. The problem stemmed from a 15-year-old Git function with O(N²) complexity, `object_array_remove_duplicates()`, used during `git bundle create`. This function caused exponential processing time increases as repositories accumulated more references.\n\nGitLab identified the bottleneck using a flame graph and contributed an upstream fix that replaced the nested loops with a map data structure, ensuring only a single copy of each reference is retained for processing. This algorithmic change resulted in a 6x performance improvement in benchmark testing.\n\nThe improved backup times translate to tangible benefits for GitLab customers, including:\n\n*   **Transformed backup strategies:** Enables comprehensive nightly schedules without impacting development workflows.\n*   **Enhanced business continuity:** Minimizes recovery point objectives (RPO), reducing business risk in disaster scenarios.\n*   **Reduced operational overhead:** Lowers server resource consumption and maintenance windows, leading to reduced compute costs.\n*   **Future-proofed infrastructure:** Allows backup strategies to scale seamlessly alongside growing codebases.\n\nThis fix is available to all GitLab customers (regardless of license tier) since version 18.0. GitLab emphasizes its ongoing commitment to scalable Git infrastructure and collaboration with the broader Git community.\n",
    "chinese_title": "我们如何将 GitLab 仓库备份时间从 48 小时缩短至 41 分钟",
    "chinese_summary": "GitLab通过解决与引用计数相关的Git扩展性问题，将代码仓库备份时间从48小时大幅缩短至41分钟。问题源于一个已有15年历史的Git函数 `object_array_remove_duplicates()`，该函数在`git bundle create`过程中使用，复杂度为O(N²)。随着代码仓库积累的引用越来越多，该函数导致处理时间呈指数级增长。\n\nGitLab使用火焰图识别出瓶颈，并贡献了一个上游修复方案，用映射数据结构替换了嵌套循环，确保只保留每个引用的单个副本进行处理。这种算法上的改变使基准测试性能提高了6倍。\n\n备份时间的改进为GitLab客户带来了切实的利益，包括：\n\n*   **转变备份策略：** 使全面的夜间计划成为可能，而不会影响开发工作流程。\n*   **增强业务连续性：** 最大限度地减少恢复点目标（RPO），降低灾难情况下的业务风险。\n*   **降低运营成本：** 降低服务器资源消耗和维护窗口，从而降低计算成本。\n*   **面向未来的基础设施：** 允许备份策略随着不断增长的代码库无缝扩展。\n\n自18.0版本起，所有GitLab客户（无论许可证级别）均可使用此修复程序。GitLab强调其对可扩展Git基础设施的持续承诺以及与更广泛的Git社区的合作。"
  },
  {
    "id": "44207095",
    "title": "Getting Past Procrastination",
    "url": "https://spectrum.ieee.org/getting-past-procastination",
    "summary": "This article, \"Getting Past Procrastination,\" is written by Rahul Pandey, founder of Taro, a career platform for tech professionals. The article likely offers strategies and systems designed to help readers overcome procrastination and become more consistently productive. Given Pandey's background in the tech industry, the advice may be particularly relevant to those in technical roles.\n\nKey takeaways will probably include actionable tips for creating structure and routines to minimize procrastination. These might involve setting clear goals, breaking down large tasks into smaller, more manageable steps, and establishing deadlines. The article is likely to emphasize the importance of consistent productivity over sporadic bursts of work. Because it's a short article (3-minute read), it's probably a targeted and concise guide focusing on practical techniques for immediate implementation.\n",
    "chinese_title": "克服拖延症",
    "chinese_summary": "文章《克服拖延症》由Taro创始人Rahul Pandey撰写，Taro是一个面向科技专业人士的职业平台。文章可能提供了旨在帮助读者克服拖延症并提高工作效率的策略和系统。鉴于Pandey在科技行业的背景，该建议可能对技术岗位的人员尤其有帮助。\n\n主要内容可能包括制定结构和常规以尽量减少拖延症的可行性建议，例如设定明确的目标、将大型任务分解为更小更易于管理的步骤，以及设定截止日期。文章可能强调持续高效的重要性，而非偶尔的爆发式工作。因为这是一篇短文（阅读时间3分钟），所以它可能是一个有针对性且简洁的指南，侧重于可以立即实施的实用技巧。"
  },
  {
    "id": "44206553",
    "title": "Why are smokestacks so tall?",
    "url": "https://practical.engineering/blog/2025/6/3/why-are-smokestacks-so-tall",
    "summary": "This article, \"Why are smokestacks so tall?\" explores the engineering behind smokestacks and their purpose in air pollution management. It begins by highlighting that while eliminating emissions entirely is ideal, it's currently not feasible, so managing their impact is crucial.\n\nThe core function of smokestacks is to disperse pollutants to a safe concentration level locally. While primary emission controls remove pollutants, smokestacks aid in dispersion. The height of a stack leverages the \"stack effect\": hotter, less dense air inside rises, creating a pressure difference that drives upward airflow. This allows pollutants to reach higher altitudes for better dispersion. Increasing stack height and temperature helps with this effect, but thermodynamics and other practical limits, such as gas cooling and frictional drag, can reduce the benefit of taller stack heights.\n\nWhile early smokestacks increased airflow for efficient combustion, environmental regulations now prioritize air quality. Plume behavior is complex, influenced by factors like wind, atmospheric stability, and surrounding structures. Atmospheric stability, determined by the adiabatic lapse rate compared to the actual environment, dramatically affects plume shape, leading to coning, looping, fanning, trapping, lofting, and fumigating plumes. Understanding and predicting plume behavior involves considering advection (wind transport) and diffusion (turbulent spread), requiring intricate models to ensure regulatory standards for air pollutants are met.\n",
    "chinese_title": "烟囱为什么要那么高？",
    "chinese_summary": "为什么烟囱这么高？\n\n本文探讨了烟囱背后的工程原理及其在空气污染管理中的作用。文章首先强调，虽然完全消除排放是理想的，但目前尚不可行，因此管理其影响至关重要。\n\n烟囱的核心功能是将污染物扩散到局部安全浓度水平。虽然主要的排放控制措施可以去除污染物，但烟囱有助于扩散。烟囱的高度利用了“烟囱效应”：内部较热、密度较低的空气上升，产生压力差，从而驱动向上气流。这使得污染物能够到达更高的高度，以便更好地扩散。增加烟囱高度和温度有助于这种效应，但热力学和其他实际限制，如气体冷却和摩擦阻力，会降低更高烟囱高度带来的益处。\n\n早期烟囱旨在增加气流以实现高效燃烧，而现在的环境法规则优先考虑空气质量。烟羽行为复杂，受风、大气稳定性和周围建筑物等因素的影响。大气稳定性由绝热递减率与实际环境的比较决定，它会显著影响烟羽形状，导致锥形、环状、扇形、滞留、抬升和熏蒸烟羽。理解和预测烟羽行为需要考虑平流（风力输送）和扩散（湍流扩散），需要复杂的模型来确保符合空气污染物监管标准。"
  },
  {
    "id": "44204224",
    "title": "A year of funded FreeBSD development",
    "url": "https://www.daemonology.net/blog/2025-06-06-A-year-of-funded-FreeBSD.html",
    "summary": "This article details the author's year of funded FreeBSD development, primarily focusing on FreeBSD releases and enhancements for the Amazon EC2 platform, sponsored by Amazon via GitHub Sponsors. The sponsorship, aimed at 40 hours/month, actually resulted in around 50 hours/month, split between EC2-specific tasks, FreeBSD release management, and related engineering work.\n\nKey achievements included managing four FreeBSD releases (13.4, 14.2, 13.5, and 14.3), developing a \"power driver\" for graceful shutdowns on AWS Graviton instances, and resolving numerous hotplug issues on various EC2 instance types. These fixes required ACPI quirks to address EC2 bugs and inconsistencies between FreeBSD and EC2 firmware.\n\nBeyond Amazon's priorities, the author addressed long boot times on EC2 instances. This involved increasing the root disk size, improving kernel entropy seeding on Graviton 2 instances, and resolving an interaction between `makefs` and ZFS leading to slow boot times for ZFS images. A problem with IPv6 support in the `aws-ec2-imdsv2-get` port was quickly identified and fixed, improving boot times. Finally, \"small\" AMIs were added, reducing disk space usage significantly. A test script was also created to automate hotplug testing, ensuring future compatibility.\n",
    "chinese_title": "一年资助的FreeBSD开发",
    "chinese_summary": "本文详细介绍了作者在亚马逊通过 GitHub Sponsors 资助下，为期一年的 FreeBSD 开发工作，主要集中在 FreeBSD 版本的发布以及对 Amazon EC2 平台的增强。该赞助原计划为每月 40 小时，但实际上达到了每月约 50 小时，这些时间分配在 EC2 相关的任务、FreeBSD 版本管理以及相关的工程工作上。\n\n主要成就包括管理了四个 FreeBSD 版本（13.4、14.2、13.5 和 14.3），开发了一个用于在 AWS Graviton 实例上实现优雅关机的“电源驱动程序”，并解决了各种 EC2 实例类型上的许多热插拔问题。 这些修复程序需要 ACPI quirks 来解决 EC2 的错误以及 FreeBSD 和 EC2 固件之间的不一致性。\n\n除了亚马逊的优先事项之外，作者还解决了 EC2 实例上的启动时间过长的问题。这包括增加根磁盘大小，改进 Graviton 2 实例上的内核熵种子，以及解决 `makefs` 和 ZFS 之间的交互导致 ZFS 镜像启动缓慢的问题。`aws-ec2-imdsv2-get` 端口中的 IPv6 支持问题被迅速发现并修复，从而缩短了启动时间。最后，添加了“小型” AMI，从而显着减少了磁盘空间的使用。还创建了一个测试脚本来自动化热插拔测试，以确保未来的兼容性。"
  },
  {
    "id": "44210614",
    "title": "Why Pandas feels clunky when coming from R (2024)",
    "url": "https://www.sumsar.net/blog/pandas-feels-clunky-when-coming-from-r/",
    "summary": "Rasmus Bååth, a long-time R user, discusses why pandas in Python feels clunky compared to the tidyverse in R, even after five years of using it daily. He argues it's difficult to explain these frustrations to \"Python people\" who see pandas as a fantastic data science tool.\n\nThe article presents a step-by-step analysis of a simple purchase dataset to illustrate the differences. In R, the analysis is concise and straightforward, allowing for incremental development using the tidyverse's intuitive pipeline. In contrast, the pandas implementation requires more verbose code, dealing with issues like column names, index manipulation, and different method behaviors for grouped and ungrouped data.\n\nThe author highlights the following specific pain points:\n\n*   **Inconsistent API:** Method names and arguments are confusing (e.g., `.filter()` doesn't filter values).\n*   **Different behavior:** Grouped and ungrouped DataFrames have different available methods, even when the method names are the same.\n*   **Missing convenience functions:** Simple operations in tidyverse require more complex code in pandas.\n*   **Index manipulation:** Pandas frequently moves columns into the index, requiring frequent use of `.reset_index()`.\n\nBååth concludes that while pandas is a powerful tool, these inconsistencies and lack of convenience functions contribute to a clunky user experience for those accustomed to R's tidyverse. He encourages \"Python people\" to be compassionate towards R users transitioning to pandas and acknowledges that these API issues persist in larger, real-world projects.\n",
    "chinese_title": "为什么从R转到Pandas会觉得笨拙 (2024)",
    "chinese_summary": "一位资深的R用户Rasmus Bååth讨论了为什么即使在每天使用五年后，Python中的pandas与R中的tidyverse相比仍然感觉笨拙。他认为向那些视pandas为出色的数据科学工具的“Python人”解释这些挫折感是很困难的。\n\n文章通过一个简单的购买数据集的逐步分析来说明这些差异。在R中，分析简洁明了，可以使用tidyverse直观的管道进行增量开发。相比之下，pandas的实现需要更冗长的代码，处理诸如列名、索引操作以及分组和未分组数据的不同方法行为等问题。\n\n作者强调了以下具体痛点：\n\n*   **API不一致：** 方法名称和参数令人困惑（例如，`.filter()` 不会过滤值）。\n*   **行为不同：** 分组和未分组的DataFrames具有不同的可用方法，即使方法名称相同。\n*   **缺少便捷函数：** tidyverse中的简单操作在pandas中需要更复杂的代码。\n*   **索引操作：** Pandas经常将列移动到索引中，需要经常使用`.reset_index()`。\n\nBååth总结说，虽然pandas是一个强大的工具，但这些不一致和缺乏便捷函数会导致习惯于R的tidyverse的用户体验笨拙。他鼓励“Python人”对过渡到pandas的R用户表示同情，并承认这些API问题在更大、更真实的项目中仍然存在。"
  },
  {
    "id": "44201527",
    "title": "Sharing everything I could understand about gradient noise",
    "url": "https://blog.pkh.me/p/42-sharing-everything-i-could-understand-about-gradient-noise.html",
    "summary": "This article provides a comprehensive, GPU-focused explanation of gradient noise, starting with the 1D version and progressing to 2D and 3D implementations. It emphasizes understanding the underlying mathematics and practical implementation details, often overlooked in other resources.\n\nThe author begins by explaining the necessity of a deterministic, coordinate-based pseudo-random system, specifically integer hashing, to generate random values for each lattice point. They highlight the \"lowbias32\" hashing function by Chris Wellons and its adaptation for normalized floats in GLSL.\n\nThe article then explores the creation of 1D value noise, using linear and quintic interpolation techniques.  It transitions to 1D gradient noise, interpreting random values as slopes or angles impacting the signal.  Expanding to 2D and 3D, the explanation covers the computation of dot products between gradient vectors and lattice corner vectors, utilizing bilinear and trilinear interpolation, along with proper methods for generating random unit vectors distributed evenly on a circle (2D) and sphere (3D).\n\nFinally, the article discusses Fractal Brownian Motion (fBm), which involves summing multiple octaves of noise to create more refined patterns. It concludes by highlighting the utility of derivatives (rate of change) in various applications, such as generating normals for lighting and simulating erosion in terrain generation. All concepts are illustrated with GLSL code snippets and visual examples, emphasizing practical GPU-based implementation.\n",
    "chinese_title": "我所理解的梯度噪声分享",
    "chinese_summary": "本文全面地从GPU角度解释了梯度噪声，从一维版本入手，逐步深入到二维和三维的实现。它强调对底层数学原理和实际实现细节的理解，这些内容在其他资源中往往被忽视。\n\n作者首先解释了确定性的、基于坐标的伪随机系统的必要性，特别是整数哈希，以便为每个晶格点生成随机值。他们重点介绍了Chris Wellons的“lowbias32”哈希函数及其在GLSL中针对归一化浮点数的适配。\n\n文章随后探讨了一维值噪声的创建，使用线性和五次插值技术。它过渡到一维梯度噪声，将随机值解释为影响信号的斜率或角度。扩展到二维和三维后，解释涵盖了梯度向量和晶格角向量之间点积的计算，利用双线性插值和三线性插值，以及用于生成均匀分布在圆（二维）和球体（三维）上的随机单位向量的正确方法。\n\n最后，文章讨论了分形布朗运动（fBm），它涉及对多个倍频程的噪声进行求和，以创建更精细的模式。最后，它强调了导数（变化率）在各种应用中的实用性，例如生成用于光照的法线以及模拟地形生成中的侵蚀。所有概念均通过GLSL代码片段和视觉示例进行说明，强调基于GPU的实际实现。"
  },
  {
    "id": "44203562",
    "title": "The Illusion of Thinking: Understanding the Limitations of Reasoning LLMs [pdf]",
    "url": "https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf",
    "summary": "This document, titled \"The Illusion of Thinking: Understanding the Limitations of Reasoning LLMs,\" is a PDF file, although its content is primarily machine-readable code and compressed text. From the title and the snippets of decipherable text, we can infer the subject matter. The article likely discusses the limitations of large language models (LLMs) in truly \"thinking\" or reasoning.\n\nThe presence of PDF structure elements suggests the document contains page layouts, outlines, annotations, and potentially interactive elements. However, the gibberish character of the decompressed text points towards proprietary or specialized content, that can't be easily parsed with readily available tools.\n\nGiven the title, one can expect that the authors will examine and critique the capabilities of LLMs, arguing they might simulate intelligence and reasoning without genuinely possessing these qualities. The document likely analyzes how LLMs process information, identify patterns, generate text, and solve problems, while pointing out deficiencies compared to human cognitive processes. It might discuss issues such as a lack of common sense, difficulty with abstract reasoning, susceptibility to biases, and the inability to truly understand meaning and context. In conclusion, the study likely warns against overestimating the capabilities of LLMs and advocates for a more nuanced understanding of their limitations.\n",
    "chinese_title": "思考的错觉：理解推理LLM的局限性 [pdf]",
    "chinese_summary": "名为“思考的幻觉：理解推理型LLM的局限性”的这份文档，是一个PDF文件，尽管其内容主要是机器可读的代码和压缩文本。从标题和可辨认的文本片段中，我们可以推断出其主题。该文章可能讨论大型语言模型（LLM）在真正“思考”或推理方面的局限性。\n\nPDF结构元素的存在表明该文档包含页面布局、大纲、注释以及潜在的交互元素。然而，解压缩文本的乱码性质表明其内容是专有或专业的，无法使用现成的工具轻松解析。\n\n根据标题，可以预见作者将考察和批判LLM的能力，论证它们可能模拟了智能和推理，但并未真正拥有这些特质。该文档可能分析LLM如何处理信息、识别模式、生成文本和解决问题，同时指出与人类认知过程相比存在的不足。它可能会讨论诸如缺乏常识、难以进行抽象推理、容易受到偏见影响以及无法真正理解意义和上下文等问题。总而言之，该研究可能警告不要高估LLM的能力，并倡导对它们的局限性进行更细致的理解。"
  },
  {
    "id": "44210390",
    "title": "Asimov and the Disease of Boredom (1964)",
    "url": "https://archive.nytimes.com/www.nytimes.com/books/97/03/23/lifetimes/asi-v-fair.html",
    "summary": "In his 1964 essay, Isaac Asimov envisions the world of 2014, inspired by the New York World's Fair. He foresees a future of technological advancements, including electroluminescent homes, underground cities, and \"automeals\" prepared by automated kitchen units. Robots, though not commonplace, will exist, performing household tasks. Power will be generated by radioisotope batteries and fusion plants, with solar power stations in desert regions.\n\nTransportation will evolve, with air-cushioned vehicles replacing cars and moving sidewalks in urban areas. Communication will be instantaneous and visual, facilitated by satellites, allowing direct-dialing to anywhere on Earth, including lunar colonies.\n\nHowever, Asimov acknowledges challenges. Population growth is a major concern, predicting a global population of 6.5 billion and a highly urbanized Boston-to-Washington corridor. He anticipates underwater colonization and the development of algae-based food sources to cope with resource constraints. Birth control will be heavily promoted, though perhaps insufficiently effective.\n\nAutomation will lead to a society of machine tenders, requiring a shift in education towards computer technology. Asimov warns of widespread boredom due to the lack of meaningful work, making psychiatry a crucial medical field. He concludes that those engaged in creative endeavors will be the \"true elite\" of this future world.\n",
    "chinese_title": "阿西莫夫与无聊之疾 (1964)",
    "chinese_summary": "在1964年的文章中，艾萨克·阿西莫夫受纽约世界博览会启发，设想了2014年的世界。他预见到一个科技进步的未来，包括电致发光住宅、地下城市和由自动化厨房单元制作的“自动餐”。机器人虽然不普遍，但将存在，执行家务。电力将由放射性同位素电池和核聚变发电厂产生，沙漠地区将建有太阳能发电站。\n\n交通运输将会发展，气垫车辆将取代汽车，城市地区将出现自动人行道。通讯将是即时和可视的，由卫星促进，允许直接拨打地球上任何地方的电话，包括月球殖民地。\n\n然而，阿西莫夫也承认挑战。人口增长是一个主要问题，他预测全球人口将达到65亿，并且波士顿到华盛顿之间将出现高度城市化的走廊。他预计水下殖民地的出现和基于藻类的食物来源的发展，以应对资源限制。节育将受到大力推广，但可能效果不足。\n\n自动化将导致一个机器照看者的社会，需要教育向计算机技术转型。阿西莫夫警告说，由于缺乏有意义的工作，将会出现普遍的厌倦感，使得精神病学成为一个至关重要的医学领域。他总结说，从事创造性事业的人将是这个未来世界的“真正精英”。"
  },
  {
    "id": "44207063",
    "title": "Reverse Engineering Cursor's LLM Client",
    "url": "https://www.tensorzero.com/blog/reverse-engineering-cursors-llm-client/",
    "summary": "This article details how the authors used their open-source framework, TensorZero, to reverse engineer Cursor's LLM client, allowing them to observe, analyze, and experiment with the LLM requests Cursor makes. They aimed to gain insight into Cursor's inner workings and potentially optimize it for individual users.\n\nThe process involved setting up TensorZero as a self-hosted proxy between Cursor and the LLM providers. This was complicated by Cursor's initial inability to connect to localhost and subsequent CORS issues, which were overcome using Ngrok, Nginx, and specific Nginx configurations.\n\nOnce successful, they gained full observability into Cursor's prompts, including the system and user prompts. They found that Cursor uses a relatively short system prompt to guide the LLM and uncovered an explicit hierarchy where a \"less intelligent\" model is used to apply code edits suggested by the main LLM.\n\nThe authors are now A/B testing different LLMs (Claude, GPT-4, o4 Mini, and Gemini) to see which performs best within the Cursor environment. They report stable performance and no noticeable latency. The article concludes by teasing a follow-up post that will detail their methods for evaluating real-world usage and optimizing models based on individual user patterns, including techniques using git hooks and tree-sitter. The goal is to demonstrate how TensorZero can improve pre-built LLM agents through personalized optimization.\n",
    "chinese_title": "逆向工程 Cursor 的 LLM 客户端",
    "chinese_summary": "本文详细介绍了作者如何使用他们的开源框架 TensorZero 来逆向工程 Cursor 的 LLM 客户端，从而观察、分析和实验 Cursor 发出的 LLM 请求。他们的目的是深入了解 Cursor 的内部运作，并有可能针对个体用户对其进行优化。\n\n该过程涉及将 TensorZero 设置为 Cursor 和 LLM 提供商之间的自托管代理。由于 Cursor 最初无法连接到 localhost 以及随后的 CORS 问题，这变得很复杂，这些问题通过使用 Ngrok、Nginx 和特定的 Nginx 配置得以克服。\n\n成功后，他们获得了对 Cursor 提示的完全可观察性，包括系统提示和用户提示。他们发现 Cursor 使用相对较短的系统提示来指导 LLM，并揭示了一个明确的层次结构，其中使用“智能较低”的模型来应用主 LLM 建议的代码编辑。\n\n作者现在正在对不同的 LLM（Claude、GPT-4、o4 Mini 和 Gemini）进行 A/B 测试，以了解哪一个在 Cursor 环境中表现最佳。他们报告了稳定的性能，并且没有明显的延迟。文章最后预告了后续文章，该文章将详细介绍他们评估实际使用情况并根据个人用户模式优化模型的方法，包括使用 git hooks 和 tree-sitter 的技术。目标是演示 TensorZero 如何通过个性化优化改进预构建的 LLM 代理。"
  },
  {
    "id": "44205599",
    "title": "Medieval Africans had a unique process for purifying gold with glass (2019)",
    "url": "https://www.atlasobscura.com/articles/medieval-african-gold",
    "summary": "This article discusses a unique gold purification process used in medieval West Africa, specifically in Tadmekka, Mali, around the 11th century. Archaeologist Sam Nixon's discovery of coin mold fragments and glass shards sparked an investigation into this innovative technique.\n\nUnlike the European cupellation method using lead, medieval Africans mixed gold ore with recycled glass. The gold, being inert, didn't dissolve in the melted glass, while impurities from the ore did. This allowed for a relatively pure gold residue to be extracted after the melting process.\n\nMarc Walton and his team at the Center for Scientific Studies in the Arts recreated this process using modern materials, substituting local resources for those available to the Malians. They mixed gold dust with Lake Michigan sand and synthetic glass, heating the mixture to dissolve the sand's minerals and leaving behind purified gold.\n\nThe results of the recreation confirmed the sophistication and ingenuity of the medieval Malian gold purification technique, highlighting their understanding of the properties of both gold and glass. The use of recycled glass also points to the industriousness and creativity of the artisans in utilizing available resources within a bustling trade center.\n",
    "chinese_title": "中世纪非洲人用玻璃提纯黄金的独特工艺 (2019)",
    "chinese_summary": "本文探讨了中世纪西非，特别是约11世纪马里Tadmekka地区使用的一种独特的黄金提纯工艺。考古学家萨姆·尼克松发现的铸币模具碎片和玻璃碎片引发了对这项创新技术的调查。\n\n与欧洲使用铅的灰吹法不同，中世纪的非洲人将金矿石与回收的玻璃混合。金的性质稳定，不会溶解在熔融的玻璃中，而矿石中的杂质则会溶解。这使得在熔炼过程后可以提取出相对纯净的黄金残留物。\n\n马克·沃尔顿及其在艺术科学研究中心的团队使用现代材料重现了这一过程，用当地资源替代了马里人可用的资源。他们将金粉与密歇根湖的沙子和合成玻璃混合，加热混合物以溶解沙子中的矿物质，从而留下提纯的黄金。\n\n重现的结果证实了中世纪马里黄金提纯技术的精妙和独创性，突显了他们对黄金和玻璃性能的理解。回收玻璃的使用也表明了工匠们在繁华的贸易中心利用现有资源的勤劳和创造力。"
  },
  {
    "id": "44204155",
    "title": "Highly efficient matrix transpose in Mojo",
    "url": "https://veitner.bearblog.dev/highly-efficient-matrix-transpose-in-mojo/",
    "summary": "This blog post details how to implement a highly efficient matrix transpose kernel in Mojo, achieving performance comparable to hand-optimized CUDA. The author focuses on leveraging the Hopper architecture's capabilities, specifically using Tensor Memory Accelerator (TMA).\n\nThe post starts with a naive transpose implementation using TMA, achieving a bandwidth of 1056.08 GB/s, already exceeding a comparable CUDA implementation (875.46 GB/s). This initial improvement is attributed to the use of the PTX API for TMA transfers in Mojo.\n\nNext, the author introduces swizzling as an optimization technique. Swizzling involves adjusting the memory access pattern to improve coalescing and memory utilization. Implementing swizzling in Mojo requires adjusting the TMA descriptors and using swizzled indices within the kernel. This approach achieves a bandwidth of 1437.55 GB/s in Mojo, compared to 1251.76 GB/s in CUDA.\n\nThe most significant performance boost comes from thread coarsening (processing a batch of columns per thread). By having each thread handle multiple columns, the kernel achieves a bandwidth of 2775.49 GB/s, closely matching the 2771.35 GB/s achieved with a highly optimized CUDA kernel on the same hardware. This highlights Mojo's ability to achieve CUDA-like performance.\n\nThe post concludes that Mojo can be used for high-performance GPU computing. The complete code is available on the author's GitHub.\n",
    "chinese_title": "Mojo 中的高效矩阵转置",
    "chinese_summary": "这篇博文详细介绍了如何在Mojo中实现高效的矩阵转置内核，达到与手工优化的CUDA相媲美的性能。作者专注于利用Hopper架构的功能，特别是使用张量内存加速器 (TMA)。\n\n文章首先介绍了一种使用TMA的简单转置实现，实现了1056.08 GB/s的带宽，已经超过了可比的CUDA实现 (875.46 GB/s)。最初的改进归功于在Mojo中使用PTX API进行TMA传输。\n\n接下来，作者介绍了混洗（swizzling）作为一种优化技术。混洗涉及调整内存访问模式以提高合并和内存利用率。在Mojo中实现混洗需要调整TMA描述符并在内核中使用混洗索引。这种方法在Mojo中实现了1437.55 GB/s的带宽，而CUDA中为1251.76 GB/s。\n\n最大的性能提升来自线程粗化（每个线程处理一批列）。通过让每个线程处理多个列，内核实现了2775.49 GB/s的带宽，与在同一硬件上使用高度优化的CUDA内核实现的2771.35 GB/s非常接近。 这突显了Mojo实现类似CUDA性能的能力。\n\n文章总结说，Mojo可用于高性能GPU计算。完整的代码可在作者的GitHub上找到。"
  },
  {
    "id": "44205590",
    "title": "Falsehoods programmers believe about aviation",
    "url": "https://flightaware.engineering/falsehoods-programmers-believe-about-aviation/",
    "summary": "This article, \"Falsehoods Programmers Believe About Aviation,\" highlights the many incorrect assumptions software engineers might make when working with aviation data. The author, a Senior Software Engineer at FlightAware, emphasizes that real-world aviation data is often messy and non-standardized, despite the desire for clean and consistent information.\n\nThe article then systematically debunks various common misconceptions about flights, airports, airlines, navigation, and transponders. Examples include assuming flights always depart from gates, adhere to their schedules, or have a consistent flight number. It also addresses inaccurate assumptions about airports, such as unique identifier codes or consistent naming schemes. Furthermore, the piece challenges beliefs about airlines, such as the idea that an airline always operates flights with its assigned code.\n\nThe article also tackles issues related to navigation data, including the reliability of altitude readings and the accuracy of radar data. It then delves into the complexities of ADS-B and transponder data, challenging the idea that these systems always provide accurate GPS positions, correct flight identification, or are free from malfunctions and manipulation.\n\nIn essence, the article serves as a cautionary guide for developers, demonstrating the need for robust software design that can handle the unpredictable nature of aviation data and avoid common pitfalls. The author acknowledges contributions from colleagues in compiling and reviewing this list of falsehoods.\n",
    "chinese_title": "程序员对航空的常见误解",
    "chinese_summary": "程序员关于航空的常见谬误"
  },
  {
    "id": "44201812",
    "title": "Sandia turns on brain-like storage-free supercomputer",
    "url": "https://blocksandfiles.com/2025/06/06/sandia-turns-on-brain-like-storage-free-supercomputer/",
    "summary": "Sandia National Labs has launched its SpiNNaker 2 supercomputer, a \"brain-inspired\" system that forgoes GPUs and internal storage in favor of a unique neuromorphic architecture. Developed in collaboration with SpiNNcloud, the system is designed to mimic between 150 and 180 million neurons, placing it among the top neuromorphic platforms globally.\n\nThe SpiNNaker 2 architecture, initially conceived by Arm pioneer Steve Furber, utilizes highly parallel processing with 48 SpiNNaker 2 chips per server board, each chip containing 152 cores and specialized accelerators. Each chip has 20 MB of SRAM and each board has 96 GB of external LPDDR4 external memory. The machine achieves high-speed chip-to-chip communication and leverages its vast memory capacity to eliminate the need for centralized storage.\n\nSandia's initial setup consists of a 24-board, 175,000-core system integrated with existing HPC infrastructure, operating without an OS or disks. The system's speed stems from its ability to keep data within SRAM and DRAM. SpiNNcloud says it's maximum system has over 10.5 million cores.\n\nAccording to SpiNNcloud, the neuromorphic design provides power efficiency advantages over GPU systems, making it suitable for computationally intensive applications like those in national security. SpiNNcloud CEO Hector A. Gonzalez envisions the SpiNNaker 2 addressing next-generation defense challenges and beyond.\n",
    "chinese_title": "桑迪亚启动类脑无存储超级计算机",
    "chinese_summary": "桑迪亚国家实验室推出SpiNNaker 2超级计算机，一种“大脑启发”系统，放弃GPU和内部存储，采用独特的神经形态架构。该系统与SpiNNcloud合作开发，旨在模拟1.5亿至1.8亿个神经元，使其跻身全球顶级神经形态平台之列。\n\nSpiNNaker 2架构最初由Arm先驱Steve Furber构思，采用高度并行处理，每个服务器板配备48个SpiNNaker 2芯片，每个芯片包含152个核心和专用加速器。每个芯片具有20MB的SRAM，每个板具有96GB的外部LPDDR4外部存储器。该机器实现了高速芯片间通信，并利用其庞大的内存容量消除了对集中式存储的需求。\n\n桑迪亚的初始设置包括一个24板、175,000核的系统，该系统与现有的HPC基础设施集成，在没有操作系统或磁盘的情况下运行。该系统的速度源于其将数据保存在SRAM和DRAM中的能力。SpiNNcloud表示，其最大系统拥有超过1050万个核心。\n\n据SpiNNcloud称，神经形态设计比GPU系统具有更高的功率效率优势，使其适用于国家安全等计算密集型应用。SpiNNcloud首席执行官Hector A. Gonzalez设想SpiNNaker 2能够应对下一代国防挑战及其他领域。"
  },
  {
    "id": "44200895",
    "title": "A masochist's guide to web development",
    "url": "https://sebastiano.tronto.net/blog/2025-06-06-webdev/",
    "summary": "This article guides C/C++ developers on using Emscripten to port their code to WebAssembly (WASM) for web applications. It starts with a basic \"Hello, web!\" example, demonstrating how to compile C code to WASM and run it in a browser.\n\nThe author then addresses building a C library for use in JavaScript, covering the essential steps of exporting functions using `-sEXPORTED_FUNCTIONS` and handling asynchronous runtime initialization with `onRuntimeInitialized`. Overcoming the initial pitfalls, a simple multiplication library is successfully built and executed.\n\nThe article includes two intermezzos: the first on WebAssembly technology, its origins, text-based representation, and future evolution with WASM64; and the second on JavaScript and the DOM (Document Object Model), explaining how to interact with HTML elements from JavaScript using functions like `document.getElementById()` and event listeners. A demonstration of a dynamic button, and how it looks with the event listener.\n\nThe guide culminates in creating a basic HTML page with JavaScript to interact with the eventual WASM library. The HTML code includes input fields and a button. For now the JS code is using the * operator.\n        \n",
    "chinese_title": "网络开发受虐指南",
    "chinese_summary": "本文指导 C/C++ 开发者使用 Emscripten 将他们的代码移植到 WebAssembly (WASM) 用于 Web 应用程序。 它从一个基本的 \"Hello, web!\" 示例开始，演示了如何将 C 代码编译成 WASM 并在浏览器中运行。\n\n然后，作者介绍了构建一个 C 库以在 JavaScript 中使用，涵盖了使用 `-sEXPORTED_FUNCTIONS` 导出函数以及使用 `onRuntimeInitialized` 处理异步运行时初始化的基本步骤。 克服最初的陷阱后，成功构建并执行了一个简单的乘法库。\n\n本文包含两个间奏：第一个关于 WebAssembly 技术，它的起源、基于文本的表示以及 WASM64 的未来发展；第二个关于 JavaScript 和 DOM（文档对象模型），解释了如何使用 `document.getElementById()` 和事件监听器等函数从 JavaScript 与 HTML 元素交互。 演示了一个动态按钮，以及它在事件监听器下的外观。\n\n本指南最终创建了一个基本的 HTML 页面，其中包含 JavaScript 来与最终的 WASM 库进行交互。 HTML 代码包括输入字段和一个按钮。 目前 JS 代码使用的是 * 运算符。"
  },
  {
    "id": "44204181",
    "title": "Show HN: AI game animation sprite generator",
    "url": "https://www.godmodeai.cloud/ai-sprite-generator",
    "summary": "God Mode AI is presented as a powerful AI sprite generator designed to help game developers create professional game animation sprites from images or text descriptions. Users upload character designs and the AI generates production-ready animations for various actions like jumping, running, punching, and special attacks, complete with transparent backgrounds, center offsets, and bounding boxes.\n\nThe tool targets indie developers, game studios, and artists, offering cost and time savings by automating sprite creation. It supports multiple styles from pixel art to anime. A key new feature is the ability to train custom action models with as few as five animation samples, allowing users to create personalized animations for unique game mechanics. These custom models can be kept private or shared publicly for revenue.\n\nThe service operates on a credit system, where one credit equals one sprite generation. Users can purchase credit packs, and credits never expire. Several pre-set credit bundles are available. The platform offers a free tier with initial credits and also offers free model training, with both standard and custom action options.\n\nFor enterprise and game studios, God Mode AI offers custom AI solutions, including tailored AI models and dedicated support to supercharge game development and significantly increase productivity. A FAQ section addresses common user queries, such as supported file formats, output formats, commercial usage rights, and generation time.\n",
    "chinese_title": "展示一下：AI游戏动画精灵生成器",
    "chinese_summary": "上帝模式AI：一款强大的AI精灵生成器，旨在帮助游戏开发者从图像或文本描述中创建专业的游戏动画精灵。用户上传角色设计，AI即可生成可用于生产的动画，包含跳跃、跑步、拳击和特殊攻击等各种动作，并配有透明背景、中心偏移和边界框。\n\n该工具面向独立开发者、游戏工作室和艺术家，通过自动化精灵创建来节省成本和时间。它支持从像素艺术到动漫的多种风格。一项关键的新功能是能够使用最少五个动画样本来训练自定义动作模型，允许用户为独特的游戏机制创建个性化动画。这些自定义模型可以保持私有或公开分享以获取收入。\n\n该服务采用积分系统，一个积分等于一个精灵生成。用户可以购买积分包，积分永不过期。提供多个预设积分包。该平台提供包含初始积分的免费层级，还提供免费的模型训练，包含标准和自定义动作选项。\n\n对于企业和游戏工作室，上帝模式AI提供定制AI解决方案，包括量身定制的AI模型和专门的支持，以加速游戏开发并显著提高生产力。常见问题解答部分解决了常见的用户问题，例如支持的文件格式、输出格式、商业使用权和生成时间。"
  },
  {
    "id": "44200866",
    "title": "Odyc.js – A tiny JavaScript library for narrative games",
    "url": "https://odyc.dev",
    "summary": "Odyc.js is a small JavaScript library designed to simplify the creation of narrative video games. It aims to empower users to code games, even without prior programming experience. The library's website showcases a gallery of games created with Odyc.js and offers learning resources to help users get started. Essentially, Odyc.js is positioned as an accessible tool for building narrative-driven games, emphasizing ease of use and accessibility to non-programmers.\n",
    "chinese_title": "Odyc.js – 一个用于叙事游戏的微型 JavaScript 库",
    "chinese_summary": "Odyc.js 是一个小型 JavaScript 库，旨在简化叙事视频游戏的创作。 它的目标是让用户能够编写游戏代码，即使没有编程经验。 该库的网站展示了用 Odyc.js 创建的游戏作品集，并提供学习资源来帮助用户入门。 本质上，Odyc.js 定位为构建叙事驱动型游戏的一种易用工具，强调易用性和非程序员的可访问性。"
  },
  {
    "id": "44200866",
    "title": "Odyc.js – A tiny JavaScript library for narrative games",
    "url": "https://odyc.dev",
    "summary": "Odyc.js is a small JavaScript library designed to simplify the creation of narrative video games, potentially even for individuals without prior programming experience. The library focuses on making game development more accessible, allowing users to \"code video games\" without needing extensive programming knowledge. The provided text highlights Odyc.js's core purpose as a tool for game development and encourages users to explore its features, including learning resources and a gallery showcasing games created using the library.\n",
    "chinese_title": "Odyc.js – 用于叙事游戏的微型JavaScript库",
    "chinese_summary": "Odyc.js 是一个小型 JavaScript 库，旨在简化叙事视频游戏的创作，甚至适用于没有编程经验的个人。该库专注于提高游戏开发的可访问性，允许用户在没有广泛编程知识的情况下“编写视频游戏”。提供的文本强调了 Odyc.js 作为游戏开发工具的核心目的，并鼓励用户探索其功能，包括学习资源和一个展示使用该库创作的游戏的画廊。"
  },
  {
    "id": "44168184",
    "title": "Wendelstein 7-X sets new fusion record",
    "url": "https://www.heise.de/en/news/Wendelstein-7-X-sets-new-fusion-record-10422955.html",
    "summary": "Wendelstein 7-X (W7-X), the stellarator fusion device in Greifswald, Germany, has achieved a new record for fusion energy production. In its latest experimental campaign, W7-X sustained a plasma with temperatures exceeding 135 million degrees Celsius (around 243 million Fahrenheit) for a significant eight minutes, generating an energy turnover of 1.3 gigajoules. This represents a substantial improvement over previous results.\n\nThe success is attributed to improvements in heating and control systems, enabling more stable and longer-lasting plasma confinement. Maintaining stable, high-temperature plasmas for extended periods is crucial for the development of commercially viable fusion power plants.\n\nWhile this is a significant achievement, W7-X is not designed to generate more energy than it consumes. Instead, it serves as a research device to prove the viability of the stellarator concept, which offers inherent advantages in plasma stability compared to tokamaks. The results from W7-X are informing the design of future fusion reactors. The team is now working towards even longer and more powerful discharges, aiming to demonstrate continuous operation in the future.\n",
    "chinese_title": "文德尔施泰因7-X 创下新的聚变记录",
    "chinese_summary": "德国格赖夫斯瓦尔德的仿星器聚变装置Wendelstein 7-X (W7-X) 在聚变能量产生方面取得新纪录。在最近的实验中，W7-X 维持了一个温度超过1.35亿摄氏度（约2.43亿华氏度）的等离子体长达重要的八分钟，产生了1.3吉焦耳的能量转换。这代表了对先前结果的显著改进。\n\n这一成功归功于加热和控制系统的改进，使等离子体能够更稳定和更持久地约束。长时间维持稳定、高温的等离子体对于开发具有商业可行性的聚变发电厂至关重要。\n\n虽然这是一项重大成就，但W7-X并非旨在产生比消耗更多的能量。相反，它作为一个研究装置，旨在证明仿星器概念的可行性，与托卡马克相比，仿星器在等离子体稳定性方面具有内在优势。来自W7-X的结果正在为未来聚变反应堆的设计提供信息。该团队目前正在努力实现更长、更强大的放电，目标是展示未来的连续运行。"
  },
  {
    "id": "44205718",
    "title": "What “working” means in the era of AI apps",
    "url": "https://a16z.com/revenue-benchmarks-ai-apps/",
    "summary": "This Andreessen Horowitz article, \"What 'Working' Means in the Era of AI Apps,\" argues that AI has significantly accelerated startup growth, with both enterprise and consumer companies achieving revenue milestones faster than in the pre-AI era.\n\nKey findings include:\n\n*   **Faster growth:** Median enterprise AI companies reach over $2 million ARR in their first year, while consumer companies achieve $4.2 million ARR, raising Series A rounds within 8-9 months of monetization. This rapid growth necessitates a strong velocity story for startups seeking venture capital.\n*   **Widening gap:** The difference between good and exceptional companies is increasing, with top performers demonstrating continuous growth throughout their first year. Traditional metrics like usage and retention remain vital for later-stage financing, however.\n*   **Consumer companies as revenue drivers:** B2C AI companies are generating substantial revenue, driven by funding for model training and revenue spikes following new model releases. Although conversion rates may be lower, user retention is comparable to pre-AI businesses.\n\nThe authors conclude that startups are moving faster, and businesses and consumers are willing to pay for new AI products, creating an opportune environment for application-layer software companies. They emphasize that speed of iteration and product development are becoming a competitive advantage (a moat).\n",
    "chinese_title": "人工智能应用时代“工作”的意义",
    "chinese_summary": "Andreessen Horowitz 文章《人工智能应用时代“工作”的意义》指出，人工智能已显著加速初创公司的增长，企业和消费者公司实现收入里程碑的速度都快于人工智能时代之前。\n\n主要发现包括：\n\n*   **增长加速：** 企业人工智能公司中位数在第一年达到超过 200 万美元的年度经常性收入 (ARR)，而消费者公司则达到 420 万美元的年度经常性收入，并在货币化后的 8-9 个月内完成 A 轮融资。这种快速增长要求寻求风险投资的初创公司拥有强大的增长速度故事。\n*   **差距扩大：** 优秀公司和卓越公司之间的差距正在扩大，顶级公司在第一年表现出持续增长。然而，诸如使用率和留存率之类的传统指标对于后期融资仍然至关重要。\n*   **消费者公司是收入驱动力：** B2C 人工智能公司正在产生可观的收入，这得益于模型训练的资金和新模型发布后的收入激增。虽然转化率可能较低，但用户留存率与人工智能之前的企业相当。\n\n作者总结说，初创公司发展速度更快，企业和消费者都愿意为新的人工智能产品付费，这为应用层软件公司创造了一个有利的环境。他们强调，迭代速度和产品开发正在成为一种竞争优势（护城河）。"
  },
  {
    "id": "44201762",
    "title": "Too Many Open Files",
    "url": "https://mattrighetti.com/2025/06/04/too-many-files-open",
    "summary": "This article details the author's experience troubleshooting a \"Too many open files\" error encountered while running Rust tests. The author explains that file descriptors (fds) are positive integers used by the OS kernel to identify open files and resources like regular files, directories, pipes, sockets, and devices in Unix-like systems. Every process starts with standard fds: stdin (0), stdout (1), and stderr (2).\n\nThe article then explores how to inspect open file descriptors using commands like `ls /dev/fd` (macOS), `ls /proc/<pid>/fd` (Linux), and `lsof`. It explains that the number of open fds a process can have is limited by the operating system. macOS uses `kern.maxfiles` (system-wide limit) and `kern.maxfilesperproc` (per-process hard limit), while `ulimit -n` shows the shell's soft limit, which can be raised up to the hard limit.\n\nThe author hypothesized that `cargo test` failed because it exceeded the shell's soft limit (256) of open file descriptors. A monitoring script using `lsof` confirmed this, showing the tests failed when fds reached around 237. The solution was to increase the shell's soft limit using `ulimit -n 8192`. After increasing the limit, the tests ran successfully, and a chart demonstrated the process reached around 1600 fds, exceeding the previous limit. The author concludes that understanding file descriptors is important for troubleshooting such errors.\n",
    "chinese_title": "打开文件过多",
    "chinese_summary": "解决Rust测试中“打开文件过多”错误的经验"
  },
  {
    "id": "44199649",
    "title": "What you need to know about EMP weapons",
    "url": "https://www.aardvark.co.nz/daily/2025/0606.shtml",
    "summary": "This Aardvark Daily article discusses the threat of electromagnetic pulse (EMP) weapons, particularly those resulting from high-altitude nuclear detonations. The author explains that EMPs are generated by the interaction of gamma radiation with the Earth's atmosphere and magnetic field, creating widespread disruption to electronics.\n\nThe article breaks down EMPs into three phases: E1, a rapid, high-frequency burst that fries sensitive devices; E2, a longer, lower-frequency phase; and E3, a low-frequency phase that can damage power lines and other long conductors.\n\nThe primary defense against EMPs is the Faraday cage, a conductive enclosure that redirects EMP energy. The article stresses the importance of complete enclosure, no gaps in the conductive layers, and insulation of devices from the shielding material.\n\nA rudimentary, last-minute protection method involves wrapping electronics in layers of plastic film and aluminum foil. The author also notes that older technology, like valve radios and cars without extensive electronics, may be more resilient to EMPs than modern devices. Overall, the article aims to inform readers about the potential dangers of EMPs and basic mitigation strategies.\n",
    "chinese_title": "关于电磁脉冲武器你需要知道的",
    "chinese_summary": "《食蚁兽日报》的这篇文章讨论了电磁脉冲（EMP）武器的威胁，特别是高空核爆炸产生的电磁脉冲。作者解释说，电磁脉冲是由伽马射线与地球大气层和磁场相互作用产生的，会对电子设备造成广泛破坏。\n\n这篇文章将电磁脉冲分为三个阶段：E1，一种快速、高频的脉冲，会烧毁敏感设备；E2，一种持续时间更长、频率更低的阶段；以及E3，一种低频阶段，会损坏电力线和其他长导体。\n\n防御电磁脉冲的主要方法是法拉第笼，一种能够转移电磁脉冲能量的导电外壳。文章强调了完全封闭的重要性，即导电层中不能有间隙，并且设备要与屏蔽材料绝缘。\n\n一种基本的、临时的保护方法是将电子设备包裹在塑料薄膜和铝箔层中。作者还指出，像真空管收音机和没有大量电子设备的汽车等老式技术，可能比现代设备更能抵抗电磁脉冲。总的来说，这篇文章旨在告知读者电磁脉冲的潜在危险和基本的缓解策略。"
  },
  {
    "id": "44204878",
    "title": "Smalltalk, Haskell and Lisp",
    "url": "https://storytotell.org/smalltalk-haskell-and-lisp",
    "summary": "This article details the author's experience writing a small program in Haskell, Common Lisp, and Smalltalk, initially meant to be written in Java by job candidates at NRAO. The goal was to reinforce existing programming knowledge, but the author unexpectedly discovered a strong preference for Haskell beyond its practicality.\n\nThe author contrasts the code snippets written in each language, arguing that the Haskell version felt more like a composable set of actions, while Smalltalk and Lisp felt like fabrications. A primary dislike for Lisp is that it feels like \"tricking\" the language instead of directly expressing intent. The author admires Haskell's syntax and ability to break problems down into small, easily understandable pieces.\n\nThe author reflects on their dependency on the compiler/interpreter, admitting a lack of strong pre-execution code analysis skills and how Haskell helps them avoid absurd coding practices earlier in the development process compared to Lisp and Smalltalk.\n\nThe author concludes that their love for Haskell might be irrational, acknowledging its limitations and potential teaching difficulties. They also question why languages like Lisp and Smalltalk lack Haskell's strong type system and reflect on the challenges of embracing code evolution and failure versus striving for compile-time correctness. They express interest in Autotest and TDD as potential future solutions. Ultimately, programming is a journey, and the author embraces the discomfort of continuous learning.\n",
    "chinese_title": "Smalltalk、Haskell和Lisp",
    "chinese_summary": "本文详细介绍了作者使用Haskell、Common Lisp和Smalltalk编写一个小型程序的经验，该程序最初是为NRAO的求职者用Java编写的。其目标是巩固现有的编程知识，但作者意外地发现，除了实用性之外，还对Haskell产生了强烈的偏好。\n\n作者对比了用每种语言编写的代码片段，认为Haskell版本感觉更像是一组可组合的操作，而Smalltalk和Lisp则感觉像是捏造出来的。对Lisp的主要不喜欢之处在于，它感觉像是“欺骗”语言，而不是直接表达意图。作者欣赏Haskell的语法以及将问题分解为小的、易于理解的部分的能力。\n\n作者反思了他们对编译器/解释器的依赖，承认缺乏强大的预执行代码分析技能，以及与Lisp和Smalltalk相比，Haskell如何帮助他们更早地避免开发过程中出现荒谬的编码实践。\n\n作者总结说，他们对Haskell的热爱可能是不理性的，承认它的局限性和潜在的教学困难。他们还质疑为什么像Lisp和Smalltalk这样的语言缺乏Haskell强大的类型系统，并反思了拥抱代码进化和失败与努力实现编译时正确性之间的挑战。他们表示对Autotest和TDD作为潜在的未来解决方案感兴趣。最终，编程是一段旅程，作者拥抱持续学习带来的不适。"
  },
  {
    "id": "44201872",
    "title": "Meta: Shut down your invasive AI Discover feed",
    "url": "https://www.mozillafoundation.org/en/campaigns/meta-shut-down-your-invasive-ai-discover-feed-now/",
    "summary": "Mozilla is demanding that Meta shut down its \"Discover\" AI feed due to concerns that private AI chats are being made public without users' explicit consent or knowledge. The organization argues that Meta is blurring the lines between private and public conversations, jeopardizing user privacy.\n\nMozilla is calling for several key actions from Meta:\n\n*   Shut down the Discover feed until robust privacy protections are implemented.\n*   Make all AI interactions private by default, requiring explicit, informed consent for public sharing.\n*   Provide transparency on how many users have unknowingly shared private information.\n*   Create a universal opt-out system across all Meta platforms to prevent data usage for AI training.\n*   Notify users whose conversations may have been made public and allow them to permanently delete their content.\n\nThe core issue is the lack of clear and informed consent, leading to users potentially sharing private information without realizing it. Mozilla believes that users have a right to know when they are communicating publicly and advocates for explicit opt-in measures to ensure privacy. The organization encourages users to sign a petition demanding Meta address these concerns.\n",
    "chinese_title": "Meta：关闭你侵入式的AI探索内容",
    "chinese_summary": "Mozilla 要求 Meta 关闭其“发现”AI 信息流，因担忧私人 AI 聊天在未经用户明确同意或知情的情况下被公开。该组织认为 Meta 正在模糊私人和公共对话之间的界限，危害用户隐私。\n\nMozilla 呼吁 Meta 采取以下关键行动：\n\n* 关闭“发现”信息流，直到实施稳健的隐私保护措施。\n* 默认情况下将所有 AI 互动设置为私密，公开分享需获得明确、知情的同意。\n* 公开有多少用户在不知情的情况下分享了私人信息。\n* 创建一个跨所有 Meta 平台的通用退出系统，以防止数据被用于 AI 训练。\n* 通知可能已被公开对话的用户，并允许他们永久删除其内容。\n\n核心问题在于缺乏明确和知情的同意，导致用户可能在不知情的情况下分享私人信息。 Mozilla 认为用户有权知道他们何时进行公开交流，并倡导采取明确的选择加入措施以确保隐私。该组织鼓励用户签署请愿书，要求 Meta 解决这些问题。"
  },
  {
    "id": "44189329",
    "title": "Show HN: Air Lab – A portable and open air quality measuring device",
    "url": "https://networkedartifacts.com/airlab/simulator",
    "summary": "This \"Show HN\" post introduces \"Air Lab,\" a portable and open-source air quality measuring device. The title highlights its key features: portability and open-source design. While the context is very limited, we can infer that Air Lab allows users to measure and analyze air quality on the go and potentially customize the device or its software thanks to its open nature. The inclusion of \"Air Lab Simulator\" suggests that there's likely a software component, perhaps allowing users to simulate air quality conditions or analyze data collected by the device. The device and simulator combo likely aims to provide a comprehensive solution for air quality monitoring, education, and potential research purposes.\n",
    "chinese_title": "Show HN: 空气实验室 – 一款便携式开源空气质量测量设备",
    "chinese_summary": "此“Show HN”帖子介绍了一款名为“Air Lab”的便携式开源空气质量测量设备。标题突出了其主要特点：便携性和开源设计。虽然背景信息有限，但我们可以推断出Air Lab允许用户随时随地测量和分析空气质量，并可能由于其开源特性而自定义设备或其软件。“Air Lab Simulator”的包含表明可能存在一个软件组件，或许允许用户模拟空气质量状况或分析设备收集的数据。该设备和模拟器组合可能旨在为空气质量监测、教育和潜在的研究目的提供一个全面的解决方案。"
  },
  {
    "id": "44210082",
    "title": "Chimera – a Linux that isn't GNU/Linux",
    "url": "https://www.theregister.com/2023/02/13/chimera_non_gnu_linux/",
    "summary": "This article introduces Chimera Linux, a new Linux distribution aiming to be entirely GNU-free and systemd-free. Developed by Daniel \"q66\" Kolesa, Chimera is built using LLVM, the musl C library (like Alpine Linux), the Dinit init system, and components from FreeBSD's userland.\n\nChimera Linux seeks to bring design clarity to Linux, offering a more integrated OS experience compared to typical distributions with thousands of separately developed components. While still Linux-based and binary-compatible, it essentially inverts Debian GNU/kFreeBSD by placing a FreeBSD-derived userland on the Linux kernel. A key part of this is replacing GNU coreutils with a forked version called chimerautils.\n\nThe distribution employs the Alpine Package Keeper (apk) for package management, utilizing APK version 3 with a custom package format for improved security. Despite being in its early stages, Chimera already supports ppc64le, x86_64, aarch64, and RISC-V_64 architectures. It offers GNOME on Wayland as its initial desktop environment, chosen for its complexity and the challenges it presents for porting.\n\nChimera prioritizes hardening and error checking using LLVM and Clang features. Beyond simply removing systemd, it aims to reproduce its functionality with tools like the Turnstile session tracker. The project, though ambitious and incomplete (lacking an installer currently), intends to be a viable alternative system with a cleaner, better implementation of core functionalities.\n",
    "chinese_title": "喀迈拉 – 非GNU/Linux的Linux",
    "chinese_summary": "本文介绍了Chimera Linux，一个旨在完全摆脱GNU和systemd的新Linux发行版。Chimera由Daniel \"q66\" Kolesa开发，使用LLVM、musl C库（如Alpine Linux）、Dinit init系统以及FreeBSD的用户空间组件构建。\n\nChimera Linux致力于为Linux带来设计上的清晰性，与典型发行版中数千个独立开发的组件相比，它提供更集成的操作系统体验。虽然仍然基于Linux且二进制兼容，但它本质上颠覆了Debian GNU/kFreeBSD，将源自FreeBSD的用户空间置于Linux内核之上。其中的关键部分是用名为chimerautils的fork版本替换GNU coreutils。\n\n该发行版采用Alpine Package Keeper (apk) 进行包管理，使用APK版本3和自定义包格式以提高安全性。尽管处于早期阶段，Chimera已经支持ppc64le、x86_64、aarch64和RISC-V_64架构。它提供GNOME on Wayland作为其初始桌面环境，选择GNOME是因为其复杂性以及移植带来的挑战。\n\nChimera优先考虑使用LLVM和Clang特性进行强化和错误检查。除了简单地移除systemd之外，它还旨在用Turnstile会话跟踪器等工具来重现其功能。该项目虽然雄心勃勃且不完整（目前缺少安装程序），但旨在成为一个可行的替代系统，具有更清洁、更好的核心功能实现。"
  },
  {
    "id": "44200870",
    "title": "Curate your shell history",
    "url": "https://esham.io/2025/05/shell-history",
    "summary": "The article discusses different philosophies regarding shell history management, contrasting a minimalist approach with the author's own \"shell history maximalist\" tendency. It begins by highlighting Simon Tatham's practice of disabling the shell history file entirely, advocating for consciously saving only valuable commands elsewhere to avoid clutter from failed attempts and accidental recalls.\n\nThe author, on the other hand, prefers a large shell history but acknowledges the problem of accumulating useless commands like typos and incorrect attempts. To address this, the author introduces a zsh function called `smite`, which uses `fzf` to provide an interactive interface for browsing and deleting unwanted history entries. By default, `smite` operates on the current session's history, but the `-a` option allows pruning the entire history file. Selected commands are permanently removed from the history file.\n\nThe author acknowledges the limitations of `smite` in handling multiline commands but hopes the concept will prompt readers to consider their own shell history habits and explore ways to improve them. Even if the specific zsh code isn't useful, the article advocates for actively curating shell history to remove \"weeds\" (unwanted commands) and make it a more valuable resource.\n",
    "chinese_title": "管理你的Shell历史记录",
    "chinese_summary": "本文探讨了关于 shell 历史管理的不同哲学，将极简主义方法与作者自身的“shell 历史最大化”倾向进行了对比。文章首先强调了 Simon Tatham 完全禁用 shell 历史文件的做法，他提倡有意识地将有价值的命令保存到其他地方，以避免因失败的尝试和意外的回调而导致混乱。\n\n另一方面，作者更喜欢大型 shell 历史，但也承认了积累无用命令（如拼写错误和不正确的尝试）的问题。为了解决这个问题，作者介绍了一个名为 `smite` 的 zsh 函数，该函数使用 `fzf` 提供了一个交互式界面，用于浏览和删除不需要的历史条目。默认情况下，`smite` 对当前会话的历史记录进行操作，但 `-a` 选项允许修剪整个历史记录文件。选定的命令将从历史记录文件中永久删除。\n\n作者承认 `smite` 在处理多行命令方面的局限性，但希望这个概念能促使读者考虑他们自己的 shell 历史习惯，并探索改进它们的方法。即使特定的 zsh 代码没有用，本文也提倡积极地整理 shell 历史，以删除“杂草”（不需要的命令），并使其成为更有价值的资源。"
  },
  {
    "id": "44203732",
    "title": "Workhorse LLMs: Why Open Source Models Dominate Closed Source for Batch Tasks",
    "url": "https://sutro.sh/blog/workhorse-llms-why-open-source-models-win-for-batch-tasks",
    "summary": "This Sutro Components blog post argues that open-source LLMs are often superior to closed-source alternatives for \"workhorse\" batch tasks like classification, summarization, and data extraction. While closed-source models lead in cutting-edge intelligence, open-source models offer better performance and cost savings for these common business applications.\n\nThe article compares performance and cost using the Artificial Analysis Intelligence Index and cost-per-token data, highlighting that open-source models can offer 2x-10x better price/performance, especially with batch inference providers like Sutro. Examples like Qwen3 4B show comparable or better performance than models like GPT-4o-mini at a significantly lower cost.\n\nThe post also provides a conversion chart to help users select appropriate open-source replacements for popular closed-source models, estimating potential cost savings. While some closed-source models like Gemini 2.5 Flash offer competitive pricing, open-source alternatives often win in overall cost-effectiveness. The conclusion emphasizes that focusing on the cost-to-performance ratio for specific tasks reveals the dominance of open-source LLMs in the workhorse category, particularly when leveraging batch processing. Finally, it encourages readers to seek consultations from Sutro for optimizing their LLM strategy.\n",
    "chinese_title": "主力LLM：为何开源模型在批量任务中胜过闭源模型",
    "chinese_summary": "Sutro Components博客文章认为，对于诸如分类、摘要和数据提取等“主力”批量任务，开源LLM通常优于闭源替代方案。虽然闭源模型在尖端智能方面领先，但开源模型在这些常见业务应用中提供了更好的性能和成本效益。\n\n文章使用人工智能分析指数和每token成本数据比较了性能和成本，强调开源模型可以提供2倍-10倍的更高性价比，尤其是在使用像Sutro这样的批量推理提供商时。例如，Qwen3 4B显示出与GPT-4o-mini等模型相当或更好的性能，但成本显著降低。\n\n该帖子还提供了一个转换图表，以帮助用户为流行的闭源模型选择合适的开源替代方案，并估算潜在的成本节省。虽然像Gemini 2.5 Flash这样的一些闭源模型提供具有竞争力的定价，但开源替代方案通常在整体成本效益方面胜出。结论强调，关注特定任务的成本与性能比，揭示了开源LLM在主力类别中的主导地位，尤其是在利用批量处理时。最后，它鼓励读者向Sutro寻求咨询，以优化他们的LLM战略。"
  },
  {
    "id": "44203003",
    "title": "Series C and scale",
    "url": "https://www.cursor.com/en/blog/series-c",
    "summary": "Anysphere, the company behind the AI coding assistant Cursor, has announced a successful Series C funding round, raising $900 million at a $9.9 billion valuation. The investment comes from prominent venture capital firms including Thrive, Accel, Andreessen Horowitz, and DST.\n\nThis new funding will be used to further Anysphere's AI coding research and improve Cursor. The article highlights Cursor's significant growth, achieving over $500 million in Annual Recurring Revenue (ARR). The tool has also achieved substantial market penetration, now used by over half of the Fortune 500 companies, including notable names like NVIDIA, Uber, and Adobe.\n\nThe announcement emphasizes Anysphere's core mission: to develop a superior coding experience. The Series C funding and the existing market traction signify that Anysphere is well-positioned to execute on its vision and push the boundaries of AI-powered coding tools.\n",
    "chinese_title": "C轮融资及规模",
    "chinese_summary": "AI 编码助手 Cursor 背后的公司 Anysphere 宣布成功完成 C 轮融资，以 99 亿美元的估值融资 9 亿美元。本轮投资来自 Thrive、Accel、Andreessen Horowitz 和 DST 等知名风险投资公司。\n\n这笔新资金将用于进一步推动 Anysphere 的 AI 编码研究并改进 Cursor。文章强调了 Cursor 的显著增长，实现了超过 5 亿美元的年度经常性收入 (ARR)。该工具也实现了显著的市场渗透，目前已被超过一半的财富 500 强公司使用，包括 NVIDIA、Uber 和 Adobe 等知名企业。\n\n该公告强调了 Anysphere 的核心使命：开发卓越的编码体验。C 轮融资和现有的市场吸引力表明，Anysphere 完全有能力实现其愿景，并推动人工智能驱动的编码工具的边界。"
  },
  {
    "id": "44199597",
    "title": "Weaponizing Dependabot: Pwn Request at its finest",
    "url": "https://boostsecurity.io/blog/weaponizing-dependabot-pwn-request-at-its-finest",
    "summary": "This article details how Dependabot, GitHub's dependency update bot, can be weaponized via \"Confused Deputy\" attacks to inject malicious code and bypass branch protection. Attackers can trick auto-merge workflows that trust Dependabot to merge malicious code from a forked repository.\n\nThe core technique involves forking a repo with an auto-merge workflow, introducing malicious code, and then manipulating Dependabot into updating a PR from the fork, thus triggering the merge. The author highlights two new TTPs to achieve command injection by manipulating the branch name. These involve creating merge conflicts and swapping the default branch to inject malicious code into Dependabot's branch. This allows command injection through branch name execution.\n\nAdditionally, the article outlines how, with `contents: write` permission, attackers can bypass branch protection by pushing malicious code directly to Dependabot's branch and then triggering a merge using the `@dependabot merge` command. The article then concludes that while Dependabot is a popular target, any trusted and controllable bot can be similarly exploited if automation is desired. The author's team has uncovered multiple bots that are prime candidates for similar shenanigans, indicating a broader threat landscape.\n",
    "chinese_title": "武器化Dependabot：精妙的Pwn请求",
    "chinese_summary": "本文详细介绍了如何通过“混乱代理”攻击方式利用 GitHub 的依赖项更新机器人 Dependabot，注入恶意代码并绕过分支保护。攻击者可以欺骗信任 Dependabot 的自动合并工作流，从而合并来自派生存储库的恶意代码。\n\n核心技术包括：派生一个具有自动合并工作流的仓库，引入恶意代码，然后操纵 Dependabot 更新来自派生仓库的 PR，从而触发合并。作者重点介绍了两种新的 TTP，通过操纵分支名称来实现命令注入。这包括创建合并冲突和交换默认分支，将恶意代码注入到 Dependabot 的分支中。这允许通过分支名称执行进行命令注入。\n\n此外，本文还概述了，借助 `contents: write` 权限，攻击者如何通过将恶意代码直接推送到 Dependabot 的分支，然后使用 `@dependabot merge` 命令触发合并来绕过分支保护。文章最后总结道，虽然 Dependabot 是一个受欢迎的目标，但如果需要自动化，任何受信任且可控的机器人都可以被类似地利用。作者的团队已经发现了多个机器人，它们是类似恶作剧的主要候选对象，表明存在更广泛的威胁格局。"
  },
  {
    "id": "44199005",
    "title": "Freight rail fueled a new luxury overnight train startup",
    "url": "https://www.freightwaves.com/news/how-freight-rail-fueled-a-new-luxury-overnight-train-startup",
    "summary": "Dreamstar, a passenger rail startup, aims to revive luxury overnight train travel between Los Angeles and San Francisco, reminiscent of the Southern Pacific's Lark from the 1940s. Co-founders Joshua Dominic and Thomas Eastmond plan to use freight rail infrastructure, having secured a memorandum of agreement with Union Pacific for track access on a route with minimal overnight freight traffic.\n\nDreamstar's vision includes all-bedroom accommodations, gourmet dining, and high-end hospitality. They are also pursuing agreements with commuter agencies like Caltrain and Metrolink. The startup claims a 75% reduction in carbon emissions compared to flying and intends to offer competitive pricing akin to a flight-plus-hotel.\n\nInspired by the Budd Hi-Level cars, Dreamstar's train design features various private cabin classes, lounges, dining spaces, and a spa, along with an Auto Ferry for car transport. Originally planning to build a new train, the company now intends to rebuild existing cars. BMW Designworks has completed the concept phase.\n\nConstruction of the train is expected to take 18 to 24 months, with service targeted to begin before the 2028 Los Angeles Olympics. While a locomotive supplier is yet to be chosen, several options are being considered. The company is also working with industry experts for regulatory approvals and has received initial funding from investors, including homebuilder Bill Lyon. Dreamstar emphasizes a lean, capital-efficient business model compared to legacy operators.\n",
    "chinese_title": "货运铁路推动新型豪华卧铺列车初创公司",
    "chinese_summary": "Dreamstar 计划重振洛杉矶至旧金山的豪华夜间火车旅行，让人想起 20 世纪 40 年代南太平洋铁路公司的云雀号列车。联合创始人 Joshua Dominic 和 Thomas Eastmond 计划利用货运铁路基础设施，并已与联合太平洋铁路公司达成协议备忘录，以获得在夜间货运流量最少的路线上使用轨道的权限。\n\nDreamstar 的愿景包括全卧室住宿、美食餐饮和高端酒店服务。他们还在寻求与 Caltrain 和 Metrolink 等通勤机构达成协议。这家初创公司声称碳排放量比飞行减少 75%，并计划提供与机票加酒店住宿相当的具有竞争力的价格。\n\n受 Budd Hi-Level 车厢的启发，Dreamstar 的列车设计包括各种私人客舱等级、休息室、用餐空间和水疗中心，以及用于汽车运输的汽车渡轮。该公司最初计划建造一列新火车，现在打算重建现有车厢。宝马设计工作室已完成概念阶段。\n\n列车建设预计需要 18 到 24 个月，目标是在 2028 年洛杉矶奥运会之前开始运营。虽然尚未选定机车供应商，但正在考虑多种选择。该公司还在与行业专家合作，以获得监管部门的批准，并已从包括房屋建筑商 Bill Lyon 在内的投资者那里获得了初步融资。与传统运营商相比，Dreamstar 强调精简、资本高效的商业模式。"
  },
  {
    "id": "44201901",
    "title": "4-7-8 Breathing",
    "url": "https://www.breathbelly.com/exercises/4-7-8-breathing",
    "summary": "This snippet indicates the existence of a breathing exercise called \"4-7-8 Breathing,\" offered (perhaps for free) by a company or website called \"Breathbelly.\" It highlights the practice as a breathing exercise that may involve \"belly breathing\" or targeting the \"breathbelly.\" The core takeaway is that the article likely details or promotes the 4-7-8 breathing technique, with Breathbelly being a provider of resources related to this technique. Because the only context is the title and website name, the exact benefits, steps of the technique, and the specific offerings of Breathbelly regarding this breathing exercise are unknown and require further exploration of the linked article.\n",
    "chinese_title": "4-7-8呼吸法",
    "chinese_summary": "这则摘要表明存在一种名为“4-7-8呼吸法”的呼吸练习，由一家名为“Breathbelly”的公司或网站提供（可能免费）。 它强调这项练习是一种可能涉及“腹式呼吸”或针对“breathbelly”的呼吸锻炼。 核心要点是，这篇文章可能详细介绍或推广4-7-8呼吸法，而Breathbelly是与该技术相关的资源提供商。 因为唯一的背景是标题和网站名称，所以该技术的具体益处、步骤以及Breathbelly关于此呼吸练习的具体服务尚不清楚，需要进一步浏览链接文章。"
  },
  {
    "id": "44208050",
    "title": "Windows 10 spies on your use of System Settings (2021)",
    "url": "https://www.michaelhorowitz.com/Windows10.spying.onsettings.php",
    "summary": "Michael Horowitz's article details how Windows 10 spies on user activity within System Settings. Using DNS and TCP logging tools by Nir Sofer, Horowitz discovered that simply opening System Settings triggers DNS queries to `www.bing.com` and `cxcs.microsoft.net`, followed by outbound HTTPS requests to those domains. This occurs even with a local account, disabled telemetry, and locked-down settings.\n\nThe author suspects `cxcs.microsoft.net` is related to Microsoft's Customer Experience Center and that `www.bing.com` is used for telemetry in addition to its search engine function. Blocking `cxcs.microsoft.net` led to further DNS requests, this time to `ctldl.windowsupdate.com`.\n\nHorowitz suggests defensive computing measures such as modifying router DNS settings to block specific domains (e.g., using Pepwave routers or Pi-Hole), using YogaDNS with NextDNS, or employing a firewall with outbound control. He notes the limitations of router-level blocking when VPNs or Secure DNS are used.\n\nHe found modifying the \"hosts\" file to block `www.bing.com` had inconsistent results, with `nslookup` ignoring the changes. Ultimately, Horowitz advocates for network-wide blocking of telemetry domains and suggests using DuckDuckGo as an alternative to Bing. He provides a list of domains to block based on his observations. An update mentions that Microsoft rewrites bing.com sub-domains, and identifies `svchost.exe` and `SearchApp.exe` as also making DNS queries to `www.bing.com`. The article also references a study by Helge Klein, which showed Windows communicating with hundreds of hosts and thousands of IP addresses.\n",
    "chinese_title": "Windows 10 窥探您对系统设置的使用 (2021)",
    "chinese_summary": "迈克尔·霍洛维茨的文章详细介绍了Windows 10如何在系统设置中监视用户活动。霍洛维茨使用Nir Sofer的DNS和TCP日志记录工具发现，仅仅打开系统设置就会触发对`www.bing.com`和`cxcs.microsoft.net`的DNS查询，然后向这些域发出出站HTTPS请求。即使使用本地帐户、禁用遥测和锁定设置，也会发生这种情况。\n\n作者怀疑`cxcs.microsoft.net`与微软的客户体验中心有关，而`www.bing.com`除了搜索引擎功能外，还用于遥测。 阻止`cxcs.microsoft.net`导致进一步的DNS请求，这次是对`ctldl.windowsupdate.com`的请求。\n\n霍洛维茨建议采取防御性计算措施，例如修改路由器DNS设置以阻止特定域（例如，使用Pepwave路由器或Pi-Hole），使用YogaDNS与NextDNS，或使用具有出站控制的防火墙。 他指出，当使用VPN或安全DNS时，路由器级别阻止的局限性。\n\n他发现修改“hosts”文件以阻止`www.bing.com`的结果不一致，`nslookup`忽略了这些更改。最终，霍洛维茨主张在网络范围内阻止遥测域，并建议使用DuckDuckGo作为Bing的替代方案。 他根据自己的观察提供了一个要阻止的域列表。 一项更新提到微软会重写bing.com的子域名，并指出`svchost.exe`和`SearchApp.exe`也会对`www.bing.com`进行DNS查询。 该文章还引用了Helge Klein的一项研究，该研究表明Windows与数百个主机和数千个IP地址进行通信。"
  },
  {
    "id": "44203494",
    "title": "SaaS is just vendor lock-in with better branding",
    "url": "https://rwsdk.com/blog/saas-is-just-vendor-lock-in-with-better-branding",
    "summary": "The article argues that while SaaS solutions promise to simplify development by handling tasks like authentication, queuing, and storage, integrating them introduces hidden costs beyond monetary expenses. These \"taxes\" include the time and effort spent on:\n\n1.  **Discovery:** Researching and evaluating different SaaS options to understand their features, compatibility, and pricing.\n2.  **Sign-Up:** Committing to a service, often handing over payment information, before even writing any code.\n3.  **Integration:** Implementing the SaaS service, wrestling with documentation, and addressing unexpected edge cases.\n4.  **Local Development:** Replicating the SaaS service locally for testing, potentially requiring complex configurations.\n5.  **Production:** Ensuring the service's reliability, managing API keys securely, and troubleshooting production issues.\n\nThe author contends that all choices, including open-source and self-hosted solutions, lead to vendor lock-in due to the code rewriting required when switching. Therefore, the author advocates choosing integrated platforms like Cloudflare or Supabase, where essential services are bundled and work seamlessly together. This approach minimizes context switching, API key management, and compatibility issues, creating a smoother developer experience and promoting \"flow.\" By opting for an all-in-one platform, developers can focus on building their core software instead of constantly managing and integrating disparate SaaS solutions.\n",
    "chinese_title": "SaaS只是换了更好说辞的厂商锁定。",
    "chinese_summary": "文章认为，虽然SaaS解决方案承诺通过处理身份验证、队列和存储等任务来简化开发，但集成它们会带来货币支出以外的隐藏成本。这些“税收”包括花费在以下方面的时间和精力：\n\n1. **发现：** 研究和评估不同的SaaS选项，以了解其功能、兼容性和定价。\n2. **注册：** 在编写任何代码之前，就承诺使用一项服务，通常要交出付款信息。\n3. **集成：** 实施SaaS服务，与文档作斗争，并解决意想不到的边缘情况。\n4. **本地开发：** 在本地复制SaaS服务进行测试，可能需要复杂的配置。\n5. **生产：** 确保服务的可靠性，安全地管理API密钥，并解决生产问题。\n\n作者认为，所有选择，包括开源和自托管解决方案，都会导致供应商锁定，因为切换时需要重写代码。因此，作者提倡选择像Cloudflare或Supabase这样的集成平台，这些平台将基本服务捆绑在一起，并无缝协同工作。这种方法最大限度地减少了上下文切换、API密钥管理和兼容性问题，从而创造了更流畅的开发者体验并促进了“心流”。通过选择一体化平台，开发者可以专注于构建其核心软件，而不是不断管理和集成不同的SaaS解决方案。"
  },
  {
    "id": "44199699",
    "title": "Swift and the Cute 2d game framework: Setting up a project with CMake",
    "url": "https://layer22.com/swift-and-cute-framework-setting-up-a-project-with-cmake",
    "summary": "This article provides a step-by-step guide on setting up a 2D game development project using the Cute Framework (written in C/C++) with Swift. It leverages CMake to manage the build process, enabling developers to write game logic in Swift while utilizing the performance benefits of C/C++ for rendering.\n\nThe guide covers the necessary prerequisites (Swift, CMake, Ninja), project structure creation, and configuration of a `CMakeLists.txt` file to manage dependencies, including downloading and linking the Cute Framework. It also details setting up Swift interoperability with C code using a shim header file (`shim.h`) and a module map (`module.modulemap`).\n\nThe example code demonstrates how to create a Cute Framework application, instantiate a sprite, play an animation, update the app and sprite states, and draw the sprite onto the screen within a game loop. Finally, the article provides commands to configure and build the project using CMake and Ninja, and instructions on running the resulting executable.  The key takeaway is a blend of Swift's expressiveness with C/C++'s performance in game development using the Cute Framework.\n",
    "chinese_title": "Swift与可爱的2D游戏框架：使用CMake设置项目",
    "chinese_summary": "本文提供了一个分步指南，介绍如何使用 Swift 设置基于 Cute Framework (用 C/C++ 编写) 的 2D 游戏开发项目。它利用 CMake 管理构建过程，使开发者能够用 Swift 编写游戏逻辑，同时利用 C/C++ 的性能优势进行渲染。\n\n该指南涵盖了必要的先决条件（Swift、CMake、Ninja）、项目结构创建以及 `CMakeLists.txt` 文件的配置，以管理依赖项，包括下载和链接 Cute Framework。它还详细介绍了如何使用 shim 头文件 (`shim.h`) 和模块映射 (`module.modulemap`) 设置 Swift 与 C 代码的互操作性。\n\n示例代码演示了如何创建 Cute Framework 应用程序、实例化精灵、播放动画、更新应用程序和精灵状态，以及在游戏循环中将精灵绘制到屏幕上。最后，本文提供了使用 CMake 和 Ninja 配置和构建项目的命令，以及运行生成的可执行文件的说明。 关键在于利用 Swift 的表达能力与 C/C++ 在使用 Cute Framework 进行游戏开发时的性能。"
  },
  {
    "id": "44199770",
    "title": "How to (actually) send DTMF on Android without being the default call app",
    "url": "https://edm115.dev/blog/2025/01/22/how-to-send-dtmf-on-android",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "如何在安卓系统上（真正地）发送DTMF信号，且不成为默认通话应用",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44201583",
    "title": "An Interactive Guide to Rate Limiting",
    "url": "https://blog.sagyamthapa.com.np/interactive-guide-to-rate-limiting",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "速率限制互动指南",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44202664",
    "title": "Researchers find a way to make the HIV virus visible within white blood cells",
    "url": "https://www.theguardian.com/global-development/2025/jun/05/breakthrough-in-search-for-hiv-cure-leaves-researchers-overwhelmed",
    "summary": "Researchers at the Peter Doherty Institute in Melbourne have made a significant breakthrough in HIV cure research. They've developed a new method to make the HIV virus visible within white blood cells where it typically hides, evading the immune system and drug treatments. This hiding ability has been a major obstacle in finding a cure.\n\nThe new method utilizes mRNA technology, similar to that used in Covid-19 vaccines. The researchers encapsulate mRNA within a newly designed fat bubble called LNP X, which can be delivered to the specific white blood cells where HIV resides. The mRNA then instructs these cells to expose the virus.\n\nThis development addresses the challenge of delivering mRNA to these cells, previously thought impossible. The researchers were \"overwhelmed\" by the effectiveness of the new approach.\n\nWhile the study is currently lab-based, using cells donated by HIV patients, it represents a significant step forward in HIV cure research. Further research is needed to determine if exposing the virus is sufficient for the immune system to eliminate it, or if it needs to be combined with other therapies. Animal and human trials are also necessary, a process that could take years.\n\nExperts acknowledge the potential of this advance, noting that it could have broader implications for other diseases involving the same white blood cells, including cancers. However, challenges remain, including the need to eliminate the entire viral reservoir and the question of whether achieving this is even possible.\n",
    "chinese_title": "研究人员找到使艾滋病毒在白细胞内可见的方法。",
    "chinese_summary": "墨尔本多尔蒂研究所的研究人员在艾滋病治愈研究方面取得重大突破。他们开发出一种新方法，使艾滋病毒在白细胞内显现，而病毒通常隐藏在其中，逃避免疫系统和药物治疗。这种隐藏能力一直是寻找治疗方法的重大障碍。\n\n这种新方法利用了mRNA技术，类似于新冠疫苗中使用的技术。研究人员将mRNA封装在一种新设计的名为LNP X的脂肪泡中，可以将其输送到艾滋病毒所在的特定白细胞。然后，mRNA指示这些细胞暴露病毒。\n\n这一进展解决了将mRNA输送到这些细胞的难题，这之前被认为是不可行的。研究人员对新方法的有效性感到“震惊”。\n\n虽然该研究目前基于实验室，使用艾滋病患者捐赠的细胞，但它代表了艾滋病治愈研究的重要一步。还需要进一步研究，以确定暴露病毒是否足以让免疫系统消除它，或者是否需要与其他疗法结合使用。动物和人体试验也是必要的，这个过程可能需要数年时间。\n\n专家们承认这一进展的潜力，并指出它可能对涉及相同白细胞的其他疾病（包括癌症）产生更广泛的影响。然而，仍然存在挑战，包括需要消除整个病毒库，以及实现这一目标是否可能的问题。"
  },
  {
    "id": "44205697",
    "title": "I Read All of Cloudflare's Claude-Generated Commits",
    "url": "https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/",
    "summary": "Max Mitchell's article analyzes Cloudflare's experience building an OAuth 2.1 library almost entirely with Claude, focusing on the documented human-AI collaboration process. He emphasizes the value of including prompts in commit messages, transforming git history into a record of intent and facilitating easier review.\n\nThe collaboration revealed patterns like \"prompt by example\" and iterative feedback (\"You did X, but we should do Y. pls fix.\"). AI excelled at documentation generation. However, AI struggled with tasks like refactoring code, requiring manual intervention for styling and bug fixes.\n\nMitchell highlights practical takeaways for working with AI coding tools: focusing on the deliverable (e.g., endpoint behavior, example usage), treating prompts as version-controlled assets, expecting multi-shot prompting, and knowing when to intervene manually.\n\nHe proposes a future where prompts are the source code, allowing for codebase regeneration with improved models and self-documenting business logic. This raises the question of whether, with sufficient model advancement, the \"application\" could become the history of prompt commits itself, eliminating the code generation step.\n\nUltimately, the experience exemplifies a new creative dynamic where AI handles implementation while humans provide direction and judgment, even though substantial human involvement is still needed for prompt creation, bug fixing, and strategic oversight.\n",
    "chinese_title": "我读了 Cloudflare 所有 Claude 生成的提交记录",
    "chinese_summary": "米切尔的文章分析了Cloudflare几乎完全使用Claude构建OAuth 2.1库的经验，重点介绍了有据可查的人工智能协作过程。他强调了在提交消息中包含提示的价值，将git历史转化为意图记录，并促进更轻松的审查。\n\n该协作揭示了诸如“示例提示”和迭代反馈（“你做了X，但我们应该做Y。请修复。”）之类的模式。人工智能擅长生成文档。然而，人工智能在诸如重构代码之类的任务中表现不佳，需要人工干预来进行样式调整和错误修复。\n\n米切尔强调了使用人工智能编码工具的实用经验：专注于可交付成果（例如，端点行为、示例用法），将提示视为版本控制资产，期望进行多轮提示，并知道何时进行手动干预。\n\n他提出了一个未来，即提示是源代码，允许使用改进的模型和自文档化的业务逻辑来重新生成代码库。这引发了一个问题，即随着模型的发展，是否“应用程序”本身会成为提示提交的历史记录，从而消除代码生成步骤。\n\n最终，该经验例证了一种新的创造性动态，即人工智能处理实施，而人类提供指导和判断，即使在提示创建、错误修复和战略监督方面仍然需要大量的人工参与。"
  },
  {
    "id": "44204277",
    "title": "United States Digital Service Origins",
    "url": "https://usdigitalserviceorigins.org/",
    "summary": "This article announces the launch of an oral history project documenting the origins and early days of the United States Digital Service (USDS). Released on June 6, 2025, the project aims to preserve the lessons learned and experiences of those who built the foundation of the USDS, particularly in light of its recent reorganization and renaming.\n\nThe oral history features nearly 50 interviews from 2009 to 2015, capturing the perspectives of founders, agency team leaders, and members of Communities of Practice. These interviews collectively tell the story of the USDS's conceptualization, creation, and the challenges of implementing new technologies within a government environment. The project identifies key themes, lessons, and a chronology of events, showcasing the experience of working within the USDS, including differing viewpoints.\n\nThe authors, Kathy Pham and Emily Tavoulareas, emphasize that this oral history is part of a larger, ongoing civic tech movement that believes in leveraging digital expertise to improve public services. They argue that the USDS's legacy and lessons remain valuable, regardless of the future form of government technology teams, because it demonstrated the potential for positive change and its impact on the individuals who served. The article concludes with an invitation to sign up for updates on the project.\n",
    "chinese_title": "美国数字服务局的起源",
    "chinese_summary": "本文宣布启动一项口述历史项目，旨在记录美国数字服务局 (USDS) 的起源和早期发展历程。该项目于 2025 年 6 月 6 日发布，旨在保存 USDS 奠基者所吸取的经验教训，尤其是在其最近的重组和更名之后。\n\n该口述历史收录了 2009 年至 2015 年期间近 50 次访谈，记录了创始人、机构团队领导者和实践社区成员的观点。这些访谈共同讲述了 USDS 的概念化、创建以及在政府环境中实施新技术的挑战。该项目确定了关键主题、经验教训和事件年表，展示了在美国数字服务局 (USDS) 工作的经历，包括不同的观点。\n\n作者 Kathy Pham 和 Emily Tavoulareas 强调，这项口述历史是更大、持续进行的公民科技运动的一部分，该运动相信利用数字专业知识来改善公共服务。他们认为，无论政府技术团队的未来形式如何，USDS 的遗产和经验教训仍然很有价值，因为它展示了积极变革的潜力及其对服务人员的影响。文章最后邀请读者注册以获取项目更新。"
  },
  {
    "id": "44196945",
    "title": "Test Postgres in Python Like SQLite",
    "url": "https://github.com/wey-gu/py-pglite",
    "summary": "Py-PGlite is a Python library designed to simplify PostgreSQL testing, offering a zero-config, instant testing solution comparable to SQLite's ease of use. It eliminates the need for Docker, manual setup, or configuration files, allowing developers to use real PostgreSQL for testing with minimal effort.\n\nKey features include:\n\n*   **Zero-Config Quick Start:** Seamless integration with SQLAlchemy and Django, automatically configuring databases and models.\n*   **Raw SQL Support:** Allows for direct execution of SQL queries, leveraging full PostgreSQL features like JSON and arrays.\n*   **Framework Ready:** Compatible with SQLAlchemy, Django, and FastAPI.\n*   **Fast Setup:** Offers significantly faster startup times compared to Docker-based PostgreSQL testing (2-3s vs. 30-60s).\n*   **Isolated Testing:** Each test receives a fresh database instance, ensuring isolation.\n*   **Custom Configuration:** Provides options for customizing configurations like port range, timeout, and cleanup.\n*   **Performance Testing:** Facilitates performance testing using real PostgreSQL features.\n*   **Framework Isolation:** Enables targeted testing for specific frameworks (SQLAlchemy or Django) or directory isolation.\n\nPy-PGlite's architecture is based on a framework-agnostic core with optional integrations, focusing on zero configuration, intelligent defaults, and perfect isolation. It streamlines PostgreSQL testing, making it accessible and efficient for Python developers.\n",
    "chinese_title": "像SQLite一样在Python中测试Postgres",
    "chinese_summary": "Py-PGlite: 简化 PostgreSQL 测试的 Python 库，提供零配置、即时可用的测试方案，媲美 SQLite 的易用性。无需 Docker、手动设置或配置文件，开发者只需极少的工作量即可使用真实的 PostgreSQL 进行测试。\n\n主要特点包括：\n\n*   **零配置快速启动:** 与 SQLAlchemy 和 Django 无缝集成，自动配置数据库和模型。\n*   **原生 SQL 支持:** 允许直接执行 SQL 查询，充分利用 PostgreSQL 的全部功能，如 JSON 和数组。\n*   **框架就绪:** 兼容 SQLAlchemy、Django 和 FastAPI。\n*   **快速设置:** 相比基于 Docker 的 PostgreSQL 测试，启动时间显著缩短 (2-3 秒 vs. 30-60 秒)。\n*   **隔离测试:** 每个测试都获得一个全新的数据库实例，确保隔离性。\n*   **自定义配置:** 提供自定义配置选项，如端口范围、超时和清理。\n*   **性能测试:** 方便使用真实的 PostgreSQL 功能进行性能测试。\n*   **框架隔离:** 能够针对特定框架 (SQLAlchemy 或 Django) 或目录隔离进行定向测试。\n\nPy-PGlite 的架构基于与框架无关的核心以及可选的集成，侧重于零配置、智能默认值和完美隔离。它简化了 PostgreSQL 测试，使其对 Python 开发者来说更易于访问和高效。"
  },
  {
    "id": "44205694",
    "title": "Dreams of improving the human race are no longer science fiction",
    "url": "https://www.economist.com/briefing/2025/03/20/dreams-of-improving-the-human-race-are-no-longer-science-fiction",
    "summary": "In a March 2025 article from The Economist, \"Dreams of improving the human race are no longer science fiction,\" the emergence of a \"human enhancement\" industry is explored. Driven by figures like Christian Angermayer, who was inspired by hallucinogenic experiences, this industry aims to make people stronger, smarter, and longer-lived.\n\nAngermayer's investment fund supports psychedelic drug treatments for mental health and pushes for broader human enhancement. He's also backing initiatives like a $101 million prize for anti-aging breakthroughs and the Enhanced Games, a competition where athletes are rewarded for breaking world records using performance-enhancing drugs typically banned in traditional sports.\n\nThe article suggests that while the idea of enhancing humans was once relegated to science fiction, it's becoming increasingly real, albeit still hampered by outdated regulations. The article also touches on other related topics, including evolving gender preferences, political shifts in El Salvador and Vietnam, economic concerns in Vietnam, the growing influence of cryptocurrency in American politics, and insights into Russia's arms industry.\n",
    "chinese_title": "改善人类种族的梦想不再是科幻小说。",
    "chinese_summary": "在2025年3月《经济学人》发表的题为《改善人类的梦想不再是科幻》的文章中，探讨了一个“人类增强”产业的兴起。受克里斯蒂安·安格迈尔等人的推动，此行业旨在使人们更强壮、更聪明、更长寿，安格迈尔的灵感来自于致幻体验。\n\n安格迈尔的投资基金支持用于精神健康的迷幻药物治疗，并推动更广泛的人类增强。他还支持诸如为抗衰老突破设立的1.01亿美元奖金和增强运动会等项目，后者是一项奖励运动员使用通常在传统体育运动中被禁止的兴奋剂打破世界纪录的比赛。\n\n文章表明，尽管增强人类的想法曾经被归为科幻小说，但它正变得越来越现实，尽管仍然受到过时法规的阻碍。文章还涉及其他相关话题，包括不断变化的性别偏好、萨尔瓦多和越南的政治转变、越南的经济担忧、加密货币在美国政治中日益增长的影响力以及对俄罗斯军工行业的见解。"
  },
  {
    "id": "44191620",
    "title": "The impossible predicament of the death newts",
    "url": "https://crookedtimber.org/2025/06/05/occasional-paper-the-impossible-predicament-of-the-death-newts/",
    "summary": "Doug Muir's \"The Impossible Predicament of the Death Newts\" explores the evolutionary arms race between the Rough-Skinned Newt (Taricha granulosa) and the common garter snake (Thamnophis sirtalis) in the Pacific Northwest. This newt is incredibly toxic due to the tetrodotoxin produced by bacteria in its skin, capable of killing humans.\n\nThe garter snakes have evolved resistance to this toxin, driving the newts to become even more toxic in a biological feedback loop. This toxicity comes at a metabolic cost for the newts, and resistance likely carries drawbacks for the snakes, though they are difficult to measure.\n\nGarter snakes eat the newts to sequester the tetrodotoxin in their livers, making themselves poisonous to predators. The author explains that the newts cannot evolve aposematic coloring as a warning, as it would make them easier targets for the snakes. The newts face a triple bind: they must be hyper-toxic, evolve defenses against their own toxin, and can't signal their toxicity.\n\nThe article then delves into regional variations, like less-toxic newts in Alaska (where garter snakes are scarce) and Vancouver Island, where the snake-newt relationship seems more harmonious. The author raises the possibility of the snakes evolving aposematic coloring, given their toxicity. He emphasizes that the Pacific Northwest ecosystem is young, suggesting the arms race is still evolving and not necessarily stable long-term. The piece highlights that while much is understood, mysteries surrounding this fascinating biological interaction remain.\n",
    "chinese_title": "死亡蝾螈的绝境",
    "chinese_summary": "道格·缪尔的《死亡蝾螈的困境》探讨了太平洋西北地区粗皮蝾螈（Taricha granulosa）和普通束带蛇（Thamnophis sirtalis）之间的进化军备竞赛。这种蝾螈由于其皮肤中细菌产生的河豚毒素而具有极高的毒性，能够杀死人类。\n\n束带蛇已经进化出对这种毒素的抵抗力，从而驱动蝾螈变得更具毒性，形成了一个生物反馈循环。这种毒性给蝾螈带来了代谢成本，而抵抗力可能也会给蛇带来缺陷，尽管这些缺陷难以衡量。\n\n束带蛇食用蝾螈以将河豚毒素储存在它们的肝脏中，使它们自身对捕食者有毒。作者解释说，蝾螈无法进化出警戒色作为警告，因为这会使它们更容易成为蛇的目标。蝾螈面临三重困境：它们必须具有超强的毒性，进化出针对自身毒素的防御机制，并且无法发出毒性信号。\n\n文章随后深入探讨了区域差异，例如阿拉斯加（束带蛇稀少）和温哥华岛毒性较低的蝾螈，在这些地方，蛇和蝾螈的关系似乎更加和谐。作者提出了蛇进化出警戒色的可能性，因为它们本身也具有毒性。他强调太平洋西北地区的生态系统还很年轻，表明这场军备竞赛仍在进化，并且不一定是长期稳定的。这篇文章强调，虽然人们已经了解了很多，但围绕着这种迷人的生物相互作用仍然存在着许多谜团。"
  },
  {
    "id": "44196850",
    "title": "How we’re responding to The NYT’s data demands in order to protect user privacy",
    "url": "https://openai.com/index/response-to-nyt-data-demands/",
    "summary": "OpenAI's blog post, \"How we’re responding to The NYT’s data demands in order to protect user privacy,\" outlines their response to the New York Times (NYT) regarding a copyright infringement lawsuit over OpenAI's use of NYT articles in training their large language models. The core of the response revolves around protecting user privacy and maintaining the core functionality of their AI models.\n\nOpenAI argues that they are taking steps to address the NYT's concerns, specifically regarding the reproduction of near-verbatim extracts of NYT articles by their models. They contend that these instances are rare \"bugs\" resulting from unintended model behavior, not inherent design flaws, and not indicative of widespread copyright infringement.\n\nThe company is actively working to improve their models to prevent such outputs, including implementing measures to limit the ability of models to recite or regurgitate content verbatim. However, OpenAI emphasizes that their priority is to do so *without* drastically reducing the utility and usefulness of their models for users. They are wary of changes that would broadly limit the models' ability to provide helpful and informative responses based on its training data, potentially damaging the user experience.\n\nThe post suggests that overly broad or restrictive measures demanded by the NYT could harm users more than protect the NYT's interests. OpenAI aims to strike a balance between respecting copyright concerns and upholding its commitment to providing users with the best possible AI tools. They believe this is achievable through targeted technical adjustments rather than wholesale restrictions. In essence, OpenAI is fighting to avoid crippling its models based on the NYT's data demands.\n",
    "chinese_title": "我们如何回应《纽约时报》的数据需求，以保护用户隐私",
    "chinese_summary": "OpenAI博客文章《我们如何回应纽约时报的数据要求以保护用户隐私》概述了他们对《纽约时报》(NYT)的回应，该回应涉及一起关于OpenAI在训练其大型语言模型时使用NYT文章的版权侵权诉讼。回应的核心在于保护用户隐私并维持其人工智能模型的核心功能。\n\nOpenAI辩称，他们正在采取措施解决纽约时报的担忧，特别是关于其模型几乎逐字复制纽约时报文章摘录的问题。他们认为这些情况是罕见的“漏洞”，是模型意外行为的结果，而不是固有的设计缺陷，也不能表明存在广泛的版权侵权行为。\n\n该公司正在积极改进其模型以防止此类输出，包括实施措施以限制模型逐字背诵或重复内容的能力。然而，OpenAI强调，他们的首要任务是在*不*大幅降低其模型对用户的效用和有用性的前提下做到这一点。他们担心，广泛限制模型根据其训练数据提供有帮助和信息丰富的响应能力的更改可能会损害用户体验。\n\n该文章表明，纽约时报要求的过于宽泛或限制性的措施可能弊大于利。OpenAI旨在在尊重版权问题和坚持为用户提供最佳人工智能工具的承诺之间取得平衡。他们认为，通过有针对性的技术调整，而不是全面的限制，这是可以实现的。本质上，OpenAI正在努力避免因纽约时报的数据要求而削弱其模型。"
  },
  {
    "id": "44205317",
    "title": "The Agentic Systems Series",
    "url": "https://gerred.github.io/building-an-agentic-system/",
    "summary": "The \"Agentic Systems Series\" is a comprehensive guide designed to help engineers build production-ready AI coding assistants. This three-book series dives into the patterns, architectures, and engineering decisions behind effective AI coding tools, drawing on real-world examples like Amp, Claude Code, and anon-kode.\n\n**Book 1: Building an Agentic System** focuses on the foundations of building a single-user AI coding agent, covering core architecture, tool systems, permission models, parallel execution, and command systems.\n\n**Book 2: Amping Up an Agentic System** explores how to scale single-user agents into enterprise-ready collaborative platforms, addressing scalable architecture, authentication, collaboration patterns, enterprise features, advanced orchestration, and production strategies.\n\n**Book 3: Contextualizing an Agentic System** delves into advanced tool systems and context management, covering tool system architecture, command system design, and how to maintain conversational context.\n\nThe series is targeted at systems engineers, platform teams, technical leaders, and researchers interested in AI-powered development tools. It requires familiarity with system design, basic AI/LLM integration, and some experience with backend technologies.\n\nThe series offers architectural patterns, implementation strategies, decision frameworks, code examples, and real-world case studies, all derived from extensive analysis of production systems.\n\nThe author, Gerred, is a systems engineer with experience in AI and infrastructure, including work on CNCF projects, Kubernetes, and AI system deployments in regulated environments. He offers consulting services and encourages support for his research.\n",
    "chinese_title": "能动系统系列",
    "chinese_summary": "\"自主代理系统系列\" 是一套旨在帮助工程师构建可用于生产环境的 AI 编码助手的综合指南。这套共三册的书籍深入探讨了高效 AI 编码工具背后的模式、架构和工程决策，并借鉴了 Amp、Claude Code 和 anon-kode 等真实案例。\n\n**第一册：构建自主代理系统** 专注于构建单用户 AI 编码代理的基础，涵盖核心架构、工具系统、权限模型、并行执行和命令系统。\n\n**第二册：增强自主代理系统** 探讨如何将单用户代理扩展到企业级协作平台，解决可扩展架构、身份验证、协作模式、企业功能、高级编排和生产策略等问题。\n\n**第三册：情境化自主代理系统** 深入研究高级工具系统和上下文管理，涵盖工具系统架构、命令系统设计以及如何维护对话上下文。\n\n本系列面向对 AI 驱动的开发工具有兴趣的系统工程师、平台团队、技术领导者和研究人员。它要求读者熟悉系统设计、基本的 AI/LLM 集成以及一些后端技术经验。\n\n本系列提供架构模式、实施策略、决策框架、代码示例和真实案例研究，所有这些都源于对生产系统的广泛分析。\n\n作者 Gerred 是一位在 AI 和基础设施方面拥有经验的系统工程师，包括参与 CNCF 项目、Kubernetes 以及在受监管环境中部署 AI 系统。他提供咨询服务，并鼓励读者支持他的研究。"
  },
  {
    "id": "44199437",
    "title": "The Coleco Adam Computer",
    "url": "https://dfarq.homeip.net/coleco-adam-computer/",
    "summary": "Dave Farquhar's article explores the rise and fall of the Coleco Adam computer, a 1983 attempt by toy maker Coleco to break into the home computer market. Unveiled with high expectations, the Adam promised a complete system including 80K RAM, a full-travel keyboard, tape storage, a daisywheel printer, and software, all for $525 (later $725). This aimed to compete with Commodore, particularly by offering a \"ready to go\" system unlike the barebones Commodore 64. It also offered compatibility with the ColecoVision game console.\n\nHowever, the Adam was plagued with problems. Coleco struggled to meet production deadlines, and the initial units suffered from a high defect rate. Design flaws included unreliable data packs (tape-based storage), a loud and slow printer that housed the entire system's power supply, and mixed reviews from critics who liked the keyboard and print quality but disliked the power supply placement.\n\nFurthermore, Commodore resolved its supply issues, offering a comparable system for a similar price. Commodore's ability to manufacture its own chips gave it a pricing advantage. Ultimately, Coleco lost almost $50 million and discontinued the Adam in early 1985, selling only 300,000-400,000 units. The entire company went out of business in 1988.\n\nDespite its failure, the Adam maintained a cult following and conceptually resembled successful MSX computers in Japan. Farquhar speculates that had Coleco delivered a functional Adam on time, it could have significantly impacted the computer market, possibly even attracting clones and shifting the competitive landscape. The article also highlights an interesting side effect of the Adam's launch: it indirectly led to the break down in negotiations between Atari and Nintendo, leading to the NES not being produced by Atari.\n",
    "chinese_title": "科莱寇亚当电脑",
    "chinese_summary": "戴夫·法夸尔的文章探讨了科莱寇亚当电脑的兴衰。这款1983年由玩具制造商科莱寇推出的产品，旨在打入家用电脑市场。亚当电脑发布时备受期待，承诺提供一套完整的系统，包括80K内存、全尺寸键盘、磁带存储、菊花式打印机和软件，总价525美元（后涨至725美元）。它的目标是与Commodore竞争，特别是通过提供一种“开箱即用”的系统，这与Commodore 64的裸机不同。它还提供了与 ColecoVision 游戏机的兼容性。\n\n然而，亚当电脑问题缠身。科莱寇难以按时完成生产，最初的设备存在很高的缺陷率。设计缺陷包括不可靠的数据包（基于磁带的存储）、一个噪音大且速度慢的打印机（该打印机容纳了整个系统的电源），以及褒贬不一的评论。评论家喜欢键盘和打印质量，但不喜欢电源的位置。\n\n此外，Commodore解决了其供应问题，以相似的价格提供了一套可比的系统。Commodore制造自己的芯片的能力使其在定价方面具有优势。最终，科莱寇损失了近5000万美元，并在1985年初停止生产亚当电脑，仅售出30万至40万台。整个公司于1988年倒闭。\n\n尽管亚当电脑失败了，但它仍然拥有一批狂热的追随者，并且在概念上类似于日本成功的MSX电脑。法夸尔推测，如果科莱寇能及时交付一台功能正常的亚当电脑，它可能会对电脑市场产生重大影响，甚至可能吸引克隆产品并改变竞争格局。文章还强调了亚当电脑发布的一个有趣的副作用：它间接导致了雅达利和任天堂之间谈判的破裂，导致 NES 没有由雅达利生产。"
  },
  {
    "id": "44203870",
    "title": "A Rippling Townhouse Facade by Alex Chinneck Takes a Seat in a London Square",
    "url": "https://www.thisiscolossal.com/2025/05/alex-chinneck-a-week-at-the-knees/",
    "summary": "British artist Alex Chinneck has unveiled \"A week at the knees,\" a striking public sculpture in London's Charterhouse Square for Clerkenwell Design Week. Drawing inspiration from his 2013 work \"From the Knees of my Nose to the Belly of my Toes,\" which appeared to show a townhouse facade sliding off, this new installation playfully reimagines a classic Georgian facade.\n\nThe sculpture is constructed from 320 meters of repurposed steel and 7,000 bricks. It depicts the lower two levels of a building facade rippling and bending over a pathway, creating the impression of a building \"seated\" with its knees up. This anthropomorphic approach invites visitors to interact with the piece as a unique portal within London's famous green spaces.\n\nMeasuring five meters tall, weighing 12 tons, and only 15 centimeters thick, the sculpture expertly mimics a life-size building with a surprisingly lightweight aesthetic. Chinneck collaborated with numerous British companies to fabricate the piece, sourcing bespoke steel beams, curved windows, and bricks. The final result is an architectonic structure that balances heft with a graceful, playful personality. The artwork will be on view in London through June.\n",
    "chinese_title": "亚历克斯·奇内克在伦敦广场打造的波纹联排别墅立面",
    "chinese_summary": "英国艺术家Alex Chinneck在伦敦Charterhouse广场为克勒肯维尔设计周揭幕了引人注目的公共雕塑作品“跪姿一周”。该作品从他2013年的作品“从我的鼻子到脚趾的膝盖”中汲取灵感，后者似乎展现了一栋联排别墅的正面滑落，而这个新装置则以一种俏皮的方式重新构想了一个经典的乔治亚风格的建筑立面。\n\n这个雕塑由320米长的再生钢材和7000块砖砌成。它描绘了一栋建筑立面的下两层在一条小路上弯曲和弯曲，创造了一种建筑“坐着”，膝盖抬起的印象。这种拟人化的方法邀请游客将这件作品作为一个独特的门户，与伦敦著名的绿地互动。\n\n这座雕塑高五米，重达12吨，厚度仅为15厘米，巧妙地模仿了一个真人大小的建筑物，并具有令人惊讶的轻量化美感。Chinneck与众多英国公司合作制造了该作品，采购了定制的钢梁、弧形窗户和砖块。最终的结果是一个建筑结构，它在重量和优雅、俏皮的个性之间取得了平衡。这件艺术品将在伦敦展出至六月。"
  },
  {
    "id": "44194468",
    "title": "I made a search engine worse than Elasticsearch (2024)",
    "url": "https://softwaredoug.com/blog/2024/08/06/i-made-search-worse-elasticsearch",
    "summary": "Doug Turnbull details his experience of building a full-text search library for Pandas, called SearchArray, and benchmarking it against Elasticsearch using the BEIR Information Retrieval benchmarks, specifically the MSMarco Passage Retrieval corpus. He humorously shares his disappointment that SearchArray performed worse than Elasticsearch in almost every aspect: NDCG@10 (a relevance metric), search throughput (queries per second), and indexing throughput (documents per second).\n\nTurnbull then delves into the reasons behind the performance gap. A key difference lies in how Elasticsearch utilizes algorithms like Weak-AND (WAND) to optimize search by focusing on high-impact, rare terms and selectively scanning document lists. SearchArray, on the other hand, naively calculates BM25 scores for all documents, leading to inefficiency.\n\nHe also explains SearchArray's internal architecture, which uses a positional index based on roaring bitmaps primarily designed for phrase matching. While this system allows for calculating term frequencies, it's less efficient than the postings lists used by Elasticsearch. Furthermore, SearchArray doesn't implement aggressive caching strategies for BM25 components or entire queries, unlike dedicated search engines.\n\nThe author concludes that SearchArray is suitable for prototyping and smaller datasets, acknowledging the complexity and sophistication of large-scale search engines like Elasticsearch, Solr, and Vespa. He emphasizes the value of the work done by search engineers and suggests that tools enabling a more dataframe-oriented DSL for query building and optimization would be beneficial. Finally, he promotes his course on applying LLMs to search.\n",
    "chinese_title": "我做了一个比Elasticsearch还差的搜索引擎 (2024)",
    "chinese_summary": "Doug Turnbull详细介绍了构建 Pandas 全文搜索库 SearchArray 的经验，并使用 BEIR 信息检索基准，特别是 MSMarco Passage Retrieval 语料库，将其与 Elasticsearch 进行了基准测试。他幽默地分享了 SearchArray 在几乎所有方面都比 Elasticsearch 表现更差的失望：NDCG@10（相关性指标）、搜索吞吐量（每秒查询次数）和索引吞吐量（每秒文档数）。\n\nTurnbull 随后深入研究了性能差距背后的原因。一个关键区别在于 Elasticsearch 如何利用 Weak-AND (WAND) 等算法来优化搜索，通过关注高影响力、稀有词项并选择性地扫描文档列表。另一方面，SearchArray 天真地计算所有文档的 BM25 分数，导致效率低下。\n\n他还解释了 SearchArray 的内部架构，该架构使用基于 roaring bitmap 的位置索引，主要为短语匹配而设计。虽然该系统允许计算词频，但它不如 Elasticsearch 使用的倒排列表高效。此外，与专用搜索引擎不同，SearchArray 没有为 BM25 组件或整个查询实施积极的缓存策略。\n\n作者总结说，SearchArray 适用于原型设计和较小的数据集，并承认了 Elasticsearch、Solr 和 Vespa 等大型搜索引擎的复杂性和精妙之处。他强调了搜索工程师所做工作的价值，并认为能够为查询构建和优化提供更面向 dataframe 的 DSL 的工具将是有益的。最后，他宣传了他关于将 LLM 应用于搜索的课程。"
  },
  {
    "id": "44208960",
    "title": "What Is OAuth and How Does It Work?",
    "url": "https://fusionauth.io/articles/oauth/modern-guide-to-oauth",
    "summary": "This article provides a comprehensive overview of OAuth 2.0, focusing on practical application and real-world integrations rather than just theoretical specifications. It explains that OAuth allows applications to delegate authentication and authorization to another service, improving security and user experience compared to directly requesting credentials.\n\nThe core of the article revolves around defining and explaining eight common \"OAuth modes,\" which are different ways OAuth can be implemented. These modes include:\n\n*   **Local Login and Registration:** Using an OAuth server you control for local authentication.\n*   **Third-party Login and Registration:** Utilizing services like Facebook or Google for user authentication, often granting access to user data.\n*   **First-party Login and Registration (Reverse Federated Identity):** Building a platform and allowing other developers access to your services using user logins\n*   **Enterprise Login and Registration:** Catering to enterprise customers by integrating with SAML and other enterprise authentication systems.\n*   **Third-party Service Authorization:** Accessing third-party services on behalf of users.\n*   **First-party Service Authorization:** Similar to third-party, but for your own APIs.\n*   **Machine-to-Machine Authentication and Authorization:** Secure communication between services without user involvement.\n*   **Device Login and Registration:** Enabling login from devices with limited input capabilities like TVs.\n\nThe article helps readers determine the appropriate OAuth mode based on their specific needs, such as outsourcing authentication, avoiding password storage, or facilitating service-to-service communication. It uses a \"ToDo List\" application example to illustrate the flow of Local Login and Registration and Third-party Login and Registration.\n",
    "chinese_title": "什么是OAuth及其工作原理？",
    "chinese_summary": "本文全面概述了 OAuth 2.0，侧重于实际应用和真实场景的集成，而不仅仅是理论规范。它解释了 OAuth 如何允许应用程序将身份验证和授权委托给其他服务，从而提高安全性并改善用户体验，而无需直接请求凭据。\n\n文章的核心在于定义和解释八种常见的“OAuth 模式”，这些模式代表了 OAuth 的不同实现方式。这些模式包括：\n\n*   **本地登录和注册：** 使用您控制的 OAuth 服务器进行本地身份验证。\n*   **第三方登录和注册：** 利用 Facebook 或 Google 等服务进行用户身份验证，通常会授予对用户数据的访问权限。\n*   **第一方登录和注册（反向联邦身份）：** 构建一个平台，并允许其他开发者使用用户登录来访问您的服务。\n*   **企业登录和注册：** 通过与 SAML 和其他企业身份验证系统集成，满足企业客户的需求。\n*   **第三方服务授权：** 代表用户访问第三方服务。\n*   **第一方服务授权：** 类似于第三方授权，但用于您自己的 API。\n*   **机器对机器的身份验证和授权：** 无需用户参与即可实现服务之间的安全通信。\n*   **设备登录和注册：** 允许从输入能力有限的设备（如电视）进行登录。\n\n本文帮助读者根据其特定需求（例如外包身份验证、避免密码存储或促进服务间通信）确定合适的 OAuth 模式。它使用“ToDo List”应用程序示例来说明本地登录和注册以及第三方登录和注册的流程。"
  },
  {
    "id": "44205060",
    "title": "Supreme Court allows DOGE to access social security data",
    "url": "https://www.nbcnews.com/politics/supreme-court/supreme-court-trump-doge-social-security-data-access-elon-musk-rcna206515",
    "summary": "The Supreme Court, with a conservative majority, has allowed the Trump administration's Department of Government Efficiency (DOGE) to access Social Security Administration (SSA) data, overriding a lower court injunction. This decision enables DOGE, an organization founded by Elon Musk, to scrutinize SSA records, including Social Security numbers, medical records, and tax information, to modernize systems and combat waste and fraud.\n\nProgressive groups, unions, and the Alliance for Retired Americans, who filed the lawsuit challenging DOGE's access, expressed concern that this ruling could lead to the theft of Americans' personal data. White House officials hailed the decision as a victory for government modernization. Justice Ketanji Brown Jackson dissented, questioning the urgency of the intervention.\n\nIn a separate ruling, the Supreme Court also shielded DOGE from Freedom of Information Act (FOIA) requests, pausing the release of documents and deposition of DOGE administrator Amy Gleason while litigation continues. Citizens for Responsibility and Ethics in Washington expressed disappointment but were pleased discovery was allowed to proceed.\n\nThe Social Security Administration Commissioner welcomed the ruling, stating it will drive modernization and improve services for beneficiaries.\n",
    "chinese_title": "最高法院允许狗狗币访问社保数据",
    "chinese_summary": "最高法院允许特朗普政府效率部访问社保署数据，引发争议\n\n最高法院，以保守派占多数，已允许特朗普政府的政府效率部（DOGE）访问社会保障管理局（SSA）的数据，推翻了下级法院的禁令。 这项决定使由埃隆·马斯克创立的DOGE能够审查SSA的记录，包括社会保障号码、医疗记录和税务信息，以实现系统现代化并打击浪费和欺诈。\n\n进步团体、工会和美国退休人员联盟提起了诉讼，挑战DOGE的访问权限，他们对这项裁决可能导致美国人个人数据被盗表示担忧。 白宫官员称这项决定是政府现代化的胜利。 法官凯坦吉·布朗·杰克逊对此表示异议，质疑干预的紧迫性。\n\n在另一项裁决中，最高法院还保护DOGE免受《信息自由法》（FOIA）的请求，暂停发布文件和DOGE管理员艾米·格里森的取证，直到诉讼继续进行。 华盛顿公民责任与道德组织对此表示失望，但对允许继续进行调查取证感到满意。\n\n社会保障管理局局长对该裁决表示欢迎，称其将推动现代化并改善对受益人的服务。"
  },
  {
    "id": "44197961",
    "title": "How much energy does it take to think?",
    "url": "https://www.quantamagazine.org/how-much-energy-does-it-take-to-think-20250604/",
    "summary": "This article explores the energy consumption of the human brain, challenging the notion that focused thinking dramatically increases energy expenditure. Neuroscientist Sharna Jamadar's research indicates that effortful tasks only require about 5% more energy than resting brain activity. The majority of the brain's energy (95%) is dedicated to maintenance functions, such as regulating bodily systems (homeostasis) and predictive processing.\n\nThe brain, consuming 20% of the body's energy despite being only 2% of its weight, relies on ATP produced from glucose and oxygen.  Studies using PET and fMRI scans show that while active tasks increase neuronal firing in relevant brain regions, the overall energy increase is minimal. Much of the resting brain activity involves the default mode network, responsible for internal mental experiences, and maintaining homeostasis.  Jordan Theriault suggests the brain constantly predicts future needs to efficiently allocate resources.\n\nNeuroscientist Zahid Padamsey emphasizes that the feeling of mental fatigue is not due to a lack of energy but stems from an evolutionary adaptation to conserve resources.  Human ancestors evolved in calorie-scarce environments, making even small energy increases significant. The brain also optimizes energy efficiency in neuronal signaling, with firing rates and synaptic transmissions far lower than theoretically possible, prioritizing information transmission per unit of ATP consumed.  The article concludes that the human brain's large size and complexity are balanced against its energetic costs, shaping its function and efficiency.\n",
    "chinese_title": "思考需要多少能量？",
    "chinese_summary": "人类大脑的能量消耗：专注思考并未显著增加能量支出\n\n这篇文章探讨了人类大脑的能量消耗，挑战了一种观点，即专注思考会显著增加能量支出。神经科学家沙尔纳·贾马达尔的研究表明，费力的任务仅比大脑休息时的活动多消耗约5%的能量。大脑的大部分能量（95%）用于维护功能，例如调节身体系统（体内平衡）和预测处理。\n\n大脑虽然仅占体重的2%，却消耗身体20%的能量，依赖于葡萄糖和氧气产生的ATP。 使用PET和fMRI扫描的研究表明，虽然活跃的任务会增加相关脑区域的神经元放电，但整体能量增加非常小。 大部分休息时的大脑活动都涉及默认模式网络，该网络负责内部精神体验和维持体内平衡。 乔丹·特里奥认为，大脑不断预测未来的需求，以有效地分配资源。\n\n神经科学家扎希德·帕达姆西强调，精神疲劳的感觉并非源于缺乏能量，而是源于一种旨在节约资源的进化适应。 人类祖先在卡路里稀缺的环境中进化，即使是很小的能量增加也意义重大。 大脑还在神经元信号传导中优化能量效率，放电率和突触传递远低于理论上的可能性，从而优先考虑每消耗一个单位ATP的信息传输。文章总结认为，人类大脑的巨大尺寸和复杂性与其能量成本相平衡，从而塑造其功能和效率。"
  },
  {
    "id": "44201748",
    "title": "Free Gaussian Primitives at Anytime Anywhere for Dynamic Scene Reconstruction",
    "url": "https://zju3dv.github.io/freetimegs/",
    "summary": "This paper introduces FreeTimeGS, a novel approach for reconstructing dynamic 3D scenes with complex motions. The method addresses limitations in existing techniques that rely on deforming canonical Gaussian primitives, which often struggle with intricate movements. FreeTimeGS proposes a 4D representation where Gaussian primitives can exist at any time and location, providing greater flexibility in modeling dynamic scenes.\n\nKey to FreeTimeGS is assigning each Gaussian primitive a motion function that dictates its movement over time, reducing temporal redundancy. The method uses a temporal opacity function to modulate each Gaussian's influence over time. These 4D Gaussians are then regularized using a 4D regularization loss, and the rasterization is optimized through a rendering loss, enabling dynamic 3D scene reconstruction from multi-view videos.\n\nExperiments demonstrate that FreeTimeGS achieves superior rendering quality compared to other state-of-the-art methods like 4DGS, STGS and Deform-3DGS. The authors provide supplementary materials, including interactive demos, real-time rendering examples with slow-motion playback, street reconstruction demos using the Waymo dataset, and real-time VR demos on Apple Vision Pro and Meta Quest 3 to showcase the capabilities of FreeTimeGS. The code will be released for reproducibility. The authors also encourage business inquiries and collaborations.\n",
    "chinese_title": "随时随地使用自由高斯基元进行动态场景重建",
    "chinese_summary": "本文介绍FreeTimeGS，一种重建具有复杂运动的动态3D场景的新方法。该方法解决了现有技术依赖于变形规范高斯基元时遇到的局限性，这些技术通常难以处理复杂的运动。FreeTimeGS提出了一种4D表示，其中高斯基元可以存在于任何时间和位置，从而为动态场景建模提供更大的灵活性。\n\nFreeTimeGS的关键在于为每个高斯基元分配一个运动函数，该函数决定了其随时间的运动，从而减少了时间冗余。该方法使用时间不透明度函数来调节每个高斯随时间的影响。然后使用4D正则化损失来正则化这些4D高斯，并通过渲染损失来优化光栅化，从而能够从多视角视频中重建动态3D场景。\n\n实验表明，与其他最先进的方法（如4DGS、STGS和Deform-3DGS）相比，FreeTimeGS实现了卓越的渲染质量。作者提供了补充材料，包括交互式演示、具有慢动作回放的实时渲染示例、使用Waymo数据集的街道重建演示，以及在Apple Vision Pro和Meta Quest 3上的实时VR演示，以展示FreeTimeGS的功能。代码将被发布以供重现。作者还鼓励商业咨询和合作。"
  },
  {
    "id": "44208886",
    "title": "Hacking Is Necessary",
    "url": "https://scharenbroch.dev/blog/hacking-is-necessary/",
    "summary": "This article argues that \"hacking,\" defined as prioritizing speed and convenience over ideal code structure and safety, is a necessary aspect of software development. The author contends that the pursuit of perfect code, with ideals like clarity, extensibility, and safety, is an asymptotic process; reaching true perfection is impossible. Thus, developers must constantly make trade-offs between idealism and practicality.\n\nThe author uses the spectrum of type strength as a prime example. While stronger type assumptions (e.g., restricting an integer to a specific range) can improve code safety and documentation, they also increase the burden of maintenance and can be overly restrictive, especially when assumptions are uncertain or hardware limitations intervene.\n\nThe piece further argues that the complex structure of code, similar to types, often needs a pragmatic approach. Refactoring, while powerful, can be time-consuming and risky. It emphasizes that sometimes, \"good enough\" is preferable to striving for an elusive ideal, particularly for \"wicked problems\" – problems so complex that a complete solution can't be planned upfront. In essence, the act of hacking acts as temporary scaffolding to help develop a real-world solution.\n\nThe conclusion advocates for deliberate hacking, acknowledging the necessity of compromise. The author encourages developers to consciously choose where to invest in ideals and where to prioritize practicality, emphasizing the importance of embracing both approaches and learning from mistakes.\n",
    "chinese_title": "黑客行为是必要的",
    "chinese_summary": "本文认为，“黑客式开发”（定义为优先考虑速度和便利性，而非理想的代码结构和安全性）是软件开发中一个必要的方面。作者认为，追求完美代码（以清晰性、可扩展性和安全性等理想为目标）是一个渐近过程，真正达到完美是不可能的。因此，开发人员必须不断在理想主义和实用主义之间做出权衡。\n\n作者以类型强度为例说明。虽然更强的类型假设（例如，将整数限制在特定范围内）可以提高代码安全性和文档质量，但也会增加维护负担，并且可能过于严格，尤其是在假设不确定或硬件限制介入时。\n\n文章进一步认为，类似于类型，代码的复杂结构通常也需要务实的方法。重构虽然强大，但可能非常耗时且有风险。文章强调，有时“足够好”比追求难以捉摸的理想更好，特别是对于“棘手的问题”——那些复杂到无法预先规划完整解决方案的问题。本质上，黑客式开发充当了临时支架，以帮助开发实际的解决方案。\n\n结论提倡有意识的黑客式开发，承认妥协的必要性。作者鼓励开发人员有意识地选择在哪里投入理想，在哪里优先考虑实用性，强调同时拥抱两种方法并从错误中学习的重要性。"
  },
  {
    "id": "44208985",
    "title": "Shirt Without Stripes (2021)",
    "url": "https://github.com/elsamuko/Shirt-without-Stripes",
    "summary": "This document, titled \"Shirt Without Stripes (2021),\" seems to be a compilation of search results and links related to the query \"shirt without stripes\" across various platforms.\n\nThe first section lists search results for \"shirt without stripes\" on Google, Amazon, and Bing, suggesting the document's purpose is to track down information or products related to plain shirts.\n\nThe rest of the document then provides links to resources categorized under the headings \"AI/ML\" and \"Assistants\" for Amazon, Microsoft, and Google. This suggests a possible association or tangential connection between the shirt search and these technologies. Perhaps these platforms are being used to facilitate or analyze the shirt search in some way.\n\nFinally, the document lists Amazon, Bing, Google, and a link to a Hacker News (news.ycombinator.com) thread. The inclusion of the Hacker News thread suggests that there might be a discussion or commentary surrounding the topic of \"shirt without stripes\" or potentially related issues within the tech community.\n\nIn summary, the document appears to be a collection of search results, related tech resources, and a discussion forum link possibly connected to the initial search query for a plain shirt. The specific connection between the shirt search and the AI/ML/Assistant links remains unclear without further context.\n",
    "chinese_title": "没有条纹的衬衫 (2021)",
    "chinese_summary": "名为“无条纹衬衫（2021）”的这份文档，似乎是对各平台关于搜索词“无条纹衬衫”的搜索结果和链接的汇编。\n\n第一部分列出了在谷歌、亚马逊和必应上搜索“无条纹衬衫”的结果，表明该文档的目的是追踪与纯色衬衫相关的信息或产品。\n\n文档的其余部分提供了在“AI/ML”和“助手”标题下分类的亚马逊、微软和谷歌资源的链接。这表明衬衫搜索与这些技术之间可能存在关联或间接联系。也许这些平台被用于以某种方式促进或分析衬衫搜索。\n\n最后，文档列出了亚马逊、必应、谷歌，以及一个 Hacker News (news.ycombinator.com) 线程的链接。包含 Hacker News 线程表明，技术社区中可能存在围绕“无条纹衬衫”主题或潜在相关问题的讨论或评论。\n\n总而言之，该文档似乎是搜索结果、相关技术资源以及可能与最初的纯色衬衫搜索查询相关的讨论论坛链接的集合。在没有进一步背景信息的情况下，衬衫搜索与 AI/ML/助手链接之间的具体联系仍然不清楚。"
  },
  {
    "id": "44197932",
    "title": "Self-hosting your own media considered harmful according to YouTube",
    "url": "https://www.jeffgeerling.com/blog/2025/self-hosting-your-own-media-considered-harmful",
    "summary": "The author recounts receiving two community guidelines strikes on YouTube, one for a video demonstrating LibreELEC on a Raspberry Pi 5 for 4K video playback, and another previously for showcasing Jellyfin. YouTube flagged these as promoting unauthorized access to paid content, despite the author emphasizing their legal acquisition of media and avoidance of piracy tools. The author primarily uses the software to self-host a legally acquired media library.\n\nThe author questions YouTube's judgment, highlighting that the LibreELEC video had been live for over a year with a million views before being flagged. The author appealed, but the appeal was initially denied, with YouTube seemingly considering open-source media management as \"harmful.\" Following public outcry, the LibreELEC video was reinstated.\n\nThe author has re-uploaded the video to Internet Archive and Floatplane. The author explores alternatives to YouTube, like PeerTube, but acknowledges the challenges in achieving sustainable content production due to a smaller audience and limited funding options.\n\nThe author also expresses concern over YouTube's AI summaries, suggesting potential misuse of content in AI models. The comment section highlights issues with false copyright claims, the power imbalances favoring large media companies, and the need for fairer regulations and competition in the content-sharing landscape. Various users suggest Rumble and Odysee as alternative platforms, while others express reservations about those platforms and the sustainability of Floatplane's business model.\n",
    "chinese_title": "根据 YouTube 的说法，自行托管媒体被认为是有害的",
    "chinese_summary": "作者叙述了在YouTube上收到两次社区准则警告，一次是关于一个演示在Raspberry Pi 5上使用LibreELEC播放4K视频的视频，另一次是之前关于展示Jellyfin的视频。尽管作者强调其媒体来源合法且避免使用盗版工具，YouTube仍将这些视频标记为宣传未经授权访问付费内容。作者主要使用这些软件来托管合法获取的媒体库。\n\n作者质疑YouTube的判断，强调LibreELEC视频已经上线一年多，拥有百万观看量后才被标记。作者提出申诉，但最初被驳回，YouTube似乎认为开源媒体管理是“有害的”。在公众强烈抗议后，LibreELEC视频被恢复。\n\n作者已将该视频重新上传到Internet Archive和Floatplane。作者正在探索YouTube的替代方案，如PeerTube，但也承认由于受众较小和资金选择有限，难以实现可持续的内容制作。\n\n作者还对YouTube的AI摘要表示担忧，认为内容可能被滥用于AI模型。评论区强调了虚假版权声明、大型媒体公司拥有的权力失衡，以及内容分享领域需要更公平的监管和竞争等问题。许多用户建议使用Rumble和Odysee作为替代平台，而另一些用户则对这些平台以及Floatplane商业模式的可持续性表示保留。"
  },
  {
    "id": "44195354",
    "title": "Defending adverbs exuberantly if conditionally",
    "url": "https://countercraft.substack.com/p/defending-adverbs-exuberantly-if",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "有条件地热情捍卫副词",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44196433",
    "title": "Show HN: Ask-human-mcp – zero-config human-in-loop hatch to stop hallucinations",
    "url": "https://masonyarbrough.com/blog/ask-human",
    "summary": "The article describes \"ask-human-mcp,\" a zero-configuration solution to prevent hallucinations in Large Language Models (LLMs) by incorporating a human-in-the-loop (HITL) mechanism. The core idea is to insert a human verification step when the LLM's confidence in its answer falls below a certain threshold.\n\nThe system monitors the LLM's \"belief\" or confidence score in its generated responses. If this confidence is high, the LLM's answer is passed directly to the user. However, if the confidence is low, the question is routed to a human reviewer for validation or correction. This prevents the LLM from confidently presenting incorrect information (hallucinations).\n\nThe article emphasizes the \"zero-configuration\" aspect, suggesting easy integration and minimal setup requirements. The system aims to strike a balance between automation and human intervention, optimizing for accuracy while minimizing human effort. The \"mcp\" in the name likely refers to \"minimum critical path,\" indicating that the human intervention is only triggered when absolutely necessary.\n\nThe article further suggests the tool is designed to be a \"hatch\" – a mechanism to catch potential errors before they reach the end-user, thus improving the overall reliability and trustworthiness of LLM-powered applications. It aims to provide a more robust and dependable experience by leveraging human judgment strategically. The author likely promotes this tool as a practical and readily deployable solution for mitigating the pervasive problem of LLM hallucinations.\n",
    "chinese_title": "Show HN: Ask-human-mcp – 零配置人机协作舱，阻止幻觉",
    "chinese_summary": "本文介绍了一种名为“ask-human-mcp”的零配置方案，通过引入人机协作（HITL）机制来防止大型语言模型（LLM）产生幻觉。其核心思想是在LLM对其答案的置信度低于特定阈值时，插入人工验证步骤。\n\n该系统监控LLM对其生成回复的“信念”或置信度评分。如果置信度高，LLM的答案将直接传递给用户。但是，如果置信度低，问题将被路由到人工审核员进行验证或更正。这可以防止LLM自信地呈现不正确的信息（幻觉）。\n\n本文强调了“零配置”方面，表明易于集成且设置要求极低。该系统旨在在自动化和人工干预之间取得平衡，优化准确性，同时最大限度地减少人工工作。名称中的“mcp”可能指的是“最小关键路径”，表明仅在绝对必要时才会触发人工干预。\n\n本文还表明，该工具旨在成为一个“舱口”——一种在潜在错误到达最终用户之前捕获它们的机制，从而提高LLM驱动应用程序的整体可靠性和可信度。它旨在通过战略性地利用人类判断来提供更强大、更可靠的体验。作者可能将此工具推广为一种实用且易于部署的解决方案，用于缓解LLM幻觉这一普遍问题。"
  },
  {
    "id": "44199592",
    "title": "Jepsen: TigerBeetle 0.16.11",
    "url": "https://jepsen.io/analyses/tigerbeetle-0.16.11",
    "summary": "This Jepsen report investigates the safety of TigerBeetle, a high-performance, fault-tolerant OLTP database designed for financial applications. TigerBeetle focuses on double-entry accounting, storing accounts and transfers with strong emphasis on speed and reliability. It uses Viewstamped Replication (VR) and claims to offer Strong Serializability even with replica failure.\n\nThe report highlights TigerBeetle's unique features, including a single-node write core for high contention workloads, extensive fault tolerance mechanisms (ECC RAM assumption, process/clock/storage/network fault handling with checksums and multi-copy writes), and automatic, coordinated upgrades across the cluster.\n\nThe Jepsen tests aimed to verify Strong Serializability by constructing a test suite utilizing Jepsen's property-based testing and fault injection capabilities (versions 0.16.11 through 0.16.30). A key challenge was adapting Jepsen's standard checks for lists/sets/registers to TigerBeetle's domain-specific data model (accounts and transfers). They bypassed the limitation by checking that the apparent timestamps of operations are Strong Serializable and the semantics of those operations, when executed in timestamp order, make sense.\n\nThe testing strategy focused on a two-phase approach: a main phase with read/write operations and a final read phase to observe the effects of writes and infer their timestamps. By analyzing the inferred timestamps and comparing them with known successful writes, the researchers aimed to identify deviations from Strong Serializability. The article only details the test design as the rest of the report is not provided.\n",
    "chinese_title": "Jepsen：TigerBeetle 0.16.11",
    "chinese_summary": "此 Jepsen 报告调查了 TigerBeetle 的安全性，TigerBeetle 是一款高性能、容错的 OLTP 数据库，专为金融应用设计。TigerBeetle 专注于复式记账，以速度和可靠性为重点存储账户和转账数据。它使用 Viewstamped Replication (VR)，并声称即使在副本发生故障的情况下也能提供强可串行化。\n\n该报告强调了 TigerBeetle 的独特功能，包括用于高争用工作负载的单节点写入核心、广泛的容错机制（ECC RAM 假设、通过校验和和多副本写入处理进程/时钟/存储/网络故障）以及跨集群的自动协调升级。\n\nJepsen 测试旨在通过构建一个测试套件来验证强可串行化，该套件利用 Jepsen 基于属性的测试和故障注入功能（版本 0.16.11 到 0.16.30）。一个关键挑战是将 Jepsen 的标准列表/集合/寄存器检查适应 TigerBeetle 的特定领域数据模型（账户和转账）。他们通过检查操作的明显时间戳是否具有强可串行性以及这些操作按时间戳顺序执行时的语义是否合理，绕过了这个限制。\n\n测试策略侧重于一个两阶段的方法：一个包含读/写操作的主阶段和一个用于观察写入效果并推断其时间戳的最终读取阶段。通过分析推断的时间戳并将其与已知的成功写入进行比较，研究人员旨在识别与强可串行化的偏差。 本文仅详细介绍了测试设计，报告的其余部分未提供。"
  },
  {
    "id": "44207055",
    "title": "Show HN: Cpdown – Copy any webpage/YouTube subtitle as clean Markdown(LLM-ready)",
    "url": "https://github.com/ysm-dev/cpdown",
    "summary": "Cpdown is a browser extension that streamlines the process of copying webpage content and YouTube subtitles as clean, LLM-ready Markdown. It aims to improve upon typical \"copy-paste\" functionality by cleaning and formatting content for LLM use cases.\n\nKey features include one-click (or keyboard shortcut) copying of webpage content and YouTube subtitles, automatic content extraction using Defuddle or Mozilla's Readability, removal of unnecessary HTML elements, and token counting for LLM applications. It offers options to wrap the copied content in triple backticks for enhanced readability, display a success toast, and even a Raycast confetti animation upon successful copying.\n\nCurrently available for Chrome, with a Firefox version \"coming soon,\" Cpdown can be installed from the Chrome Web Store or manually by cloning the repository, installing dependencies with Bun, building the extension, and loading the unpacked directory in Chrome's extension settings.\n\nThe extension offers configuration options, including the ability to choose between Defuddle and Mozilla Readability for content extraction, and toggling visual feedback (toast, confetti).\n\nCpdown is built using a variety of tools and frameworks including Cursor, WXT, React, Shadcn UI, Sonner, Tailwind CSS, Defuddle, Mozilla Readability, Turndown, and tiktoken. The extension is licensed under the MIT license.\n",
    "chinese_title": "Show HN: Cpdown – 将任何网页/YouTube字幕复制为干净的Markdown格式(LLM就绪)",
    "chinese_summary": "Cpdown 浏览器扩展程序简化了将网页内容和 YouTube 字幕复制为干净、可用于 LLM 的 Markdown 格式的过程。它旨在通过清理和格式化内容以供 LLM 使用，从而改进典型的“复制-粘贴”功能。\n\n主要功能包括一键（或键盘快捷键）复制网页内容和 YouTube 字幕、使用 Defuddle 或 Mozilla 的 Readability 自动提取内容、删除不必要的 HTML 元素以及为 LLM 应用进行 token 计数。它提供选项将复制的内容包装在三个反引号中以增强可读性，显示成功提示，甚至在成功复制后显示 Raycast 五彩纸屑动画。\n\n目前可用于 Chrome，Firefox 版本“即将推出”，Cpdown 可以从 Chrome 网上应用店安装，也可以通过克隆存储库、使用 Bun 安装依赖项、构建扩展程序，然后在 Chrome 的扩展程序设置中加载解压缩的目录来手动安装。\n\n该扩展程序提供配置选项，包括选择 Defuddle 和 Mozilla Readability 用于内容提取的能力，以及切换视觉反馈（提示、五彩纸屑）。\n\nCpdown 使用各种工具和框架构建，包括 Cursor、WXT、React、Shadcn UI、Sonner、Tailwind CSS、Defuddle、Mozilla Readability、Turndown 和 tiktoken。该扩展程序根据 MIT 许可证获得许可。"
  },
  {
    "id": "44204916",
    "title": "Semi-Sync Meetings: Stop Wasting Our Time",
    "url": "https://lukebechtel.com/blog/semi-sync-meetings-stop-wasting-our-time",
    "summary": "Luke Bechtel argues that most meetings are inefficient, single-threaded processes that waste time and talent. AI notetaking isn't a solution; a structural change is needed: semi-synchronous meetings. These begin with silent, parallel work in a shared document before transitioning to focused discussion.\n\nThe author highlights the problems of synchronous meetings: serial processing (only one person speaking at a time), hierarchy bias (senior voices dominating), and accountability theater (vague ownership).\n\nThe semi-synchronous solution involves a \"Semi-Sync Phase\" (10-15 minutes) where everyone silently collaborates in a shared document (Notion, Miro, or Jira), followed by a \"Sync Phase\" (15-20 minutes) for focused discussion of flagged items. The facilitator guides the process, monitoring the document, adding structure, and taking notes. Participants add information, comment on others' input, flag items for discussion, and respond to comments.\n\nThe article suggests specific formats for sprint planning, retrospectives, design reviews, brainstorming, and status updates. This approach leverages parallel thinking, promotes equal participation, builds documentation in real-time, and accelerates convergence.\n\nHe also suggests extending this by integrating pre-meeting async work.\n\nAddressing objections, the author acknowledges initial awkwardness but emphasizes the increased productivity and contribution from quieter team members. He urges readers to experiment with this approach for one meeting type and track the results.\n",
    "chinese_title": "半同步会议：别再浪费时间",
    "chinese_summary": "卢克·贝克特尔认为，大多数会议都是低效、单线程的过程，浪费时间和人才。AI笔记并非解决方案，需要的是结构性变革：半同步会议。这种会议开始于共享文档中的静默并行工作，然后过渡到专注讨论。\n\n作者强调了同步会议的问题：串行处理（一次只能一人发言）、等级偏见（资深声音主导）和问责制表演（模糊的责任归属）。\n\n半同步解决方案包括一个“半同步阶段”（10-15分钟），在此阶段，每个人都在共享文档（Notion、Miro或Jira）中静默协作，随后进入“同步阶段”（15-20分钟），针对标记的项目进行专注讨论。主持人引导流程，监控文档，添加结构，并做笔记。参与者添加信息，评论他人的输入，标记需要讨论的项目，并回复评论。\n\n文章针对 sprint 计划、回顾、设计评审、头脑风暴和状态更新提出了具体的会议形式建议。这种方法利用并行思考，促进平等参与，实时构建文档，并加速收敛。\n\n他还建议通过整合会前异步工作来扩展这种方法。\n\n对于反对意见，作者承认最初会有些尴尬，但强调了更高生产力以及更安静的团队成员的贡献。他敦促读者尝试将这种方法应用于一种会议类型，并跟踪结果。"
  },
  {
    "id": "44201072",
    "title": "Top researchers leave Intel to build startup with 'the biggest, baddest CPU'",
    "url": "https://www.oregonlive.com/silicon-forest/2025/06/top-researchers-leave-intel-to-build-startup-with-the-biggest-baddest-cpu.html",
    "summary": "A group of top chip architects, formerly of Intel, have left to form a startup called AheadComputing, based in Beaverton, Oregon. Led by CEO and co-founder Debbie Marr, the company aims to build a powerful CPU based on the open-source RISC-V architecture, diverging from Intel's proprietary x86 design. The founders believe that the shift towards specialized \"chiplets\" and open standards provides an opportunity for smaller, agile companies to innovate in the semiconductor industry.\n\nAheadComputing's focus on RISC-V allows for customized chip designs and efficient processing, potentially attracting clients like Google, Amazon, and Samsung. The company has already raised $22 million in venture capital and added semiconductor expert Jim Keller to its board. While RISC-V has traditionally been used in embedded systems, AheadComputing aims to adapt it for PCs, laptops, and data centers.\n\nThe move reflects a broader trend of Intel alumni starting new chip businesses in Oregon, contributing to the state's evolving semiconductor ecosystem. The article emphasizes that while Intel remains a dominant force, its recent challenges and layoffs have created space for innovative startups like AheadComputing to emerge and potentially drive the future of microprocessor technology. The founders believe their smaller size and focused approach will allow them to move faster and be more disruptive than they could within a large corporation like Intel.\n",
    "chinese_title": "顶尖研究人员离开英特尔，打造拥有“最强大CPU”的初创公司",
    "chinese_summary": "一群前英特尔顶级芯片架构师离职，在俄勒冈州比弗顿成立了一家名为AheadComputing的初创公司。该公司由首席执行官兼联合创始人黛比·马尔领导，旨在基于开源RISC-V架构构建一款强大的CPU，与英特尔专有的x86设计不同。创始人认为，向专用“芯片组”和开放标准的转变为规模较小、灵活的公司提供了在半导体行业进行创新的机会。\n\nAheadComputing专注于RISC-V，可以实现定制化的芯片设计和高效的处理，有潜力吸引谷歌、亚马逊和三星等客户。该公司已筹集了2200万美元的风险投资，并邀请了半导体专家吉姆·凯勒加入董事会。虽然RISC-V传统上用于嵌入式系统，但AheadComputing的目标是将其应用于PC、笔记本电脑和数据中心。\n\n这一举动反映了一个更广泛的趋势，即英特尔的离职员工在俄勒冈州创办新的芯片业务，为该州不断发展的半导体生态系统做出贡献。文章强调，虽然英特尔仍然是一支主导力量，但其最近面临的挑战和裁员为AheadComputing等创新型初创公司创造了机会，使其得以涌现并有可能推动微处理器技术的未来发展。创始人认为，他们较小的规模和专注的策略将使他们能够比在英特尔这样的大公司内部更快地行动，更具颠覆性。"
  },
  {
    "id": "44183799",
    "title": "A proposal to restrict sites from accessing a users’ local network",
    "url": "https://github.com/explainers-by-googlers/local-network-access",
    "summary": "This document proposes a new browser feature, \"Local Network Access,\" to restrict websites from accessing a user's local network without explicit permission. Currently, websites can exploit a user's browser to attack vulnerable devices on the local network. This proposal aims to mitigate this risk by requiring websites to request user permission before making requests to private IP addresses, loopback addresses, or addresses with a \".local\" domain.\n\nThe core idea is to gate access to the local network behind a new \"local network access\" permission. If a website tries to connect to a local IP address without this permission, the browser will display a prompt asking the user for authorization. The proposal defines \"local network requests\" as requests crossing address space boundaries to more-private spaces (public -> local, public -> loopback, local -> loopback).\n\nTo facilitate existing workflows, the proposal includes a `targetAddressSpace` parameter for the `fetch()` API, allowing developers to explicitly declare that a request should be treated as going to a local or loopback address, even if it uses HTTP. This helps to address mixed content blocking issues caused by the lack of HTTPS on many local network devices. The proposal also considers integration with WebRTC, Permissions Policy, and Permissions API. Existing workflows that rely on local network access will require updates to explicitly request the permission.\n",
    "chinese_title": "限制网站访问用户本地网络的提议",
    "chinese_summary": "本文档提出一项新的浏览器功能：“本地网络访问”，以限制网站在未经明确许可的情况下访问用户的本地网络。目前，网站可以利用用户的浏览器攻击本地网络上易受攻击的设备。本提案旨在通过要求网站在向私有 IP 地址、回环地址或具有“.local”域名的地址发起请求之前请求用户许可，来缓解此风险。\n\n核心思想是通过新的“本地网络访问”权限来限制对本地网络的访问。如果网站尝试在没有此权限的情况下连接到本地 IP 地址，浏览器将显示提示，要求用户授权。本提案将“本地网络请求”定义为跨越地址空间边界到更私密空间的请求（公共 -> 本地，公共 -> 回环，本地 -> 回环）。\n\n为了方便现有工作流程，本提案为 `fetch()` API 包含了一个 `targetAddressSpace` 参数，允许开发者明确声明应将请求视为前往本地或回环地址的请求，即使它使用 HTTP。 这有助于解决由于许多本地网络设备缺乏 HTTPS 而引起的混合内容阻止问题。 本提案还考虑了与 WebRTC、权限策略和权限 API 的集成。 依赖本地网络访问的现有工作流程将需要更新以明确请求该权限。"
  },
  {
    "id": "44201736",
    "title": "Self-reported race, ethnicity don't match genetic ancestry in the U.S.: study",
    "url": "https://www.science.org/content/article/race-ethnicity-don-t-match-genetic-ancestry-according-large-u-s-study",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "美国研究表明：自述种族、族裔与基因祖源不符",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44200797",
    "title": "Small Programs and Languages",
    "url": "https://ratfactor.com/cards/pl-small",
    "summary": "This article explores the appeal of small programs, small languages, and miniature things in general, arguing they offer a unique form of understanding and control. The author highlights examples like a 25-line DOM diffing library, a 46-byte \"Forth,\" and concise language implementations such as Lisp interpreters in Lisp.\n\nThe author contends that these examples are meaningful because they reveal the minimum complexity of a concept, referencing Kolmogorov complexity. They cite instances like a ray tracer fitting on a business card or a LISP with garbage collection being only 436 bytes, arguing that these miniatures prove concepts can be grasped and held in the mind.\n\nThe article then shifts to small programming languages, contrasting assembly with higher-level languages like Forth, Lisp, Tcl, and Lua, noting the trade-off between size and expressiveness. It emphasizes the importance of simplicity over expressiveness, echoing David Ungar's sentiment.\n\nFinally, the piece delves into the general fascination with miniatures, suggesting they offer a sense of mastery, order, and control in a chaotic world. Quoting authors on miniatures, the author asserts that shrinking things down makes them more accessible, manageable, and allows for low-stakes experimentation, ultimately restoring our sense of order and worth. The article concludes by linking this attraction to the field of computer science, where individual solutions to \"little\" problems accumulate into significant advancements.\n",
    "chinese_title": "小程序与小语言",
    "chinese_summary": "本文探讨了小型程序、小型语言以及一般微型事物的吸引力，认为它们提供了一种独特的理解和控制形式。作者重点介绍了诸如一个 25 行的 DOM 差异库、一个 46 字节的“Forth”以及 Lisp 解释器用 Lisp 编写等简洁的语言实现示例。\n\n作者认为这些例子之所以有意义，是因为它们揭示了一个概念的最小复杂度，并引用了柯尔莫哥洛夫复杂度。他们引用了诸如可放在名片上的光线追踪器，或仅有 436 字节且带有垃圾回收的 LISP 实例，认为这些微型事物证明概念是可以被掌握和理解的。\n\n然后，文章转向小型编程语言，将汇编语言与 Forth、Lisp、Tcl 和 Lua 等高级语言进行对比，指出了大小和表达能力之间的权衡。它强调了简单性比表达能力更重要，呼应了 David Ungar 的观点。\n\n最后，文章深入探讨了对微型事物的一般迷恋，认为它们在混乱的世界中提供了一种掌控感、秩序感和控制感。作者引用了关于微型事物的作者的观点，断言缩小事物会使其更易于访问、更易于管理，并允许低风险的实验，最终恢复我们的秩序感和价值感。文章最后将这种吸引力与计算机科学领域联系起来，在这个领域中，解决“小”问题的个体方案会积累成重大的进步。"
  },
  {
    "id": "44200101",
    "title": "ThornWalli/web-workbench: Old operating system as homepage",
    "url": "https://github.com/ThornWalli/web-workbench",
    "summary": "ThornWalli's \"web-workbench\" project presents an interactive, emulated old operating system as a homepage. Two live instances are available: `https://lammpee.de/` and the beta version at `https://beta.lammpee.de/`.\n\nThe system offers several debugging options through GET parameters to modify the boot sequence and functionality. These include disabling the boot sequence (`?no-boot`), disabling the \"WebDOS\" sequence (`?no-webdos`), disabling cloud storage (`?no-cloud-storage`), specifying an initial command to run after boot (`?start-command`), and showing a floppy disk hint (`?no-disk`). An example shows how to disable boot and WebDOS while automatically starting the \"Synthesizer\" application.\n\nSeveral applications are available within the emulated environment and can be launched directly using the `?start-command` parameter. Examples of available applications and their corresponding URLs are: Clock, Calculator, Cloud, DocumentEditor, DocumentReader, Say, Guestbook, WebPainting, WebBasic, Synthesizer, and Moon City. Each application's URL pre-loads the specific application after the workbench environment initializes.\n",
    "chinese_title": "ThornWalli/web-workbench: 将旧操作系统作为主页",
    "chinese_summary": "ThornWalli 的 \"web-workbench\" 项目将一个交互式的、模拟的老式操作系统作为主页呈现。有两个可用实例：`https://lammpee.de/` 和测试版 `https://beta.lammpee.de/`。\n\n该系统通过 GET 参数提供多种调试选项，以修改启动顺序和功能。这些选项包括禁用启动顺序 (`?no-boot`)、禁用 \"WebDOS\" 顺序 (`?no-webdos`)、禁用云存储 (`?no-cloud-storage`)、指定启动后要运行的初始命令 (`?start-command`) 以及显示软盘提示 (`?no-disk`)。一个示例展示了如何禁用启动和 WebDOS，同时自动启动 \"Synthesizer\" 应用程序。\n\n模拟环境中提供了多个应用程序，可以使用 `?start-command` 参数直接启动。可用的应用程序及其对应 URL 的示例包括：Clock、Calculator、Cloud、DocumentEditor、DocumentReader、Say、Guestbook、WebPainting、WebBasic、Synthesizer 和 Moon City。每个应用程序的 URL 会在 workbench 环境初始化后预加载特定的应用程序。"
  },
  {
    "id": "44208161",
    "title": "iFixit says the Switch 2 is even harder to repair than the original",
    "url": "https://www.theverge.com/news/681568/ifixit-nintendo-switch-2-repairability",
    "summary": "iFixit's teardown of the Nintendo Switch 2 reveals that it's even harder to repair than the original, receiving a repairability score of 3 out of 10. Key issues include a battery heavily glued in place, soldered flash storage modules and USB-C ports, and tri-point screws hidden behind easily damaged stickers. While components like the headphone jack and cooling fan are relatively easy to remove, replacing the battery is described as an \"absolute mission.\"\n\nA significant downgrade is the gamecard reader, now soldered to the mainboard, unlike the original Switch's modular design. iFixit also highlights the use of multiple types of thermal paste, echoing concerns about potential overheating issues seen in the original Switch.\n\nEven the new Joy-Cons are harder to disassemble, a major concern given that they use the same drift-prone joystick technology as the original. This will make future repairs or joystick replacements more difficult. The lack of official repair parts or manuals from Nintendo further compounds the problem.\n",
    "chinese_title": "iFixit称Switch 2比初代更难维修。",
    "chinese_summary": "iFixit拆解任天堂Switch 2，发现其维修难度甚至高于初代，维修评分仅为3分（满分10分）。主要问题包括电池被大量胶水固定、闪存模块和USB-C接口焊接在主板上，以及隐藏在易损贴纸下的Y字螺丝。虽然耳机接口和散热风扇等组件相对容易拆卸，但更换电池被描述为“一项艰巨的任务”。\n\n一个显著的降级是游戏卡槽，现在被焊接到主板上，不像初代Switch的模块化设计。iFixit还强调使用了多种类型的散热硅脂，这引发了人们对初代Switch可能存在的过热问题的担忧。\n\n即使是新的Joy-Cons手柄也更难拆卸，考虑到它们与初代手柄一样使用容易漂移的摇杆技术，这是一个主要问题。这将使未来的维修或摇杆更换更加困难。任天堂缺乏官方维修零件或手册进一步加剧了这个问题。"
  },
  {
    "id": "44210491",
    "title": "Cloudflare Warns EU About Extensive Piracy Overblocking, Calls for Safeguards",
    "url": "https://torrentfreak.com/cloudflare-warns-eu-about-extensive-piracy-overblocking-calls-for-safeguards/",
    "summary": "Cloudflare is warning the EU against expanding automated piracy blocking measures, particularly those targeting live sports streams, arguing they lead to significant overblocking and harm legitimate internet users and businesses. The European Commission is currently evaluating its recommendation on combating online piracy and considering more robust legislation that favors advanced blocking systems.\n\nCloudflare highlights experiences in Italy, Spain, and France, where broad blocking orders have resulted in collateral damage, impacting thousands of non-targeted websites. The company specifically criticizes Italy's \"Piracy Shield\" law for massive overblocking and Spain's broad court orders that blocked millions of users from accessing legitimate sites. Cloudflare argues such measures misunderstand how the internet works and may violate EU law.\n\nInstead of expanding blocking powers, Cloudflare urges the EU to limit them, especially for core internet technologies like global DNS resolvers and VPNs, which are used for privacy and free expression. The company advocates for a multi-faceted approach focusing on transparency, safeguards, and cooperation, including prioritizing notice-and-takedown procedures, independent verification of blocking requests, transparency reports, rapid rectification of incorrect blocks, independent dispute resolution, and holding rightsholders liable for overblocking consequences. Cloudflare believes piracy requires a combination of data sharing, law enforcement, industry cooperation, and improved distribution of legal content, rather than solely relying on potentially damaging blocking measures.\n",
    "chinese_title": "Cloudflare警告欧盟注意大规模盗版过度封锁，呼吁采取保护措施",
    "chinese_summary": "Cloudflare警告欧盟勿扩大自动化盗版封锁措施，特别是针对体育赛事直播，称其会导致过度封锁，损害合法互联网用户和企业。欧盟委员会目前正在评估其打击网络盗版的建议，并考虑制定更有力的立法，以支持更先进的封锁系统。\n\nCloudflare强调了意大利、西班牙和法国的经验，这些国家的广泛封锁令导致了附带损害，影响了数千个非目标网站。该公司特别批评了意大利的“盗版盾牌”法律造成的大规模过度封锁，以及西班牙的广泛法院命令，阻止了数百万用户访问合法网站。Cloudflare认为，此类措施误解了互联网的运作方式，并可能违反欧盟法律。\n\nCloudflare敦促欧盟限制而非扩大封锁权力，特别是针对全球DNS解析器和VPN等核心互联网技术，这些技术用于保护隐私和自由表达。该公司倡导一种多方面的方法，侧重于透明度、保障措施和合作，包括优先考虑通知-移除程序、独立验证封锁请求、透明度报告、快速纠正不正确的封锁、独立争议解决，以及追究版权所有者对过度封锁后果的责任。Cloudflare认为，打击盗版需要数据共享、执法、行业合作以及改善合法内容的传播，而不是仅仅依靠可能造成损害的封锁措施。"
  },
  {
    "id": "44204767",
    "title": "Supreme Court Gives Doge Access to Social Security Data",
    "url": "https://www.bloomberg.com/news/articles/2025-06-06/supreme-court-gives-doge-access-to-social-security-data",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "最高法院允许狗狗访问社保数据",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44204603",
    "title": "Online sports betting: As you do well, they cut you off",
    "url": "https://doc.searls.com/2025/05/21/online-sports-betting-is-for-losers/",
    "summary": "Doc Searls' blog post argues that online sports betting is rigged against the bettor, ultimately benefiting the \"house\" at the expense of \"losers.\" He supports this claim by pointing to reports from ESPN, The Wall Street Journal, and The New York Post, highlighting how sportsbooks limit or ban successful bettors. Searls also cites Michael Lewis' podcast, \"Against the Rules,\" which illustrates how quickly sportsbooks cut off bettors who begin winning.\n\nHe further criticizes sportsbooks for being better at identifying profitable gamblers than aiding problem gamblers, suggesting that these platforms are designed to create addiction, particularly among young people. While acknowledging sportsbooks' need to make a profit, Searls views their focus on \"casual, recreational bettors\" as exploitative, as they essentially prefer those who throw money away.\n\nThe post concludes with the prediction that sports gambling will eventually be viewed with the same societal disapproval as smoking and drunk driving. The comment section reinforces the author's view, with one commenter comparing the experience to a loss at the casino and another suggesting the online betting algorithms take advantage of naive bettors.\n",
    "chinese_title": "在线体育博彩：赢钱多了，就会限制你。",
    "chinese_summary": "Doc Searls 的博文认为，在线体育博彩存在庄家作弊，最终让“庄家”获利，牺牲“输家”的利益。 他通过引用 ESPN、《华尔街日报》和《纽约邮报》的报道来支持这一观点，强调体育博彩公司如何限制或禁止成功的博彩者。 Searls 还引用了迈克尔·刘易斯的播客节目“违反规则”，该节目说明了体育博彩公司会多么迅速地切断开始赢钱的博彩者。\n\n他还批评体育博彩公司更擅长识别有利可图的赌徒，而不是帮助问题赌徒，这表明这些平台旨在制造上瘾，尤其是在年轻人中。 虽然承认体育博彩公司需要盈利，但 Searls 认为他们对“休闲博彩者”的关注具有剥削性，因为他们本质上更喜欢那些乱花钱的人。\n\n该博文最后预测，体育博彩最终会像吸烟和酒后驾车一样受到社会谴责。 评论部分强化了作者的观点，一位评论员将这种体验比作在赌场输钱，另一位评论员则认为在线博彩算法会利用天真的博彩者。"
  },
  {
    "id": "44161607",
    "title": "The Universal Tech Tree",
    "url": "https://asteriskmag.com/issues/10/the-universal-tech-tree",
    "summary": "Étienne Fortier-Dubois introduces the \"Universal Tech Tree,\" a project aiming to map the historical development of technology and reveal unexpected connections between inventions. Inspired by the tech trees in the Civilization video game, this interactive visualization places over 1,550 technologies on a timeline, connecting them based on influence and ancestry.\n\nThe article illustrates this interconnectedness with the example of firearms and cameras. The \"photographic gun\" of Étienne-Jules Marey was directly inspired by firearms, and its development ultimately led to the invention of the movie camera. This connection traces back to the revolving components of Colt revolvers, which themselves originated from earlier gun innovations.\n\nFortier-Dubois outlines the process of building the tech tree, which involved defining \"technology\" as intentional knowledge implemented in a physical substrate, discretizing innovation into specific inventions, and establishing rules for dating them. He primarily utilized Wikipedia and scholarly sources, while prioritizing building his own mental model over relying on automated data mining.\n\nThe tech tree reveals surprising connections, such as the simultaneous invention of the bicycle, automobile, and motorcycle in 1885, and the early origins of drones shortly after the invention of powered flight. It highlights how one invention can unexpectedly lead to others, as exemplified by the Wright brothers' bicycle business influencing the design of their airplane. Ultimately, the Universal Tech Tree offers a new perspective on technological history, uncovering hidden relationships and prompting a deeper understanding of innovation.\n",
    "chinese_title": "通用科技树",
    "chinese_summary": "艾蒂安·福蒂埃-杜布瓦介绍了“通用科技树”项目，该项目旨在绘制技术的历史发展图谱，并揭示发明之间意想不到的联系。受《文明》系列电子游戏中科技树的启发，这个互动可视化工具将超过1550项技术置于时间线上，并根据影响和传承关系将它们连接起来。\n\n文章以枪械和相机为例说明了这种相互关联性。艾蒂安-朱尔·马雷的“摄影枪”直接受到枪械的启发，而它的发展最终导致了电影摄影机的发明。这种联系可以追溯到柯尔特左轮手枪的旋转部件，这些部件本身就源于早期的枪械创新。\n\n福蒂埃-杜布瓦概述了构建科技树的过程，其中包括将“技术”定义为在物理基质中实现的有意知识，将创新离散为具体的发明，并建立确定发明日期的规则。他主要使用维基百科和学术来源，同时优先建立自己的心智模型，而不是依赖于自动数据挖掘。\n\n科技树揭示了一些令人惊讶的联系，例如自行车、汽车和摩托车于1885年同时被发明，以及无人机在动力飞行发明后不久的早期起源。它强调了一项发明如何出乎意料地导致其他发明，例如莱特兄弟的自行车业务影响了他们的飞机设计。最终，通用科技树为技术史提供了一个新的视角，揭示了隐藏的关系，并促使人们对创新有更深入的理解。"
  },
  {
    "id": "44204637",
    "title": "Tesla seeks to block city of Austin from releasing records on robotaxi trial",
    "url": "https://www.reuters.com/business/autos-transportation/tesla-seeks-block-city-austin-releasing-records-robotaxi-trial-2025-06-06/",
    "summary": "Tesla is attempting to prevent the City of Austin, Texas from releasing documents related to its planned robotaxi trial, scheduled for 2025. Tesla argues that the requested records contain proprietary information and trade secrets that, if made public, could provide competitors with a significant advantage and harm Tesla's competitive position.\n\nThe company filed a lawsuit in Texas state court, seeking to block the city from complying with a public information request submitted by an unnamed party. Tesla claims that the documents detail technical specifications, performance data, and other crucial aspects of its autonomous driving technology, including the neural networks and software that underpin the robotaxi functionality. Releasing this information, Tesla argues, would essentially hand over its research and development efforts to rivals.\n\nThe case highlights the ongoing tension between transparency in government operations and the protection of sensitive corporate information, particularly in the rapidly evolving field of autonomous vehicle technology. Tesla maintains that the records are commercially valuable and that their disclosure would cause irreparable harm to the company. The outcome of the lawsuit will determine whether the City of Austin is obligated to release the documents or can protect Tesla's alleged trade secrets. The requesting party and the specific content of the requested documents remain undisclosed beyond the lawsuit filed by Tesla.\n",
    "chinese_title": "特斯拉试图阻止奥斯汀市公开关于机器人出租车试验的记录",
    "chinese_summary": "特斯拉正试图阻止德克萨斯州奥斯汀市公布与其计划于2025年进行的Robotaxi试验相关的文件。特斯拉辩称，被要求的记录包含专有信息和商业机密，如果公开，可能会为竞争对手提供显著优势并损害特斯拉的竞争地位。\n\n该公司已在德克萨斯州州法院提起诉讼，试图阻止该市遵守一个匿名方提交的公共信息请求。特斯拉声称，这些文件详细说明了其自动驾驶技术的技术规格、性能数据和其他关键方面，包括支持Robotaxi功能的神经网络和软件。特斯拉认为，发布这些信息实际上会将该公司的研发成果拱手让给竞争对手。\n\n此案凸显了政府运营透明度与保护敏感公司信息之间持续存在的紧张关系，尤其是在快速发展的自动驾驶汽车技术领域。特斯拉坚称，这些记录具有商业价值，并且披露它们将对公司造成无法弥补的损害。诉讼结果将决定奥斯汀市是否有义务公布这些文件，或者是否可以保护特斯拉声称的商业机密。除了特斯拉提起的诉讼之外，请求方和所请求文件的具体内容仍未公开。"
  },
  {
    "id": "44200773",
    "title": "Dystopian tales of that time when I sold out to Google",
    "url": "https://wordsmith.social/elilla/deep-in-mordor-where-the-shadows-lie-dystopian-stories-of-my-time-as-a-googler",
    "summary": "In this blog post, the author recounts their disillusioning experience working for Google in Brazil in 2007, highlighting the discrepancies between the company's image as a \"Best Place To Work\" and the reality of the workplace. Google promised perks like \"20% time\" for personal projects, but the author found themselves overworked fixing bugs and facing pressure to work unpaid overtime.\n\nTheir attempt to address the underutilization of \"20% time\" through an internal blog post was met with reprimand, as expressing dissatisfaction was seen as \"backstabbing.\" They also describe creating a bot to define company jargon for new employees, which led to the glossary being restricted for temps, part-timers, and contractors, thus becoming responsible for making their situation worse.\n\nThe author recounts another instance involving a Project Android programmer who initially expressed disappointment with the project's direction, only to retract their statement later, suggesting pressure to maintain a positive image. As an openly queer employee (\"Gaygler\"), the author was also approached by the AdSense team to provide slang and cultural references for advertising purposes, leaving them feeling exploited.\n\nThe author emphasizes the divide between engineers and the \"Google precariat\" (temps, part-timers, and contractors), noting that while engineers received perks like free snacks and toys, they were still underpaid and pressured. The company used the illusion of high-paying opportunities in the Global North to keep workers motivated despite harsh work conditions. This created a situation where engineers were pampered with superficial benefits while the precariat class was treated as inferior.\n",
    "chinese_title": "我向谷歌出卖灵魂的那个时代的末世故事",
    "chinese_summary": "在这篇博文中，作者回忆了2007年在巴西谷歌工作时令人失望的经历，突显了该公司作为“最佳工作场所”的形象与实际工作环境之间的差异。谷歌承诺提供“20%时间”用于个人项目等福利，但作者发现自己过度劳累地修复bug，并面临无偿加班的压力。\n\n他们试图通过一篇内部博文来解决“20%时间”未被充分利用的问题，却受到了训斥，因为表达不满被视为“背后捅刀”。他们还描述了创建一个机器人来为新员工定义公司术语，结果导致该词汇表对临时工、兼职员工和合同工进行了限制，从而导致他们的处境更加糟糕。\n\n作者回忆了另一个例子，一位Android项目程序员最初对项目的方向表示失望，但后来撤回了他的声明，暗示他面临着保持积极形象的压力。作为一名公开的酷儿员工（“Gaygler”），作者还被AdSense团队联系，要求为广告提供俚语和文化参考，这让他们感到被利用。\n\n作者强调了工程师和“谷歌无产阶级”（临时工、兼职员工和合同工）之间的鸿沟，指出虽然工程师获得了免费零食和玩具等福利，但他们的薪水仍然偏低，并且面临着压力。该公司利用全球北方高薪机会的幻想来保持员工的积极性，尽管工作条件恶劣。这造成了一种局面，即工程师受到肤浅的好处的宠爱，而无产阶级则被视为低人一等。"
  },
  {
    "id": "44198503",
    "title": "Aether: A CMS That Gets Out of Your Way",
    "url": "https://lebcit.github.io/post/meet-aether-a-cms-that-actually-gets-out-of-your-way/",
    "summary": "Aether CMS is presented as a fast, minimal, and modular content management system designed for simplicity and built from real-world development experience. Frustrated with the bloat of platforms like WordPress and the complexity of many JAMstack tools, the creator distilled years of experience into Aether, running on only four core modules.\n\nAether champions a \"files over databases\" philosophy, storing content as Markdown files with YAML frontmatter, making content portable and version-controllable. This approach promotes development speed, content creation speed (through a familiar admin interface), and runtime speed (via static site generation).\n\nThemes are simple folders of HTML, CSS, and JavaScript, utilizing LiteNode's Simple Template Engine. Aether's design caters to various use cases, including personal blogs, company documentation, marketing sites, multi-author publications, and portfolio sites, without requiring plugins or extensive configuration.\n\nAether aims to be a compromise-free solution – simple for content creators, flexible for developers, and fast for users. It's built on Node.js with vanilla JavaScript, leveraging LiteNode, Marked, file-based storage, and Argon2. Getting started is quick with a simple CLI command.\n\nFuture development plans include scheduled publishing, search functionality, advanced user permissions, page caching, plugin system expansion, a comment system, SEO tools, editor enhancements, and new themes. The article concludes with an invitation to try Aether, highlighting the absence of vendor lock-in due to its file-based nature.\n",
    "chinese_title": "以太：一款让你轻松使用的内容管理系统",
    "chinese_summary": "Aether CMS：快速、极简、模块化的内容管理系统。基于实际开发经验构建，Aether致力于解决WordPress等平台臃肿和诸多JAMstack工具复杂性的问题，仅通过四个核心模块实现。\n\nAether提倡“文件优于数据库”的理念，将内容存储为带有YAML frontmatter的Markdown文件，保证内容的可移植性和版本控制。这种方式提高了开发速度、内容创建速度（通过熟悉的管理界面）和运行时速度（通过静态站点生成）。\n\n主题是简单的HTML、CSS和JavaScript文件夹，采用LiteNode的Simple Template Engine。Aether的设计适用于各种用例，包括个人博客、公司文档、营销网站、多作者出版物和作品集网站，无需插件或大量配置。\n\nAether旨在成为一个无损的解决方案——对内容创作者来说简单，对开发者来说灵活，对用户来说快速。它基于Node.js和原生JavaScript构建，利用LiteNode、Marked、基于文件的存储和Argon2。通过简单的CLI命令即可快速上手。\n\n未来的开发计划包括定时发布、搜索功能、高级用户权限、页面缓存、插件系统扩展、评论系统、SEO工具、编辑器增强和新主题。文章最后邀请用户尝试Aether，并强调其基于文件的特性避免了供应商锁定。"
  },
  {
    "id": "44200585",
    "title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
    "url": "https://arxiv.org/abs/2505.07897",
    "summary": "This arXiv article, submitted on May 12, 2025, introduces LongCodeBench (LCB), a new benchmark designed to evaluate the coding abilities of Large Language Models (LLMs) with extremely long context windows (up to 1 million tokens). The authors, led by Stefano Rando, identify code comprehension and repair as suitable tasks for assessing these models in realistic, long-context scenarios.\n\nLCB draws from real-world GitHub issues to create two task types: LongCodeQA (question answering) and LongSWE-Bench (bug fixing). The benchmark is carefully stratified by complexity, allowing evaluation across a range of models, from smaller models like Qwen2.5 14B Instruct to larger models like Google's Gemini.\n\nThe study's findings reveal that long-context performance remains a significant weakness for all models tested. The results highlight performance drops, such as Claude 3.5 Sonnet decreasing from 29% to 3% and Qwen2.5 dropping from 70.2% to 40%, demonstrating the challenges LLMs face when dealing with very long code contexts. The research emphasizes the need for continued improvement in LLMs' ability to effectively utilize and understand information within extensive context windows for coding tasks.\n",
    "chinese_title": "LongCodeBench：百万窗口规模下编码LLM的评估",
    "chinese_summary": "该arXiv文章于2025年5月12日提交，介绍了LongCodeBench (LCB)，这是一个新的基准，旨在评估具有极长上下文窗口（高达100万个token）的大型语言模型（LLM）的编码能力。由Stefano Rando领导的作者认为，代码理解和修复是评估这些模型在真实的、长上下文场景中能力的合适任务。\n\nLCB借鉴了真实世界的GitHub问题，创建了两种任务类型：LongCodeQA（问答）和LongSWE-Bench（错误修复）。该基准经过精心分层，按复杂性划分，从而可以评估各种模型，从较小的模型（如Qwen2.5 14B Instruct）到较大的模型（如Google的Gemini）。\n\n该研究的发现表明，长上下文性能仍然是所有测试模型的显著弱点。结果突显了性能下降，例如Claude 3.5 Sonnet从29%降至3%，Qwen2.5从70.2%降至40%，这表明LLM在处理非常长的代码上下文时面临挑战。该研究强调，需要持续改进LLM有效利用和理解广泛上下文窗口内信息以完成编码任务的能力。"
  },
  {
    "id": "44205602",
    "title": "The Case for Terraform Modules: Scaling Your Infrastructure Organization",
    "url": "https://infisical.com/blog/terraform-modules-organization-scaling",
    "summary": "This article argues that Terraform modules are essential for scaling infrastructure organizations effectively. Initially, teams often duplicate Terraform code, leading to technical debt. Modules solve this by encapsulating infrastructure patterns into reusable, version-controlled components. Benefits include standardized configurations, reduced configuration drift, and proactive infrastructure design.\n\nThe article explores different module approaches: local, Git-hosted, and registry-hosted. Local modules are ideal for early development, while Git-hosted modules enable sharing across projects with version pinning. For large, complex infrastructures, private module registries within TACOS platforms provide structured versioning, automation, and governance.\n\nA key consideration is whether to build custom modules or leverage public community registries. Internal modules are generally more secure but require more development effort. External modules offer readily available solutions but need careful security review and may introduce unnecessary complexity.\n\nThe article highlights the challenge of managing secrets in modules and recommends using Infisical, a secrets management solution that integrates seamlessly with Terraform. Infisical utilizes ephemeral resources to prevent secrets from being stored in state files, enabling secure credential rotation and flexible, reusable modules.\n\nIn conclusion, the article emphasizes that as infrastructure scales, structured module management, versioning, and automation are crucial for maintaining consistency and avoiding pitfalls in infrastructure code.\n",
    "chinese_title": "Terraform模块的用例：扩展您的基础设施组织",
    "chinese_summary": "Terraform 模块是高效扩展基础设施组织的关键。初期团队常重复 Terraform 代码，导致技术债务。模块通过将基础设施模式封装为可重用、版本控制的组件来解决此问题。优点包括标准化配置、减少配置漂移和前瞻性基础设施设计。\n\n本文探讨了不同的模块方法：本地、Git 托管和注册表托管。本地模块适用于早期开发，而 Git 托管模块支持跨项目共享和版本锁定。对于大型复杂的基础设施，TACOS 平台内的私有模块注册表可提供结构化版本控制、自动化和治理。\n\n一个关键考虑因素是构建自定义模块还是利用公共社区注册表。内部模块通常更安全，但需要更多开发工作。外部模块提供现成的解决方案，但需要仔细的安全审查，并可能引入不必要的复杂性。\n\n本文强调了模块中管理密钥的挑战，并建议使用 Infisical，一种与 Terraform 无缝集成的密钥管理解决方案。Infisical 利用临时资源来防止密钥存储在状态文件中，从而实现安全的凭证轮换和灵活、可重用的模块。\n\n总之，本文强调，随着基础设施的扩展，结构化的模块管理、版本控制和自动化对于保持一致性并避免基础设施代码中的陷阱至关重要。"
  },
  {
    "id": "44196589",
    "title": "Show HN: Lambduck, a Functional Programming Brainfuck",
    "url": "https://imjakingit.github.io/lambduck/",
    "summary": "Lambduck is a functional programming language based on lambda calculus principles and heavily inspired by Brainfuck. It uses a minimalist syntax consisting of only a few characters: `\\`, `|`, `-`, `+`, and `*`, each representing core functional constructs like lambda abstraction, function application, and argument access.\n\nThe language is eager (leftmost-innermost evaluation order) and provides specific constructs for I/O. The top-level program receives a Church-encoded pair of `getchar` (reads a byte from stdin and calls its argument with the Church numeral representation) and `putchar` (decodes a Church numeral mod 256, writes it to stdout, and returns the original numeral).  Program termination happens upon successful evaluation or EOF from `getchar`.\n\nThe documentation provides a table outlining the meaning of each character in Lambduck. It then presents several example functions (true, false, identity, pair, fst, snd, left, right, either, ap, fix) and demonstrates two simple example programs: \"echo\" which echoes the input, and one that prints the \"@\" character. The program emphasizes functional programming principles and leveraging Church numerals for data representation and manipulation.\n",
    "chinese_title": "展示 HN: Lambduck，一种函数式编程 Brainfuck",
    "chinese_summary": "Lambduck是一种基于lambda演算原理并深受Brainfuck启发的函数式编程语言。它使用极简的语法，仅包含少量字符：`\\`、`|`、`-`、`+`和`*`，分别代表lambda抽象、函数应用和参数访问等核心函数式构造。\n\n该语言是急求值的（最左-最内求值顺序），并为I/O提供了特定的构造。顶层程序接收一个Church编码的`getchar`（从stdin读取一个字节，并使用Church数码表示调用其参数）和`putchar`（解码Church数码模256，将其写入stdout，并返回原始数码）的pair。程序在成功求值或`getchar`遇到EOF时终止。\n\n文档提供了一个表格，概述了Lambduck中每个字符的含义。然后，它展示了几个示例函数（true、false、identity、pair、fst、snd、left、right、either、ap、fix），并演示了两个简单的示例程序：“echo”，用于回显输入，以及一个打印“@”字符的程序。该程序强调函数式编程原则，并利用Church数码进行数据表示和操作。"
  },
  {
    "id": "44189426",
    "title": "From tokens to thoughts: How LLMs and humans trade compression for meaning",
    "url": "https://arxiv.org/abs/2505.17117",
    "summary": "This arXiv article, \"From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning,\" explores the differences in how Large Language Models (LLMs) and humans represent and categorize knowledge. The authors, Chen Shani, Dan Jurafsky, Yann LeCun, and Ravid Shwartz-Ziv, investigate whether LLMs achieve a human-like balance between compressing information for efficiency and preserving semantic fidelity.\n\nThe researchers introduce an information-theoretic framework based on Rate-Distortion Theory and the Information Bottleneck principle to compare LLM token embeddings with human categorization benchmarks. Their analysis reveals that while LLMs can form broad conceptual categories similar to humans, they often fail to capture subtle semantic distinctions crucial for human understanding.\n\nA key finding is that LLMs exhibit a strong bias towards aggressive statistical compression, prioritizing efficiency over nuanced representation. In contrast, human conceptual systems seem to prioritize adaptive nuance and contextual richness, even if this means sacrificing compressional efficiency. This suggests that current LLM architectures differ significantly from human cognitive architectures in how they balance compression and meaning. The paper concludes that understanding these differences is crucial for developing LLMs with more human-aligned conceptual representations.\n",
    "chinese_title": "从词元到思想：大型语言模型与人类如何以压缩换取意义",
    "chinese_summary": "从词元到思想：大型语言模型与人类如何以压缩换取意义"
  },
  {
    "id": "44205424",
    "title": "CRDTs #4: Convergence, Determinism, Lower Bounds and Inflation",
    "url": "https://jhellerstein.github.io/blog/crdt-inflationary/",
    "summary": "This article delves into the subtle yet crucial aspects of CRDT (Conflict-free Replicated Data Type) design, focusing on the relationship between determinism, convergence, and the properties of update functions. It highlights that strong eventual consistency (SEC) in CRDTs doesn't inherently guarantee determinism. Specifically, if CRDTs are to be deterministic or if reads are to be treated as lower bounds, the update functions must be inflationary.\n\nThe author defines key terms like join semi-lattices and inflationary functions, emphasizing that while the merge operation in CRDTs is inherently inflationary, update functions can introduce non-determinism. This non-determinism arises when updates are not inflationary, potentially leading to different converged states based on the interleaving of updates and messages.\n\nThe article demonstrates through examples that non-inflationary updates can spoil the lower bound property of CRDT reads, making it unsafe to rely on intermediate values as stable observations. To ensure inflationarity, the author suggests either modifying the update API to merge the update result with the current state or removing the update API altogether, forcing developers to handle the merge explicitly.\n\nFinally, the article clarifies the relevance of monotonicity in this context, showing that while it's an important property in general, inflationarity is the key requirement for achieving deterministic convergence in CRDTs.\n",
    "chinese_title": "CRDTs #4: 收敛性、确定性、下界和膨胀",
    "chinese_summary": "本文深入探讨了CRDT（无冲突复制数据类型）设计的微妙而关键的方面，重点关注确定性、收敛性以及更新函数性质之间的关系。它强调了CRDT中的强最终一致性(SEC)并不必然保证确定性。具体而言，如果CRDT要具有确定性，或者如果读取要被视为下界，则更新函数必须是膨胀性的。\n\n作者定义了诸如并半格和膨胀函数等关键术语，强调虽然CRDT中的合并操作本质上是膨胀性的，但更新函数可能会引入非确定性。当更新不是膨胀性的时，这种非确定性就会出现，可能导致基于更新和消息的交错的不同收敛状态。\n\n本文通过示例证明，非膨胀性更新会破坏CRDT读取的下界属性，从而使得依赖中间值作为稳定观察变得不安全。为了确保膨胀性，作者建议要么修改更新API，将更新结果与当前状态合并，要么完全删除更新API，强制开发人员显式处理合并。\n\n最后，本文阐明了单调性在此上下文中的相关性，表明虽然它通常是一个重要的属性，但膨胀性是实现CRDT中确定性收敛的关键要求。"
  },
  {
    "id": "44197112",
    "title": "Open Source Distilling",
    "url": "https://opensourcedistilling.com/",
    "summary": "This article, titled \"Open Source Distilling,\" focuses on the iSpindel and its components, specifically \"The Jeffrey 2.69.\" It highlights a video demonstration covering key aspects of working with this technology. The video includes:\n\n*   **The Jeffrey 2.69:** A showcase of new features related to this particular version of the iSpindel component.\n*   **Flat Soldering Technique:** Instruction on how to perform flat soldering, a specific soldering method presumably relevant to assembling or modifying the iSpindel.\n*   **Balancing Method:** Details a new approach to balancing the iSpindel to a 25-degree angle. This method involves using solder pad weights to achieve the desired balance.\n\nIn essence, the article points to a resource (a video) that provides practical guidance and demonstrations on using, soldering, and balancing an iSpindel device, focusing on the features of \"The Jeffrey 2.69\" version. The balancing method using solder pad weights is presented as a novel technique.\n",
    "chinese_title": "开源蒸馏",
    "chinese_summary": "本文题为《开源蒸馏》，重点介绍iSpindel及其组件，特别是“The Jeffrey 2.69”。文章着重介绍了一个视频演示，涵盖了使用该技术的关键方面。视频内容包括：\n\n*   **The Jeffrey 2.69：** 展示与此特定版本的iSpindel组件相关的新功能。\n*   **平面焊接技术：** 指导如何进行平面焊接，这是一种可能与组装或修改iSpindel相关的特定焊接方法。\n*   **平衡方法：** 详细介绍了一种将iSpindel平衡至25度角的新方法。该方法涉及使用焊盘配重来实现所需的平衡。\n\n总而言之，本文指向一个资源（视频），该资源提供了关于使用、焊接和平衡iSpindel设备的实用指导和演示，重点介绍了“The Jeffrey 2.69”版本的功能。使用焊盘配重进行平衡的方法被提出作为一种新颖的技术。"
  },
  {
    "id": "44208058",
    "title": "HZ-program (Typesetting algorithm by Hermann Zapf)",
    "url": "https://en.wikipedia.org/wiki/Hz-program",
    "summary": "The Hz-program, created by Hermann Zapf, was a patented typographic composition computer program designed to produce even text justification by minimizing excessive word spacing. Zapf's goal was to create a \"perfect grey type area\" free of \"rivers and holes.\"\n\nDevelopment of the program spanned from Harvard University to the Rochester Institute of Technology. Key elements of the algorithm involved scaling (condensing and expanding) letters and a fast kerning program. The program could adjust spacing both negatively and positively between characters.\n\nURW patented the Hz-program; the patent has since expired. Adobe Systems later acquired it for use in Adobe InDesign. While it's unclear if the algorithm is still used in current versions of InDesign, a detailed analysis was performed by Hàn Thế Thành, leading to the implementation of microtypography extensions in TeX typesetting systems (pdfTeX) available in LaTeX and ConTeXt.\n\nThe program's quality and the ambiguity around its internal workings have led to a degree of mystique. Claims comparing its output to the quality of Gutenberg's work have also spurred debate, particularly regarding the glyph scaling technique. Some typographers, such as Ari Rafaeli and Torbjørn Eng, have expressed criticism and questioned the Gutenberg comparison.\n",
    "chinese_title": "HZ程序 (赫尔曼·察普夫排版算法)",
    "chinese_summary": "Hz程序，由赫尔曼·察普夫创建，是一项获得专利的排版合成计算机程序，旨在通过最大限度地减少多余的字间距来产生均匀的文本对齐效果。察普夫的目标是创造一个没有“河流和孔洞”的“完美的灰色文字区域”。\n\n该程序的开发横跨哈佛大学至罗切斯特理工学院。算法的关键要素包括缩放（压缩和扩展）字母以及快速字距调整程序。该程序可以对字符之间的间距进行负向和正向调整。\n\nURW对Hz程序进行了专利注册；该专利现已过期。Adobe Systems后来收购了该程序，用于Adobe InDesign中。虽然尚不清楚该算法是否仍在当前版本的InDesign中使用，但Hàn Thế Thành对其进行了详细分析，从而在TeX排版系统（pdfTeX）中实现了微排版扩展，这些扩展可在LaTeX和ConTeXt中使用。\n\n该程序的质量以及围绕其内部运作方式的模糊性导致了一定程度的神秘感。将其输出与古登堡作品质量相提并论的主张也引发了争议，尤其是在字形缩放技术方面。一些排版师，例如Ari Rafaeli和Torbjørn Eng，表达了批评，并质疑了与古登堡的比较。"
  },
  {
    "id": "44196417",
    "title": "Show HN: Claude Composer",
    "url": "https://github.com/possibilities/claude-composer",
    "summary": "Claude Composer is a tool designed to enhance the Claude Code experience by automating permission dialog handling, managing Claude's access to tools, and providing better visibility through system notifications. It reduces interruptions by automatically handling permission prompts based on configurable rulesets, offering flexible control over what actions Claude is allowed to perform. It also enables tool management by defining toolsets that specify which tools Claude can use.\n\nThe tool can be installed globally using `npm`, `yarn`, or `pnpm`. Configuration is initialized via `claude-composer cc-init`, allowing for global or project-specific configuration. The `config.yaml` file allows users to define rulesets, toolsets, trusted project roots, and notification preferences.\n\nClaude Composer provides various command-line options for specifying rulesets and toolsets, controlling notification display, enabling debug features, and managing safety settings. Subcommands like `cc-init` offer options for initializing configuration with specific rulesets or toolsets. It also supports passing unrecognized options directly to Claude Code. The tool leverages environment variables for further configuration. Trusted roots can be defined to auto-accept trust prompts for specified directories. Finally, the document outlines the release process for different types of updates.\n",
    "chinese_title": "展示一下：Claude Composer",
    "chinese_summary": "Claude Composer：通过自动化权限对话框处理、管理Claude的工具访问权限以及通过系统通知提供更好的可见性来增强Claude Code体验的工具。它基于可配置的规则集自动处理权限提示，减少中断，并灵活控制Claude允许执行的操作。它还通过定义指定Claude可以使用的工具集的工具集来启用工具管理。\n\n该工具可以使用`npm`、`yarn`或`pnpm`全局安装。配置通过`claude-composer cc-init`初始化，允许全局或项目特定的配置。`config.yaml`文件允许用户定义规则集、工具集、受信任的项目根目录和通知首选项。\n\nClaude Composer提供了各种命令行选项，用于指定规则集和工具集、控制通知显示、启用调试功能和管理安全设置。诸如`cc-init`之类的子命令提供了使用特定规则集或工具集初始化配置的选项。它还支持将无法识别的选项直接传递给Claude Code。该工具利用环境变量进行进一步配置。可以定义受信任的根目录，以便自动接受指定目录的信任提示。最后，本文档概述了不同类型更新的发布流程。"
  },
  {
    "id": "44193965",
    "title": "Programming language Dino and its implementation",
    "url": "https://github.com/dino-lang/dino",
    "summary": "The Dino programming language is a high-level, scripting, object-oriented language currently under development (version 0.98). It draws inspiration from C but incorporates features like multi-precision integers, heterogeneous arrays, associative tables, powerful class composition, first-class functions, concurrency, pattern matching, and Unicode support. It aims for safety and efficiency, utilizing array slices and hash tables for data structures.\n\nDino's implementation emphasizes performance. It features a byte code compiler with optimizations (dead code elimination, jump optimization, inlining), a fast optimizing interpreter with a garbage collector (Mark and Sweep/Mark and Copy), and a function-level JIT compiler. Type inference is used to specialize byte code instructions for further speedups. Concurrency is achieved through green threads, promising deterministic behavior and deadlock detection, with plans to support OS threads for parallelism.\n\nObject orientation is supported via class composition, offering inheritance and traits. Pattern matching simplifies code structure, while regular expression matching is provided through the `rmatch` statement. Exception handling is supported with `try-catch` blocks. The language includes a built-in Earley parser (YAEP) for rapid language prototyping.\n\nDino is built using COCOM tools (SPRUT, MSTA, SHILKA, AMMUNITION), GMP for multi-precision integers, and Oniguruma for regular expressions. The document anticipates performance comparisons with Python, PyPy, Ruby, JS, Scala, and OCaml.\n",
    "chinese_title": "Dino编程语言及其实现",
    "chinese_summary": "Dino编程语言是一种高级的、脚本的、面向对象的语言，目前正在开发中（版本 0.98）。它从 C 语言中汲取灵感，但融入了诸如多精度整数、异构数组、关联表、强大的类组合、一等函数、并发、模式匹配和 Unicode 支持等特性。它旨在实现安全性和效率，利用数组切片和哈希表作为数据结构。\n\nDino 的实现强调性能。它具有带优化的字节码编译器（死代码消除、跳转优化、内联）、带有垃圾回收器（标记清除/标记复制）的快速优化解释器以及函数级 JIT 编译器。类型推断用于专门化字节码指令以进一步加速。通过绿色线程实现并发，承诺确定性行为和死锁检测，并计划支持操作系统线程以实现并行性。\n\n通过类组合支持面向对象，提供继承和特征。模式匹配简化了代码结构，而正则表达式匹配则通过 `rmatch` 语句提供。异常处理通过 `try-catch` 块支持。该语言包含一个内置的 Earley 解析器 (YAEP)，用于快速语言原型设计。\n\nDino 使用 COCOM 工具（SPRUT、MSTA、SHILKA、AMMUNITION）、GMP（用于多精度整数）和 Oniguruma（用于正则表达式）构建。该文档预计会与 Python、PyPy、Ruby、JS、Scala 和 OCaml 进行性能比较。"
  },
  {
    "id": "44207922",
    "title": "Mixtela Precision Clock MkIV",
    "url": "https://mitxela.com/shop/clock4",
    "summary": "The Mixtela Precision Clock Mk IV is a high-precision wall clock synchronized via GPS, featuring a millisecond display that automatically adjusts brightness and avoids flicker even when filmed at high speed. A unique feature is its accuracy-tied display: if GPS signal is lost and time drifts, the least significant digits disappear until re-synchronization.\n\nThe clock automatically determines the correct local time, including daylight saving, by utilizing on-board world map and timezone databases and GPS coordinates. Updates to these databases are easily done via drag-and-drop through a USB port that presents as a mass storage device.\n\nIt offers multiple display modes like ISO-ordinal, ISO-week, Unix timestamp, Julian date, and a high-precision countdown mode, with potential for more modes in future firmware updates, also delivered via USB.\n\nThe clock can fold in half for compactness, with the top display automatically rotating, held together by a magnet. Unfolded, it's 53cm (21 inches) wide; folded, it's 27cm (10.5 inches) wide and 7cm (3 inches) tall.\n\nIt's available as a kit (with surface mount parts pre-soldered) for £250 GBP and fully assembled for £350 GBP. Due to high demand, the clock is currently out of stock, and potential buyers can sign up for email notifications when more units become available. The clocks ship from the UK, and international orders may be subject to import duties.\n",
    "chinese_title": "Mixtela精密时钟MkIV",
    "chinese_summary": "Mixtela精密时钟Mk IV是一款通过GPS同步的高精度挂钟，具有毫秒显示功能，可自动调节亮度，即使在高速拍摄时也能避免闪烁。其独特之处在于其精度绑定显示：如果GPS信号丢失且时间漂移，最低有效位数字将会消失，直到重新同步。\n\n该时钟通过利用内置的世界地图和时区数据库以及GPS坐标，自动确定正确的当地时间，包括夏令时。这些数据库的更新可以通过USB端口以拖放方式轻松完成，该端口显示为大容量存储设备。\n\n它提供多种显示模式，如ISO-序数、ISO-周、Unix时间戳、儒略日，以及高精度倒计时模式，未来固件更新可能会增加更多模式，同样通过USB传送。\n\n该时钟可以对折以实现紧凑性，顶部显示屏自动旋转，由磁铁固定。展开时，宽度为53厘米（21英寸）；折叠时，宽度为27厘米（10.5英寸），高度为7厘米（3英寸）。\n\n它以套件形式（表面贴装元件预先焊接）的售价为250英镑，完全组装的售价为350英镑。由于需求量大，该时钟目前缺货，潜在买家可以注册邮件通知，以便在有更多产品可用时收到通知。时钟从英国发货，国际订单可能需要缴纳进口关税。"
  },
  {
    "id": "44194120",
    "title": "Show HN: iOS Screen Time from a REST API",
    "url": "https://www.thescreentimenetwork.com/api/",
    "summary": "This \"Show HN\" post introduces \"The Screen Time Network,\" a project offering access to iOS Screen Time data through a REST API. The primary takeaway is that this API enables developers (or potentially advanced users) to programmatically access and analyze screen time data collected by iOS devices.\n\nThe post likely aims to demonstrate the feasibility of extracting this data and making it available in a structured format via a standard API. This could have a variety of potential applications, such as:\n\n*   **Parental controls and monitoring:** Integrating with existing parental control apps or creating new ones.\n*   **Personal analytics and self-improvement:** Tracking and analyzing one's own screen time habits to identify patterns and set goals.\n*   **Research and development:** Providing data for research into digital wellbeing, addiction, and the impact of screen time on various demographics.\n*   **Integration with other services:** Connecting screen time data to other platforms for comprehensive digital life management.\n\nEssentially, the project provides a way to break out of the walled garden of Apple's Screen Time implementation and use the data in more flexible and potentially innovative ways. While the post itself doesn't detail the implementation or specific API endpoints, it serves as an announcement and invitation for discussion and potential collaboration within the Hacker News community. It implies that the project might be open-source or have some level of openness for others to build upon.\n",
    "chinese_title": "Show HN: 通过 REST API 获取 iOS 屏幕使用时间",
    "chinese_summary": "此“Show HN”帖子介绍“屏幕时间网络”，一个通过REST API提供iOS屏幕时间数据访问的项目。主要亮点是该API使开发者（或潜在的高级用户）能够以编程方式访问和分析由iOS设备收集的屏幕时间数据。\n\n该帖子很可能旨在展示提取这些数据并通过标准API以结构化格式提供数据的可行性。 这可能具有多种潜在应用，例如：\n\n*   **家长控制和监控：** 与现有家长控制应用程序集成或创建新的应用程序。\n*   **个人分析和自我提升：** 跟踪和分析自己的屏幕时间习惯，以识别模式并设定目标。\n*   **研究和开发：** 为数字健康、成瘾以及屏幕时间对不同人群影响的研究提供数据。\n*   **与其他服务集成：** 将屏幕时间数据连接到其他平台，以实现全面的数字生活管理。\n\n本质上，该项目提供了一种突破Apple屏幕时间实施的围墙花园的方式，并以更灵活和潜在创新的方式使用数据。 虽然帖子本身没有详细说明实现或具体的API端点，但它作为公告和邀请，旨在与Hacker News社区进行讨论和潜在的协作。 它暗示该项目可能是开源的，或者具有一定程度的开放性，供其他人在此基础上进行构建。"
  },
  {
    "id": "44195961",
    "title": "Tokasaurus: An LLM inference engine for high-throughput workloads",
    "url": "https://scalingintelligence.stanford.edu/blogs/tokasaurus/",
    "summary": "Tokasaurus is a new LLM inference engine designed for high-throughput workloads, outperforming existing engines like vLLM and SGLang by up to 3x+ on certain benchmarks. It's optimized for both small and large models, addressing the need for efficient batch processing rather than individual request latency.\n\nFor small models, Tokasaurus minimizes CPU overhead with an adaptive, asynchronous manager that prioritizes keeping the GPU busy. It also employs dynamic prefix identification using a greedy depth-first search algorithm to exploit shared prefixes in sequences, especially beneficial for workloads like repetitive sampling.\n\nFor larger models, Tokasaurus leverages pipeline parallelism (PP) for GPUs without NVLink, achieving significant throughput improvements compared to vLLM and SGLang. It also supports asynchronous tensor parallelism (Async-TP) for GPUs with NVLink, dynamically switching it on for large batch sizes to maximize communication overlap and boost performance.\n\nThe engine is written in Python, supporting Llama-3 and Qwen-2 models with data, tensor, and pipeline parallelism. Users can install it via pip. The authors provide benchmark details and code on GitHub for reproducibility. They acknowledge Prime Intellect and Together AI for compute resources and beta testers for their feedback.\n",
    "chinese_title": "Tokasaurus：一种用于高吞吐量工作负载的LLM推理引擎",
    "chinese_summary": "Tokasaurus：一款新型LLM推理引擎，专为高吞吐量工作负载设计，在某些基准测试中性能超越现有引擎vLLM和SGLang高达3倍以上。它针对大小模型进行了优化，旨在高效处理批量任务，而非单个请求延迟。\n\n对于小型模型，Tokasaurus采用自适应异步管理器，最大限度减少CPU开销，优先保持GPU繁忙。它还采用贪婪深度优先搜索算法进行动态前缀识别，以利用序列中的共享前缀，这对于重复采样等工作负载尤其有利。\n\n对于大型模型，Tokasaurus利用流水线并行 (PP) 技术，显著提升无NVLink GPU的吞吐量，优于vLLM和SGLang。它还支持带NVLink GPU的异步张量并行 (Async-TP)，并在大批量情况下动态启用，以最大限度地重叠通信并提高性能。\n\n该引擎用Python编写，支持具有数据并行、张量并行和流水线并行的Llama-3和Qwen-2模型。用户可以通过pip安装。作者在GitHub上提供了基准测试详情和代码，以确保可复现性。他们感谢Prime Intellect和Together AI提供的计算资源，以及beta测试者提供的反馈。"
  },
  {
    "id": "44192995",
    "title": "Seven Days at the Bin Store",
    "url": "https://defector.com/seven-days-at-the-bin-store",
    "summary": "Jen Kinney's article \"Seven Days at the Bin Store\" explores Amazing Binz, a new discount store in West Philadelphia selling overstock and returned merchandise from major retailers like Walmart, Amazon, and Target. The store operates on a daily decreasing price model, starting at $10 on Fridays after a restock and dropping to $1 by Wednesdays.\n\nKinney spends a week observing the store, starting with the Thursday restock where owner Ahmed receives a truckload of unsorted goods, highlighting the growing \"reverse logistics\" industry fueled by increasing online returns and overstocked warehouses. She observes the intense Friday opening, attracting bargain hunters and resellers seeking valuable items at low prices.\n\nThe article also examines local reaction to Amazing Binz. Some residents are excited about the cheap prices and the opportunity to resell items, while others express concern about the store's impact on the neighborhood's character and the ethics of consumerism. Some perceive the store as a symptom of late-stage capitalism, a funnel for unwanted consumer goods before they potentially end up in landfills.\n\nUltimately, the article paints a complex picture of Amazing Binz as a business benefiting from and contributing to the cycle of overconsumption and waste, while simultaneously offering affordable goods and potential income opportunities for some in the community. The store’s location amidst a backdrop of gentrification and diverse opinions makes it a microcosm of larger economic and social trends.\n",
    "chinese_title": "垃圾站七日",
    "chinese_summary": "Jen Kinney的文章《垃圾箱商店七日记》探索了位于西费城的折扣店Amazing Binz，该店出售沃尔玛、亚马逊和塔吉特等大型零售商的积压商品和退货商品。该商店采用每日降价模式，周五补货后起价为10美元，周三降至1美元。\n\nKinney花了一周时间观察这家商店，从周四的补货开始，店主Ahmed收到一卡车未分类的商品，凸显了由不断增长的在线退货和积压仓库推动的日益壮大的“逆向物流”行业。她观察到周五开业时场面火爆，吸引了寻求以低价购买有价值商品的廉价商品爱好者和经销商。\n\n这篇文章还探讨了当地居民对Amazing Binz的反应。一些居民对低廉的价格和转售商品的机会感到兴奋，而另一些居民则对商店对社区特色和消费主义伦理的影响表示担忧。一些人认为这家商店是晚期资本主义的症状，是无用消费品最终可能进入垃圾填埋场的渠道。\n\n最终，这篇文章描绘了一幅关于Amazing Binz的复杂图景，它既受益于又促进了过度消费和浪费的循环，同时又为社区中的一些人提供了负担得起的商品和潜在的收入机会。该商店位于士绅化和各种意见的背景下，使其成为更大经济和社会趋势的缩影。"
  },
  {
    "id": "44194521",
    "title": "Eleven v3",
    "url": "https://elevenlabs.io/v3",
    "summary": "Eleven v3 (alpha) is ElevenLabs' most expressive Text to Speech (TTS) model to date, offering a broad dynamic range controllable through inline audio tags for added emotion, audio events, and immersive soundscapes. It enables dynamic conversations between multiple speakers, sharing context and emotion for natural-sounding dialogue. The model supports human-like speech in over 70 languages, allowing users to reach a global audience.\n\nKey features include support for audio tags to control emotion, delivery, and direction, the ability to generate dynamic multi-speaker conversations, and support for a wide range of emotions, direction, and audio effects.\n\nThe alpha version is available with an 80% discount for self-serve users via the UI until the end of June 2025. The audio samples on the website were generated solely with Eleven v3. Dialogue generation weaves multiple voices together, matching prosody and emotional range. Public API access is coming soon, with early access available through contacting sales. A wide variety of audio tags are supported. The article includes a list of all the supported languages.\n",
    "chinese_title": "十一 v3",
    "chinese_summary": "Eleven v3 (alpha) 是 ElevenLabs 迄今为止最具表现力的文本转语音 (TTS) 模型，通过内联音频标签提供广泛的动态范围控制，以增加情感、音频事件和沉浸式声景。 它支持多个说话者之间的动态对话，共享上下文和情感，从而实现听起来自然的对话。 该模型支持 70 多种语言的类人语音，使用户能够覆盖全球受众。\n\n主要功能包括支持使用音频标签来控制情感、表达和方向，生成动态的多说话者对话的能力，以及支持广泛的情感、方向和音频效果。\n\n在 2025 年 6 月底之前，自助服务用户可以通过 UI 享受 8 折优惠使用 alpha 版本。 网站上的音频样本完全由 Eleven v3 生成。 对话生成将多个声音融合在一起，匹配韵律和情感范围。 公共 API 访问即将推出，通过联系销售人员可以获得早期访问权限。 支持多种音频标签。 本文包含所有支持语言的列表。"
  }
]