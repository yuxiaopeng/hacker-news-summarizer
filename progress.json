[
  {
    "id": "44826997",
    "title": "GPT-5",
    "url": "http://openai.com/gpt-5",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "GPT-5",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44826164",
    "title": "Building Bluesky Comments for My Blog",
    "url": "https://natalie.sh/posts/bluesky-comments/",
    "summary": "This blog post outlines a basic setup for integrating Bluesky comments into a personal blog. The core purpose is to encourage audience engagement by providing a space for comments, questions, and concerns. Instead of building a native commenting system, the author leverages the existing Bluesky social media platform.\n\nThe post showcases a placeholder message indicating that the comments are loading. It also includes a fallback message for users who have JavaScript disabled in their browsers, alerting them to the requirement for JavaScript to view the comments. This suggests the implementation relies on JavaScript to fetch and display Bluesky comments dynamically.\n\nWhile the post lacks specifics about the technical implementation (e.g., the use of an API, specific libraries, or code snippets), it establishes the intent to utilize Bluesky as a commenting system and hints at the user experience – a loading state and a JavaScript dependency. The brevity suggests this is an introductory piece or a part of a larger, more detailed tutorial.\n",
    "chinese_title": "为我的博客构建Bluesky评论功能",
    "chinese_summary": "本博文概述了将Bluesky评论集成到个人博客的基本设置。其核心目的是通过提供评论、提问和表达顾虑的空间来鼓励受众参与。作者没有构建原生评论系统，而是利用现有的Bluesky社交媒体平台。\n\n该文章展示了一条占位符消息，表明评论正在加载中。它还包含一条回退消息，提示浏览器禁用JavaScript的用户，查看评论需要启用JavaScript。这表明该实现依赖JavaScript来动态获取和显示Bluesky评论。\n\n虽然这篇文章缺乏关于技术实现的具体细节（例如，API的使用、特定的库或代码片段），但它确立了利用Bluesky作为评论系统的意图，并暗示了用户体验——加载状态和JavaScript依赖。简洁的篇幅表明这是一篇介绍性文章，或是更详细教程的一部分。"
  },
  {
    "id": "44824056",
    "title": "Infinite Pixels",
    "url": "https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/",
    "summary": "This article explores how different web browsers handle \"infinite\" pixel values assigned via CSS using `calc(infinity * 1px)`. The author tests various CSS properties (width, height, font-size, and line-height) in Safari, Chrome, and Firefox Nightly on macOS, observing inconsistent and often bizarre behavior.\n\nSafari and Chrome consistently clamp the \"infinite\" values to a similar, large number around 2<sup>25</sup>-1 for width, height, and line-height. For font-size, they impose hard limits of 100,000px and 10,000px, respectively, seemingly based on arbitrarily chosen base-ten numbers.\n\nFirefox Nightly exhibits the most unpredictable results. For height, it defaults to the height of a line of text unless an explicit `line-height` is set. Width is assigned a large computed value (around 17.9 million pixels) but renders at roughly half that size. Font size calculations yield a 32-bit single-precision floating-point number, but the actual rendered font-size is around 2,400 pixels, often interacting strangely with `line-height`. Line height behaves similarly to width in Firefox, with a large computed value halved for rendering.\n\nThe author expresses bewilderment at these inconsistencies and seeks explanations for the observed browser quirks, particularly the odd behavior in Firefox and the arbitrary limits in Chrome and Safari. They invite readers with insights into the browser engine workings to share their knowledge.\n",
    "chinese_title": "无限像素",
    "chinese_summary": "此文探讨了不同网页浏览器如何处理通过CSS使用`calc(infinity * 1px)`赋值的“无限”像素值。作者在macOS上的Safari、Chrome和Firefox Nightly中测试了各种CSS属性（width、height、font-size和line-height），观察到不一致且通常很奇怪的行为。\n\nSafari和Chrome始终将width、height和line-height的“无限”值限制为相似的大数字，大约为2<sup>25</sup>-1。对于font-size，它们分别施加了100,000px和10,000px的硬性限制，似乎基于随意选择的十进制数字。\n\nFirefox Nightly表现出最不可预测的结果。对于height，除非设置了明确的`line-height`，否则它默认为一行文本的高度。 Width被赋予一个很大的计算值（大约1790万像素），但渲染时大约为该尺寸的一半。字体大小计算会产生一个32位单精度浮点数，但实际渲染的字体大小约为2,400像素，通常与`line-height`产生奇怪的交互。Line-height在Firefox中的行为与width相似，计算值很大，但渲染时减半。\n\n作者对这些不一致之处感到困惑，并寻求对观察到的浏览器怪癖的解释，特别是Firefox中的奇怪行为以及Chrome和Safari中的任意限制。他们邀请对浏览器引擎工作原理有深入了解的读者分享他们的知识。"
  },
  {
    "id": "44825491",
    "title": "How to Sell if Your User is not the Buyer",
    "url": "https://writings.founderlabs.io/p/how-to-sell-if-your-user-is-not-the",
    "summary": "This article addresses the challenge of selling a product when the user isn't the buyer, specifically using the example of developers as users and CTOs/Directors of Engineering as buyers. The key lies in understanding *who actually has the power*, not just who holds the budget.\n\nThe author outlines two scenarios:\n\n*   **Smaller Organizations:** Developers often hold significant influence due to the need for speed and iteration. They can champion tools that improve their efficiency, effectively \"trojan-horsing\" the product into the company.\n*   **Larger Organizations:** Leadership often has more control, especially where security is a primary concern. In this case, a longer sales cycle is required to demonstrate value and meet security requirements.\n\nThe author emphasizes that identifying who *values* the product the most, *in a way that translates to action*, is crucial. If the developer values it more than the budget holder, the goal is to *empower the developer to champion the product internally*.\n\nThis involves:\n\n*   Providing developers with compelling data and tools to convince leadership of the product's value.\n*   Translating the product's benefits into terms that resonate with leadership (e.g., time savings, improved efficiency, achievement of company goals).\n*   Conducting customer interviews with developers to understand their internal conversations with leadership and identifying any friction points in the buying process.\n\nUltimately, the author argues that developers become the de facto salespeople in this scenario, and empowering them to succeed is paramount. The goal is to make the \"yes\" decision obvious for leadership by highlighting the positive outcomes for the developer, the company, and leadership itself.\n",
    "chinese_title": "如果用户不是购买者，如何销售？",
    "chinese_summary": "当用户非购买者时，如何销售产品：以开发者为用户，CTO/工程总监为购买者为例。 关键在于理解 *谁真正掌握决策权*，而不仅仅是谁掌握预算。\n\n作者概述了两种情况：\n\n*   **小型组织：** 由于需要速度和迭代，开发者通常拥有重要的影响力。 他们可以拥护那些提高效率的工具，有效地将产品“特洛伊木马”式地引入公司。\n*   **大型组织：** 领导层通常拥有更多控制权，尤其是在安全是主要考虑因素的情况下。 在这种情况下，需要更长的销售周期来展示价值并满足安全要求。\n\n作者强调，识别 *谁最重视* 产品，并且 *这种重视能够转化为行动*，至关重要。 如果开发者比预算持有者更重视产品，那么目标是 *赋能开发者在内部拥护该产品*。\n\n这包括：\n\n*   为开发者提供引人注目的数据和工具，以说服领导层产品的价值。\n*   将产品的优势转化为与领导层产生共鸣的术语（例如，节省时间，提高效率，实现公司目标）。\n*   与开发者进行客户访谈，以了解他们与领导层的内部对话，并找出购买过程中的任何摩擦点。\n\n最终，作者认为，在这种情况下，开发者实际上变成了事实上的销售人员，而赋能他们取得成功至关重要。 目标是通过强调开发者、公司和领导层自身的积极成果，使领导层做出“同意”的决定变得显而易见。"
  },
  {
    "id": "44827046",
    "title": "GPT-5 System Card",
    "url": "https://openai.com/index/gpt-5-system-card",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "GPT-5系统卡",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44825326",
    "title": "Lithium Reverses Alzheimer's in Mice",
    "url": "https://hms.harvard.edu/news/could-lithium-explain-treat-alzheimers-disease",
    "summary": "This article reports on a study suggesting that lithium deficiency in the brain may be a key early driver of Alzheimer's disease and that a novel lithium compound can reverse the disease in mice. Researchers at Harvard Medical School found that lithium occurs naturally in the brain and is essential for normal brain function. They discovered that lithium levels are significantly lower in the brains of people with Alzheimer's, and this depletion is linked to lithium binding to amyloid plaques, thus impairing its function.\n\nIn mouse models, lithium deficiency accelerated the development of Alzheimer's hallmarks, including amyloid plaques, neurofibrillary tangles, synaptic loss, and cognitive decline. Importantly, the researchers identified a new lithium compound, lithium orotate, which avoids capture by amyloid plaques. Treating mice with this compound reversed Alzheimer's pathology, prevented brain cell damage, and restored memory, even at very low, non-toxic doses.\n\nThe findings suggest that measuring lithium levels could be a tool for early Alzheimer's screening and that lithium orotate or similar compounds could potentially be used for treatment or prevention. While clinical trials in humans are needed, the researchers are cautiously optimistic about the potential of lithium-based therapies to address the root causes of Alzheimer's and potentially reverse cognitive decline. The study highlights the importance of lithium as a critical nutrient for brain health and offers a new perspective on the development and treatment of Alzheimer's disease.\n",
    "chinese_title": "锂逆转小鼠阿尔茨海默症",
    "chinese_summary": "本文报告了一项研究，该研究表明大脑中锂缺乏可能是阿尔茨海默病早期的一个关键驱动因素，并且一种新型锂化合物可以逆转小鼠的疾病。哈佛医学院的研究人员发现，锂天然存在于大脑中，对正常大脑功能至关重要。他们发现，阿尔茨海默病患者的大脑中锂含量显著降低，这种减少与锂结合淀粉样蛋白斑块有关，从而损害其功能。\n\n在小鼠模型中，锂缺乏加速了阿尔茨海默病特征的发展，包括淀粉样蛋白斑块、神经原纤维缠结、突触丧失和认知能力下降。重要的是，研究人员发现了一种新的锂化合物，乳清酸锂，它可以避免被淀粉样蛋白斑块捕获。用该化合物治疗小鼠可以逆转阿尔茨海默病的病理，防止脑细胞损伤，并恢复记忆，即使在非常低的无毒剂量下也是如此。\n\n这些发现表明，测量锂水平可能成为阿尔茨海默病早期筛查的工具，乳清酸锂或类似化合物可能用于治疗或预防。虽然还需要在人体中进行临床试验，但研究人员对基于锂的疗法解决阿尔茨海默病的根本原因并可能逆转认知能力下降的潜力持谨慎乐观态度。该研究强调了锂作为大脑健康的关键营养素的重要性，并为阿尔茨海默病的发展和治疗提供了新的视角。"
  },
  {
    "id": "44827003",
    "title": "Foundry (YC F24) Is Hiring Staff Level Product Engineers",
    "url": "https://www.ycombinator.com/companies/foundry/jobs/jwdYx6v-founding-product-engineer",
    "summary": "Foundry, a Y Combinator (F24) startup, is seeking a Staff Level Founding Product Engineer to build the foundational infrastructure for automating digital work using AI agents. They are tackling the challenge of unreliable AI agents in complex browser-based workflows by creating a high-fidelity simulation environment for training, testing, and deploying these agents.\n\nThe role involves architecting and implementing the simulation core engine, designing evaluation and benchmarking systems, contributing to full-stack platform development (Python, Rust, Go, React/Next.js, TypeScript), owning end-to-end production lifecycles, and establishing engineering best practices.\n\nIdeal candidates possess 6-10+ years of experience building complex platforms at top companies, deep system knowledge (distributed systems, browser internals), a master builder mindset, elite coding skills in TypeScript and Python, and familiarity with Kubernetes, Docker, and cloud platforms. Open-source contributions or competitive programming accolades are a plus.\n\nFoundry offers meaningful ownership, competitive compensation, and collaboration with a strong team from companies like Scale AI and Meta. Their platform focuses on deterministic web simulation, live web evaluation, automated annotation & labeling, and RL-driven agent optimization to build reliable web agents.\n",
    "chinese_title": "Foundry (YC F24) 招聘资深产品工程师",
    "chinese_summary": "Foundry招募创始产品工程师（Staff级别），构建AI代理自动化数字工作的基础设施。他们正通过创建高保真模拟环境来训练、测试和部署AI代理，以解决复杂浏览器工作流程中AI代理不可靠的问题。\n\n该职位涉及架构和实现模拟核心引擎、设计评估和基准测试系统、参与全栈平台开发（Python、Rust、Go、React/Next.js、TypeScript）、负责端到端生产生命周期，以及建立工程最佳实践。\n\n理想人选需具备6-10年以上在顶级公司构建复杂平台的经验、深厚的系统知识（分布式系统、浏览器内部原理）、精通构建的心态、顶尖的TypeScript和Python编码技能，以及熟悉Kubernetes、Docker和云平台。开源贡献或竞技编程荣誉加分。\n\nFoundry提供有意义的所有权、有竞争力的薪酬，以及与来自Scale AI和Meta等公司的强大团队合作的机会。他们的平台专注于确定性Web模拟、实时Web评估、自动标注和标记，以及RL驱动的代理优化，以构建可靠的Web代理。"
  },
  {
    "id": "44826463",
    "title": "Live: GPT-5",
    "url": "https://www.youtube.com/watch?v=0Uu_VJeVVfo",
    "summary": "The title \"Live: GPT-5\" strongly suggests an announcement or presentation about the release or a live demonstration of GPT-5, the presumed next iteration of the GPT language model from OpenAI.\n\nThe content, however, is simply a generic YouTube footer. This suggests the information is from YouTube and contains links to important policy and administrative information such as:\n\n*   **Copyright:** Links to information on YouTube's copyright policies.\n*   **Contact:** Links to ways to contact YouTube.\n*   **Creators:** Information tailored for YouTube content creators.\n*   **Advertising:** Information regarding advertising on YouTube.\n*   **Developers:** Resources for developers building on the YouTube platform.\n*   **Terms:** YouTube's terms of service.\n*   **Privacy:** YouTube's privacy policy.\n*   **Safety:** YouTube's safety guidelines.\n*   **How YouTube works:** Explanation of YouTube's platform and processes.\n*   **New features:** Information about testing new features.\n*   **NFL Sunday Ticket:** Reference to NFL Sunday Ticket, suggesting it's available on YouTube.\n*   **Copyright Date:** Copyright notice for Google LLC.\n\nTherefore, while the title implies a GPT-5 announcement, the content is unrelated, appearing to be boilerplate information from the YouTube website. There's no actual information about GPT-5 provided. The information is not consistent.\n",
    "chinese_title": "直播：GPT-5",
    "chinese_summary": "标题“直播：GPT-5”强烈暗示了关于OpenAI的GPT语言模型（假定的下一个版本）GPT-5的发布公告、演示，或现场展示。\n\n然而，内容仅仅是通用的YouTube页脚。这表明信息来自YouTube，并包含指向重要政策和管理信息的链接，例如：\n\n*   **版权：** 链接到关于YouTube版权政策的信息。\n*   **联系方式：** 链接到联系YouTube的各种方式。\n*   **创作者：** 为YouTube内容创作者量身定制的信息。\n*   **广告：** 关于在YouTube上投放广告的信息。\n*   **开发者：** 为在YouTube平台上构建内容的开发者提供的资源。\n*   **条款：** YouTube的服务条款。\n*   **隐私：** YouTube的隐私政策。\n*   **安全：** YouTube的安全准则。\n*   **YouTube运作方式：** 对YouTube平台和流程的解释。\n*   **新功能：** 关于测试新功能的信息。\n*   **NFL周日联赛：** 提及NFL周日联赛，暗示它在YouTube上可用。\n*   **版权日期：** Google LLC的版权声明。\n\n因此，虽然标题暗示了GPT-5的发布公告，但内容却与之无关，似乎是YouTube网站上的样板信息。没有提供关于GPT-5的实际信息。信息不一致。"
  },
  {
    "id": "44826484",
    "title": "Ditching GitHub (2024)",
    "url": "https://tomscii.sig7.se/2024/01/Ditching-GitHub",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "放弃 GitHub (2024)",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44824502",
    "title": "Laptop Support and Usability (LSU): July 2025 Report from the FreeBSD Foundation",
    "url": "https://github.com/FreeBSDFoundation/proj-laptop/blob/main/monthly-updates/2025-07.md",
    "summary": "This report, titled \"Laptop Support and Usability (LSU): July 2025 Report from the FreeBSD Foundation,\" is sourced from the FreeBSD Foundation's public project repository \"proj-laptop\" on a code hosting platform (likely GitHub or GitLab).\n\nThe key information gleaned is:\n\n*   **Project Goal:** The project, \"proj-laptop,\" aims to improve Laptop Support and Usability (LSU) within the FreeBSD operating system.\n*   **Source:** The report originates from the FreeBSD Foundation, indicating its commitment to this area.\n*   **Date:** The report specifically pertains to July 2025, suggesting regular updates or milestones for the project.\n*   **Publicly Available:** The repository is public, making the report accessible to anyone interested.\n*   **Community Engagement:** The \"Fork 4\" and \"Star 133\" metrics suggest a level of community interest and engagement with the project, with people forking the repository (copying it for their own use) and starring it (marking it as important for future reference).\n\nIn essence, the report likely details the progress and challenges faced in enhancing FreeBSD's functionality and user experience on laptop computers as of July 2025, benefiting from, and contributing to, the wider FreeBSD community.\n",
    "chinese_title": "笔记本电脑支持和可用性（LSU）： FreeBSD 基金会 2025 年 7 月报告",
    "chinese_summary": "本报告，题为“笔记本电脑支持与可用性 (LSU)：FreeBSD 基金会 2025 年 7 月报告”，来源于 FreeBSD 基金会在代码托管平台（很可能是 GitHub 或 GitLab）上的公开项目仓库“proj-laptop”。\n\n从中获得的关键信息包括：\n\n*   **项目目标：** “proj-laptop”项目旨在改进 FreeBSD 操作系统中的笔记本电脑支持与可用性 (LSU)。\n*   **来源：** 报告源自 FreeBSD 基金会，表明其对该领域的投入。\n*   **日期：** 报告专门针对 2025 年 7 月，表明该项目有定期更新或里程碑。\n*   **公开可用：** 该存储库是公开的，任何感兴趣的人都可以访问该报告。\n*   **社区参与：** “Fork 4”和“Star 133”的指标表明社区对该项目有一定程度的兴趣和参与，人们 Fork 了该存储库（复制供自己使用）并 Star 了它（将其标记为重要，以供将来参考）。\n\n本质上，该报告很可能详细介绍了截至 2025 年 7 月在增强 FreeBSD 在笔记本电脑上的功能和用户体验方面取得的进展和面临的挑战，并受益于更广泛的 FreeBSD 社区并为其做出贡献。"
  },
  {
    "id": "44824802",
    "title": "SUSE Donates USD 11,500 to the Perl and Raku Foundation",
    "url": "https://www.perl.com/article/suse-donates-to-tprf/",
    "summary": "SUSE has donated $11,500 to The Perl and Raku Foundation (TPRF) to support the Perl 5 Core Maintenance Fund. This donation, comprised of $10,000 from SUSE LLC and $1,500 from The SUSE Open Source Network, underscores SUSE's commitment to the open-source ecosystem and the sustainability of Perl.\n\nSUSE relies heavily on Perl in its Linux offerings, including SUSE Linux Enterprise and openSUSE, and uses it extensively in crucial tools like OpenQA (an automated testing framework) and Open Build Service (which builds Linux packages and Kubernetes distributions).\n\nMiguel Pérez Colino, Director of Operations at SUSE, emphasizes that Perl is a \"fundamental component\" of their ecosystem and the donation demonstrates SUSE's belief in digital stewardship. The funds will contribute to security vigilance, performance evolution, platform diversity, and community responsiveness. These efforts are vital for maintaining the security, efficiency, and relevance of Perl.\n\nSUSE's donation serves as a model for sustainable open-source stewardship, highlighting the importance of organizations reinvesting in the open-source foundations they utilize. This collective stewardship ensures the ongoing health and development of the digital commons.\n",
    "chinese_title": "SUSE 向 Perl 和 Raku 基金会捐赠 11,500 美元",
    "chinese_summary": "SUSE 向 Perl 和 Raku 基金会 (TPRF) 捐赠了 11,500 美元，以支持 Perl 5 核心维护基金。 其中，SUSE LLC 捐赠了 10,000 美元，SUSE 开源网络捐赠了 1,500 美元。 这笔捐款彰显了 SUSE 对开源生态系统和 Perl 可持续性的承诺。\n\nSUSE 在其 Linux 产品（包括 SUSE Linux Enterprise 和 openSUSE）中大量依赖 Perl，并在 OpenQA（一个自动化测试框架）和 Open Build Service（构建 Linux 软件包和 Kubernetes 发行版）等关键工具中广泛使用它。\n\nSUSE 运营总监 Miguel Pérez Colino 强调，Perl 是其生态系统的“基本组成部分”，此次捐赠表明了 SUSE 对数字化管理的信念。 这笔资金将有助于安全警戒、性能提升、平台多样性和社区响应。 这些努力对于维护 Perl 的安全性、效率和相关性至关重要。\n\nSUSE 的捐赠为可持续的开源管理树立了榜样，突显了组织对其使用的开源基金会进行再投资的重要性。 这种集体管理确保了数字共享资源的持续健康发展。"
  },
  {
    "id": "44779688",
    "title": "Monte Carlo Crash Course: Quasi-Monte Carlo",
    "url": "https://thenumb.at/QMC/",
    "summary": "This article, \"Quasi-Monte Carlo,\" explores techniques to improve Monte Carlo integration beyond simple random sampling. It focuses on reducing variance and achieving faster convergence rates. The article introduces the concept of negatively correlated samples and explores different methods to generate them.\n\nKey methods discussed include:\n\n*   **Poisson Disk Sampling:** Rejects samples falling too close to existing ones, ensuring a minimum separation distance.\n*   **Stratified Sampling:** Partitions the domain into equal-sized regions and takes independent samples from each, introducing negative correlation and reducing variance. Dynamic Stratification improves this further by scaling the number of regions with the sample count.\n*   **Adaptive Sampling:** Allocates more samples to regions with higher variance, optimizing sample distribution based on estimated deviations.\n*   **Latin Hypercube Sampling:** Stratifies each dimension independently and then combines the results, offering a computationally cheaper approach for generating negatively correlated samples, especially in higher dimensions.\n*   **Quasi-Monte Carlo (QMC):** Uses deterministic, pseudo-random number sequences instead of purely random samples. While biased, QMC estimators are consistent and can achieve faster convergence under certain conditions.\n\nThe article highlights the Koksma-Hlawka inequality, which links the error of a QMC estimator to the \"star-discrepancy\" of the sample sequence, a deterministic equivalent of negative correlation. In essence, the article presents various strategies to intelligently select samples, whether randomly or deterministically, to achieve more accurate integration results with fewer samples compared to naive Monte Carlo integration.\n",
    "chinese_title": "蒙特卡洛速成课：拟蒙特卡洛",
    "chinese_summary": "本文《拟蒙特卡罗方法》探讨了改进蒙特卡罗积分的技术，使其超越简单的随机抽样。 它着重于降低方差和实现更快的收敛速度。文章介绍了负相关样本的概念，并探讨了生成它们的不同方法。\n\n讨论的关键方法包括：\n\n*   **泊松圆盘采样:** 拒绝落在现有样本附近过于近的样本，确保最小分离距离。\n*   **分层采样:** 将域划分为大小相等的区域，并从每个区域中提取独立样本，引入负相关并减少方差。 动态分层通过随样本数量缩放区域数量进一步改进这一点。\n*   **自适应采样:** 将更多样本分配给具有较高方差的区域，根据估计偏差优化样本分布。\n*   **拉丁超立方采样:** 独立地对每个维度进行分层，然后组合结果，提供了一种计算成本较低的生成负相关样本的方法，尤其是在更高维度中。\n*   **拟蒙特卡罗 (QMC):** 使用确定性的伪随机数序列代替纯随机样本。 虽然 QMC 估计器是有偏的，但在某些条件下是一致的，并且可以实现更快的收敛速度。\n\n文章重点介绍了 Koksma-Hlawka 不等式，该不等式将 QMC 估计器的误差与样本序列的“星偏差”联系起来，后者是负相关的确定性等价物。 本质上，本文介绍了各种策略，以智能地选择样本（无论是随机的还是确定性的），从而与朴素的蒙特卡罗积分相比，以更少的样本获得更准确的积分结果。"
  },
  {
    "id": "44827216",
    "title": "Show HN: Browser AI agent platform designed for reliability",
    "url": "https://github.com/nottelabs/notte",
    "summary": "Notte is presented as a full-stack framework for building and deploying reliable AI web automation agents. It combines AI agents with traditional scripting, offering cost savings and improved reliability by using AI only when needed. The platform offers both an open-source core and a recommended API service, allowing users to develop, deploy, and scale web automations.\n\nThe open-source core enables running web agents with natural language tasks, structured output using Pydantic models, and site interactions using Playwright. The API service provides stealth browser sessions with CAPTCHA solving, proxies, and anti-detection, hybrid workflows, secure secrets vaults, and digital personas.\n\nKey features include:\n\n*   **Agent Features:** Structured output, agent vaults for credential management, and agent personas for digital identities.\n*   **Session Features:** Stealth mode with CAPTCHA solving and proxy configuration, file download/upload capabilities, cookie/auth session management, and CDP browser compatibility.\n*   **Workflows:** Hybrid workflows combining Playwright scripting and AI agents for optimized cost and performance.\n*   **Scraping:** Dedicated scraping endpoint for fast data extraction with structured outputs and stealth mode.\n\nThe platform also showcases benchmarks demonstrating superior performance compared to other browser automation tools and includes code examples demonstrating usage. It's licensed under the Server Side Public License v1. There is also a mention of a demo of an LLM leveraging the scraping endpoint in an MCP server to make real-time search in an LLM chatbot, available at https://search.notte.cc/.\n",
    "chinese_title": "Show HN：专为可靠性设计的浏览器AI代理平台",
    "chinese_summary": "Notte是一个全栈框架，用于构建和部署可靠的AI网络自动化代理。它将AI代理与传统脚本相结合，通过仅在需要时使用AI来节省成本并提高可靠性。该平台提供开源核心和推荐的API服务，允许用户开发、部署和扩展网络自动化。\n\n开源核心支持运行具有自然语言任务的网络代理，使用Pydantic模型进行结构化输出，并使用Playwright进行站点交互。API服务提供具有CAPTHA解决、代理和反检测的隐身浏览器会话、混合工作流程、安全密钥库和数字角色。\n\n主要功能包括：\n\n*   **代理功能:** 结构化输出、用于凭证管理的代理密钥库以及用于数字身份的代理角色。\n*   **会话功能:** 具有CAPTHA解决和代理配置的隐身模式、文件下载/上传功能、cookie/auth会话管理以及CDP浏览器兼容性。\n*   **工作流程:** 结合Playwright脚本和AI代理的混合工作流程，以优化成本和性能。\n*   **抓取:** 专用抓取端点，用于快速数据提取，具有结构化输出和隐身模式。\n\n该平台还展示了基准测试，证明其性能优于其他浏览器自动化工具，并包括演示用法的代码示例。它已获得Server Side Public License v1许可。此外，还提到了一个利用MCP服务器中抓取端点在LLM聊天机器人中进行实时搜索的LLM演示，可在https://search.notte.cc/找到。"
  },
  {
    "id": "44826455",
    "title": "The Sunlight Budget of Earth",
    "url": "https://www.asimov.press/p/sunlight-budget",
    "summary": "Sam Clamons' article \"The Sunlight Budget of Earth\" explores how sunlight, a seemingly limitless energy source, is utilized by humanity and nature. While sunlight is abundant and renewable, its availability isn't infinite, prompting considerations about its allocation.\n\nThe article quantifies sunlight usage, estimating current solar power absorption at 1,200 GW, with potential expansion to 18,000 GW to meet global electricity demand. Agriculture utilizes approximately 22,000 GW, while natural ecosystems (terrestrial plants and marine plankton) absorb around 120,000 GW and 120,000 GW respectively.\n\nHuman solar use, predominantly through agriculture, represents approximately 11% of wild photosynthesis. However, all combined solar energy consumption by nature and humans only accounts for 0.5% of the sunlight absorbed at the Earth's surface. The remaining vast majority is absorbed as heat or reflected back into space.\n\nThe article points out that primary producers are limited by factors like water, carbon dioxide, nitrogen, and phosphorus, not solely by sunlight. Agriculture can be disruptive to natural ecosystems due to competition for water, land, and nutrients. Solar farms can also compete for land, but alternatives like agrivoltaics and utilizing degraded land can mitigate this. The author concludes that future competition will be driven by resources other than sunlight, and encourages innovative approaches to utilize the abundant energy available.\n",
    "chinese_title": "地球的阳光预算",
    "chinese_summary": "萨姆·克莱蒙斯撰写的《地球的阳光预算》一文探讨了看似无限的能源——阳光，如何被人类和自然利用。虽然阳光充足且可再生，但其可用性并非无限，这引发了对其分配的思考。\n\n文章量化了阳光的使用情况，估计目前太阳能吸收量为1200吉瓦，有潜力扩展到18000吉瓦以满足全球电力需求。农业利用约22000吉瓦，而自然生态系统（陆地植物和海洋浮游生物）分别吸收约120000吉瓦和120000吉瓦。\n\n人类对太阳能的利用，主要通过农业，约占野生光合作用的11%。然而，自然和人类所有加起来的太阳能消耗仅占地球表面吸收阳光的0.5%。其余绝大部分以热量的形式被吸收或反射回太空。\n\n文章指出，初级生产者受到水、二氧化碳、氮和磷等因素的限制，而不仅仅是阳光。由于对水、土地和养分的竞争，农业可能会扰乱自然生态系统。太阳能农场也会争夺土地，但农光互补和利用退化土地等替代方案可以缓解这种情况。作者得出结论，未来的竞争将由阳光以外的资源驱动，并鼓励采用创新方法来利用可用的丰富能源。"
  },
  {
    "id": "44822389",
    "title": "New AI Coding Teammate: Gemini CLI GitHub Actions",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-github-actions/",
    "summary": "This article introduces Gemini CLI GitHub Actions, a free AI coding assistant designed to enhance team collaboration within GitHub repositories. Built upon the open-source Gemini CLI agent, it automates routine coding tasks and acts as an on-demand collaborator.\n\nThe GitHub Actions offer three initial open-source workflows: Intelligent issue triage (analyzing, labeling, and prioritizing new issues), accelerated pull request reviews (providing feedback on code quality, style, and correctness), and on-demand collaboration (delegating tasks by mentioning \"@gemini-cli\"). Users can request tasks like writing tests, implementing suggested changes, brainstorming solutions, or fixing bugs. These workflows are fully customizable, allowing users to create their own or configure existing ones.\n\nThe system is built with enterprise-grade security, offering features like secure credential-less authentication (using Workload Identity Federation), granular control through command allowlisting and custom identities, and complete transparency via OpenTelemetry integration for monitoring logs and metrics.\n\nGemini CLI GitHub Actions is available in beta with free quotas for Google AI Studio. Support for Vertex AI and Gemini Code Assist (Standard and Enterprise) is also included, with free use for Gemini Code Assist individual users coming soon. Developers are encouraged to contribute their own workflows to the repository. To get started, users need to download Gemini CLI 0.1.18 or later and run `/setup-github`, and find the GitHub Action at google-github-actions/run-gemini-cli.\n",
    "chinese_title": "全新AI编码助手：Gemini CLI GitHub Actions",
    "chinese_summary": "本文介绍 Gemini CLI GitHub Actions，一款免费的 AI 编码助手，旨在增强 GitHub 仓库内的团队协作。它基于开源的 Gemini CLI 代理构建，可自动执行例行编码任务并充当按需协作工具。\n\n该 GitHub Actions 提供三个初始的开源工作流程：智能问题分流（分析、标记和确定新问题的优先级）、加速的拉取请求审查（提供有关代码质量、风格和正确性的反馈）以及按需协作（通过提及“@gemini-cli”来委派任务）。用户可以请求诸如编写测试、实施建议的更改、集思广益解决方案或修复错误之类的任务。这些工作流程是完全可定制的，允许用户创建自己的工作流程或配置现有的工作流程。\n\n该系统采用企业级安全性构建，提供诸如安全无凭证身份验证（使用 Workload Identity Federation）、通过命令允许列表和自定义身份进行细粒度控制以及通过 OpenTelemetry 集成实现监控日志和指标的完全透明性等功能。\n\nGemini CLI GitHub Actions 目前提供 Google AI Studio 的免费配额的 Beta 版本。同时还支持 Vertex AI 和 Gemini Code Assist（标准版和企业版），Gemini Code Assist 个人用户的免费使用即将推出。鼓励开发人员向存储库贡献自己的工作流程。要开始使用，用户需要下载 Gemini CLI 0.1.18 或更高版本并运行“/setup-github”，并在 google-github-actions/run-gemini-cli 中找到 GitHub Action。"
  },
  {
    "id": "44825146",
    "title": "Jepsen: Capela dda5892",
    "url": "https://jepsen.io/analyses/capela-dda5892",
    "summary": "This Jepsen report analyzes Capela, an unreleased distributed programming environment designed to unify processing and storage. Jepsen tested Capela's safety and fault tolerance through a variety of simulated faults and workloads, including write-read registers, list appends, partition creation, ad-hoc queries, and generative Python code.\n\nThe tests revealed several issues, primarily concerning Capela's early development stage. These included inconsistencies in the Capela language (for loops not evaluating, unimplemented `match` expressions, leaked internal structures, and inconsistent variable assignment), and numerous crashes or panics related to unset environments and replication lag. A notable issue was nodes crashing due to timeout during history synchronization. Performance degradation was observed after a minute of operation. The report also identified three safety errors (detailed later in the original article).\n\nJepsen filed issues in a private GitHub repository, highlighting the expectation that they would be made public for transparency. The report stresses that these issues are typical of early-stage software and had no user-facing impact at the time of writing. The goal was to provide feedback to Capela developers during their pre-release phase.\n",
    "chinese_title": "Jepsen: 卡佩拉 dda5892",
    "chinese_summary": "Jepsen报告分析了Capela，一个旨在统一处理和存储的未发布分布式编程环境。Jepsen通过各种模拟故障和工作负载测试了Capela的安全性及容错能力，包括读写寄存器、列表追加、分区创建、即席查询和生成式Python代码。\n\n测试揭示了一些问题，主要与Capela的早期开发阶段有关。这些问题包括Capela语言的不一致性（for循环未执行、`match`表达式未实现、内部结构泄露以及不一致的变量赋值）以及与未设置环境和复制延迟相关的多次崩溃或紧急情况。一个显著问题是节点因历史同步期间超时而崩溃。运行一分钟后观察到性能下降。该报告还指出了三个安全错误（详见原文后续部分）。\n\nJepsen在私有GitHub仓库中提交了问题，并强调希望这些问题能够公开以提高透明度。该报告强调，这些问题是早期软件的典型问题，并且在撰写时没有对用户产生影响。目标是在Capela的预发布阶段向开发者提供反馈。"
  },
  {
    "id": "44824539",
    "title": "Windows XP Professional",
    "url": "https://win32.run/",
    "summary": "This short excerpt shows the initial boot screen of a Windows XP Professional operating system running in a virtualized environment. It identifies the operating system as Microsoft Windows XP Professional and indicates it's running on a VMware virtual machine. The PhoenixBIOS version 1.4 Release 6.0 is used by the virtual BIOS and copyright information for Phoenix Technologies Ltd. and VMware, Inc. are displayed. The specific VMware BIOS build is 314. Finally, the boot screen also identifies a virtual IDE CD-ROM drive and indicates that it is being initialized. This suggests the system is about to boot from the virtual CD-ROM or will use it during the boot process.\n",
    "chinese_title": "Windows XP 专业版",
    "chinese_summary": "此短文展示了在虚拟化环境中运行的 Windows XP Professional 操作系统的初始启动画面。它标识操作系统为 Microsoft Windows XP Professional，并表明它运行在 VMware 虚拟机上。虚拟 BIOS 使用 PhoenixBIOS 版本 1.4 Release 6.0，并显示了 Phoenix Technologies Ltd. 和 VMware, Inc. 的版权信息。特定的 VMware BIOS 构建版本为 314。最后，启动画面还标识了一个虚拟 IDE CD-ROM 驱动器，并表明它正在初始化。这表明系统即将从虚拟 CD-ROM 启动或将在启动过程中使用它。"
  },
  {
    "id": "44819917",
    "title": "We replaced passwords with something worse",
    "url": "https://blog.danielh.cc/blog/passwords",
    "summary": "This article critiques the growing trend of websites replacing password logins with email/phone number verification codes. The author argues this method, where a website sends a 6-digit code to a user's email or phone for login, is detrimental to account security and worse than passwords.\n\nThe core problem is the vulnerability to attack: anyone can enter an email or phone number into a service and trigger the sending of a login code. This leaves users vulnerable because they cannot easily verify the legitimacy of the request. They don't know if they should input the code because they are unsure if it's part of a legitimate login attempt or an attack.\n\nFurthermore, the author points out that standard security measures like password managers are ineffective against this type of attack. Password managers are useless because the login relies on a one-time code, not a stored password.\n\nThe article concludes with a concrete example, highlighting that Microsoft's Minecraft account login system utilizes this flawed method and has already led to successful account theft. Essentially, the convenience of this login system comes at the significant cost of increased vulnerability to account hijacking.\n",
    "chinese_title": "我们用更糟的东西取代了密码。",
    "chinese_summary": "本文批判了网站以电子邮件/电话号码验证码取代密码登录的日益增长的趋势。作者认为，这种通过网站向用户的电子邮件或电话发送6位代码进行登录的方法，对账户安全有害，比密码更糟糕。\n\n核心问题在于其易受攻击的特性：任何人都可以将电子邮件或电话号码输入服务并触发登录代码的发送。这使得用户很容易受到攻击，因为他们无法轻易验证请求的合法性。他们不知道是否应该输入代码，因为他们不确定这是否是合法的登录尝试或攻击的一部分。\n\n此外，作者指出，密码管理器等标准安全措施在这种类型的攻击面前是无效的。密码管理器毫无用处，因为登录依赖于一次性代码，而不是存储的密码。\n\n文章最后以一个具体的例子结尾，强调微软的Minecraft账户登录系统就使用了这种有缺陷的方法，并且已经导致了成功的账户盗窃。本质上，这种登录系统的便利性是以账户劫持风险增加为代价的。"
  },
  {
    "id": "44823580",
    "title": "Arm Desktop: x86 Emulation",
    "url": "https://marcin.juszkiewicz.com.pl/2025/07/22/arm-desktop-emulation/",
    "summary": "This article explores the feasibility of using x86-64 emulation on an Arm-based desktop system, specifically an Ampere Altra-based machine running Fedora. The author dives into the software stack needed, focusing on FEX-emu and recommending the removal of unnecessary QEMU packages.\n\nInitial performance tests with Geekbench 6 revealed poor emulation speeds, comparable to an old Intel Atom CPU. The author then consulted with FEX-emu developers and implemented suggested tweaks like reducing FPU precision and disabling TSO, which significantly improved performance in practical scenarios like running the game Factorio.\n\nThe author then details the process of installing and running Steam under emulation, highlighting the need to bypass dependency checks during installation. While Factorio was initially unplayable, the configuration tweaks made it reasonably playable at lower settings.\n\nA humorous anecdote illustrates the importance of ensuring native Arm binaries are used instead of accidentally running x86-64 binaries under emulation, which drastically reduced build times.\n\nUltimately, the author concludes that while x86-64 emulation is possible, it's not something they plan to use heavily, except perhaps for older games. The piece offers practical tips and insights for anyone looking to run x86-64 applications on Arm hardware, emphasizing the importance of proper configuration for optimal performance.\n",
    "chinese_title": "Arm 桌面：x86 模拟",
    "chinese_summary": "在Arm桌面系统上使用x86-64模拟的可行性探索：以Ampere Altra/Fedora为例\n\n本文探讨了在基于Arm的桌面系统上使用x86-64模拟的可行性，特别是运行Fedora的Ampere Altra机器。作者深入研究了所需的软件栈，重点介绍了FEX-emu，并建议移除不必要的QEMU包。\n\n使用Geekbench 6的初步性能测试显示，模拟速度很慢，与旧款Intel Atom CPU相当。随后，作者咨询了FEX-emu开发者，并实施了建议的调整，例如降低FPU精度和禁用TSO，这显著提高了实际场景（如运行游戏Factorio）中的性能。\n\n作者随后详细介绍了在模拟下安装和运行Steam的过程，强调了在安装过程中需要绕过依赖性检查。虽然Factorio最初无法运行，但配置调整使其在较低设置下可以合理地运行。\n\n一个幽默的轶事说明了确保使用原生Arm二进制文件而不是意外地在模拟下运行x86-64二进制文件的重要性，后者会大大缩短构建时间。\n\n最终，作者得出结论，虽然x86-64模拟是可行的，但他们并不打算大量使用它，或许除了老游戏之外。本文为任何希望在Arm硬件上运行x86-64应用程序的人提供了实用的技巧和见解，强调了适当配置对于优化性能的重要性。"
  },
  {
    "id": "44825175",
    "title": "More shell tricks: first class lists and jq",
    "url": "https://alurm.github.io/blog/2025-08-07-first-class-lists-in-shells.html",
    "summary": "This article explores workarounds for the limitations of common shells regarding first-class lists, focusing on the task of implementing a `split-by-double-dash` function that separates command-line arguments before and after a `--` delimiter into two separate lists.\n\nThe first approach leverages `jq`, a powerful JSON processor, to create shell-escaped strings representing lists.  The article demonstrates how `jq` can transform JSON arrays into shell-compatible strings suitable for use with `eval`, a potentially dangerous but unavoidable tool for dynamically creating lists in the shell. A complete solution for `split-by-double-dash` using `jq` is provided, showing how to parse command-line arguments passed to `jq` itself and then construct the two lists.\n\nThe second approach utilizes the `es` shell, a descendant of the Plan 9 `rc` shell, which features first-class functions and structured returns. The article showcases how to emulate lists in `es` using closures, functions that capture their environment. A `split-by-double-dash` function is implemented in `es`, which returns two lists (emulated via closures) representing the arguments before and after the delimiter. This approach avoids the need for `eval` and complex quoting seen in the `jq` solution.\n\nThe article concludes by acknowledging the pitfalls of shell scripting but also highlights the creative solutions possible, especially with tools like `jq` and more advanced shells like `es`. It also includes a quote highlighting the dangers of relying on `sh` for anything other than basic tasks.\n",
    "chinese_title": "更多 Shell 技巧：一流列表和 jq",
    "chinese_summary": "本文探讨了针对常见 shell 在一流列表方面局限性的变通方案，重点在于实现一个 `split-by-double-dash` 函数，该函数将命令行参数中 `--` 分隔符之前和之后的内容分成两个独立的列表。\n\n第一种方法利用了强大的 JSON 处理器 `jq` 来创建表示列表的 shell 转义字符串。本文展示了 `jq` 如何将 JSON 数组转换为与 shell 兼容的字符串，这些字符串适合与 `eval` 一起使用，`eval` 是一个潜在危险但又不可避免的工具，用于在 shell 中动态创建列表。文中提供了一个使用 `jq` 的完整 `split-by-double-dash` 解决方案，展示了如何解析传递给 `jq` 本身的命令行参数，然后构造两个列表。\n\n第二种方法利用了 `es` shell，它是 Plan 9 `rc` shell 的后代，具有一流的函数和结构化返回值。本文展示了如何使用闭包（捕获其环境的函数）在 `es` 中模拟列表。在 `es` 中实现了一个 `split-by-double-dash` 函数，该函数返回两个列表（通过闭包模拟），分别表示分隔符之前和之后的参数。这种方法避免了 `jq` 解决方案中对 `eval` 和复杂引用的需求。\n\n文章最后承认了 shell 脚本的缺陷，但也强调了可能出现的创造性解决方案，特别是使用 `jq` 和像 `es` 这样更高级的 shell。它还包含一句引言，强调了依赖 `sh` 来完成基本任务以外的任何事情的危险性。"
  },
  {
    "id": "44824560",
    "title": "Sweatshop Data Is Over",
    "url": "https://www.mechanize.work/blog/sweatshop-data-is-over/",
    "summary": "This article argues that the era of \"sweatshop data\" – large datasets generated by low-skill, low-paid workers – is ending and a new approach to AI training is needed for continued progress. While this data fueled early AI advancements, current models struggle with complex, long-horizon tasks.\n\nThe authors propose a shift from static datasets to interactive software environments where AIs can learn through trial and error, similar to how humans learn. This requires sophisticated environments designed to enable iterative, autonomous learning. Instead of relying on contractors for data labeling, the focus should be on employing full-time specialists with deep expertise in specific domains to design these complex training environments.\n\nThe authors emphasize that good Reinforcement Learning (RL) environments are now the bottleneck to further AI progress. Scaling up models without improving the quality of training environments will lead to diminishing returns, as pretraining is already showing signs of saturation. Current RL methods, while useful for tasks with verifiable rewards, are insufficient for dealing with the open-ended nature of reality.\n\nTo overcome this, better rewards and more realistic RL environments are needed to simulate real-world challenges and accurately reward AIs for skilled navigation. Ultimately, the authors call for a reframing of the data generation process, recognizing it as a high-status activity requiring top talent and clever engineering. The authors are hiring software engineers to help build this software.\n",
    "chinese_title": "血汗工厂数据已结束",
    "chinese_summary": "本文认为，“血汗工厂数据”（由低技能、低薪工人生成的大型数据集）的时代正在结束，需要一种新的AI训练方法来实现持续进步。尽管此类数据推动了早期的AI发展，但目前的模型难以处理复杂、长期的任务。\n\n作者建议从静态数据集转向交互式软件环境，让AI可以通过试错来学习，类似于人类的学习方式。这需要设计精巧的环境，以实现迭代式自主学习。与其依赖承包商进行数据标记，不如专注于聘用在特定领域拥有深厚专业知识的全职专家来设计这些复杂的训练环境。\n\n作者强调，良好的强化学习（RL）环境现在是进一步AI进步的瓶颈。在不提高训练环境质量的情况下扩大模型规模将会导致收益递减，因为预训练已经显示出饱和的迹象。目前的RL方法虽然对具有可验证奖励的任务有用，但不足以应对现实世界的开放性。\n\n为了克服这一问题，需要更好的奖励和更真实的RL环境来模拟现实世界的挑战，并准确地奖励AI的熟练导航。最终，作者呼吁重新构建数据生成过程，将其视为一项需要顶尖人才和巧妙工程的高地位活动。作者正在招聘软件工程师来帮助构建此软件。"
  },
  {
    "id": "44826465",
    "title": "PyPI: Preventing ZIP parser confusion attacks on Python package installers",
    "url": "https://blog.pypi.org/posts/2025-08-07-wheel-archive-confusion-attacks/",
    "summary": "PyPI is implementing new restrictions to prevent ZIP parser confusion attacks, a vulnerability that can be exploited due to inconsistencies in how different ZIP implementations extract files. This stems from the complexity of the ZIP standard and the fact that most Python installers don't strictly validate the contents of a wheel (a ZIP archive) against its RECORD file (which lists files and checksums).\n\nTo mitigate this, PyPI will now reject ZIP archives with various issues like invalid record information, duplicate filenames, mismatches between headers, trailing data, and incorrect header locator values. While existing compression-bomb detection is in place, PyPI will also begin warning users about wheels with discrepancies between the ZIP contents and the RECORD file, with rejections planned to start February 1st, 2026.\n\nThe goal is to prevent malicious actors from smuggling files past security checks. While most top Python packages are compliant, some exhibit issues. Users installing packages should keep their tools updated, maintainers should address upload errors, and installer maintainers should ensure proper ZIP implementation (checking the Central Directory) and begin validating against the RECORD file. The authors thank Caleb Brown and Tim Hatch, and acknowledge Alpha-Omega for their funding of the Python Software Foundation's security efforts. End users do not need to take immediate action, but should take steps to ensure future compliance with packaging and ZIP standards.\n",
    "chinese_title": "PyPI：防止 Python 包安装器上的 ZIP 解析器混淆攻击",
    "chinese_summary": "PyPI 将实施新限制以防止 ZIP 解析器混淆攻击。该漏洞源于不同 ZIP 实现提取文件方式的不一致性。由于 ZIP 标准的复杂性以及大多数 Python 安装程序没有严格验证 wheel（ZIP 压缩包）的内容与其 RECORD 文件（列出文件和校验和）的匹配性，因此可能被利用。\n\n为缓解此问题，PyPI 现在将拒绝存在各种问题的 ZIP 压缩包，例如无效的记录信息、重复的文件名、header 之间的不匹配、尾随数据以及不正确的 header locator 值。尽管现有的压缩炸弹检测机制已经到位，PyPI 还将开始警告用户关于 ZIP 内容与 RECORD 文件之间存在差异的 wheel，并计划于 2026 年 2 月 1 日开始拒绝此类 wheel。\n\n目标是防止恶意行为者将文件偷偷绕过安全检查。虽然大多数顶级的 Python 包都符合标准，但有些也存在问题。安装包的用户应保持工具更新，维护者应解决上传错误，安装程序维护者应确保正确的 ZIP 实现（检查中央目录）并开始验证与 RECORD 文件的匹配性。作者感谢 Caleb Brown 和 Tim Hatch，并感谢 Alpha-Omega 为 Python 软件基金会的安全工作提供资金。最终用户无需立即采取行动，但应采取措施确保未来符合打包和 ZIP 标准。"
  },
  {
    "id": "44824728",
    "title": "Global Trade Dynamics",
    "url": "https://alhadaqa.github.io/globaltradedynamics/",
    "summary": "The article, titled \"Global Trade Dynamics,\" likely explores the fluctuating nature of international trade. Without the actual article content, I can provide a generalized summary of what that might entail:\n\nThe article likely discusses the complex interplay of factors influencing global trade patterns. It probably examines key economic drivers such as GDP growth in major economies, currency fluctuations, and changes in commodity prices that impact export and import volumes.\n\nThe summary would also likely address the role of trade policies, including tariffs, trade agreements (both bilateral and multilateral), and non-tariff barriers, and how these policies shape trade flows and competitiveness. It might discuss the impact of geopolitical events, such as conflicts, political instability, and sanctions, on global supply chains and trade relationships.\n\nFurthermore, the article may highlight the rise of e-commerce and digital trade, analyzing its impact on cross-border transactions and the need for updated regulatory frameworks. It could also cover the increasing importance of sustainable and ethical trade practices, including environmental regulations and labor standards.\n\nFinally, the article probably touches upon the challenges and opportunities facing global trade, such as protectionist tendencies, technological disruptions (like automation and AI), and the need for resilient and diversified supply chains in the face of global crises. The overall message is likely centered around understanding the dynamic and evolving nature of global trade and its significant impact on national economies and international relations.\n",
    "chinese_title": "全球贸易动态",
    "chinese_summary": "题为《全球贸易动态》的文章可能探讨国际贸易的波动性。在没有实际文章内容的情况下，我可以提供一个关于其可能包含内容的概括性总结：\n\n该文章可能讨论影响全球贸易模式的复杂因素。它很可能考察关键的经济驱动因素，如主要经济体的GDP增长、货币波动以及影响进出口量的商品价格变化。\n\n该总结还可能涉及贸易政策的作用，包括关税、贸易协定（双边和多边）和非关税壁垒，以及这些政策如何塑造贸易流动和竞争力。它可能讨论地缘政治事件（如冲突、政治不稳定和制裁）对全球供应链和贸易关系的影响。\n\n此外，该文章可能强调电子商务和数字贸易的兴起，分析其对跨境交易的影响以及对更新监管框架的需求。它还可能涵盖可持续和合乎道德的贸易实践日益重要的地位，包括环境法规和劳动标准。\n\n最后，该文章可能触及全球贸易面临的挑战和机遇，如保护主义倾向、技术颠覆（如自动化和人工智能）以及在全球危机面前建立具有弹性和多元化的供应链的需求。总的来说，文章的主旨很可能是围绕理解全球贸易的动态和演变性质，及其对国民经济和国际关系的重大影响。"
  },
  {
    "id": "44783442",
    "title": "Koalas vs. Crows: An Evolutionary Theory of Software",
    "url": "https://ajmoon.com/posts/koalas-vs-crows-an-evolutionary-theory-of-software",
    "summary": "This article proposes an evolutionary theory of software development, drawing parallels between animal survival strategies and software design principles. It posits that software, like organisms, evolves under \"energy cost\" pressures, analogous to the scarcity of energy in biological ecosystems.\n\nThe central concept is the distinction between \"koala software\" and \"crow software.\" Koala software is characterized by simplicity, ease of use, and hyper-specialization for a specific niche, prioritizing low cognitive load for users. Examples include SMTP, FAT32, CSV, and JSON. This type thrives in well-defined, stable niches.\n\nCrow software, on the other hand, is complex, adaptable, and capable of handling a broad range of use cases, requiring a higher \"learning curve\" or \"power users.\" Examples include the Adobe suite, Blender, IDEs, and infrastructure tools like Ansible and Kubernetes. This type excels in dynamic environments needing versatility.\n\nThe article explores the Unix philosophy (\"do one thing well\") and contrasts it with the \"MIT Approach,\" exemplified by the X Window System, to illustrate these contrasting strategies. It also connects these concepts to Clayton Christensen's theory of \"disruptive innovation,\" where \"worse is better\" (koala software) disrupts established markets. Finally, \"sustaining innovation\" (crow software) represents the continuous improvement and addition of features by incumbents.\n\nThe author uses the evolution of front-end JavaScript libraries like jQuery (a koala) and React (a crow) to demonstrate the cyclical nature of software development, where simplicity can initially displace complexity, but complexity eventually becomes necessary to address evolving requirements. The underlying premise is that both types of software are crucial, each thriving in different niches determined by the trade-off between energy expenditure (cognitive load) and adaptability.\n",
    "chinese_title": "考拉大战乌鸦：软件的进化论",
    "chinese_summary": "本文提出了一种软件开发的进化理论，将动物的生存策略与软件设计原则进行类比。它假设软件，如同生物一样，在“能量成本”的压力下进化，类似于生物生态系统中能量的稀缺性。\n\n其核心概念是区分“考拉软件”和“乌鸦软件”。考拉软件的特点是简单、易用，并为特定领域进行高度专业化，优先考虑用户较低的认知负荷。例如SMTP、FAT32、CSV和JSON。这种类型在定义明确、稳定的领域中蓬勃发展。\n\n另一方面，乌鸦软件是复杂的、适应性强的，并且能够处理广泛的用例，需要更高的“学习曲线”或“高级用户”。例如Adobe套件、Blender、IDE以及像Ansible和Kubernetes这样的基础设施工具。这种类型在需要多功能的动态环境中表现出色。\n\n本文探讨了Unix哲学（“做好一件事”）并将它与以X Window System为例的“MIT方法”进行对比，以说明这些对比鲜明的策略。它还将这些概念与克莱顿·克里斯坦森的“颠覆性创新”理论联系起来，其中“更差即更好”（考拉软件）颠覆了既定的市场。最后，“持续性创新”（乌鸦软件）代表了现有企业不断改进和增加功能。\n\n作者使用像jQuery（考拉）和React（乌鸦）这样的前端JavaScript库的演变来证明软件开发的周期性，即简单性最初可以取代复杂性，但复杂性最终变得必要，以解决不断发展的需求。其基本前提是，这两种类型的软件都至关重要，每种软件都在由能量消耗（认知负荷）和适应性之间的权衡决定的不同领域中蓬勃发展。"
  },
  {
    "id": "44822684",
    "title": "The Whispering Earring (Scott Alexander)",
    "url": "https://croissanthology.com/earring",
    "summary": "The Whispering Earring is a magical artifact that offers its wearer advice, starting with the suggestion to remove it. If the wearer ignores this, the earring continues to whisper advice on decisions, always correct and always leading to the wearer's greatest happiness, though not necessarily optimal success.\n\nInitially, the advice focuses on major life choices, but as the earring becomes familiar with the wearer, it offers guidance on increasingly minute details, like breakfast choices. Eventually, it communicates through high-bandwidth hisses and clicks corresponding to individual muscle movements, which the wearer subconsciously internalizes.\n\nWearers who follow the earring's advice live successful and happy lives, becoming pillars of their communities. However, Kadmi Rachumion investigated the earring and discovered that wearers' brains exhibit significant deformation: their neocortexes atrophy, while lower brain regions associated with reflexive action become hypertrophied. This implies the earring gradually reduces its wearers to creatures of pure instinct.\n\nAfter experimenting with the earring himself, Kadmi Rachumion recommended locking it away, recognizing its insidious nature. The story concludes with Niderion-nomai's commentary suggesting that human foolishness and the refusal to always take the most efficient path might be what preserves freedom.\n",
    "chinese_title": "低语耳环 (斯科特·亚历山大)",
    "chinese_summary": "低语耳环是一种魔法神器，能够为佩戴者提供建议，首先会建议佩戴者摘下它。如果佩戴者忽略这一建议，耳环会继续低语，为各种决定提供建议，这些建议总是正确的，并且总是能引导佩戴者走向最大的幸福，尽管不一定是最佳的成功。\n\n最初，建议主要集中于重大的人生选择，但随着耳环与佩戴者的熟悉程度加深，它会就越来越细微的细节提供指导，比如早餐的选择。最终，它会通过高带宽的嘶嘶声和咔哒声进行交流，这些声音对应于单个肌肉的运动，佩戴者会下意识地将其内化。\n\n听从耳环建议的佩戴者会过上成功而幸福的生活，成为他们社区的支柱。然而，卡德米·拉楚米翁调查了这枚耳环，发现佩戴者的大脑表现出明显的变形：新皮层萎缩，而与反射行为相关的较低脑区则变得肥大。这意味着耳环逐渐将佩戴者变成纯粹凭本能行事的生物。\n\n在自己尝试过这枚耳环后，卡德米·拉楚米翁建议将其锁起来，并认识到它阴险的本质。故事以尼德里昂-诺迈的评论结尾，暗示人类的愚蠢以及拒绝总是采取最有效率的道路，可能才是保持自由的原因。"
  },
  {
    "id": "44824981",
    "title": "Let's stop pretending that managers and executives care about productivity",
    "url": "https://www.baldurbjarnason.com/2025/disingenuous-discourse/",
    "summary": "Baldur Bjarnason argues that businesses today don't genuinely care about productivity, management, or even costs, focusing instead on control over labor and stock prices. He contends that modern management theory, born from World War II efforts and later adopted in Japan, has been largely ignored by the tech industry and financialization.\n\nHe highlights examples like open offices and the handling of work-from-home policies as evidence. Open offices harm productivity and collaboration, while remote work, though often productive and beneficial for employee well-being, is resisted due to reduced surveillance capabilities.\n\nBjarnason believes analyzing \"AI\" from a modern management perspective is meaningless because businesses prioritize control over practical benefits. He questions whether there's an audience that values both good management and is open to generative models, given the associated financial bubble, lock-in, environmental impact, and political risks.\n\nHe uses concepts like task sequences, vector maths, and queueing theory to illustrate how the high variability of \"AI\" tools can negatively impact organizational capacity and potentially lead to disastrous outcomes like project delays and failures. Even small productivity gains at the task level can be swamped by large losses due to the variability introduced by \"AI\".\n\nIn essence, Bjarnason suggests that the implementation of \"AI\" is often driven by factors other than genuine productivity enhancement and can be detrimental to organizational efficiency and employee well-being.\n",
    "chinese_title": "别再假装管理者和高管关心生产力了",
    "chinese_summary": "Baldur Bjarnason 认为，当今企业并非真正关心生产力、管理，甚至成本，而是专注于控制劳动力和股票价格。他认为，源于二战努力并在日本得到采用的现代管理理论，很大程度上被科技行业和金融化所忽视。\n\n他以开放式办公室和居家办公政策的处理为例来佐证。开放式办公室损害生产力和协作，而远程办公虽然通常具有生产力并且有益于员工福祉，但由于监控能力降低而受到抵制。\n\nBjarnason 认为，从现代管理角度分析“人工智能”毫无意义，因为企业将控制置于实际利益之上。考虑到相关的金融泡沫、锁定效应、环境影响和政治风险，他质疑是否存在一个既重视良好管理又对生成模型持开放态度的受众。\n\n他使用任务序列、向量数学和排队理论等概念来阐述“人工智能”工具的高变异性如何对组织能力产生负面影响，并可能导致项目延误和失败等灾难性后果。即使任务层面的小幅生产力提升，也可能因“人工智能”引入的变异性所带来的巨大损失而黯然失色。\n\n本质上，Bjarnason 认为，“人工智能”的实施往往并非由真正的生产力提升所驱动，并且可能对组织效率和员工福祉产生不利影响。"
  },
  {
    "id": "44811567",
    "title": "Claude Code IDE integration for Emacs",
    "url": "https://github.com/manzaltu/claude-code-ide.el",
    "summary": "This document describes `claude-code-ide.el`, an Emacs package providing deep integration with the Claude Code CLI. Unlike basic terminal wrappers, it utilizes the Model Context Protocol (MCP) to create a bidirectional communication bridge, empowering Claude to understand and leverage Emacs' features like LSP, project management, and custom Elisp functions.\n\nKey features include automatic project detection and session management, terminal integration, MCP protocol implementation for accessing Emacs commands and workspace info, diagnostics integration with Flycheck/Flymake, and an advanced diff view with ediff. It supports language server integration (eglot, lsp-mode), Tree-sitter, and Imenu for enhanced code navigation and analysis.\n\nThe package allows exposing any Emacs command as an MCP tool, enabling Claude to perform project-wide searches, refactoring, and execute custom Elisp functions. Installation requires Emacs 28.1+, the Claude Code CLI, and `vterm` or `eat`. Configuration options allow customization of CLI path, buffer naming, debugging, terminal backend (vterm or eat), side window placement, and custom system prompts. It also provides a workaround for a terminal reflow glitch and supports Flycheck/Flymake for diagnostics.\n\nThe document also discusses debugging techniques, using git worktrees for multiple Claude Code instances within the same project, and the built-in MCP tools that expose Emacs functionality like xref and tree-sitter for code analysis. Users can create custom MCP tools by defining Emacs functions with descriptions and parameters to extend Claude's capabilities.\n",
    "chinese_title": "Claude 代码 IDE Emacs 集成",
    "chinese_summary": "本文档介绍了 `claude-code-ide.el`，一个 Emacs 包，它提供与 Claude Code CLI 的深度集成。与基本终端包装器不同，它利用模型上下文协议 (MCP) 创建双向通信桥梁，使 Claude 能够理解和利用 Emacs 的特性，如 LSP、项目管理和自定义 Elisp 函数。\n\n主要特性包括自动项目检测和会话管理、终端集成、用于访问 Emacs 命令和工作区信息的 MCP 协议实现、与 Flycheck/Flymake 的诊断集成以及带有 ediff 的高级 diff 视图。它支持语言服务器集成（eglot、lsp-mode）、Tree-sitter 和 Imenu，以增强代码导航和分析。\n\n该软件包允许将任何 Emacs 命令公开为 MCP 工具，使 Claude 能够执行项目范围的搜索、重构和执行自定义 Elisp 函数。安装需要 Emacs 28.1+、Claude Code CLI 以及 `vterm` 或 `eat`。配置选项允许自定义 CLI 路径、缓冲区命名、调试、终端后端（vterm 或 eat）、侧窗口位置和自定义系统提示。它还提供了一个终端回流故障的解决方法，并支持 Flycheck/Flymake 进行诊断。\n\n该文档还讨论了调试技术，使用 git 工作树在同一项目中创建多个 Claude Code 实例，以及内置的 MCP 工具，这些工具公开了 Emacs 的功能，例如 xref 和 tree-sitter 用于代码分析。用户可以通过定义带有描述和参数的 Emacs 函数来创建自定义 MCP 工具，以扩展 Claude 的功能。"
  },
  {
    "id": "44789750",
    "title": "Hopfield Networks Is All You Need (2020)",
    "url": "https://arxiv.org/abs/2008.02217",
    "summary": "This 2020 paper, \"Hopfield Networks is All You Need,\" introduces a novel, modern Hopfield network with continuous states and an updated rule set. This new network boasts significantly improved capabilities compared to traditional Hopfield networks, including exponential storage capacity (relative to the associative space dimension), single-update pattern retrieval, and exponentially small retrieval errors.\n\nThe key innovation lies in the observation that the update rule is mathematically equivalent to the attention mechanism used in Transformer models. This equivalence allows for a novel interpretation of Transformer heads, suggesting that early layers perform global averaging, while higher layers leverage metastable states for partial averaging.\n\nThe paper proposes integrating these modern Hopfield networks as layers within deep learning architectures, providing memory, association, attention, and pooling mechanisms, thus moving beyond traditional architectures.\n\nThe authors demonstrate the broad applicability of these \"Hopfield layers\" through empirical results. The inclusion of Hopfield layers improved state-of-the-art performance on multiple instance learning problems, immune repertoire classification, and UCI benchmark collections (small classification tasks). Furthermore, they achieved state-of-the-art results on two drug design datasets. The authors also provide links to their implementation.\n",
    "chinese_title": "Hopfield网络：你所需要的一切 (2020)",
    "chinese_summary": "这篇2020年的论文《Hopfield网络足矣》介绍了一种新型的、现代的Hopfield网络，该网络具有连续状态和更新的规则集。与传统的Hopfield网络相比，这种新网络具有显著改进的性能，包括指数级的存储容量（相对于关联空间维度）、单次更新模式检索以及指数级小的检索误差。\n\n关键创新在于观察到更新规则在数学上等同于Transformer模型中使用的注意力机制。这种等价性允许对Transformer头部进行新的解释，表明早期层执行全局平均，而较高层利用亚稳态进行部分平均。\n\n该论文提出将这些现代Hopfield网络作为层集成到深度学习架构中，从而提供内存、关联、注意力和池化机制，从而超越了传统架构。\n\n作者通过经验结果证明了这些“Hopfield层”的广泛适用性。包含Hopfield层改进了多示例学习问题、免疫库分类和UCI基准集合（小型分类任务）上的最先进性能。此外，他们在两个药物设计数据集上实现了最先进的结果。作者还提供了其实现的链接。"
  },
  {
    "id": "44823850",
    "title": "An LLM does not need to understand MCP",
    "url": "https://hackteam.io/blog/your-llm-does-not-care-about-mcp/",
    "summary": "This blog post explains that while Model Context Protocol (MCP) is a valuable tool for developers building agents with Large Language Models (LLMs), the LLM itself doesn't need to \"understand\" MCP. The author clarifies that LLMs are merely predicting the next block of text based on the prompt, which includes a list of available tools, their descriptions, and expected inputs.\n\nMCP standardizes how agents connect to data sources, especially tools, simplifying integration and management. It acts like a universal adapter, allowing developers to access numerous tools without writing custom code for each.  MCP involves a host application, an MCP client, and MCP servers that expose tools, prompts, or resources. The developer uses MCP to call these tools, while the LLM remains focused on generating the correct tool call snippet based on its context.\n\nThe core benefit of MCP lies in simplifying the developer's workflow, enabling reuse of tools across projects, consistent formatting, and easier integration of new systems. This ultimately makes context engineering, the process of providing the LLM with the right inputs for useful outputs, more manageable and scalable.  The LLM doesn't inherently know or care about the underlying MCP implementation, only the tool definitions it receives as part of the prompt. In essence, MCP is a tool for developers, streamlining agentic application development without affecting the LLM's fundamental function.\n",
    "chinese_title": "大型语言模型无需理解MCP。",
    "chinese_summary": "虽然模型上下文协议 (MCP) 对于使用大型语言模型 (LLM) 构建代理的开发者来说是一个有价值的工具，但 LLM 本身并不需要“理解”MCP。作者阐明，LLM 仅仅是根据提示预测下一个文本块，该提示包括可用工具列表、其描述和预期输入。\n\nMCP 标准化了代理连接到数据源（尤其是工具）的方式，从而简化了集成和管理。它就像一个通用适配器，允许开发者访问大量工具而无需为每个工具编写自定义代码。 MCP 涉及宿主应用程序、MCP 客户端和暴露工具、提示或资源的 MCP 服务器。开发者使用 MCP 调用这些工具，而 LLM 仍然专注于根据其上下文生成正确的工具调用代码片段。\n\nMCP 的核心优势在于简化开发者的工作流程，实现跨项目工具的重用、一致的格式化以及新系统的更轻松集成。这最终使上下文工程（为 LLM 提供正确的输入以获得有用的输出的过程）更易于管理和扩展。 LLM 本质上并不了解或关心底层的 MCP 实现，只关心它作为提示一部分收到的工具定义。本质上，MCP 是开发者的工具，简化了代理应用程序的开发，而不会影响 LLM 的基本功能。"
  },
  {
    "id": "44821434",
    "title": "Cracking the Vault: How we found zero-day flaws in HashiCorp Vault",
    "url": "https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/",
    "summary": "This article, titled \"Cracking the Vault: How we found zero-day flaws in HashiCorp Vault,\" published on August 6, 2025, details how researchers discovered zero-day vulnerabilities in HashiCorp Vault. Written by Yarden Porat, the article likely outlines the process of finding and exploiting these flaws.\n\nThe provided text fragment also mentions another successful exploit in CyberArk Conjur, achieving arbitrary remote code execution (RCE) from an unauthenticated state by exploiting a full chain of trust flaws. While the main focus seems to be on HashiCorp Vault, the reference to the CyberArk Conjur exploit indicates a common theme: vulnerabilities in enterprise-level secret management systems.\n\nTherefore, the article probably dives into the technical details of the discovered flaws in HashiCorp Vault, potentially covering:\n\n*   The specific vulnerabilities identified.\n*   The methods used to discover and exploit them.\n*   The impact of these vulnerabilities, emphasizing the potential for RCE or other critical security breaches.\n*   A discussion on the importance of securing enterprise vaults and the risks associated with neglecting security best practices.\n",
    "chinese_title": "破解金库：我们如何发现 HashiCorp Vault 中的零日漏洞",
    "chinese_summary": "《破解金库：我们如何发现 HashiCorp Vault 中的零日漏洞》这篇于2025年8月6日发表的文章，详细介绍了研究人员如何发现 HashiCorp Vault 中的零日漏洞。该文章由 Yarden Porat 撰写，很可能概述了发现和利用这些漏洞的过程。\n\n提供的文本片段还提及了 CyberArk Conjur 中另一个成功的漏洞利用，通过利用完整的信任链缺陷，从未经身份验证的状态实现任意远程代码执行 (RCE)。 虽然主要重点似乎是 HashiCorp Vault，但提及 CyberArk Conjur 漏洞利用表明了一个共同的主题：企业级密钥管理系统中的漏洞。\n\n因此，这篇文章可能深入探讨了 HashiCorp Vault 中发现的漏洞的技术细节，可能涵盖：\n\n*   已识别的特定漏洞。\n*   用于发现和利用它们的方法。\n*   这些漏洞的影响，强调 RCE 或其他关键安全漏洞的潜力。\n*   关于保护企业金库的重要性以及忽视安全最佳实践所带来的风险的讨论。"
  },
  {
    "id": "44787738",
    "title": "Debounce",
    "url": "https://developer.mozilla.org/en-US/docs/Glossary/Debounce",
    "summary": "Debouncing is a programming technique used to consolidate multiple function invocations that occur closely together within a specified interval into a single invocation. Its primary purpose is to prevent unnecessary or excessive execution of a function when dealing with rapid, repeated triggers.\n\nUnlike throttling, which limits the rate of continuous operations, debouncing specifically waits for a period of inactivity before executing the function. This period of inactivity (the \"debounce interval\") allows for the aggregation of numerous noisy invocations into one consolidated action.\n\nA common use case is handling user input, such as typing in a search box. Debouncing prevents actions like filtering or suggestion generation from occurring with every keystroke, which can lead to lag. Instead, the action is triggered only after the user pauses typing for a certain duration.\n\nKey concepts in debouncing include:\n\n*   **Leading Edge:** The first call to the function.\n*   **Trailing Edge:** The point when the debounce interval has elapsed since the last call, indicating the end of the \"batch\" of invocations.\n\nTypically, the debounced function is executed only on the trailing edge. However, it can also be executed on the leading edge or even both, depending on the specific implementation requirements. If executed on both edges, special care is taken to ensure the interval constraint is still satisfied.\n",
    "chinese_title": "防抖",
    "chinese_summary": "防抖是一种编程技术，用于将指定时间间隔内紧密发生的多次函数调用合并为一次调用。其主要目的是在处理快速、重复触发时，防止不必要或过度的函数执行。\n\n与限制连续操作频率的节流不同，防抖专门等待一段非活动期后才执行函数。这段非活动期（“防抖间隔”）允许将大量嘈杂的调用聚合为一次整合的操作。\n\n一个常见的用例是处理用户输入，例如在搜索框中键入。防抖可以防止每次按键都触发过滤或建议生成等操作，从而导致延迟。相反，只有在用户暂停键入一段时间后才触发该操作。\n\n防抖的关键概念包括：\n\n*   **前沿：** 对函数的首次调用。\n*   **后沿：** 自上次调用以来防抖间隔已过去的时间点，表示调用“批次”的结束。\n\n通常，防抖函数仅在后沿执行。但是，它也可以在前沿甚至两者上执行，具体取决于特定的实现要求。如果在两个边缘上都执行，则需要特别注意，以确保仍然满足时间间隔约束。"
  },
  {
    "id": "44811840",
    "title": "Show HN: Aura – Like robots.txt, but for AI actions",
    "url": "https://github.com/osmandkitay/aura",
    "summary": "Aura is a new open protocol designed to make websites understandable and operable by AI agents. It aims to replace the current brittle methods of screen scraping and DOM manipulation with a robust, secure, and efficient machine-readable layer for the web.\n\nThe core of Aura involves websites declaring their capabilities in a `aura.json` manifest file, similar to an API documentation for AI. This manifest defines available resources and capabilities, such as \"create_post,\" explicitly mapping them to HTTP requests with required parameters. The protocol also uses an `AURA-State` HTTP header to inform agents about the current context and available capabilities.\n\nThe repository provides the AURA protocol specification, including a TypeScript package with JSON Schema validation (`@aura/protocol`), a Next.js reference server, and a backend-only reference client. The client demonstrates how to consume the protocol without a browser or extension. Demonstrations include running the reference server, using an agent to execute capabilities based on prompts, and running a crawler that indexes an AURA-enabled site to understand its functions.\n\nThe project encourages community contributions through adapters for various web frameworks and clients in different programming languages. The goal is to build a collaborative ecosystem that fosters a more intelligent and interoperable web.\n",
    "chinese_title": "显示 HN: Aura – 类似 robots.txt，但用于 AI 行为",
    "chinese_summary": "Aura：一种使网站可被AI代理理解和操作的新型开放协议。它旨在用一个健壮、安全且高效的机器可读层来取代目前脆弱的屏幕抓取和DOM操作方法。\n\nAura的核心在于网站在`aura.json`清单文件中声明其能力，类似于AI的API文档。该清单定义了可用的资源和能力，例如“create_post”，并将其明确映射到带有必需参数的HTTP请求。该协议还使用`AURA-State` HTTP头部来通知代理关于当前上下文和可用能力的信息。\n\n该存储库提供了AURA协议规范，包括一个带有JSON Schema验证的TypeScript包 (`@aura/protocol`)、一个Next.js参考服务器和一个仅限后端的参考客户端。该客户端演示了如何在没有浏览器或扩展的情况下使用该协议。演示包括运行参考服务器、使用代理根据提示执行能力，以及运行一个爬虫来索引一个启用AURA的站点以了解其功能。\n\n该项目鼓励通过各种Web框架的适配器以及不同编程语言的客户端来进行社区贡献。目标是构建一个协作生态系统，从而促进一个更智能和可互操作的Web。"
  },
  {
    "id": "44807868",
    "title": "Show HN: Kitten TTS – 25MB CPU-Only, Open-Source TTS Model",
    "url": "https://github.com/KittenML/KittenTTS",
    "summary": "Kitten TTS is a new open-source, realistic text-to-speech (TTS) model focused on being lightweight and deployable on CPU-only devices. The model boasts a tiny 25MB footprint and only 15 million parameters, making it suitable for devices without GPUs. Despite its small size, it aims for high-quality voice synthesis.\n\nThe developer preview is available for testing and includes several premium voice options. It's designed for fast inference, enabling real-time speech synthesis. Installation is achieved through a single pip command using a wheel file. Usage is straightforward with a Python interface to generate audio from text. The documentation includes sample code for installing the model, generating speech, and saving the output to a WAV file.\n\nFuture plans include releasing the fully trained model weights, a mobile SDK, and a web version. Kitten TTS emphasizes accessibility by being able to run on a wide range of devices, promising to \"work literally everywhere.\"\n",
    "chinese_title": "Show HN: Kitten TTS – 25MB CPU-Only, Open-Source TTS Model\n\nShow HN：Kitten TTS – 25MB CPU单核开源TTS模型",
    "chinese_summary": "Kitten TTS 是一款新的开源、逼真的文本转语音 (TTS) 模型，专注于轻量级和可在纯 CPU 设备上部署。 该模型拥有 25MB 的极小体积和仅 1500 万个参数，使其适用于没有 GPU 的设备。 尽管体积小巧，但它旨在实现高质量的语音合成。\n\n开发者预览版可供测试，并包含多个优质语音选项。 它专为快速推理而设计，可实现实时语音合成。 只需使用 wheel 文件通过一个 pip 命令即可完成安装。 通过 Python 接口从文本生成音频，使用方法简单明了。 该文档包含用于安装模型、生成语音以及将输出保存到 WAV 文件的示例代码。\n\n未来的计划包括发布完全训练的模型权重、移动 SDK 和 Web 版本。 Kitten TTS 强调可访问性，能够在各种设备上运行，并承诺“真正地在任何地方都能工作”。"
  },
  {
    "id": "44823614",
    "title": "Maybe we should do an updated Super Cars",
    "url": "https://spillhistorie.no/2025/07/31/maybe-we-should-do-an-updated-version/",
    "summary": "This article from Spillhistorie.no features an interview with Andrew Morris and Shaun Southern, the creators of the classic Amiga racing game, Super Cars II. The interview explores the game's inspiration, development challenges, and legacy.\n\nMorris and Southern cite Super Sprint as a major influence for the racing mechanics. They added depth to Super Cars II with weapons, trading, and humorous dialogue.\n\nDevelopment was challenging due to processor limitations and the need for detailed scrolling graphics. They used photographs for realistic textures and manually created maps to guide AI opponents. The \"challenging\" questions in the game were meant to be humorous and learnable, not necessarily an English test.\n\nMorris hadn't heard of Death Rally, but upon seeing it, agrees it looks like a modern version of Super Cars. Southern said he hadn't seen Death Rally either but agrees it looks like a modern version of Super Cars. Both expressed frustration about piracy impacting sales on the Amiga, though the success of Super Cars and Lotus led to their involvement in PC rally games later on.\n\nBoth Southern and Morris have tried Super Cars 2 on THEA500 Mini. Morris believes Super Cars International was the best version of the game. They are both proud of Super Cars' legacy. They also expressed interest in potentially creating an updated version of the game.\n",
    "chinese_title": "也许我们应该做一个更新版的超级跑车。",
    "chinese_summary": "Spillhistorie.no网站的这篇文章采访了经典Amiga赛车游戏《超级赛车2》的创作者Andrew Morris和Shaun Southern。采访探讨了游戏的灵感来源、开发挑战以及其影响。\n\nMorris和Southern认为《超级短跑》是赛车机制的主要灵感来源。他们通过武器、交易和幽默的对话，为《超级赛车2》增加了深度。\n\n由于处理器限制和对精细滚动图形的需求，开发充满挑战。他们使用照片制作逼真的纹理，并手动创建地图来引导AI对手。游戏中“具有挑战性”的问题旨在幽默且可学习，不一定是英语测试。\n\nMorris没听说过《死亡拉力》，但在看到后，他同意它看起来像是《超级赛车》的现代版。Southern说他也没看过《死亡拉力》，但也同意它看起来像是《超级赛车》的现代版。两人都对盗版影响Amiga游戏销量感到沮丧，不过《超级赛车》和《莲花》的成功让他们后来参与了PC拉力赛游戏的制作。\n\nSouthern和Morris都曾在THEA500 Mini上试玩过《超级赛车2》。Morris认为《超级赛车国际》是该游戏最好的版本。他们都为《超级赛车》的遗产感到自豪。他们还表示有兴趣潜在地创作该游戏的更新版本。"
  },
  {
    "id": "44822637",
    "title": "Leonardo Chiariglione: “I closed MPEG on 2 June 2020”",
    "url": "https://leonardo.chiariglione.org/",
    "summary": "Leonardo Chiariglione, the founder of the Moving Picture Experts Group (MPEG), recounts his journey in creating and ultimately closing the organization. Driven by a mission to develop interoperable digital media technologies, he established MPEG in 1988, leading it through the creation of groundbreaking standards like MPEG-1 (MP3, Video CD), MPEG-2 (digital TV), and MPEG-4 (internet video distribution). Over 200 standards were developed under his leadership, with membership growing significantly.\n\nHowever, Chiariglione states he closed MPEG on June 2, 2020, because he believed it had been \"hijacked\" by \"obscure forces\" that impeded technical development, maintained outdated intellectual property licensing models, and ultimately turned the organization from a facilitator of innovation into a roadblock. He felt this stifled industry and deprived consumers of new technologies.\n\nFollowing the closure of MPEG, Chiariglione initiated the Moving Picture, Audio and Data Coding by Artificial Intelligence (MPAI) in September 2020. This new organization aims to develop standards based on AI technologies, overcoming the stagnation and licensing issues he perceived in MPEG. MPAI has already developed and adopted five standards, with several more AI-based projects in the pipeline, focusing on areas such as video coding, healthcare, avatars, autonomous vehicles, and the metaverse. He authored two books documenting the end of MPEG and beginning of MPAI.\n",
    "chinese_title": "莱昂纳多·基亚里格利奥内：“我于2020年6月2日关闭了MPEG”",
    "chinese_summary": "莱昂纳多·奇亚里廖内，运动图像专家组 (MPEG) 的创始人，回顾了他创建并最终关闭该组织的历程。出于开发可互操作的数字媒体技术的使命，他于 1988 年创立了 MPEG，并带领其制定了具有开创性的标准，如 MPEG-1 (MP3, 视频 CD)、MPEG-2 (数字电视) 和 MPEG-4 (互联网视频分发)。在他的领导下，制定了 200 多项标准，成员数量也大幅增长。\n\n然而，奇亚里廖内表示，他于 2020 年 6 月 2 日关闭了 MPEG，因为他认为该组织已被“暗势力”“劫持”，这些势力阻碍了技术发展，维持了过时的知识产权许可模式，并最终将该组织从创新的推动者变成了障碍。他认为这扼杀了行业发展，剥夺了消费者获得新技术的机会。\n\nMPEG 关闭后，奇亚里廖内于 2020 年 9 月启动了人工智能运动图像、音频和数据编码 (MPAI)。这个新组织旨在开发基于人工智能技术的标准，克服他在 MPEG 中 perceived 的停滞和许可问题。MPAI 已经开发并采用了五项标准，还有几个基于人工智能的项目正在筹备中，重点关注视频编码、医疗保健、头像、自动驾驶汽车和元宇宙等领域。他撰写了两本书，记录了 MPEG 的终结和 MPAI 的开始。"
  },
  {
    "id": "44823094",
    "title": "AI Ethics is being narrowed on purpose, like privacy was",
    "url": "https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "人工智能伦理正被有意收窄，就像隐私一样。",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44782097",
    "title": "Children's movie leads art historian to long-lost Hungarian masterpiece (2014)",
    "url": "https://www.theguardian.com/world/2014/nov/27/stuart-little-art-historian-long-lost-hungarian-masterpiece",
    "summary": "In 2009, art historian Gergely Barki spotted a long-lost Hungarian avant-garde painting, Róbert Berény's \"Sleeping Lady with Black Vase,\" while watching the film *Stuart Little* with his daughter. Barki recognized the painting, which disappeared in the 1920s, from a faded black-and-white photograph. He contacted Sony Pictures and Columbia Pictures, eventually learning that a former set designer had bought the painting cheaply in an antique shop in Pasadena, California, believing its avant-garde style would suit Stuart Little's living room. After leaving Sony, the designer sold the painting to a private collector.\n\nBerény, a leader of the Group of Eights, fled to Berlin in 1920 after designing recruitment posters for Hungary's communist revolution and reportedly had a romance with Marlene Dietrich and a rumored fling with Anastasia Romanov. The painting resurfaced in Hungary and was put up for auction in December with a starting price of around €110,000. Barki believes the original buyer from 1928 likely left Hungary during or before World War II, contributing to the loss of many Hungarian masterpieces throughout the 20th century.\n",
    "chinese_title": "儿童电影促使艺术史学家发现遗失已久的匈牙利杰作 (2014)",
    "chinese_summary": "2009年，艺术史学家盖尔盖伊·巴尔基与女儿一同观看电影《精灵鼠小弟》时，发现了一幅失踪已久的匈牙利先锋派画作——罗伯特·贝雷尼的《带黑花瓶的睡美人》。巴尔基通过一张褪色的黑白照片认出了这幅画，它在20世纪20年代就已失踪。他联系了索尼影业和哥伦比亚影业，最终得知一位前布景设计师在加州帕萨迪纳的一家古董店里廉价买下了这幅画，认为其先锋派风格适合斯图尔特·小老鼠的客厅。离开索尼后，这位设计师将这幅画卖给了一位私人收藏家。\n\n贝雷尼是“八人画派”的领袖人物，在为匈牙利共产主义革命设计招募海报后，于1920年逃往柏林，据说曾与玛琳·黛德丽有过恋情，并传闻与阿纳斯塔西娅·罗曼诺夫有过一段风流韵事。这幅画在匈牙利重新出现，并在12月被拍卖，起拍价约为11万欧元。巴尔基认为，1928年的原始买家很可能在二战期间或之前离开了匈牙利，导致许多匈牙利杰作在整个20世纪的流失。"
  },
  {
    "id": "44783372",
    "title": "Splatshop: Efficiently Editing Large Gaussian Splat Models",
    "url": "https://momentsingraphics.de/HPG2025.html",
    "summary": "Splatshop is a novel toolbox designed for efficient and interactive editing of large 3D Gaussian Splatting (3DGS) models, addressing the challenge of editing scenes with millions of primitives in real-time. The core innovation lies in its collection of heuristic approaches that intelligently balance rendering accuracy with speed, enabling precise editing actions like selection, deletion, painting, and transformation without compromising performance.\n\nThe authors demonstrate that Splatshop can handle scenes containing up to 100 million primitives, making it a significant advancement in 3DGS editing capabilities. Furthermore, the pipeline is adaptable for use with head-mounted displays, making Splatshop the first VR-capable editor for large-scale 3DGS models. This VR capability significantly enhances the editing experience.\n\nBy providing efficient editing tools for 3DGS models, Splatshop aims to become the \"Photoshop for Gaussian Splatting,\" simplifying the process of manipulating and refining these increasingly popular representations of 3D scenes. The authors presented this work at HPG 2025 and have made the paper, source code, presentation recording, and slides publicly available.\n",
    "chinese_title": "Splatshop: 高效编辑大型高斯溅射模型",
    "chinese_summary": "Splatshop：用于高效交互式编辑大型3D高斯溅射模型的工具箱。它创新性地采用启发式方法，智能平衡渲染精度与速度，实现对包含上亿图元的场景进行实时编辑，包括选择、删除、绘制和变换等操作，且不影响性能。Splatshop是首个支持VR的大型3DGS模型编辑器，并旨在成为高斯溅射领域的“Photoshop”。该论文已在HPG 2025上发表，并公开了论文、源码、演示视频和幻灯片。"
  },
  {
    "id": "44819037",
    "title": "Rules by which a great empire may be reduced to a small one (1773)",
    "url": "https://founders.archives.gov/documents/Franklin/01-20-02-0213",
    "summary": "\"Rules by Which a Great Empire May Be Reduced to a Small One\" is a satirical essay by Benjamin Franklin, published in 1773, that critiques British policies towards its American colonies. Written as advice to ministers, the essay ironically outlines how to alienate and ultimately lose control of a vast empire.\n\nFranklin suggests several key strategies:\n\n1.  **Neglect and Division:** Focus on the outermost provinces first, and ensure they are never fully integrated into the mother country, denying them equal rights and imposing harsher laws.\n\n2.  **Disregard Colonial Contributions:** Ignore any merit or loyalty the colonies may have demonstrated, even resentment towards their principles of liberty.\n\n3.  **Foster Mistrust and Oppression:** Assume the colonies are always on the verge of revolt, quarter troops to incite unrest, and appoint corrupt, self-serving officials as governors and judges.\n\n4.  **Obstruct Justice:** Punish colonists who seek redress for grievances with delays, exorbitant costs, and unjust rulings.\n\n5.  **Exploitation and Contempt:** Disregard the colonies' financial burdens and contributions to the empire's wealth. Impose arbitrary taxes without colonial representation, and publicly assert unlimited power to tax.\n\n6.  **Erosion of Liberties:** Undermine colonial liberties by creating complex trade regulations, eliminating jury trials for property disputes, declaring opposition to edicts as treason, and establishing courts of inquisition.\n\n7.  **Provocative Tax Collection:** Appoint insolent and corrupt tax collectors with high salaries, exempt them from local taxes, and protect them from complaints.\n\n8.  **Misappropriation of Funds:** Divert tax revenue from colonial defense to reward officials hostile to the colonists.\n\nFranklin's satire highlights the counterproductive nature of British policies, arguing that they would inevitably lead to colonial disaffection and ultimately, the empire's downfall. He emphasizes the importance of fair treatment, representation, and respect for colonial liberties.\n",
    "chinese_title": "使大帝国衰落为小帝国的规则 (1773)",
    "chinese_summary": "将大国变为小国的规则\n\n富兰克林于1773年发表的讽刺文章《将大国变为小国的规则》，批判了英国对其美洲殖民地的政策。该文以给大臣们建议的形式写成，讽刺性地概述了如何疏远并最终失去对一个庞大帝国的控制。\n\n富兰克林提出了几个关键策略：\n\n1. **忽视与分裂：** 首先关注最外围的省份，并确保它们永远无法完全融入宗主国，剥夺它们的平等权利并强加更严厉的法律。\n\n2. **无视殖民地的贡献：** 忽略殖民地可能表现出的任何优点或忠诚，甚至蔑视他们对自由原则的坚持。\n\n3. **培养不信任和压迫：** 假设殖民地总处于叛乱的边缘，驻扎军队以煽动骚乱，并任命腐败、自私的官员担任总督和法官。\n\n4. **阻碍司法公正：** 通过拖延、高昂的费用和不公正的判决来惩罚寻求 redress 申诉的殖民者。\n\n5. **剥削与蔑视：** 无视殖民地的财政负担和对帝国财富的贡献。在没有殖民地代表的情况下征收武断的税收，并公开声称拥有无限的征税权。\n\n6. **侵蚀自由：** 通过制定复杂的贸易法规、取消财产纠纷的陪审团审判、宣布反对法令为叛国罪以及设立宗教裁判所来破坏殖民地的自由。\n\n7. **挑衅性的税收征收：** 任命傲慢和腐败的收税员，给予他们高额薪水，免除他们的当地税收，并保护他们免受投诉。\n\n8. **挪用资金：** 将殖民地国防的税收转移到奖励对殖民者怀有敌意的官员。\n\n富兰克林的讽刺突出了英国政策的反作用力，认为这些政策将不可避免地导致殖民地的离心离德，并最终导致帝国的垮台。他强调了公平待遇、代表权和对殖民地自由的尊重的重要性。"
  },
  {
    "id": "44816755",
    "title": "Litestar is worth a look",
    "url": "https://www.b-list.org/weblog/2025/aug/06/litestar/",
    "summary": "This article advocates for Litestar as a Python web framework worth considering, especially for async-first, type-hint-driven applications. The author, a long-time Litestar user, highlights its advantages over more hyped alternatives like FastAPI.\n\nOne key benefit is Litestar's superior scaling for codebases. Unlike frameworks that bind route decorators to a parent object, Litestar's standalone route decorators avoid circular import issues and streamline the transition from single-file to multi-file applications. This promotes a coherent layered architecture, enabling powerful route grouping and configuration sharing, like easily applying authentication or dependencies to specific route subsets.\n\nAnother advantage lies in Litestar's flexible data handling. While supporting Pydantic, Litestar isn't solely reliant on it, offering broader support for data schema definitions beyond Pydantic models and dataclasses. It includes plugins for attrs and SQLAlchemy, and a protocol for custom serialization. Litestar's automatic data-transfer object (DTO) generation from data-access objects (DAOs) like SQLAlchemy models significantly reduces boilerplate and errors, particularly when DTOs represent subsets of DAO fields. This avoids redundant field declarations and ensures consistency. Given SQLAlchemy's prevalence in Python web development, Litestar's excellent integration with it is a significant advantage. The framework offers serialization plugins, DTO helpers, and a plugin ecosystem that enhances SQLAlchemy integration.\n",
    "chinese_title": "Litestar 值得一看",
    "chinese_summary": "本文力荐Litestar作为值得考虑的Python Web框架，尤其适用于异步优先、类型提示驱动的应用。作者作为Litestar的长期用户，强调了其相对于FastAPI等更受追捧的替代方案的优势。\n\n一个关键优势是Litestar在代码库扩展方面的卓越性能。与将路由装饰器绑定到父对象的框架不同，Litestar的独立路由装饰器避免了循环导入问题，并简化了从单文件到多文件应用程序的过渡。这促进了连贯的分层架构，从而实现了强大的路由分组和配置共享，例如轻松地将身份验证或依赖项应用于特定的路由子集。\n\n另一个优势在于Litestar灵活的数据处理能力。虽然支持Pydantic，但Litestar并不完全依赖它，而是为Pydantic模型和数据类之外的数据模式定义提供了更广泛的支持。它包括attrs和SQLAlchemy的插件，以及自定义序列化协议。Litestar从数据访问对象 (DAO)（如 SQLAlchemy 模型）自动生成数据传输对象 (DTO)，从而显著减少了样板代码和错误，尤其是在 DTO 代表 DAO 字段子集时。这避免了冗余字段声明并确保了数据一致性。鉴于SQLAlchemy在Python Web开发中的普及，Litestar与其的优秀集成是一个显著优势。该框架提供序列化插件、DTO助手和一个增强SQLAlchemy集成的插件生态系统。"
  },
  {
    "id": "44819738",
    "title": "A candidate giant planet imaged in the habitable zone of α  Cen A",
    "url": "https://arxiv.org/abs/2508.03814",
    "summary": "This arXiv article, submitted on August 5, 2025, reports on coronagraphic observations of Alpha Centauri A using the James Webb Space Telescope's MIRI instrument. The observations, conducted over three epochs (August 2024, February 2025, and April 2025), achieved the sensitivity required to detect planets around 1-1.2 Jupiter radii with effective temperatures of 225-250 K within the habitable zone, and to set upper limits on exozodiacal dust. The study found an unprecedentedly low limit for exozodiacal dust, just a few times the brightness of our own solar system's zodiacal cloud.\n\nIn August 2024, a point source, S1, with a flux of 3.5 mJy at 15.5 μm was detected at a separation of 1.5\" from Alpha Cen A. While this initial detection couldn't be definitively confirmed as a planet due to a single observation at one roll angle, analysis ruled out background or foreground objects. S1 wasn't observed in the follow-up epochs. However, the authors speculate that S1 could be related to an object, C1, previously observed in 2019 by the VLT/NEAR program. They calculated a 52% chance that a planet matching both S1 and C1 characteristics was missed in the subsequent JWST observations due to its orbital motion.\n\nAssuming S1 and C1 represent the same object, the researchers determined potential dynamically stable orbits with periods between 2-3 years, suggesting an eccentric orbit (e ≈ 0.4) inclined at approximately 50° or 130° relative to the Alpha Cen AB orbital plane. The proposed planet candidate could have a temperature of 225 K, a radius of about 1-1.1 Jupiter radii, and a mass of 90-150 Earth masses, consistent with radial velocity limits. The paper is accepted for publication in the Astrophysical Journal Letters.\n",
    "chinese_title": "在半人马座α星A宜居带内成像的一颗疑似巨行星",
    "chinese_summary": "这篇于2025年8月5日提交的 arXiv 文章报告了使用詹姆斯·韦伯太空望远镜的 MIRI 仪器对半人马座阿尔法星 A 进行的日冕观测。这些观测在三个历元（2024年8月、2025年2月和2025年4月）进行，达到了探测宜居带内半径约为 1-1.2 个木星半径、有效温度为 225-250 K 的行星，以及设定系外黄道尘埃上限所需的灵敏度。该研究发现系外黄道尘埃的上限空前低，仅为我们太阳系黄道云亮度的几倍。\n\n2024年8月，在距离半人马座阿尔法星 A 1.5 角秒处，检测到一个点光源 S1，在 15.5 微米处的流量为 3.5 mJy。虽然由于在单个滚动角度进行的一次观测，无法明确确认该初始探测结果为行星，但分析排除了背景或前景物体。在后续历元中未观测到 S1。然而，作者推测 S1 可能与此前在 2019 年由 VLT/NEAR 项目观测到的物体 C1 相关。他们计算出，由于其轨道运动，在随后的 JWST 观测中，有 52% 的概率会错过一颗符合 S1 和 C1 特征的行星。\n\n假设 S1 和 C1 代表同一个物体，研究人员确定了潜在的动力学稳定轨道，周期在 2-3 年之间，表明该轨道为偏心轨道（e ≈ 0.4），相对于半人马座阿尔法星 AB 轨道平面倾斜约 50° 或 130°。拟议的行星候选者温度可能为 225 K，半径约为 1-1.1 个木星半径，质量为 90-150 个地球质量，与径向速度限制一致。该论文已被《天体物理学杂志通讯》接收发表。"
  },
  {
    "id": "44819968",
    "title": "Running GPT-OSS-120B at 500 tokens per second on Nvidia GPUs",
    "url": "https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/",
    "summary": "This article details Baseten's efforts to optimize the performance of OpenAI's GPT-OSS-120B model on NVIDIA GPUs immediately after its release, achieving state-of-the-art latency and throughput. Baseten emphasized a flexible inference stack and a team of specialized engineers who quickly improved the model.\n\nThe optimization process involved:\n\n*   **Framework Evaluation:** Testing and benchmarking across TensorRT-LLM, vLLM, and SGLang.\n*   **Hardware Compatibility:** Ensuring compatibility with NVIDIA Hopper (H100) and Blackwell (B200) GPU architectures.\n*   **Integration:** Leveraging Baseten's inference stack, including NVIDIA Dynamo.\n*   **Optimizations:** Applying techniques like KV cache-aware routing and speculative decoding.\n\nBaseten adopted TensorRT-LLM and addressed compatibility bugs arising from new technologies introduced with GPT-OSS. For model configuration, Tensor Parallelism was chosen over Expert Parallelism for its latency benefits. They also utilized the TensorRT-LLM MoE Backend on Blackwell GPUs to improve CUDA kernel performance. These optimizations were packaged for dedicated deployments of the 120B and 20B models.\n\nThe article concludes by outlining further planned performance enhancements, including speculative decoding using models like Eagle 3. Baseten offers its expertise in model optimization to other AI engineering teams and is actively hiring model performance engineers.\n",
    "chinese_title": "在英伟达GPU上以每秒500个token的速度运行GPT-OSS-120B",
    "chinese_summary": "本文详细介绍了Baseten在OpenAI的GPT-OSS-120B模型发布后立即对其在NVIDIA GPU上的性能进行的优化工作，实现了最先进的延迟和吞吐量。Baseten强调了灵活的推理堆栈和一支由专业工程师组成的团队，他们迅速改进了该模型。\n\n优化过程包括：\n\n*   **框架评估：**跨TensorRT-LLM、vLLM和SGLang进行测试和基准测试。\n*   **硬件兼容性：**确保与NVIDIA Hopper (H100) 和 Blackwell (B200) GPU架构的兼容性。\n*   **集成：**利用Baseten的推理堆栈，包括NVIDIA Dynamo。\n*   **优化：**应用KV缓存感知路由和推测解码等技术。\n\nBaseten采用了TensorRT-LLM，并解决了GPT-OSS引入的新技术带来的兼容性错误。对于模型配置，选择张量并行性而非专家并行性，以获得延迟优势。他们还在Blackwell GPU上利用TensorRT-LLM MoE后端来提高CUDA内核性能。这些优化已打包用于120B和20B模型的专用部署。\n\n文章最后概述了进一步的性能增强计划，包括使用Eagle 3等模型进行推测解码。Baseten向其他人工智能工程团队提供其模型优化方面的专业知识，并积极招聘模型性能工程师。"
  },
  {
    "id": "44826645",
    "title": "A defense of learning Latin and Greek",
    "url": "https://www.americamagazine.org/arts-culture/2021/06/17/classics-greek-latin-spinale-princeton-240887/",
    "summary": "In this article, Kevin Spinale defends the value of learning Latin and Greek, prompted by Princeton University's decision to drop the requirement for Classics majors. He argues that a true understanding of ancient texts requires the ability to read them in their original languages.\n\nSpinale contends that translating from Latin and Greek cultivates objective skills, as these languages are governed by finite grammatical rules and surviving texts. While translation allows for creativity, it also has objective limits, and a specialist knows when an interpretation strays too far from the original meaning. He laments that many American students default to relying on others' interpretations, even in English.\n\nSpinale acknowledges that extensive resources, including translations, grammars, and online databases, make it seem unnecessary to learn ancient languages. He uses the example of New Testament studies, where numerous resources exist to analyze the Greek and Latin texts. However, he argues that direct engagement with the original languages enriches one's understanding and allows for a deeper connection to the text, illustrated by his personal experience with the Latin Vulgate of Mary's words in the Gospel of John.\n\nUltimately, Spinale believes that those who study Classics without knowing Latin and Greek are reliant on the interpretations of others. He proposes alternative mottos for departments comfortable with this approach, emphasizing blind acceptance of translations. He concludes that such an approach undermines critical thinking, which is essential in any intellectual field.\n",
    "chinese_title": "为学习拉丁语和希腊语辩护",
    "chinese_summary": "在这篇文章中，凯文·斯皮纳莱为学习拉丁语和希腊语的价值辩护，起因是普林斯顿大学决定取消古典文学专业对这两种语言的要求。他认为，真正理解古代文本需要能够阅读其原文。\n\n斯皮纳莱认为，从拉丁语和希腊语进行翻译可以培养客观技能，因为这些语言受有限的语法规则和现存文本的约束。虽然翻译允许创造性，但它也具有客观限制，专家知道何时解释偏离了原文含义。他感叹许多美国学生默认依赖他人的解释，即使是在英语方面。\n\n斯皮纳莱承认，包括翻译、语法和在线数据库在内的广泛资源，使得学习古代语言似乎没有必要。他以新约研究为例，其中存在大量分析希腊语和拉丁语文本的资源。然而，他认为直接接触原文可以丰富人们的理解，并允许与文本建立更深层次的联系，他以自己阅读拉丁语武加大本《约翰福音》中玛丽话语的个人经历为例。\n\n最终，斯皮纳莱认为，那些在不了解拉丁语和希腊语的情况下研究古典文学的人，依赖于他人的解释。他为那些对这种方法感到舒适的系科提出了替代座右铭，强调盲目接受翻译。他总结说，这种方法破坏了批判性思维，而批判性思维在任何智力领域都至关重要。"
  },
  {
    "id": "44822665",
    "title": "How AI Conquered the US Economy: A Visual FAQ",
    "url": "https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a",
    "summary": "Derek Thompson's \"How AI Conquered the US Economy: A Visual FAQ\" argues that the AI boom is already here, significantly impacting the US economy and stock market. AI investments are outpacing consumer spending, and AI-related companies are driving stock market growth and revenue increases.\n\nThe boom is fueled by massive investments in hardware (chips, data centers) by major tech companies (Meta, Google, Microsoft, Amazon), funded by their unprecedented free cash flow. These investments rival historical infrastructure projects like the railroad boom and the early computer age.\n\nWhile companies are spending heavily, profitability is still uncertain, potentially indicating an infrastructure bubble. However, Stripe data suggests AI startups are achieving revenue milestones faster than previous generations.\n\nAI adoption is rapid, particularly in information services and management. Workers report increased productivity from AI, especially in roles like teaching. However, studies also indicate that workers may overestimate AI's productivity gains; some analyses find that AI use can increase task completion time. Furthermore, academic writing has been affected by AI.\n",
    "chinese_title": "人工智能如何征服美国经济：图解问答",
    "chinese_summary": "德里克·汤普森的《人工智能如何征服美国经济：可视化问答》认为，人工智能的繁荣已经到来，正在显著影响美国经济和股市。人工智能投资正在超过消费者支出，人工智能相关公司正在推动股市增长和收入增加。\n\n这场繁荣得益于大型科技公司（Meta、谷歌、微软、亚马逊）对其前所未有的自由现金流所资助的硬件（芯片、数据中心）的大规模投资。这些投资堪比铁路繁荣和早期计算机时代等历史性基础设施项目。\n\n虽然公司正在大量支出，但盈利能力仍不确定，可能表明存在基础设施泡沫。然而，Stripe的数据表明，人工智能初创公司实现收入里程碑的速度比以往更快。\n\n人工智能的应用正在迅速普及，尤其是在信息服务和管理领域。员工报告称，人工智能提高了生产力，尤其是在教学等领域。然而，研究也表明，员工可能高估了人工智能的生产力提升；一些分析发现，使用人工智能会增加完成任务的时间。此外，学术写作也受到了人工智能的影响。"
  },
  {
    "id": "44816692",
    "title": "We'd be better off with 9-bit bytes",
    "url": "https://pavpanchekha.com/blog/9bit.html",
    "summary": "The article argues that adopting 9-bit bytes instead of 8-bit bytes historically would have led to several significant benefits in computing and networking, mitigating some limitations we currently face. The author posits that while 8 bits being a power of two is advantageous, a series of \"historical coincidences\" would have favored 9-bit bytes.\n\nThe core arguments revolve around:\n\n*   **IPv4 address exhaustion:** 36-bit addresses (derived from 9-bit bytes) would have delayed the need for NATs and the slow adoption of IPv6, possibly pushing exhaustion beyond current population growth.\n*   **UNIX time:** 36-bit timestamps would extend the timeline to 3058, negating the need for painful transitions to 64-bit structures.\n*   **Unicode:** 18-bit characters would provide ample space, lessening the limitations imposed by 16-bit Unicode and eliminating the CJK unification flaw. UTF-9 would be more of a compression format.\n*   **Pointers and Memory:** 36-bit systems would allow more memory per process (32GB) than 32-bit systems (2GB), although there might be a tradeoff due to bigger strings.\n\nOther potential advantages include roomier AS numbers, ports, process/user IDs, saner instruction encodings, and improved half-precision floats and extended ASCII.\n\nThe author considers potential downsides, mainly that TCP sequence number exhaustion might have happened early, requiring a TCPv2 upgrade in the mid-90s. However, this would still be better than IPv6, as ISPs would upgrade to compete.\n\nUltimately, the article suggests that a 9-bit byte world could have avoided numerous limits, frustrating extensions, and US-centric design choices, leading to a more elegant and capable computing landscape.\n",
    "chinese_title": "用9位字节会更好",
    "chinese_summary": "该文章认为，如果历史上采用 9 位字节而非 8 位字节，本会在计算和网络领域带来诸多显著优势，从而缓解我们目前面临的一些局限性。作者认为，虽然 8 位是 2 的幂次方具有优势，但一系列“历史巧合”本会更有利于 9 位字节。\n\n核心论点围绕以下几点：\n\n*   **IPv4 地址耗尽：** 36 位地址（源于 9 位字节）本会延缓 NAT 的需求和 IPv6 的缓慢采用，可能将耗尽推迟到超过当前人口增长。\n*   **UNIX 时间：** 36 位时间戳会将时间线延长至 3058 年，从而无需痛苦地过渡到 64 位结构。\n*   **Unicode：** 18 位字符将提供充足的空间，减轻 16 位 Unicode 带来的限制，并消除 CJK 统一缺陷。 UTF-9 将更像是一种压缩格式。\n*   **指针和内存：** 36 位系统将允许每个进程比 32 位系统（2GB）更多的内存（32GB），尽管由于更大的字符串可能会有所权衡。\n\n其他潜在优势包括更宽裕的 AS 编号、端口、进程/用户 ID、更合理的指令编码，以及改进的半精度浮点数和扩展 ASCII 码。\n\n作者考虑了潜在的缺点，主要是 TCP 序列号耗尽可能会提前发生，需要在 90 年代中期进行 TCPv2 升级。然而，这仍然比 IPv6 更好，因为 ISP 会通过升级来竞争。\n\n最终，文章表明，一个 9 位字节的世界本可以避免许多限制、令人沮丧的扩展和以美国为中心的设计选择，从而带来一个更优雅和更有能力的计算格局。"
  },
  {
    "id": "44789964",
    "title": "PastVu: Historical Photographs on Current Maps",
    "url": "https://pastvu.com/?_nojs=1",
    "summary": "PastVu is a website that showcases historical photographs overlaid on current maps. The core concept is to provide a visual way to explore how places have changed over time by viewing old photos in their original geographical context.\n\nThe content also mentions a technical issue: the website requires JavaScript to function properly. The user is informed that JavaScript is disabled in their browser and instructed on how to enable it. A link is provided for further assistance. Finally, there's an option to report the issue to the website's developers if the error message is incorrect.\n\nIn essence, PastVu aims to connect the past with the present through geo-located historical photographs, but requires JavaScript to be enabled for optimal functionality.\n",
    "chinese_title": "PastVu：历史照片在当前地图上",
    "chinese_summary": "PastVu是一个将历史照片叠加在当前地图上的网站。其核心理念是以一种可视化的方式，通过查看旧照片在其原始地理环境中的位置，来探索各地随时间推移的变化。\n\n网站内容还提及一个技术问题：网站需要JavaScript才能正常运行。用户被告知他们的浏览器中JavaScript已禁用，并获得了如何启用的说明。还提供了一个链接以获取更多帮助。最后，如果错误消息不正确，用户可以选择将问题报告给网站的开发者。\n\n总而言之，PastVu旨在通过地理定位的历史照片将过去与现在联系起来，但需要启用JavaScript才能获得最佳功能。"
  },
  {
    "id": "44826482",
    "title": "Is Universal Basic Income Effective? Not Really",
    "url": "https://www.city-journal.org/article/universal-basic-income-costs-jobs-work",
    "summary": "Robert VerBruggen's article in City Journal argues against the effectiveness of Universal Basic Income (UBI). It cites the OpenResearch Unconditional Income Study (ORUS) and other similar experiments that provide evidence of lackluster outcomes.\n\nThe ORUS study, which gave lower-income Americans $1,000 a month for three years, showed participants worked less, spent more time on leisure, and increased healthcare spending without significant health improvements. A further analysis focused on parents and children revealed a 13% increase in child-related spending, a rise in food and medical expenses, and more frequent relocation. Parenting quality scores improved marginally based on survey responses.\n\nHowever, the increased spending and attention did not lead to improved academic performance for K-12 students, college enrollment, or completion rates. Surprisingly, parents reported more developmental and stress-related problems in their children, potentially due to heightened attentiveness.\n\nThe article highlights that existing research from other UBI projects, including those in Compton, Chelsea, and the Baby’s First Year pilot, reinforces these findings. While some projects showed positive effects like reduced debt or increased food spending, many failed to produce significant improvements in key areas like health, school attendance, or children's development. VerBruggen critiques studies with positive results for methodological issues or skewed interpretations of insignificant findings.\n\nThe author concludes that while UBI proponents should be commended for their scientific approach, the limited positive impact of UBI programs doesn't justify widespread implementation, at least until technological unemployment necessitates it.\n",
    "chinese_title": "全民基本收入有效吗？ 效果不佳",
    "chinese_summary": "罗伯特·弗尔布鲁根在《城市期刊》上的文章论证了全民基本收入(UBI)的无效性。文章引用了开放研究无条件收入研究（ORUS）以及其他类似实验，这些实验提供了效果不佳的证据。\n\nORUS研究为期三年，每月向低收入美国人提供1000美元。研究表明，参与者工作时间减少，休闲时间增多，医疗保健支出增加，但健康状况没有显著改善。一项针对父母和孩子的进一步分析显示，与儿童相关的支出增加了13%，食品和医疗费用上涨，搬家频率增加。根据调查反馈，育儿质量评分略有提高。\n\n然而，增加的支出和关注并未提高K-12学生的学业成绩、大学入学率或完成率。令人惊讶的是，父母报告说他们的孩子出现了更多的发育和压力相关问题，这可能是由于他们的注意力提高了。\n\n文章强调，来自其他UBI项目（包括康普顿、切尔西和“婴儿的第一年”试点项目）的现有研究也证实了这些发现。虽然一些项目显示出积极影响，例如减少债务或增加食品支出，但许多项目未能显著改善健康、出勤率或儿童发展等关键领域。弗尔布鲁根批评了结果呈阳性的研究，认为其存在方法论问题或对不重要发现的歪曲解读。\n\n作者总结说，虽然UBI的支持者应该因其科学方法而受到赞扬，但UBI计划的有限的积极影响不足以证明其广泛实施是合理的，至少在技术性失业需要它之前是这样。"
  },
  {
    "id": "44790132",
    "title": "You know more Finnish than you think",
    "url": "https://dannybate.com/2025/08/03/you-know-more-finnish-than-you-think/",
    "summary": "This article argues that English speakers know more Finnish than they think, thanks to historical linguistics and language contact. While Finnish is often perceived as a \"tricky\" and alien language due to its non-Indo-European origin within a predominantly Indo-European European continent, its lexicon contains numerous words borrowed from other languages over millennia.\n\nThe article focuses on early loanwords, particularly from Proto-Germanic, the ancestor of English, German, and other Germanic languages. It highlights how around 500 words in Finnish stem from early Germanic origins, significantly impacting even Finnish phonology. Examples include \"kattila\" (pot/kettle), \"naula\" (nail), \"leipä\" (loaf), \"raaka\" (raw), and \"sama\" (same).\n\nThe article further explores how Finnish has preserved older features of Proto-Germanic, like the masculine singular noun ending *-az (preserved in words like \"kuningas\" - king), and vowels that were later lost or changed in Germanic languages. It touches upon the idea that Finnish might even contain loanwords from \"Pre-Germanic,\" reflecting linguistic features before certain sound changes defined Proto-Germanic. This is seen in words like \"kana\" (chicken) and \"kavio\" (hoof).\n\nThe author emphasizes that understanding language history and contact can break down perceived barriers between languages, making Finnish seem less daunting and more approachable. By recognizing the shared linguistic heritage, learners can discover a surprising degree of familiarity.\n",
    "chinese_title": "你比你想象的更懂芬兰语。",
    "chinese_summary": "本文认为，由于历史语言学和语言接触，英语使用者所知的芬兰语比他们想象的要多。虽然芬兰语由于其在以印欧语系为主的欧洲大陆上非印欧语系的起源，经常被认为是“棘手”和陌生的语言，但其词汇包含了数千年来从其他语言借用的众多词汇。\n\n本文重点关注早期借词，特别是来自原始日耳曼语，即英语、德语和其他日耳曼语的祖先。它强调了芬兰语中大约有500个单词源于早期日耳曼语，甚至对芬兰语语音产生了重大影响。例如，“kattila”（锅/水壶），“naula”（钉子），“leipä”（面包），“raaka”（生的），和“sama”（相同）。\n\n本文进一步探讨了芬兰语如何保留了原始日耳曼语的较旧特征，例如阳性单数名词结尾*-az（保留在“kuningas”-国王等词中），以及后来在日耳曼语中丢失或改变的元音。它探讨了芬兰语可能甚至包含来自“前日耳曼语”的借词的想法，反映了在某些语音变化定义原始日耳曼语之前的语言特征。这可以在“kana”（鸡）和“kavio”（蹄）等词中看到。\n\n作者强调，理解语言历史和接触可以打破语言之间 perceived 的壁垒，使芬兰语看起来不那么令人生畏，也更平易近人。通过认识到共同的语言遗产，学习者可以发现惊人的熟悉度。"
  },
  {
    "id": "44817583",
    "title": "The Bluesky Dictionary",
    "url": "https://www.avibagla.com/blueskydictionary/",
    "summary": "The Bluesky Dictionary is a project aimed at compiling a glossary of terms and slang used on the Bluesky social media platform. The document displays its progress, showing that it's currently in the early stages of development.\n\nKey indicators of progress are prominently displayed: \"Dictionary Coverage\" (currently at 0%), \"Total Words Seen\" (0), and \"Posts Processed\" (0), signifying that no data has been collected yet.\n\nThe project intends to actively discover new words by connecting to the Bluesky stream in real-time. It's currently \"Waiting for data,\" indicating that it's listening for posts to analyze.\n\nTwo sections, \"Words We Have Seen\" and \"Words We Haven't Seen,\" are designed to list discovered and undiscovered vocabulary, respectively. Both sections are currently in a loading state, suggesting the system is prepared but lacks input data to populate them. The message \"Disconnected\" at the bottom indicates a possible interruption in the data stream connection, needing a reconnection for the project to function properly.\n",
    "chinese_title": "蓝天词典",
    "chinese_summary": "Bluesky词典是一个旨在编纂Bluesky社交媒体平台上使用的术语和俚语的词汇表项目。该文档展示了其进度，表明目前处于开发的早期阶段。\n\n进度的关键指标被突出显示：“词典覆盖率”（目前为0%）、“已见词汇总数”（0）和“已处理帖子”（0），表明尚未收集任何数据。\n\n该项目计划通过实时连接到Bluesky数据流来主动发现新词。目前显示为“等待数据”，表明它正在监听要分析的帖子。\n\n“已见词汇”和“未见词汇”这两个部分旨在分别列出已发现和未发现的词汇。这两个部分目前都处于加载状态，表明系统已准备就绪，但缺乏输入数据来填充它们。底部的“已断开连接”消息表明数据流连接可能中断，需要重新连接才能使项目正常运行。"
  },
  {
    "id": "44825091",
    "title": "Does the Stock Market Know Something We Don't?",
    "url": "https://www.theatlantic.com/economy/archive/2025/08/stock-market-theories/683780/",
    "summary": "This article explores the perplexing behavior of the stock market, which has defied economic headwinds and traditional explanations. Despite a pandemic, high inflation, and rising interest rates, the S&P 500 has experienced remarkable growth, outpacing its historical average.\n\nThe author examines several theories attempting to explain this phenomenon. The \"fundamentals\" theory, which links stock prices to company earnings and the broader economy, faltered after the 2008 financial crisis. The \"liquidity\" theory, attributing market performance to the Federal Reserve's monetary policies, also proved inadequate when the market continued to rise despite the Fed's tightening measures in 2023 and 2024.\n\nThe rise of the \"Magnificent Seven\" tech companies (Apple, Amazon, Alphabet, Meta, Microsoft, Tesla, and Nvidia) fueled the \"AI revolution\" theory, suggesting the market was supercharged by the potential of artificial intelligence. However, concerns arose about a speculative bubble due to overvalued stock prices.\n\nThe article also considers the \"TACO trade\" theory, suggesting that President Trump's aversion to falling stock prices would prevent him from implementing policies that harm the market. However, this theory is weakened by the fact that the market has continued to rise despite existing tariffs.\n\nFinally, the article presents the \"passive fund\" theory, arguing that the shift from actively managed funds to passively managed index funds is responsible for the market's resilience and concentration. Passive investors, who automatically buy and hold stocks regardless of economic conditions, create a constant flow of money into the market, leading to higher valuations and benefiting the largest companies. The author concludes that while this theory may provide a compelling explanation, it, too, could be disproven by future events.\n",
    "chinese_title": "股市是否预示着我们所不知道的内情？",
    "chinese_summary": "股市之谜：为何逆经济而行？\n\n本文探讨了股市令人困惑的行为，它无视经济逆风和传统解释。尽管面临疫情、高通胀和利率上升，标普500指数仍经历了显著增长，超过了其历史平均水平。\n\n作者考察了几种试图解释这一现象的理论。“基本面”理论，即股票价格与公司盈利和整体经济相关联的理论，在2008年金融危机后失效。“流动性”理论，将市场表现归因于美联储的货币政策，在2023年和2024年美联储收紧措施的情况下，市场继续上涨时，也被证明是不充分的。\n\n“七巨头”（苹果、亚马逊、Alphabet、Meta、微软、特斯拉和英伟达）科技公司的崛起助长了“人工智能革命”理论，认为市场受到了人工智能潜力的推动。然而，由于股票价格被高估，人们开始担心出现投机泡沫。\n\n本文还考虑了“TACO交易”理论，该理论认为特朗普总统对股市下跌的厌恶将阻止他实施损害市场的政策。然而，由于市场在现有关税的情况下持续上涨，这一理论的解释力减弱。\n\n最后，本文提出了“被动基金”理论，认为从主动管理型基金向被动管理型指数基金的转变是市场韧性和集中的原因。无论经济状况如何，被动投资者都会自动买入并持有股票，从而源源不断地将资金注入市场，导致估值上升并使最大的公司受益。作者总结说，虽然这一理论可能提供一个令人信服的解释，但它也可能在未来的事件中被证伪。"
  },
  {
    "id": "44825660",
    "title": "AWS Restored My Account: The Human Who Made the Difference",
    "url": "https://www.seuros.com/blog/aws-restored-account-plot-twist/",
    "summary": "This article recounts the author's harrowing experience of having their 10-year AWS account deleted due to a payer linking issue. Despite initially being told their data was \"terminated\" and unrecoverable by AWS support, a single AWS employee, Tarus Balog, intervened. Tarus escalated the issue internally, leading to a Severity 2 ticket, VP-level awareness, and ultimately the restoration of the author's account.\n\nThe restoration revealed that the instances were stopped, not terminated, and backups were still being created days after support claimed data was gone, exposing potential gaslighting or a hidden recovery mechanism. The root cause was identified as a problematic payer linking architecture where deleting a payer account cascaded to linked accounts.\n\nThe incident has triggered a \"Correction of Error\" process within AWS to prevent similar occurrences. The author criticizes the robotic, unhelpful nature of AWS support agents and points out systemic issues like the confusing \"terminated\" vs \"stopped\" terminology and the use of a generic Amazon email domain for critical account notices.\n\nThe article highlights the importance of documentation, the power of a single individual to make a difference, and the need for human intervention in automated systems. It also raises concerns about the security of cloud infrastructure and the potential for regional discrepancies within AWS (specifically AWS MENA) to negatively impact users. The author underscores the crucial lesson learned by the technical community: backups of backups are essential and complete trust in cloud providers is risky.\n",
    "chinese_title": "AWS恢复了我的账户：那位带来改变的人",
    "chinese_summary": "本文讲述了作者因付款人关联问题导致其使用了 10 年的 AWS 账户被删除的惊险经历。虽然 AWS 支持最初告知其数据已被“终止”且无法恢复，但一位名叫 Tarus Balog 的 AWS 员工介入此事。Tarus 在内部升级了问题，使其升级为二级紧急事件，引起了副总裁级别的关注，并最终恢复了作者的账户。\n\n账户恢复后发现，实例只是被停止了，而不是被终止，并且在 AWS 支持声称数据已丢失几天后，备份仍在创建，这暴露了潜在的隐瞒或隐藏的恢复机制。根本原因被确定为有问题的付款人关联架构，即删除付款人账户会波及到关联账户。\n\n该事件已在 AWS 内部启动了“错误纠正”流程，以防止类似情况再次发生。作者批评了 AWS 支持人员的机械化和无助，并指出了诸如令人困惑的“终止”与“停止”术语以及使用通用的亚马逊电子邮件域名发送关键账户通知等系统性问题。\n\n本文强调了文档的重要性、个人发挥作用的力量以及在自动化系统中进行人为干预的必要性。它还引发了人们对云基础设施安全性的担忧，以及 AWS 内部（特别是 AWS MENA）的区域差异可能对用户产生负面影响的可能性。作者强调了技术社区吸取的重要教训：备份的备份至关重要，完全信任云提供商是危险的。"
  },
  {
    "id": "44817539",
    "title": "Project Hyperion: Interstellar ship design competition",
    "url": "https://www.projecthyperion.org",
    "summary": "Project Hyperion, a design competition organized by the Initiative for Interstellar Studies (i4is), challenged interdisciplinary teams to design a generation ship for a 250-year interstellar journey to a habitable planet. The competition focused on habitability, artificial gravity, societal sustainability, life support, and knowledge transfer for a crew of 1,000 ± 500 people over centuries in a resource-constrained environment.\n\nThe winning design, Chrysalis, impressed the jury with its system-level coherence, modularity, and attention to detail, including in-space manufacturing. Second place went to WFP Extreme, which focused on cultural and societal dimensions. Systema Stellare Proximum secured third place with its immersive storytelling and use of an asteroid as a radiation shield.\n\nHonorable Mentions included Arkkana (decoupled artificial gravity), EBS: Endless Beyond the Stars (Negotiopolis governance model), F.A.O.C. first asteroid O'Neill colony (habitat within a mined asteroid), Helios Ark (comprehensive integration of systems), Orion (thermal management system), Principium Hereditatis (culturally nuanced vision), and STASS (knowledge transmission system). The submissions were judged by a jury of experts in architecture, engineering, and social sciences. The competition aimed to explore the feasibility of crewed interstellar travel using current and near-future technologies.\n",
    "chinese_title": "海伯利安计划：星际飞船设计大赛",
    "chinese_summary": "“海伯利安”计划是由星际研究倡议（i4is）组织的一项设计竞赛，旨在挑战跨学科团队设计一艘世代飞船，用于历时250年的星际航行，抵达一颗宜居行星。竞赛重点关注在资源受限的环境中，1000±500人的船员在数个世纪内的宜居性、人造重力、社会可持续性、生命维持以及知识转移。\n\n获胜设计“蛹”号以其系统层面的连贯性、模块化以及对细节的关注（包括太空制造）给评审团留下了深刻印象。第二名是“WFP Extreme”，其重点关注文化和社会维度。“Systema Stellare Proximum”凭借其沉浸式故事讲述和利用小行星作为辐射屏蔽获得了第三名。\n\n荣誉提名包括Arkkana（解耦人造重力）、EBS：星辰之外的永恒（谈判都市治理模式）、F.A.O.C.第一颗小行星奥尼尔殖民地（在采矿小行星内的栖息地）、Helios Ark（系统的全面集成）、Orion（热管理系统）、Principium Hereditatis（具有文化细微差别的愿景）和STASS（知识传输系统）。参赛作品由建筑、工程和社会科学领域的专家组成的评审团进行评审。该竞赛旨在探索使用当前和近期技术进行载人星际旅行的可行性。"
  },
  {
    "id": "44788107",
    "title": "Synthetic Biology for Space Exploration",
    "url": "https://www.nature.com/articles/s41526-025-00488-7",
    "summary": "This article explores the potential of synthetic biology to address the challenges of long-term human space exploration, specifically focusing on In Situ Resource Utilization (ISRU), Bioregenerative Life Support Systems, Radiation Protection, and Human Health. It highlights the limitations of relying on Earth-based resources for extended missions due to cost and logistical constraints, emphasizing the need for self-sufficiency in space.\n\nThe article advocates for the use of synthetic biology to convert both astronaut waste and in-situ resources into valuable products. This involves using microorganisms like bacteria, algae, yeast, and fungi for material production, raw material extraction, waste recycling, and food production. Key areas of focus include:\n\n*   **ISRU:** Utilizing local resources on the Moon and Mars to produce necessary materials, reducing reliance on Earth. Extremotolerant organisms can be used to utilize local resources.\n*   **Bioregenerative Life Support:** Creating closed-loop systems for food production, waste recycling, and oxygen generation.\n*   **Radiation Protection:** Developing biomolecules and materials that shield astronauts from harmful space radiation. Microorganisms can play an important role in bioprinting.\n*   **Human Health:** Engineering customized therapies, nutraceuticals, and biosensors to maintain astronaut health and manage emergencies.\n\nThe article identifies promising chassis organisms like *Bacillus subtilis* and desert strains of *Chroococcidiopsis* for space applications due to their robustness and genetic tractability. Filamentous fungi are also highlighted for their potential in building habitats and providing radiation protection.\n",
    "chinese_title": "太空探索的合成生物学",
    "chinese_summary": "本文探讨了合成生物学在应对长期人类太空探索挑战方面的潜力，特别关注原位资源利用（ISRU）、生物再生生命保障系统、辐射防护和人类健康。文章强调了长期任务依赖地球资源的局限性，原因在于成本和后勤方面的制约，并强调了太空自给自足的必要性。\n\n文章提倡利用合成生物学将宇航员废物和原位资源转化为有价值的产品。这包括利用微生物，如细菌、藻类、酵母和真菌，进行材料生产、原材料提取、废物回收和食物生产。重点关注的领域包括：\n\n*   **原位资源利用（ISRU）：** 利用月球和火星上的当地资源生产必要的材料，减少对地球的依赖。极端耐受性生物可用于利用当地资源。\n*   **生物再生生命保障：** 创建用于食物生产、废物回收和氧气产生的闭环系统。\n*   **辐射防护：** 开发能够保护宇航员免受有害太空辐射的生物分子和材料。微生物可以在生物打印中发挥重要作用。\n*   **人类健康：** 设计定制的疗法、保健食品和生物传感器，以维持宇航员的健康并应对紧急情况。\n\n文章确定了有前景的底盘生物，如枯草芽孢杆菌和沙漠地衣藻的沙漠菌株，由于其稳健性和遗传可操作性，可用于太空应用。丝状真菌也因其在建造栖息地和提供辐射防护方面的潜力而受到关注。"
  },
  {
    "id": "44782229",
    "title": "What is the average length of a queue of cars? (2023)",
    "url": "https://e-dorigatti.github.io/math/2023/11/01/queue-length.html",
    "summary": "This article explores the problem of determining the average length of queues of cars on a long road where overtaking is impossible. The author initially proposes an intuitive (but incorrect) solution based on the assumption that the speeds of cars are independent and identically distributed. This leads to a geometric distribution with an expected queue length of 2, which contradicts real-world observations.\n\nThe author then implements a simulation that reveals a much higher average queue length, disproving the initial hypothesis. This prompts a deeper analysis, recognizing that the speed of the first car in a queue significantly influences the likelihood of additional cars joining it. The author correctly conditions on the velocity of the first car.\n\nThe correct solution involves integrating over all possible velocities of the first car and leveraging the probability integral transform to convert the integral into one involving quantiles. This results in the formula p(N=n) = 1/(n(n+1)) for the probability of a queue having length *n*. The derived formula is validated by comparing it against the empirical distribution from the simulation, revealing a strong match.\n\nFinally, the expected queue length is calculated as the sum of 1/(n+1) from n=1 to infinity, which is a divergent harmonic series. This implies that the average queue length is infinite, meaning that long queues are inevitable regardless of driver skill or road quality, provided roads are sufficiently long.\n",
    "chinese_title": "车辆队列的平均长度是多少？ (2023)",
    "chinese_summary": "本文探讨了在无法超车的长路上确定车辆队列平均长度的问题。作者最初提出了一个基于车辆速度是独立同分布的直观（但错误）的解决方案。这导致了一个几何分布，其预期队列长度为 2，这与现实世界的观察结果相矛盾。\n\n作者随后进行了一项模拟，结果表明平均队列长度要高得多，从而否定了最初的假设。这促使了更深入的分析，认识到队列中第一辆车的速度会显着影响后续车辆加入队列的可能性。作者正确地对第一辆车的速度进行了条件化。\n\n正确的解决方案包括对第一辆车所有可能的速度进行积分，并利用概率积分变换将积分转换为涉及分位数的积分。这导出了队列长度为 *n* 的概率公式 p(N=n) = 1/(n(n+1))。通过将其与模拟中的经验分布进行比较，验证了导出的公式，结果显示两者高度吻合。\n\n最后，预期队列长度被计算为从 n=1 到无穷大的 1/(n+1) 之和，这是一个发散的调和级数。这意味着平均队列长度是无限的，这意味着无论驾驶员的技术或道路质量如何，只要道路足够长，长队列都是不可避免的。"
  },
  {
    "id": "44814596",
    "title": "Multics",
    "url": "https://www.multicians.org/multics.html",
    "summary": "The Multicians website is dedicated to preserving the history and technical innovations of the Multics operating system. Its primary goals are to prevent the re-invention of Multics' advancements, document its history and the contributions of its creators and users, acknowledge important innovations, and commemorate the experiences and individuals involved. The website serves as a repository of information, comprising a substantial collection of HTML files, PDF documents, and graphic images. It is a collaborative effort, welcoming contributions from anyone with knowledge, corrections, or anecdotes related to Multics. The site aims to share this knowledge with the \"Multicians\" community and ensure that the legacy of Multics is remembered and appreciated.\n",
    "chinese_title": "Multics",
    "chinese_summary": "Multicians网站致力于保存Multics操作系统的历史和技术创新。其主要目标是防止重复发明Multics的先进技术，记录其历史以及创造者和用户的贡献，认可重要的创新，并纪念相关的经历和个人。该网站作为一个信息库，包含大量的HTML文件、PDF文档和图形图像。这是一个协作项目，欢迎任何拥有关于Multics的知识、更正或轶事的人做出贡献。该网站旨在与“Multicians”社区分享这些知识，并确保Multics的遗产得到铭记和赞赏。"
  },
  {
    "id": "44823672",
    "title": "Baltimore Assessments Accidentally Subsidize Blight–and How We Can Fix It",
    "url": "https://progressandpoverty.substack.com/p/how-baltimore-assessments-accidentally",
    "summary": "Here's a summary of the article \"Baltimore Assessments Accidentally Subsidize Blight–and How We Can Fix It,\" based on my understanding of similar arguments related to property assessments and urban blight:\n\nThe article likely argues that Baltimore's current property assessment system unintentionally incentivizes blight and discourages property improvements, particularly in lower-income neighborhoods. This happens because assessments don't accurately reflect the true potential value of well-maintained or renovated properties, and often over-assess blighted properties.\n\nThe system likely assesses poorly maintained properties as if they had potential for better use, resulting in high property tax burdens. This makes it financially challenging for owners to improve the properties. Conversely, when properties are improved, the immediate reassessment leads to higher taxes, effectively penalizing investment.\n\nThis creates a vicious cycle: high tax burdens discourage improvements, leading to further blight. This further reinforces the over-assessment of blighted properties and perpetuates the financial burden on owners of these properties.\n\nThe article probably proposes solutions, potentially including:\n\n*   **Land Value Taxation (LVT):** Shifting the tax base from buildings to land value, encouraging development of underutilized land and reducing the tax burden on structures. This encourages improvements and deters land speculation.\n*   **More accurate and responsive assessments:** Implementing assessment practices that more accurately reflect the actual condition of properties and responding to changes in condition in a timelier fashion.\n*   **Targeted tax incentives:** Providing targeted tax incentives or abatements for property improvements in blighted areas.\n\nThe core argument is that Baltimore's assessment system is a counterproductive tool that actively hinders revitalization efforts and exacerbates the problem of urban blight. Implementing reforms, such as shifting the tax burden to land value and improving assessment accuracy, could encourage investment and improve the overall condition of the city.\n",
    "chinese_title": "巴尔的摩评估无意中助长了衰败——以及我们如何解决它",
    "chinese_summary": "以下是我对文章“巴尔的摩评估体系意外地补贴了衰败——以及我们如何修复它”的总结，基于我对类似关于房产评估和城市衰败的论点的理解：\n\n该文章可能认为，巴尔的摩目前的房产评估体系无意中激励了衰败，并阻碍了房产改善，尤其是在低收入社区。 这是因为评估未能准确反映维护良好或翻新房产的真实潜在价值，并且经常过度评估衰败的房产。\n\n该体系可能将维护不善的房产评估为具有更好使用潜力，导致高额房产税负担。 这使得业主在经济上难以改善房产。 相反，当房产得到改善时，立即重新评估会导致更高的税收，实际上是对投资的惩罚。\n\n这形成了一个恶性循环：高税负阻碍了改善，导致进一步的衰败。 这进一步加强了对衰败房产的过度评估，并使这些房产的业主承受持续的经济负担。\n\n文章可能提出了一些解决方案，可能包括：\n\n*   **土地价值税 (LVT)：** 将税基从建筑物转移到土地价值，鼓励对未充分利用土地的开发，并减轻建筑物上的税收负担。 这鼓励了改善并阻止了土地投机。\n*   **更准确和响应性的评估：** 实施更准确地反映房产实际状况的评估方法，并及时响应状况的变化。\n*   **有针对性的税收优惠：** 为衰败地区的房产改善提供有针对性的税收优惠或减免。\n\n核心论点是，巴尔的摩的评估体系是一种适得其反的工具，它积极阻碍了振兴工作并加剧了城市衰败的问题。 实施改革，例如将税收负担转移到土地价值并提高评估准确性，可以鼓励投资并改善城市的整体状况。"
  },
  {
    "id": "44825873",
    "title": "Federal court filing system hit in hack",
    "url": "https://www.politico.com/news/2025/08/06/federal-court-filing-system-pacer-hack-00496916",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "联邦法院文件系统遭黑客攻击",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44778898",
    "title": "Comptime.ts: compile-time expressions for TypeScript",
    "url": "https://comptime.js.org/",
    "summary": "Comptime.ts is a TypeScript compiler extension that enables compile-time evaluation of expressions marked with `comptime`. This allows for performance optimization by moving computations from runtime to compile time, similar to macros in other languages.\n\nKey features include:\n\n*   **Compile-time Evaluation:** Evaluates expressions at compile time, inlining the results.\n*   **Zero-Runtime CSS Libraries:** Example use case includes converting emotion CSS into zero-runtime CSS by pre-computing styles.\n*   **Forced Comptime Evaluation:** The `comptime()` function, used with `with { type: \"comptime\" }`, forces compile-time evaluation and promise resolution.\n*   **Opt-Out of Virality:** Parentheses can be used to limit comptime evaluation to specific sub-expressions.\n*   **Deferred Execution:** `comptime.defer()` allows running code after all comptime evaluations, useful for tasks like writing CSS files.\n\nComptime.ts works by parsing TypeScript, identifying comptime imports, collecting necessary code, evaluating it in isolation, and replacing the comptime expression with the result.\n\nLimitations include JSON-serializable return values only, isolated evaluation contexts, and potential build time increases with complex expressions.\n\nThe library offers integrations for Vite and Bun bundlers via plugins, a command-line interface, and a direct API. Best practices recommend using comptime for constants, static content generation, and performance-critical code, while avoiding it for complex runtime logic, side effects, and non-deterministic operations.\n",
    "chinese_title": "Comptime.ts：TypeScript 的编译时表达式",
    "chinese_summary": "Comptime.ts 是一个 TypeScript 编译器扩展，它允许对标记为 `comptime` 的表达式进行编译时求值。这可以通过将计算从运行时转移到编译时来实现性能优化，类似于其他语言中的宏。\n\n主要特性包括：\n\n*   **编译时求值:** 在编译时对表达式求值，内联结果。\n*   **零运行时 CSS 库:** 示例用例包括通过预计算样式将 emotion CSS 转换为零运行时 CSS。\n*   **强制 Comptime 求值:** `comptime()` 函数与 `with { type: \"comptime\" }` 一起使用，强制进行编译时求值和 Promise 解析。\n*   **退出传染性:** 括号可用于将 comptime 求值限制在特定的子表达式中。\n*   **延迟执行:** `comptime.defer()` 允许在所有 comptime 求值完成后运行代码，对于编写 CSS 文件等任务非常有用。\n\nComptime.ts 的工作原理是解析 TypeScript，识别 comptime 导入，收集必要的代码，在隔离环境中对其进行求值，并将 comptime 表达式替换为结果。\n\n限制包括仅 JSON 可序列化的返回值，隔离的求值上下文，以及复杂表达式可能导致构建时间增加。\n\n该库通过插件为 Vite 和 Bun 打包器提供集成，并提供命令行界面和直接 API。最佳实践建议将 comptime 用于常量、静态内容生成和性能关键型代码，同时避免将其用于复杂的运行时逻辑、副作用和非确定性操作。"
  },
  {
    "id": "44815046",
    "title": "AI in Search is driving more queries and higher quality clicks",
    "url": "https://blog.google/products/search/ai-search-driving-more-queries-higher-quality-clicks/",
    "summary": "This Google Search Central blog post, dated August 6, 2025, addresses concerns about the impact of AI-powered Search features, like AI Overviews and AI Mode, on website traffic. Liz Reid, VP, Head of Google Search, asserts that **AI in Search is driving more queries and higher quality clicks to websites.**\n\nThe key points are:\n\n*   **Stable Traffic & Increased Quality:** Overall, organic click volume from Google Search to websites has remained relatively stable year-over-year, with slightly more \"quality clicks\" (clicks where users don't immediately click back) being sent.\n*   **More Queries, More Links:** AI features enable users to ask more complex questions, leading to increased search activity. AI Overviews also present more links on the search results page, creating more opportunities for websites.\n*   **Evolving User Needs:** While quick-answer queries may reduce clicks in some cases, users are increasingly clicking through for deeper exploration, in-depth reviews, and authentic perspectives (forums, videos, podcasts). This shift is benefiting sites that provide valuable and engaging content.\n*   **AI Highlights the Web:** Google emphasizes its commitment to the web ecosystem. Its AI experiences are designed to highlight the web, with prominent links, source citations, and in-line attribution to websites. Google respects open web protocols, giving websites control over content display in Search.\n*   **AI as Opportunity:** Google believes AI will be a major expansionary force for the web, enabling more complex queries and deeper engagement between creators and audiences.\n",
    "chinese_title": "AI 在搜索中驱动了更多查询和更高质量的点击。",
    "chinese_summary": "这篇2025年8月6日发布的 Google Search Central 博客文章，旨在消除人们对 AI 驱动的搜索功能（如 AI 概览和 AI 模式）对网站流量影响的担忧。Google 搜索副总裁兼负责人 Liz Reid 断言，**搜索中的 AI 正在驱动更多的查询和更高质量的网站点击。**\n\n要点如下：\n\n*   **流量稳定 & 质量提升：** 总体而言，从 Google 搜索到网站的自然点击量同比保持相对稳定，并且发送了略多“高质量点击”（用户没有立即点击返回的点击）。\n*   **更多查询，更多链接：** AI 功能使用户能够提出更复杂的问题，从而增加搜索活动。AI 概览还在搜索结果页面上显示更多链接，为网站创造更多机会。\n*   **不断变化的用户需求：** 虽然快速解答的查询可能会在某些情况下减少点击次数，但用户越来越多地点击以进行更深入的探索、深入的评论和真实的观点（论坛、视频、播客）。这种转变正在使提供有价值和引人入胜内容的网站受益。\n*   **AI 突出显示网络：** Google 强调其对网络生态系统的承诺。其 AI 体验旨在突出显示网络，具有突出的链接、来源引文和对网站的内联署名。Google 尊重开放 Web 协议，使网站可以控制其内容在搜索中的显示方式。\n*   **AI 带来机遇：** Google 认为 AI 将成为网络的主要扩张力量，从而实现更复杂的查询以及创作者和受众之间更深入的互动。"
  },
  {
    "id": "44800746",
    "title": "Open models by OpenAI",
    "url": "https://openai.com/open-models/",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "OpenAI 的开放模型",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44777419",
    "title": "Herbie detects inaccurate expressions and finds more accurate replacements",
    "url": "https://herbie.uwplse.org/",
    "summary": "Herbie is a tool designed to automatically improve the accuracy of floating-point expressions. It identifies inaccurate expressions and provides more accurate replacements, as demonstrated by the example of `sqrt(x+1) - sqrt(x)` being replaced by `1/(sqrt(x+1) + sqrt(x))`.\n\nThe tool offers a web demo and installation options, with regular updates and news highlighting improvements in speed, accuracy, and features, such as a new platform API for pluggable compilation targets and optimization for both accuracy and speed.  It also features redesigned reports and metrics.\n\nHerbie has a sister project called Herbgrind, which identifies inaccurate floating-point expressions in large codebases.  Herbie supports the FPBench format for benchmarks.\n\nRecent project news includes the releases of Herbie versions 2.2, 2.1, and 2.0, and announcements about talks and presentations given by the developers at various conferences. These talks cover topics like precision tuning, Herbie's history, and the FPBench project.\n\nHerbie is developed at UW PLSE with contributions from a supportive community, with key contributors including Pavel Panchekha, Alex Sanchez-Stern, David Thien, Zachary Tatlock, Jason Qiu, Jack Firth, and James R. Wilcox.\n",
    "chinese_title": "Herbie检测不准确的表达并找到更准确的替代方案。",
    "chinese_summary": "Herbie：自动提升浮点表达式精度的工具。它能识别不准确的表达式，并提供更精确的替代方案，例如将`sqrt(x+1) - sqrt(x)`替换为`1/(sqrt(x+1) + sqrt(x))`。\n\n该工具提供网页演示和安装选项，并定期更新和发布新闻，重点介绍速度、精度和功能方面的改进，例如用于可插拔编译目标的新平台API以及对精度和速度的优化。它还具有重新设计的报告和指标。\n\nHerbie有一个名为Herbgrind的姊妹项目，用于识别大型代码库中不准确的浮点表达式。 Herbie支持FPBench格式的基准测试。\n\n最近的项目新闻包括Herbie 2.2、2.1和2.0版本的发布，以及开发者在各种会议上发表的演讲和报告的公告。这些演讲涵盖了精度调整、Herbie的历史以及FPBench项目等主题。\n\nHerbie由UW PLSE开发，并得到了支持社区的贡献，主要贡献者包括Pavel Panchekha、Alex Sanchez-Stern、David Thien、Zachary Tatlock、Jason Qiu、Jack Firth和James R. Wilcox。"
  },
  {
    "id": "44819962",
    "title": "Mac history echoes in current Mac operating systems",
    "url": "http://tenfourfox.blogspot.com/2025/08/mac-history-echoes-in-mac-operating.html",
    "summary": "This 2025 blog post by \"ClassicHasClass\" explores the persistence of historical Mac icons and glyphs within the latest macOS (Tahoe, running on Sequoia), even as the OS evolves and hardware becomes obsolete. The author notes the replacement of classic hard drive icons, drawing a parallel to Apple CEO transitions. They then highlight the surprising number of vintage icons still present in system files like `/System/Library/Extensions/IOStorageFamily.kext/Contents/Resources` and `/System/Library/CoreServices/CoreTypes.bundle/Contents/Resources`.\n\nThese include icons for PowerPC logos, various obsolete ports (modem, printer, SCSI, ADB), classic Apple symbols (Balloon Help, Apple Guide), floppy disks, Newton devices, and even specific Mac models like the eMac, iBook G4, iMac G4/G5, PowerBook G4, Power Macintosh G4 (different versions), Xserve G4, and early Mac Mini, all meticulously rendered in multiple sizes for different screen resolutions. A Windows PC icon is also present.\n\nThe author questions why these legacy assets remain, discounting nostalgia as a primary motive since Apple often aggressively removes older features. While a commenter suggests the icons might be kept to avoid breaking obscure code, the author leans towards the idea of trademark protection. The icons, being Apple-specific labeling, could be considered part of Apple's \"trade dress,\" providing a legal basis if someone attempts to copy Apple's older IP. A commenter also points out the Mac Mini icon is for an early Intel model, identifiable by the infrared receiver, prompting an update from the author.\n",
    "chinese_title": "Mac的历史在当前的Mac操作系统中回响。",
    "chinese_summary": "\"ClassicHasClass\" 在2025年的博文中探讨了即使在最新的 macOS (Tahoe, 运行于 Sequoia) 不断发展，硬件逐渐淘汰的情况下，历史悠久的 Mac 图标和字形仍然存在。作者注意到经典硬盘图标的替换，并将此比作苹果 CEO 的更替。随后，他们强调了大量复古图标仍然存在于系统文件中，例如 `/System/Library/Extensions/IOStorageFamily.kext/Contents/Resources` 和 `/System/Library/CoreServices/CoreTypes.bundle/Contents/Resources`，这令人惊讶。\n\n这些图标包括 PowerPC 标志、各种已过时的端口（调制解调器、打印机、SCSI、ADB）、经典的 Apple 符号（气球帮助、Apple 指南）、软盘、Newton 设备，甚至特定的 Mac 型号，如 eMac、iBook G4、iMac G4/G5、PowerBook G4、Power Macintosh G4（不同版本）、Xserve G4 和早期 Mac Mini，所有这些都经过精心渲染，以适应不同的屏幕分辨率。还有一个 Windows PC 图标。\n\n作者质疑为什么这些遗留资产仍然存在，认为怀旧不是主要动机，因为 Apple 经常积极删除旧功能。 虽然一位评论员认为保留这些图标是为了避免破坏晦涩的代码，但作者倾向于商标保护的观点。 这些图标作为 Apple 特定的标签，可以被视为 Apple “商业外观”的一部分，如果有人试图复制 Apple 的旧 IP，则可以提供法律依据。一位评论员还指出 Mac Mini 图标是早期 Intel 型号的，可以通过红外接收器来识别，这促使作者进行了更新。"
  },
  {
    "id": "44823761",
    "title": "You Don't Need Monads",
    "url": "https://muratkasimov.art/Ya/Articles/You-don%27t-really-need-monads",
    "summary": "This article argues that the concept of monads is overrated and proposes a more flexible approach using natural transformations directly. While acknowledging the usefulness of monadic terminology for describing concepts like binding, it claims that monads are too restrictive.\n\nThe article begins by defining monads as functors with natural transformations (η for \"producing\" the functor structure and μ for \"squashing\" layers) that satisfy a coherence condition. An example using the Maybe monad is provided.\n\nIt then addresses the issue of monad composition, clarifying that while monads of the same type can be composed, combining different monads requires special handling, often through monad transformers. Я achieves this via \"jointed effects,\" which decompose state management (like the State monad) and allow effects like Stops to be interleaved, using the `yok` operator.\n\nThe core argument is that instead of relying on the pre-packaged \"monad\" abstraction, developers should focus on the underlying natural transformations. By defining custom transformations to squash layers of *different* functors, a more flexible and composable effect system can be built. The article provides examples of such transformations (ψ[i]) that handle the interaction between \"World,\" \"Stops,\" and \"State\" effects.\n\nThe author concludes by advocating for using these \"bricks\" (natural transformations) to construct desired effects, rather than trying to force-fit problems into the monadic paradigm.  This open interface allows for greater control and customization when dealing with complex effect interactions.\n",
    "chinese_title": "你不需要Monad。",
    "chinese_summary": "本文认为单子的概念被过度炒作，并提出了一种更灵活的方法，直接使用自然变换。 虽然承认单子术语对于描述诸如绑定之类的概念很有用，但它声称单子过于严格。\n\n本文首先将单子定义为具有自然变换的函子（η 用于“产生”函子结构，μ 用于“压缩”层），这些自然变换满足一致性条件。 提供了一个使用 Maybe 单子的例子。\n\n然后，它解决了单子组合的问题，阐明了虽然相同类型的单子可以组合，但组合不同的单子需要特殊处理，通常通过单子转换器。 Я 通过“联合效应”实现这一点，它分解了状态管理（如 State 单子）并允许诸如 Stops 之类的效果交错，使用 `yok` 运算符。\n\n核心论点是，开发者应该专注于底层的自然变换，而不是依赖于预先包装的“单子”抽象。 通过定义自定义变换来压缩*不同*函子的层，可以构建更灵活和可组合的效果系统。 本文提供了此类变换 (ψ[i]) 的示例，这些变换处理“World”、“Stops”和“State”效果之间的交互。\n\n作者最后主张使用这些“砖块”（自然变换）来构建所需的效果，而不是试图将问题强行塞入单子范式。 这种开放的接口允许在处理复杂的效果交互时获得更大的控制和定制。"
  },
  {
    "id": "44826420",
    "title": "Think Linux desktop market share isn't over 6%? This scan says otherwise",
    "url": "https://www.zdnet.com/article/think-linux-desktop-market-share-isnt-over-6-this-15-million-system-scan-says-otherwise/",
    "summary": "According to a Lansweeper analysis of over 15 million consumer desktop operating systems, Linux desktop market share has surpassed 6%. This figure aligns with recent data from the US Federal Government and StatCounter, indicating a consistent upward trend.\n\nThe analysis differentiates between \"consumer\" PCs (workgroup-based, standalone, or BYOD) and business computers managed by Windows Active Directory (AD). Linux usage is significantly higher on consumer PCs (6%) compared to business systems (1.9%). However, Linux adoption in AD-managed networks is gradually increasing.\n\nNew devices show a higher propensity to run Linux (2.5%) compared to older systems. Regional differences exist, with Europe exhibiting higher Linux adoption in sectors like business services and government, while North America sees greater Linux usage in technology, telecommunications, and finance. SMBs in North America favor Linux more than their European counterparts, while the reverse is true for European SMBs.\n\nLansweeper collects data through a combination of agentless and agent-based scanning techniques, including active and passive network scanning.\n\nThe article attributes Linux's increasing popularity to factors like the rise of AI programming, where Linux is the dominant OS due to its support for leading open-source AI frameworks. While Linux may not overtake MacOS in overall market share, it has become a significant platform for power users and developers.\n",
    "chinese_title": "Linux桌面市场份额不到6%？这份扫描报告却说不然",
    "chinese_summary": "根据Lansweeper对超过1500万台消费者桌面操作系统的分析，Linux桌面市场份额已超过6%。该数据与美国联邦政府和StatCounter的最新数据一致，表明其呈持续上升趋势。\n\n该分析区分了“消费者”PC（基于工作组、独立或自带设备）和由Windows Active Directory (AD)管理的商业计算机。Linux在消费者PC上的使用率明显高于商业系统（分别为6%和1.9%）。然而，在AD管理的网络中，Linux的采用率正在逐渐增加。\n\n与旧系统相比，新设备更有可能运行Linux（2.5%）。存在区域差异，欧洲在商业服务和政府等行业中Linux的采用率较高，而北美在技术、电信和金融领域中Linux的使用率更高。北美中小企业比欧洲同行更喜欢Linux，而欧洲中小企业的情况则相反。\n\nLansweeper通过无代理和基于代理的扫描技术相结合的方式收集数据，包括主动和被动网络扫描。\n\n文章将Linux日益普及归因于人工智能编程的兴起等因素，由于Linux支持领先的开源人工智能框架，因此它成为人工智能领域的主导操作系统。虽然Linux可能不会在总体市场份额上超过MacOS，但它已成为高级用户和开发人员的重要平台。"
  },
  {
    "id": "44808794",
    "title": "I gave the AI arms and legs then it rejected me",
    "url": "https://grell.dev/blog/ai_rejection",
    "summary": "This article details the author's surprise and pride upon discovering that Anthropic, a multi-billion dollar AI company, is using their open-source library, enigo, in Claude Desktop's \"Computer Use\" feature, which allows the AI to interact with a computer. Enigo is a cross-platform Rust library for simulating user input (mouse and keyboard), and the author maintains it.\n\nDespite enigo being used by such a prominent company, the author doesn't earn any money from it due to the MIT license. They highlight enigo's popularity and capabilities, mentioning its cross-platform support, memory safety, and lack of root requirement.\n\nThe author then recounts their attempt to get a job at Anthropic in the team working on a similar, unreleased feature. They felt confident, given their existing contribution to Claude Desktop. However, they received a rejection email stating the team lacked capacity to review further applications.\n\nThe author expresses a mix of feelings: elation that their project is used by Claude Desktop, disappointment at the job rejection, and wry amusement at the possibility that the AI they indirectly helped empower might have been involved in rejecting their application. The author also jokes about being safe from Roko's Basilisk as a result of the rejection.\n",
    "chinese_title": "我给了人工智能手臂和腿，然后它拒绝了我。",
    "chinese_summary": "本文详细描述了作者发现价值数十亿美元的人工智能公司 Anthropic 在 Claude Desktop 的“计算机使用”功能中使用其开源库 enigo 时的惊讶和自豪。“计算机使用”功能允许人工智能与计算机交互。Enigo 是一个用于模拟用户输入（鼠标和键盘）的跨平台 Rust 库，作者负责维护它。\n\n尽管 enigo 被如此知名的公司使用，但由于 MIT 许可证，作者并没有从中获得任何收入。他们强调了 enigo 的受欢迎程度和功能，提及其跨平台支持、内存安全和无需 root 权限。\n\n作者随后讲述了他们试图在 Anthropic 团队获得一份工作的经历，该团队正在开发一个类似的、未发布的功能。考虑到他们对 Claude Desktop 的现有贡献，他们感到自信。然而，他们收到了一封拒绝信，称该团队缺乏能力审查更多的申请。\n\n作者表达了一种复杂的情感：他们的项目被 Claude Desktop 使用的喜悦，求职被拒的失望，以及他们间接帮助赋能的人工智能可能参与拒绝他们的申请的啼笑皆非。作者还开玩笑说，由于被拒绝，他们免受了罗科的罗勒怪的伤害。"
  },
  {
    "id": "44813905",
    "title": "Show HN: Sinkzone DNS – Forwarder that blocks everything except your allowlist",
    "url": "https://github.com/berbyte/sinkzone",
    "summary": "Sinkzone is a local DNS resolver that blocks all domains by default, allowing users to create a highly focused internet experience. It aims to eliminate distractions like notifications and social media by only resolving domains explicitly added to an allowlist.\n\nKey features include DNS-level blocking, a \"Focus Mode\" for temporary restriction to allowlisted domains, wildcard support for flexible domain matching, an HTTP API for monitoring and control, and a real-time terminal UI (TUI). Sinkzone is cross-platform, supporting macOS, Linux, and Windows.\n\nThe software consists of a DNS resolver, an HTTP API server, and a TUI/CLI for user interaction. The resolver intercepts DNS queries and uses the allowlist to determine whether to resolve the domain or return NXDOMAIN (domain does not exist). Configuration is managed through `sinkzone.yaml` and `allowlist.txt` files.\n\nInstallation instructions are provided for various platforms, including package manager installations and direct downloads. Common commands include `sinkzone monitor`, `sinkzone tui`, `sinkzone resolver`, and `sinkzone focus`. The TUI allows real-time DNS traffic monitoring and allowlist management.  It's licensed under the MIT license, and contributions are welcomed.\n",
    "chinese_title": "Show HN: Sinkzone DNS – 仅允许你的白名单的转发器",
    "chinese_summary": "Sinkzone：默认阻止所有域名的本地 DNS 解析器，允许用户创建高度专注的互联网体验。它旨在通过仅解析显式添加到允许列表中的域名来消除诸如通知和社交媒体之类的干扰。\n\n主要功能包括 DNS 级别阻止、用于临时限制到允许列表域名的“专注模式”、用于灵活域名匹配的通配符支持、用于监控和控制的 HTTP API 以及实时终端 UI (TUI)。 Sinkzone 是跨平台的，支持 macOS、Linux 和 Windows。\n\n该软件由 DNS 解析器、HTTP API 服务器和用于用户交互的 TUI/CLI 组成。解析器拦截 DNS 查询并使用允许列表来确定是解析域名还是返回 NXDOMAIN（域名不存在）。配置通过 `sinkzone.yaml` 和 `allowlist.txt` 文件进行管理。\n\n提供了适用于各种平台的安装说明，包括软件包管理器安装和直接下载。常用命令包括 `sinkzone monitor`、`sinkzone tui`、`sinkzone resolver` 和 `sinkzone focus`。 TUI 允许实时 DNS 流量监控和允许列表管理。它在 MIT 许可证下获得许可，欢迎贡献。"
  },
  {
    "id": "44813854",
    "title": "Jules, our asynchronous coding agent",
    "url": "https://blog.google/technology/google-labs/jules-now-available/",
    "summary": "Jules, Google's asynchronous coding agent, is officially launching publicly after a successful beta period powered by Gemini 2.5. During the beta, developers used Jules to complete tens of thousands of tasks and contributed over 140,000 code improvements. Based on beta feedback, the user interface has been improved, bugs have been fixed, and new features like task setup reuse, GitHub issue integration, and multimodal support have been added.\n\nNow powered by Gemini 2.5 Pro, Jules can create higher-quality code through improved coding plans. Google is also introducing structured tiers with higher usage limits for Google AI Pro and Ultra subscribers: Introductory access, Jules in Google AI Pro (5x higher limits), and Jules in Google AI Ultra (20x higher limits). These tiers are designed to cater to different levels of coding intensity. Google AI Pro is also available to eligible college students for a free year. More details on usage limits are available at jules.google. The rollout of these changes is starting today for Google AI Pro and Ultra subscribers.\n",
    "chinese_title": "朱尔斯，我们的异步编码代理",
    "chinese_summary": "Jules，谷歌异步编程助手，在 Gemini 2.5 的支持下成功完成 Beta 测试后正式公开上线。在 Beta 期间，开发者使用 Jules 完成了数万个任务，并贡献了超过 14 万个代码改进。根据 Beta 反馈，用户界面得到了改进，漏洞得到了修复，并添加了任务设置重用、GitHub 问题集成和多模态支持等新功能。\n\n现在，由 Gemini 2.5 Pro 提供支持，Jules 可以通过改进的编码计划创建更高质量的代码。 谷歌还推出了结构化层级，为 Google AI Pro 和 Ultra 订阅者提供更高的使用限制：入门级访问、Google AI Pro 中的 Jules（限制提高 5 倍）和 Google AI Ultra 中的 Jules（限制提高 20 倍）。 这些层级旨在满足不同强度的编码需求。符合条件的大学生还可以免费使用 Google AI Pro 一年。有关使用限制的更多详细信息，请访问 jules.google。这些变更的推出将于今日开始面向 Google AI Pro 和 Ultra 订阅者。"
  },
  {
    "id": "44825690",
    "title": "Digital Foundry is going independent",
    "url": "https://www.theverge.com/games/743535/digital-foundry-game-console-analysis-going-independent",
    "summary": "生成摘要时出错",
    "chinese_title": "Digital Foundry is going independent",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44813789",
    "title": "Writing a Rust GPU kernel driver: a brief introduction on how GPU drivers work",
    "url": "https://www.collabora.com/news-and-blog/blog/2025/08/06/writing-a-rust-gpu-kernel-driver-a-brief-introduction-on-how-gpu-drivers-work/",
    "summary": "生成摘要时出错",
    "chinese_title": "Writing a Rust GPU kernel driver: a brief introduction on how GPU drivers work",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44821642",
    "title": "40 Years of the Amiga",
    "url": "https://www.goto10retro.com/p/40-years-of-the-amiga-from-commodore",
    "summary": "生成摘要时出错",
    "chinese_title": "40 Years of the Amiga",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44824461",
    "title": "We Don't Believe in Work-Life Balance",
    "url": "https://www.entrepreneur.com/business-news/ai-coding-startup-work-weekends-or-take-a-buyout/495554",
    "summary": "生成摘要时出错",
    "chinese_title": "We Don't Believe in Work-Life Balance",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44781343",
    "title": "Compaq’s Rod Canion broke IBM's hold on the PC market",
    "url": "https://every.to/feeds/b0e329f3048258e8eeb7/the-man-who-beat-ibm",
    "summary": "生成摘要时出错",
    "chinese_title": "Compaq’s Rod Canion broke IBM's hold on the PC market",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44823123",
    "title": "Photographer spends years on street corner capturing same commuters daily (2017)",
    "url": "https://mymodernmet.com/peter-funch-candid-photographs-commuters/",
    "summary": "生成摘要时出错",
    "chinese_title": "Photographer spends years on street corner capturing same commuters daily (2017)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44817725",
    "title": "301party.com: Intentionally open redirect",
    "url": "https://301party.com/",
    "summary": "生成摘要时出错",
    "chinese_title": "301party.com: Intentionally open redirect",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44788997",
    "title": "SQLite offline sync for Android quick start",
    "url": "https://github.com/sqliteai/sqlite-sync/tree/main/examples/android-integration",
    "summary": "生成摘要时出错",
    "chinese_title": "SQLite offline sync for Android quick start",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44816977",
    "title": "The History of F1 Design",
    "url": "https://www.espn.com/espn/feature/story/_/id/43832710/how-f1-evolved-1950-where-headed-2026",
    "summary": "生成摘要时出错",
    "chinese_title": "The History of F1 Design",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44818957",
    "title": "Out-Fibbing CPython with the Plush Interpreter",
    "url": "https://pointersgonewild.com/2025-08-06-out-fibbing-cpython-with-the-plush-interpreter/",
    "summary": "生成摘要时出错",
    "chinese_title": "Out-Fibbing CPython with the Plush Interpreter",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44824573",
    "title": "What Happens to Public Media Now?",
    "url": "https://www.newyorker.com/news/the-lede/what-happens-to-public-media-now",
    "summary": "生成摘要时出错",
    "chinese_title": "What Happens to Public Media Now?",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44810281",
    "title": "About the BLOBs in Ventoy",
    "url": "https://github.com/ventoy/Ventoy/issues/3224",
    "summary": "生成摘要时出错",
    "chinese_title": "About the BLOBs in Ventoy",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44809387",
    "title": "Python performance myths and fairy tales",
    "url": "https://lwn.net/SubscriberLink/1031707/73cb0cf917307a93/",
    "summary": "生成摘要时出错",
    "chinese_title": "Python performance myths and fairy tales",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44778772",
    "title": "The 1090 Megahertz Riddle: A Guide to Decoding Mode S and ADS-B Signals",
    "url": "https://books.open.tudelft.nl/home/catalog/book/11",
    "summary": "生成摘要时出错",
    "chinese_title": "The 1090 Megahertz Riddle: A Guide to Decoding Mode S and ADS-B Signals",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44824723",
    "title": "Underused Techniques for Effective Emails · Refactoring English",
    "url": "https://refactoringenglish.com/chapters/techniques-for-writing-emails/",
    "summary": "生成摘要时出错",
    "chinese_title": "Underused Techniques for Effective Emails · Refactoring English",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44783717",
    "title": "The Real Origin of Cisco Systems (1999)",
    "url": "https://www.tcracs.org/tcrwp/1origin-of-cisco/",
    "summary": "生成摘要时出错",
    "chinese_title": "The Real Origin of Cisco Systems (1999)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44818836",
    "title": "Why Building Billing Systems Is So Painful (2024)",
    "url": "https://www.dmitry.ie/2024/why-building-billing-systems-is-so-painful",
    "summary": "生成摘要时出错",
    "chinese_title": "Why Building Billing Systems Is So Painful (2024)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44824675",
    "title": "Google denies AI search features are killing website traffic",
    "url": "https://techcrunch.com/2025/08/06/google-denies-ai-search-features-are-killing-website-traffic/",
    "summary": "生成摘要时出错",
    "chinese_title": "Google denies AI search features are killing website traffic",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44798166",
    "title": "Genie 3: A new frontier for world models",
    "url": "https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/",
    "summary": "生成摘要时出错",
    "chinese_title": "Genie 3: A new frontier for world models",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44818734",
    "title": "Git-fetch-file – Sync files from other repos with commit tracking and safety",
    "url": "https://github.com/andrewmcwattersandco/git-fetch-file",
    "summary": "生成摘要时出错",
    "chinese_title": "Git-fetch-file – Sync files from other repos with commit tracking and safety",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44818925",
    "title": "Apple announces American Manufacturing Program",
    "url": "https://www.apple.com/newsroom/2025/08/apple-increases-us-commitment-to-600-billion-usd-announces-ambitious-program/",
    "summary": "生成摘要时出错",
    "chinese_title": "Apple announces American Manufacturing Program",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44815702",
    "title": "A fast, growable array with stable pointers in C",
    "url": "https://danielchasehooper.com/posts/segment_array/",
    "summary": "生成摘要时出错",
    "chinese_title": "A fast, growable array with stable pointers in C",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44825695",
    "title": "Being in Control Is Hurting Your Startup",
    "url": "https://businessofsoftware.org/2025/08/modern-ceo/",
    "summary": "生成摘要时出错",
    "chinese_title": "Being in Control Is Hurting Your Startup",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44823826",
    "title": "LG ordered to pay £150k after phone defect caused Scotland house fire",
    "url": "https://www.theregister.com/2025/08/07/lg_ordered_to_pay_150k/",
    "summary": "生成摘要时出错",
    "chinese_title": "LG ordered to pay £150k after phone defect caused Scotland house fire",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44820341",
    "title": "Show HN: Rust framework for advanced file recognition and identification",
    "url": "https://crates.io/crates/magical_rs",
    "summary": "生成摘要时出错",
    "chinese_title": "Show HN: Rust framework for advanced file recognition and identification",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44823262",
    "title": "Show HN: Stasher – Burn-after-read secrets from the CLI, no server, no trust",
    "url": "https://github.com/stasher-dev/stasher-cli",
    "summary": "生成摘要时出错",
    "chinese_title": "Show HN: Stasher – Burn-after-read secrets from the CLI, no server, no trust",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44777086",
    "title": "Automerge 3.0",
    "url": "https://automerge.org/blog/automerge-3/",
    "summary": "生成摘要时出错",
    "chinese_title": "Automerge 3.0",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44813397",
    "title": "We shouldn't have needed lockfiles",
    "url": "https://tonsky.me/blog/lockfiles/",
    "summary": "生成摘要时出错",
    "chinese_title": "We shouldn't have needed lockfiles",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44808542",
    "title": "Rethinking DOM from first principles",
    "url": "https://acko.net/blog/html-is-dead-long-live-html/",
    "summary": "生成摘要时出错",
    "chinese_title": "Rethinking DOM from first principles",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44815718",
    "title": "Vibe coding the MIT course catalog",
    "url": "https://stackdiver.com/posts/vibe-coding-the-mit-course-catalog/",
    "summary": "生成摘要时出错",
    "chinese_title": "Vibe coding the MIT course catalog",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44795825",
    "title": "uBlock Origin Lite now available for Safari",
    "url": "https://apps.apple.com/app/ublock-origin-lite/id6745342698",
    "summary": "生成摘要时出错",
    "chinese_title": "uBlock Origin Lite now available for Safari",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44822258",
    "title": "About AI",
    "url": "https://priver.dev/blog/ai/about-ai/",
    "summary": "生成摘要时出错",
    "chinese_title": "About AI",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44825809",
    "title": "Budget Car Buyers Want Automakers to K.I.S.S",
    "url": "https://www.thedrive.com/news/budget-car-buyers-want-automakers-to-k-i-s-s",
    "summary": "生成摘要时出错",
    "chinese_title": "Budget Car Buyers Want Automakers to K.I.S.S",
    "chinese_summary": "生成摘要时出错"
  }
]