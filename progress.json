[
  {
    "id": "45387462",
    "title": "Fast UDP I/O for Firefox in Rust",
    "url": "https://max-inden.de/post/fast-udp-io-in-firefox/",
    "summary": "This article details the project to revamp Firefox's UDP I/O stack for improved HTTP/3 QUIC performance and security, leveraging the Rust-based `quinn-udp` library. The original implementation relied on outdated NSPR APIs, hindering potential performance gains from modern OS features like multi-message APIs (sendmmsg/recvmmsg) and segmentation offloading (GSO/GRO).\n\nThe project successfully replaced `sendto/recvfrom` with modern, OS-specific system calls across Windows, MacOS, Linux, and Android.  Linux saw significant benefits from GSO/GRO, which offloads UDP segmentation to the kernel or NIC, achieving up to 4 Gbit/s throughput in CPU-bound scenarios.  Each platform presented unique challenges. Windows USO/URO were rolled back due to instability and bugs. MacOS lacks native segmentation offloading, and undocumented batching calls were deemed too risky to deploy. Android required specific handling for its older versions and socketcall system.\n\nBeyond performance, the transition enhanced security by using Rust, a memory-safe language, for UDP I/O. The upgrade also enabled QUIC ECN (Explicit Congestion Notification) support, improving network congestion management.  While some platform-specific optimizations require further refinement, the project represents a significant step forward in optimizing Firefox's UDP I/O, contributing to faster and more secure HTTP/3 experiences.\n",
    "chinese_title": "用 Rust 实现 Firefox 的快速 UDP I/O",
    "chinese_summary": "本文详细介绍了改进 Firefox UDP I/O 堆栈的项目，旨在提高 HTTP/3 QUIC 的性能和安全性，利用了基于 Rust 的 `quinn-udp` 库。最初的实现依赖于过时的 NSPR API，阻碍了利用现代操作系统特性（如多消息 API (sendmmsg/recvmmsg) 和分段卸载 (GSO/GRO)）带来的潜在性能提升。\n\n该项目成功地在 Windows、MacOS、Linux 和 Android 上用现代的、特定于操作系统的系统调用替换了 `sendto/recvfrom`。Linux 从 GSO/GRO 中获得了显著收益，GSO/GRO 将 UDP 分段卸载到内核或 NIC，在 CPU 密集型场景中实现了高达 4 Gbit/s 的吞吐量。每个平台都带来了独特的挑战。由于不稳定和存在 bug，Windows USO/URO 被回滚。MacOS 缺乏原生分段卸载，且未公开的批处理调用被认为部署风险过高。Android 需要对其旧版本和 socketcall 系统进行专门处理。\n\n除了性能之外，此次迁移还通过使用内存安全的 Rust 语言进行 UDP I/O，提高了安全性。升级还启用了 QUIC ECN (显式拥塞通知) 支持，从而改善了网络拥塞管理。虽然某些特定于平台的优化需要进一步完善，但该项目代表了优化 Firefox UDP I/O 的重要一步，有助于实现更快、更安全的 HTTP/3 体验。"
  },
  {
    "id": "45388021",
    "title": "Open Social",
    "url": "https://overreacted.io/open-social/",
    "summary": "This article introduces the concept of \"Open Social\" as a potential successor to the current state of social media, drawing parallels to the rise of open-source software. The author argues that current social media platforms trap user data within their proprietary databases, creating an imbalance of power and hindering user freedom.\n\nOpen Social aims to decentralize social data, giving users control over their profiles, posts, likes, and follows. The proposed model utilizes the AT Protocol, developed by Bluesky, where users like \"Alice\" and \"Bob\" own their internet handles (e.g., @alice.com) and their data resides in personal repositories on the web as signed JSON with \"at://\" URIs for linking.\n\nThese repositories act as web servers, storing user data accessible via the AT Protocol, essentially creating a web of hyperlinked JSON records instead of rows in a social media company's database. While technically complex, the goal is to make this process invisible to the average user, similar to how users interact with the web without needing to understand server technology.\n\nThe benefits include users being able to switch social apps without losing their data or social connections, fostering competition and encouraging platforms to respect user rights. The article argues that this shift could lead to a more open, user-centric social media landscape, akin to the democratizing effect of open-source software. The author anticipates that adoption will take time but believes open social is an inevitable evolution.\n",
    "chinese_title": "开放社交",
    "chinese_summary": "本文介绍了“开放社交”的概念，将其视为当前社交媒体状态的潜在替代者，并将其与开源软件的兴起相提并论。作者认为，当前的社交媒体平台将用户数据困在其专有数据库中，造成权力失衡并阻碍用户自由。\n\n开放社交旨在分散社交数据，让用户掌控自己的个人资料、帖子、点赞和关注。该模型采用了Bluesky开发的AT协议，用户如“Alice”和“Bob”拥有自己的互联网句柄（例如，@alice.com），其数据以签名JSON形式存储在网络上的个人存储库中，并使用“at://”URI进行链接。\n\n这些存储库充当Web服务器，存储可通过AT协议访问的用户数据，本质上创建了一个超链接JSON记录网络，而不是社交媒体公司数据库中的行。虽然技术上很复杂，但其目标是让普通用户对此过程不可见，就像用户与Web交互而无需了解服务器技术一样。\n\n其好处包括用户能够在不丢失其数据或社交连接的情况下切换社交应用程序，从而促进竞争并鼓励平台尊重用户权利。本文认为，这种转变可能会带来更加开放、以用户为中心的社交媒体格局，类似于开源软件的民主化效应。作者预计采用需要时间，但相信开放社交是不可避免的演变。"
  },
  {
    "id": "45334001",
    "title": "How to make sense of any mess",
    "url": "https://www.howtomakesenseofanymess.com",
    "summary": "\"How to Make Sense of Any Mess\" by Abby Covert is a guide to understanding and resolving complex information problems through the lens of information architecture. The book walks the reader through a structured process, emphasizing the importance of understanding both information and the people who interact with it.\n\nThe core steps involve: **Identifying the Mess**, recognizing the complexities of information, users, and stakeholders. **Stating your Intent**, defining clear goals and choosing precise language to articulate them. **Facing Reality**, acknowledging all relevant factors, channels, contexts, and players involved and using diagrams to visualize the situation. **Choosing a Direction**, selecting a course of action by defining the \"what\" being made, understanding the impact of different levels, and controlling vocabulary by listing words that will and will not be said. **Measuring the Distance**, setting goals, tracking progress, and establishing baselines and indicators to ensure the project is on the right track. **Playing with Structure**, exploring various taxonomies (hierarchical, heterarchical, sequential) and facets to organize information effectively. Finally, **Preparing to Adjust**, anticipating changes, resolving conflicts, and adapting to the reality of the situation.\n\nThe book stresses the iterative nature of information architecture, encouraging readers to embrace ambiguity, prioritize clarity, and continually adjust their approach based on feedback and evolving circumstances. It uses relatable case studies (\"Meet [Name]\") to illustrate the concepts and provides practical tools like diagrams and worksheets to help readers apply the principles to their own messy situations.\n",
    "chinese_title": "如何理清任何混乱局面",
    "chinese_summary": "如何理清任何混乱：Abby Covert通过信息架构的视角，指导读者理解和解决复杂的信息问题。本书引导读者完成一个结构化的过程，强调理解信息和与之互动的人群的重要性。\n\n核心步骤包括：**识别混乱**，认识信息、用户和利益相关者的复杂性；**明确意图**，定义清晰的目标，并选择精确的语言来阐述它们；**面对现实**，承认所有相关的因素、渠道、背景和参与者，并使用图表来可视化情况；**选择方向**，通过定义正在制作的“内容”，理解不同级别的影响，并通过列出将被说和不被说的词语来控制词汇；**衡量距离**，设定目标，跟踪进度，并建立基线和指标，以确保项目走在正确的轨道上；**玩转结构**，探索各种分类法（层级式、异构式、顺序式）和方面，以有效地组织信息；最后，**准备调整**，预测变化，解决冲突，并适应现实情况。\n\n本书强调信息架构的迭代性，鼓励读者拥抱模糊性，优先考虑清晰度，并根据反馈和不断变化的情况不断调整其方法。它使用相关的案例研究（“认识[姓名]”）来说明这些概念，并提供实用工具，如图表和工作表，以帮助读者将这些原则应用于他们自己的混乱情况。"
  },
  {
    "id": "45357732",
    "title": "Traefik's 10-Year Journey from Zero to Standard",
    "url": "https://traefik.io/blog/celebrating-10-years-of-traefik",
    "summary": "This article celebrates the 10th anniversary of Traefik, a modern reverse proxy and load balancer, tracing its journey from a small personal project to a widely adopted cloud-native standard. The author reflects on the initial motivation: simplifying microservice management by automating reverse proxy configuration based on container and service discovery.\n\nThe article highlights key milestones: Traefik v1's automatic service discovery and Let's Encrypt integration; Traefik v2's architectural redesign with routers, middlewares, TCP/UDP support, and Kubernetes CRDs; and Traefik v3's focus on modern standards like Gateway API and OpenTelemetry. It emphasizes the shift in the cloud-native landscape from experimentation to production readiness and how Traefik has adapted to this evolution.\n\nLooking ahead, the article details upcoming features: Traefik 3.5's NGINX compatibility layer to ease migration from ingress-nginx, Traefik 3.6's multi-layer routing and KNative integration. The author also introduces a new release strategy for Traefik v4, where features will be rolled out incrementally in v3.x releases to ensure a smoother upgrade experience.\n\nFinally, the author emphasizes the crucial role of the open-source community, highlighting their contributions through code, documentation, testing, and feedback, and announces an anniversary contest with limited-edition t-shirts for contributors. The article concludes with gratitude to the community and a commitment to continue innovating in the ever-evolving cloud-native ecosystem.\n",
    "chinese_title": "Traefik十年征程：从零到标准",
    "chinese_summary": "本文庆祝 Traefik 十周年，回顾了这款现代反向代理和负载均衡器从小型个人项目发展成为广泛采用的云原生标准的历程。作者回顾了最初的动机：通过基于容器和服务发现自动配置反向代理来简化微服务管理。\n\n文章重点介绍了几个关键里程碑：Traefik v1 的自动服务发现和 Let's Encrypt 集成；Traefik v2 的架构重新设计，包括路由器、中间件、TCP/UDP 支持和 Kubernetes CRDs；以及 Traefik v3 专注于 Gateway API 和 OpenTelemetry 等现代标准。文章强调了云原生领域从实验到生产就绪的转变，以及 Traefik 如何适应这种演变。\n\n展望未来，文章详细介绍了即将推出的功能：Traefik 3.5 的 NGINX 兼容层，以简化从 ingress-nginx 的迁移，以及 Traefik 3.6 的多层路由和 KNative 集成。作者还介绍了 Traefik v4 的新发布策略，其中功能将在 v3.x 版本中逐步推出，以确保更流畅的升级体验。\n\n最后，作者强调了开源社区的关键作用，突出了他们通过代码、文档、测试和反馈做出的贡献，并宣布了一项周年纪念竞赛，为贡献者提供限量版 T 恤。文章最后对社区表示感谢，并承诺继续在不断发展的云原生生态系统中进行创新。"
  },
  {
    "id": "45388728",
    "title": "Thinking Machines – Modular Manifolds",
    "url": "https://thinkingmachines.ai/blog/modular-manifolds/",
    "summary": "This article explores the benefits of normalizing tensors, particularly weight matrices, in large neural networks to maintain stability and predictability during training. It argues that constraining weight matrices to submanifolds offers a promising approach, enabling co-design of optimization algorithms with these constraints.\n\nThe article introduces the concept of manifold optimization, starting with a simple example of a vector constrained to a hypersphere. It emphasizes the importance of choosing an appropriate distance measure in the tangent space, as it influences the direction of the optimal optimization step.\n\nThe core of the article then introduces \"manifold Muon,\" an algorithm based on constraining weight matrices to the Stiefel manifold, where all singular values are one. This ensures a consistent stretching effect on input vectors, preventing excessively small or large outputs. The article presents the manifold Muon optimization problem and highlights its connection to the original Muon optimizer, which constrains the spectral norm of the weight updates. It references work by Jianlin Su and Franz Louis Cesista, who helped develop a numerical solution.\n\nThe article concludes by emphasizing that this is an active area of research. The authors encourage further exploration into manifold constraints, distance functions, and composable manifolds for large-scale training, aiming to improve the stability and performance of neural networks.\n",
    "chinese_title": "思考机器 - 模块化流形",
    "chinese_summary": "本文探讨了在大规模神经网络中规范化张量（特别是权重矩阵）的益处，以在训练期间保持稳定性和可预测性。文章认为，将权重矩阵约束到子流形提供了一种有前景的方法，能够实现优化算法与这些约束的协同设计。\n\n文章介绍了流形优化的概念，从一个约束到超球面的向量的简单例子开始。它强调了在切线空间中选择适当距离度量的重要性，因为它会影响最佳优化步骤的方向。\n\n文章的核心介绍了“流形 Muon”，这是一种基于将权重矩阵约束到Stiefel流形的算法，在该流形中所有奇异值都为一。这确保了对输入向量的一致拉伸效果，防止产生过小或过大的输出。文章提出了流形 Muon 优化问题，并强调了其与原始 Muon 优化器的联系，后者约束了权重更新的谱范数。它参考了 Jianlin Su 和 Franz Louis Cesista 的工作，他们帮助开发了一种数值解。\n\n文章最后强调这是一个活跃的研究领域。作者鼓励进一步探索流形约束、距离函数和可组合流形，用于大规模训练，旨在提高神经网络的稳定性和性能。"
  },
  {
    "id": "45387337",
    "title": "A recent chess controversy",
    "url": "https://www.chicagobooth.edu/review/did-us-chess-champion-cheat",
    "summary": "This article from the Chicago Booth Review investigates allegations of cheating against chess grandmaster Hikaru Nakamura by Vladimir Kramnik, based on Nakamura's improbable winning streak in an online blitz tournament. Researchers Shiva Maharaj, Nicholas Polson, and Vadim Sokolov conducted a statistical analysis, using Nakamura's performance data from over 3,500 chess.com games, and concluded that there was a 99.6% probability that Nakamura did not cheat.\n\nThe researchers emphasized the importance of initial assumptions in statistical analysis, particularly regarding the prevalence of cheating in online chess. Using an estimated cheating rate from Viswanathan Anand, they found a high likelihood of Nakamura's innocence. They also recalculated probabilities using higher cheating estimates, demonstrating the impact of these initial assumptions on the final outcome.\n\nThe study also highlights potential statistical fallacies. Kramnik's claim was identified as a \"prosecutor's fallacy,\" confusing the probability of evidence given innocence with the probability of innocence given evidence. Nakamura's counter-argument of \"cherry-picking\" was also challenged, as it violates the likelihood principle by considering data beyond the observed streak.\n\nThe researchers ultimately stress the need for critical evaluation of information and data framing, cautioning against assigning absolute probabilities (Cromwell's rule) and urging consideration of underlying assumptions before drawing conclusions, to avoid damaging reputations based on statistically skewed interpretations.\n",
    "chinese_title": "近期国际象棋争议",
    "chinese_summary": "芝加哥大学布斯商学院评论的这篇文章调查了弗拉基米尔·克拉姆尼克对国际象棋特级大师中村光涉嫌作弊的指控，该指控基于中村在一次在线闪电战比赛中不太可能出现的连胜纪录。研究人员希瓦·马哈拉杰、尼古拉斯·波尔森和瓦迪姆·索科洛夫对中村在chess.com上的3500多场比赛的表现数据进行了统计分析，并得出结论：中村没有作弊的可能性为99.6%。\n\n研究人员强调了统计分析中初始假设的重要性，特别是关于在线国际象棋作弊的普遍程度。他们使用维斯瓦纳坦·阿南德估计的作弊率，发现中村无罪的可能性很高。他们还使用更高的作弊估计值重新计算了概率，证明了这些初始假设对最终结果的影响。\n\n该研究还强调了潜在的统计谬误。克拉姆尼克的指控被认定为“检察官谬误”，即将在无罪情况下出现证据的概率与在出现证据情况下无罪的概率混淆。中村提出的“选择性取样”的反驳也受到了质疑，因为它通过考虑观察到的连胜之外的数据而违反了似然原则。\n\n研究人员最终强调需要对信息和数据框架进行批判性评估，警告不要赋予绝对概率（克伦威尔规则），并敦促在得出结论之前考虑基本假设，以避免基于统计上倾斜的解释损害声誉。"
  },
  {
    "id": "45388675",
    "title": "Gauntlet AI (YC S17) is looking for engineers who want to master AI",
    "url": "https://apply.gauntletai.com/",
    "summary": "The Gauntlet AI (YC S17) is actively recruiting engineers who are passionate about mastering artificial intelligence. This is the central takeaway from the title and the brief accompanying text. The \"Gauntlet Apply - Join the Elite Network\" further suggests that the company aims to be selective, looking for top-tier talent to contribute to their AI endeavors. The offer is presented as an opportunity to not only work in AI but to achieve mastery in the field, implying a challenging and growth-oriented environment. In essence, Gauntlet AI is positioning itself as a destination for ambitious engineers seeking to excel in AI.\n",
    "chinese_title": "Gauntlet AI (YC S17) 正在寻找想要精通人工智能的工程师。",
    "chinese_summary": "Gauntlet AI (YC S17) 正在积极招聘对掌握人工智能充满热情的工程师。公司旨在打造精英网络，寻求顶尖人才，为雄心勃勃、渴望在人工智能领域有所建树的工程师提供精进技艺的平台。"
  },
  {
    "id": "45387155",
    "title": "How to stop AI's \"lethal trifecta\"",
    "url": "https://www.economist.com/leaders/2025/09/25/how-to-stop-ais-lethal-trifecta",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "如何阻止人工智能的“致命三连击”",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "45386872",
    "title": "DeepFabric – Generate High-Quality Synthetic Datasets at Scale",
    "url": "https://lukehinds.github.io/deepfabric/",
    "summary": "DeepFabric is a tool designed to generate high-quality synthetic datasets for language model training, evaluation, and research. Its core strength lies in its topic-driven data generation approach, using both hierarchical topic trees and experimental graph-based topic modeling to create diverse and contextually rich training examples.\n\nThe tool caters to researchers, engineers, and practitioners who need high-quality synthetic data for tasks like model distillation, agent evaluation, or statistical research. It offers a three-stage pipeline: topic generation (creating trees or graphs representing the domain), dataset generation (producing contextually appropriate training examples), and packaging into standard formats.\n\nDeepFabric stands out by building a conceptual map of the domain, ensuring broader coverage and more consistent quality than simple prompt-based generation. It supports both traditional topic trees for domains with clear hierarchies and topic graphs for interconnected domains.\n\nGetting started involves installation, configuration, and dataset generation. Users can leverage YAML configurations for detailed control or use the Python API for programmatic integration. DeepFabric integrates with platforms like OpenAI, Anthropic, Ollama, and Hugging Face Hub, allowing for dataset exporting with automatic metadata. The CLI offers utilities for validation, visualization, and dataset uploading.\n",
    "chinese_title": "DeepFabric – 大规模生成高质量合成数据集",
    "chinese_summary": "DeepFabric 是一款旨在为语言模型训练、评估和研究生成高质量合成数据集的工具。其核心优势在于其主题驱动的数据生成方法，利用分层主题树和实验性的基于图的主题建模来创建多样且上下文丰富的训练示例。\n\n该工具适用于需要高质量合成数据的研究人员、工程师和从业者，用于模型蒸馏、代理评估或统计研究等任务。它提供了一个三阶段流程：主题生成（创建代表领域的主题树或图）、数据集生成（生成上下文适当的训练示例）和打包成标准格式。\n\nDeepFabric 通过构建领域的概念图脱颖而出，确保比简单的基于提示的生成更广泛的覆盖范围和更一致的质量。它支持具有清晰层次结构的领域的传统主题树，以及用于互连领域的主题图。\n\n入门包括安装、配置和数据集生成。用户可以利用 YAML 配置进行详细控制，或使用 Python API 进行程序化集成。DeepFabric 与 OpenAI、Anthropic、Ollama 和 Hugging Face Hub 等平台集成，允许导出具有自动元数据的数据集。CLI 提供了用于验证、可视化和数据集上传的实用程序。"
  },
  {
    "id": "45387494",
    "title": "SpaceX – Evolving the Multi-User Spaceport",
    "url": "https://www.spacex.com/updates#multiuser-spaceport",
    "summary": "The article, titled \"SpaceX – Evolving the Multi-User Spaceport,\" likely focuses on SpaceX's efforts to transform its launch facilities into multi-user spaceports. This implies a shift from exclusive use to a model where other companies and organizations can utilize SpaceX's infrastructure for their own space-related activities.\n\nKey aspects that the article might cover include:\n\n*   **Increased Launch Capacity:** By creating a multi-user spaceport, SpaceX could significantly increase the overall number of launches occurring, boosting the space industry as a whole.\n*   **Revenue Diversification:** Offering launch services and infrastructure to other companies provides SpaceX with additional revenue streams beyond its own missions.\n*   **Competition and Collaboration:** The multi-user model could foster competition among launch providers while also potentially leading to collaboration and innovation.\n*   **Infrastructure Improvements:** To accommodate multiple users, SpaceX would likely need to invest in upgrading and expanding its launch facilities, including launch pads, payload processing facilities, and ground support equipment.\n*   **Regulatory and Safety Considerations:** Operating a multi-user spaceport requires navigating complex regulatory requirements and ensuring the safety of all users and the surrounding environment.\n*   **Future of Spaceports:** The article may discuss how SpaceX's efforts are shaping the future of spaceports and the broader space industry.\n",
    "chinese_title": "SpaceX – 发展多用户航天港",
    "chinese_summary": "文章题为《SpaceX：多用户太空发射场的演进》，可能重点介绍SpaceX将其发射设施转变为多用户太空发射场的努力。这意味着从独家使用转变为其他公司和组织可以利用SpaceX的基础设施进行其自身太空相关活动的模式。\n\n文章可能涵盖的关键方面包括：\n\n*   **增加发射能力：** 通过创建多用户太空发射场，SpaceX可以显著增加整体发射次数，从而推动整个航天工业的发展。\n*   **收入多样化：** 向其他公司提供发射服务和基础设施为SpaceX提供了除自身任务之外的额外收入来源。\n*   **竞争与合作：** 多用户模式可以促进发射服务提供商之间的竞争，同时也可能促成合作和创新。\n*   **基础设施改进：** 为了容纳多个用户，SpaceX可能需要投资升级和扩展其发射设施，包括发射台、有效载荷处理设施和地面支持设备。\n*   **监管和安全考量：** 运营多用户太空发射场需要应对复杂的监管要求，并确保所有用户和周围环境的安全。\n*   **太空发射场的未来：** 文章可能讨论SpaceX的努力如何塑造太空发射场和更广泛的航天工业的未来。"
  },
  {
    "id": "45347619",
    "title": "Ultra efficient vector extension for SQLite",
    "url": "https://marcobambini.substack.com/p/the-state-of-vector-search-in-sqlite",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "SQLite 的超高效向量扩展",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "45348634",
    "title": "Athlon 64: How AMD turned the tables on Intel",
    "url": "https://dfarq.homeip.net/athlon-64-how-amd-turned-the-tables-on-intel/",
    "summary": "In this article, Dave Farquhar discusses how AMD's Athlon 64 processor revolutionized the x86 architecture and forced Intel to adopt a 64-bit extension that they initially resisted.\n\nIntel wanted to move to a completely new 64-bit architecture with Itanium, avoiding the baggage of x86 and creating a design they hoped would be more efficient and harder to copy. However, AMD recognized that Itanium wasn't gaining widespread adoption, especially for desktop Windows.\n\nAMD took a risk by extending the existing x86 architecture to 64 bits with the Athlon 64. The key advantage was backward compatibility, allowing users to run existing 32-bit applications smoothly while being ready for the future of 64-bit software. This made the transition more appealing to users.\n\nThe Athlon 64 was a success, not only for its 64-bit capabilities but also as a superior 32-bit processor, outperforming Intel in clock speed and power efficiency. This efficiency was crucial for data centers. The Athlon 64 was so compelling that even Intel relented in 2004 and cloned AMD's AMD64 architecture, rebranding it as Intel64. While Itanium continued in niche applications, Intel's move effectively solidified AMD's approach.\n\nThe Athlon 64 marked a significant turning point, showcasing AMD's innovation and establishing them as a true competitor to Intel.\n",
    "chinese_title": "速龙64：AMD如何扭转乾坤，战胜英特尔",
    "chinese_summary": "在本文中，Dave Farquhar讨论了AMD的Athlon 64处理器如何革新了x86架构，并迫使英特尔采用他们最初抵制的64位扩展。\n\n英特尔原本希望通过安腾（Itanium）转向一种全新的64位架构，避免x86的包袱，并创造一种他们希望更高效且更难复制的设计。然而，AMD意识到安腾并没有获得广泛采用，尤其是在Windows桌面领域。\n\nAMD冒险通过Athlon 64将现有的x86架构扩展到64位。关键优势在于向后兼容性，这使得用户可以流畅地运行现有的32位应用程序，同时为未来的64位软件做好准备。这使得过渡对用户更具吸引力。\n\nAthlon 64取得了成功，不仅在于其64位功能，还在于它作为一款卓越的32位处理器，在时钟速度和能效方面都优于英特尔。这种效率对于数据中心至关重要。Athlon 64极具竞争力，以至于英特尔甚至在2004年让步，克隆了AMD的AMD64架构，并将其重新命名为Intel64。虽然安腾继续在利基应用中使用，但英特尔的举动有效地巩固了AMD的方法。\n\nAthlon 64标志着一个重要的转折点，展示了AMD的创新，并将他们确立为英特尔真正的竞争对手。"
  },
  {
    "id": "45387421",
    "title": "Show HN: Dreamtap – Make your AI more creative",
    "url": "https://dreamtap.xyz/",
    "summary": "Dreamtap aims to address the issue of AI-generated stories lacking originality. The author points out that AI models like Claude often exhibit \"mode collapse,\" where they default to predictable and repetitive patterns, resulting in similar stories despite being asked for something unique. This leads to a lack of creativity as the AI relies on the \"safest, most average patterns\" learned from its training data, essentially producing variations of the same core narrative instead of truly novel content. The core problem identified is the lack of genuine creativity and originality in AI-generated narratives due to this tendency toward predictable patterns. The author implies that Dreamtap is a potential solution to counteract this issue.\n",
    "chinese_title": "Show HN: Dreamtap – 让你的 AI 更具创造力",
    "chinese_summary": "Dreamtap旨在解决AI生成故事缺乏原创性的问题。作者指出，像Claude这样的AI模型经常出现“模式崩溃”，它们会默认使用可预测和重复的模式，导致即使被要求提供独特的内容，生成的故事也大同小异。这导致缺乏创造力，因为AI依赖于从其训练数据中学习到的“最安全、最平均的模式”，本质上是产生相同核心叙事的变体，而不是真正的新颖内容。所识别的核心问题是，由于这种趋向于可预测模式的倾向，AI生成叙事缺乏真正的创造力和原创性。作者暗示Dreamtap可能是解决此问题的潜在方案。"
  },
  {
    "id": "45386690",
    "title": "Titanic's Sister, Britannic, Sank in 1916. Divers Have Recovered Artifacts",
    "url": "https://www.smithsonianmag.com/smart-news/the-titanics-sister-ship-the-britannic-sank-in-1916-for-the-first-time-ever-divers-have-recovered-artifacts-from-its-wreck-180987402/",
    "summary": "Divers have recovered artifacts from the wreck of the Britannic, sister ship to the Titanic and Olympic, which sank in 1916 during World War I after hitting a naval mine. The Britannic, originally intended as a luxury liner, was repurposed as a hospital ship. The recovery operation, organized by historian Simon Mills, took place in May at the wreck site, nearly 400 feet below sea level in the Aegean Sea.\n\nThe artifacts, recovered by an 11-member team using specialized equipment, include the ship's bell, binoculars, a navigation lamp, silver-plated trays, ceramic tiles, and a porcelain sink. These items are undergoing conservation in Athens and will be displayed at the National Museum of Underwater Antiquities in Piraeus, Greece, slated to open in 2026.\n\nThe Britannic, despite being the largest vessel lost during the Great War, saw relatively few casualties (30 out of 1,066) compared to other wartime shipwrecks, contributing to its relative obscurity compared to the Titanic. The Olympic, the third ship in the trio, had a long career, serving as both a troopship and passenger liner before being retired in 1935.\n",
    "chinese_title": "泰坦尼克号的姐妹舰，不列颠号，于1916年沉没。潜水员已寻回文物。",
    "chinese_summary": "潜水员已从不列颠号残骸中打捞出文物，该船是泰坦尼克号和奥林匹克号的姊妹船，于1916年第一次世界大战期间触雷沉没。不列颠号最初计划作为豪华班轮，后被改造成医院船。由历史学家西蒙·米尔斯组织的打捞行动于五月在爱琴海海平面下近400英尺的沉船地点进行。\n\n这11名成员组成的团队使用专用设备打捞出的文物包括船铃、双筒望远镜、航行灯、镀银托盘、瓷砖和瓷质水槽。这些物品正在雅典进行保护，并将于2026年在希腊比雷埃夫斯国家水下文物博物馆展出。\n\n不列颠号虽然是第一次世界大战期间损失的最大船只，但与其他战时沉船相比，伤亡相对较少（1066人中仅30人丧生），这也导致它与泰坦尼克号相比相对默默无闻。奥林匹克号是这三艘船中的第三艘，服役时间很长，在1935年退役前曾担任运兵船和客轮。"
  },
  {
    "id": "45384481",
    "title": "Pop OS 24.04 LTS Beta",
    "url": "https://system76.com/pop/pop-beta/",
    "summary": "Pop!_OS 24.04 LTS Beta is available for download and testing, featuring the new COSMIC Desktop Environment developed by System76. This beta release is feature-complete but still contains bugs that are being addressed.\n\nUpgrading from Pop!_OS 22.04 LTS requires backing up your current installation and running a terminal command. Post-upgrade, users should re-enable PPAs and re-pin their favorite apps to the dock (now called \"Pin to app tray\").\n\nTwo versions are available: one for computers with Intel/AMD or older NVIDIA graphics, and another for newer NVIDIA graphics (16 series and newer). Both versions require disabling Secure Boot in BIOS and have a minimum requirement of 4 GB RAM and 16 GB storage.\n\nThe release notes highlight the replacement of several GNOME apps with COSMIC counterparts (Files, Terminal, Text Editor, Media Player, and the Pop!_Shop which is now the COSMIC Store). The kernel is 6.16.3, Mesa is 25.1.5-1, and the NVIDIA driver is 580.\n\nKnown issues include: Dragging files between Wayland and X11 apps not supported, potential Firefox theming issues on other distros, games starting partially off-screen. Further, display toggle hotkeys, application indicator issues, and printing in COSMIC Text Editor are not yet supported. Accessibility features are still under development. Bug fixes and additional features are planned for the Release Candidate.\n",
    "chinese_title": "Pop OS 24.04 LTS Beta 测试版",
    "chinese_summary": "Pop!_OS 24.04 LTS Beta 版现已提供下载和测试，其搭载了由 System76 开发的全新 COSMIC 桌面环境。此 Beta 版本功能完整，但仍包含正在修复的错误。\n\n从 Pop!_OS 22.04 LTS 升级需要备份当前安装，并运行终端命令。升级后，用户应重新启用 PPA，并将他们喜爱的应用程序重新固定到 dock（现在称为“固定到应用程序托盘”）。\n\n提供两个版本：一个适用于配备 Intel/AMD 或较旧 NVIDIA 显卡的电脑，另一个适用于较新的 NVIDIA 显卡（16 系列及更新版本）。两个版本都需要在 BIOS 中禁用安全启动，并且最低要求 4 GB 内存和 16 GB 存储空间。\n\n发行说明重点介绍了使用 COSMIC 对应程序替换了几个 GNOME 应用程序（文件、终端、文本编辑器、媒体播放器和 Pop!_Shop，现在是 COSMIC 商店）。内核为 6.16.3，Mesa 为 25.1.5-1，NVIDIA 驱动程序为 580。\n\n已知问题包括：不支持在 Wayland 和 X11 应用程序之间拖动文件，其他发行版上可能存在 Firefox 主题问题，游戏启动时可能部分超出屏幕。此外，显示切换热键、应用程序指示器问题以及在 COSMIC 文本编辑器中打印尚不受支持。辅助功能仍在开发中。Bug 修复和其他功能计划在候选版本中提供。"
  },
  {
    "id": "45383637",
    "title": "Translating a Fortran F-16 Simulator to Unity3D",
    "url": "https://vazgriz.com/762/f-16-flight-sim-in-unity-3d/",
    "summary": "This article details the author's journey of translating an F-16 flight simulator written in Fortran into Unity3D. The simulator's flight model is based on wind tunnel data and relies on lookup tables and mathematical equations.\n\nThe article covers essential aerospace conventions, including the coordinate system (X forward, Y right, Z down), which differs from typical 3D software, and the use of US customary units (feet, slugs, knots, Rankine). It emphasizes the need for converting between these units and Unity's metric system. Key aerospace terms like angle of attack (alpha), angle of side slip (beta), and angular velocities (P, Q, R) are also defined.\n\nA significant portion of the article is dedicated to explaining how the simulator calculates \"Air Data,\" specifically dynamic pressure (qBar) and Mach number, based on the aircraft's velocity and altitude. The original Fortran code for this calculation is presented and translated into a C# class within Unity. The code simulates the impact of altitude on temperature and air density to accurately derive these air data parameters, which are critical for the flight model. The article mentions limitations of the model, such as the altitude cap of 35,000 feet due to simplified temperature modeling.\n\nFinally, the article briefly introduces the concept of table interpolation, which the Fortran code uses for flight characteristics. It explains how 1D lookup tables are created.\n",
    "chinese_title": "将 Fortran F-16 模拟器翻译成 Unity3D",
    "chinese_summary": "本文详细介绍了作者将用Fortran编写的F-16飞行模拟器翻译成Unity3D的旅程。该模拟器的飞行模型基于风洞数据，并依赖于查找表和数学公式。\n\n文章涵盖了重要的航空航天惯例，包括坐标系（X轴向前，Y轴向右，Z轴向下），这与典型的3D软件不同，以及使用美国习惯单位（英尺，斯勒格，节，兰金）。文章强调了需要在这些单位和Unity的公制单位之间进行转换。还定义了关键的航空航天术语，如迎角（alpha），侧滑角（beta）和角速度（P，Q，R）。\n\n文章的很大一部分致力于解释模拟器如何根据飞机的速度和高度计算“空速数据”，特别是动压（qBar）和马赫数。展示了此计算的原始Fortran代码，并将其转换为Unity中的C#类。该代码模拟了高度对温度和空气密度的影响，从而准确地得出这些对飞行模型至关重要的空速数据参数。文章提到了模型的局限性，例如由于简化的温度建模而导致的高度上限为35,000英尺。\n\n最后，本文简要介绍了表格插值的概念，Fortran代码将其用于飞行特性。文章解释了如何创建一维查找表。"
  },
  {
    "id": "45387242",
    "title": "They don't make 'em like that any more: Dyson Pure Cool-Me personal air purifier",
    "url": "https://kevinboone.me/cool-me.html",
    "summary": "This article reviews the now-discontinued Dyson Pure Cool-Me personal air purifier, a high-end desk fan designed for individual use. The author acknowledges the privilege inherent in owning such an expensive device, received as a gift, and questions its necessity for most people.\n\nThe Cool-Me is praised for its quiet operation, effective cooling, and air purification capabilities, removing pollen and particulates to alleviate allergy symptoms. It features a \"bladeless\" design for safety and low energy consumption. The author finds it effective for cooling, especially at lower temperatures, and appreciates its air cleaning function.\n\nHowever, the Cool-Me has downsides. The remote control is poorly designed and largely useless, and the external power supply is bulky. The limited up-down airflow adjustment requires makeshift solutions for nighttime use.\n\nThe main drawback is the expensive HEPA filter, requiring annual replacement at a cost of £70. While compatible, cheaper filters are available from third-party suppliers, their effectiveness is uncertain. Cleaning the HEPA filter is difficult, and the author fears the lack of future filter availability will render the Cool-Me useless.\n\nUltimately, the Cool-Me is presented as a well-designed, albeit overpriced, device that quietly improves the author's daily life. Its high price point likely contributed to its discontinuation, as cheaper, less refined alternatives exist. The author concludes that while not revolutionary, the Cool-Me was a valuable addition to their desk.\n",
    "chinese_title": "他们再也不生产那样的产品了：戴森 Pure Cool Me 个人空气净化器",
    "chinese_summary": "本文评测已停产的戴森Pure Cool-Me个人空气净化器，这是一款专为个人使用设计的高端桌面风扇。作者承认拥有如此昂贵的设备是一种特权，这台设备是作为礼物收到的，并质疑其对大多数人的必要性。\n\nCool-Me因其安静运行、有效制冷和空气净化能力而受到赞扬，它可以去除花粉和颗粒物以缓解过敏症状。它采用“无叶”设计，以确保安全和低能耗。作者发现它在制冷方面非常有效，尤其是在较低温度下，并赞赏其空气清洁功能。\n\n然而，Cool-Me也有缺点。遥控器设计糟糕且基本无用，外部电源笨重。有限的上下气流调节需要临时解决方案才能在夜间使用。\n\n主要的缺点是昂贵的HEPA过滤器，需要每年更换，费用为70英镑。虽然兼容，但可以从第三方供应商处购买更便宜的过滤器，但其有效性尚不确定。清洁HEPA过滤器很困难，作者担心未来无法获得过滤器将使Cool-Me变得毫无用处。\n\n总的来说，Cool-Me是一款设计精良但价格过高的设备，它可以悄无声息地改善作者的日常生活。其高昂的价格可能导致其停产，因为存在更便宜、更简化的替代品。作者总结说，虽然Cool-Me并非革命性的产品，但它是他们办公桌上的宝贵补充。"
  },
  {
    "id": "45384653",
    "title": "Genode OS Framework",
    "url": "https://genode.org",
    "summary": "The Genode OS framework is an open-source toolkit for building secure, component-based operating systems suitable for both embedded devices and general-purpose computing. It addresses the inherent complexity of modern OSes by implementing a strict organizational structure across all software components, promoting security through capability-based security, microkernel architecture, the principle of least authority, sandboxing, and virtualization.\n\nKey resources include the \"Genode Foundations\" book, providing a comprehensive understanding of the architecture and development environment, and the \"Genode Applications\" book, a beginner-friendly guide for application development and porting. A third document, \"Genode Platforms,\" focuses on hardware-related topics for integrators and device driver developers.\n\nRecent updates and news highlight Genode's ongoing development. Release 25.08 introduced a new kernel scheduler and updated Linux-based PC drivers. Revised editions of the \"Genode Foundations\" and \"Genode Applications\" books are available to match framework 25.05 and Sculpt OS 25.04. Genode 25.05 focuses on API hardening, Goa SDK sandboxing, TCP/IP stack consolidation, and enhanced graphics. Sculpt OS 25.04 offers compatibility with new Intel hardware and introduces multi-monitor window management. The 25.02 release extended multi-monitor support to virtual machines, featured ports of Qemu and Chromium, boosted graphics performance, and improved support for specific hardware platforms. The roadmap for 2025 is focused on improvements to rigidity, clarity, and performance.\n",
    "chinese_title": "Genode操作系统框架",
    "chinese_summary": "Genode操作系统框架是一个开源工具包，用于构建安全的、基于组件的操作系统，适用于嵌入式设备和通用计算。它通过在所有软件组件中实施严格的组织结构来解决现代操作系统固有的复杂性，并通过基于能力的安全性、微内核架构、最小权限原则、沙盒和虚拟化来提高安全性。\n\n主要资源包括《Genode Foundations》一书，它提供了对架构和开发环境的全面理解，以及《Genode Applications》一书，这是一本面向初学者的应用程序开发和移植指南。第三份文档《Genode Platforms》侧重于集成商和设备驱动程序开发人员的硬件相关主题。\n\n最近的更新和新闻突显了Genode的持续开发。25.08版本引入了一个新的内核调度器和更新的基于Linux的PC驱动程序。《Genode Foundations》和《Genode Applications》的修订版已发布，以匹配框架25.05和Sculpt OS 25.04。Genode 25.05侧重于API强化、Goa SDK沙盒化、TCP/IP协议栈整合以及增强的图形功能。Sculpt OS 25.04提供了与新型英特尔硬件的兼容性，并引入了多显示器窗口管理。25.02版本将多显示器支持扩展到虚拟机，包含Qemu和Chromium的移植，提高了图形性能，并改进了对特定硬件平台的支持。2025年的路线图侧重于刚性、清晰度和性能的改进。"
  },
  {
    "id": "45387214",
    "title": "When hackathon judging is a public benchmark: my report from Hack the North",
    "url": "https://github.com/trycua/cua/blob/main/blog/hack-the-north.md",
    "summary": "The provided information describes a GitHub repository related to \"trycua/cua,\" which is publicly accessible. The title suggests the repository is relevant to a \"Hack the North\" hackathon, possibly discussing the experience of judging at the event and the unusual aspect of it functioning as a public benchmark.\n\nThe repository appears to have encountered an error while loading, preventing full access to the content. However, key metrics are visible: it has been forked 499 times and starred 9.8k times, indicating considerable interest and usage within the developer community. The fact that it resides on GitHub suggests it likely contains code, documentation, or other materials related to the hackathon project.\n\nGiven the title, the content of the repository is probably a report on the author's experience judging at Hack the North, focusing on the interesting dynamic of the judging process being observable as a public benchmark. This could involve analyzing the quality of submissions, reflecting on the judging criteria, or discussing the challenges and benefits of having judging criteria and results made public. Due to the error loading the content, the specific details and arguments within the report remain unknown.\n",
    "chinese_title": "当黑客马拉松评审成为公共基准：我的 Hack the North 报告",
    "chinese_summary": "提供的信息描述了一个与“trycua/cua”相关的GitHub仓库，该仓库是公开访问的。标题表明该仓库与“Hack the North”黑客马拉松相关，可能讨论了在该赛事中担任评委的经验，以及它作为公共基准的特殊之处。\n\n该仓库在加载时似乎遇到了错误，导致无法完全访问内容。然而，关键指标是可见的：它已被fork 499次，并被star 9.8k次，表明在开发者社区中具有相当大的兴趣和使用率。它位于GitHub这一事实表明，它可能包含与该黑客马拉松项目相关的代码、文档或其他材料。\n\n鉴于标题，该仓库的内容很可能是作者在Hack the North担任评委的经验报告，重点是评审过程作为公共基准的可观察的有趣动态。这可能涉及分析提交作品的质量，反思评审标准，或讨论评审标准和结果公开所带来的挑战和好处。由于加载内容时出现错误，报告中的具体细节和论点仍然未知。"
  },
  {
    "id": "45382755",
    "title": "No reachable chess position with more than 218 moves",
    "url": "https://lichess.org/@/Tobs40/blog/there-is-no-reachable-chess-position-with-more-than-218-moves/a5xdxeqs",
    "summary": "This article details the author's quest to definitively prove that no reachable chess position exists with more than 218 legal moves for White. This problem was originally posed by Nenad Petrović, who created a 218-move position in 1964.\n\nThe author, a computer scientist, attempted to solve this using computers and mathematical optimization techniques. Initial attempts to brute-force the problem were deemed infeasible due to the astronomically large number of possible positions. The author then employed an integer programming approach using a solver (Gurobi), but even with simplifications and the relaxing of certain chess rules (e.g., castling, pins, checks, en passant), the computational cost remained high.\n\nTo further refine the search, the author introduced \"Chess with Cheating,\" allowing partial pieces and moves to establish upper bounds. This initially led to unrealistic scenarios, like fractional pieces spread across the board, yielding inflated move counts. Redundant constraints were then added to limit pieces moving from the same direction onto a square.\n\nUltimately, the Gurobi solver, using the refined model, found 12 representative positions, each with 218 moves, confirming that 218 is the maximum possible number of legal moves in a reachable chess position for White. The author also confirmed the optimality of the 144-move record without promotions. The code used is freely available on Github and suggests future problems for enthusiasts to tackle, like finding positions with the most captures, stalemates, or checks.\n",
    "chinese_title": "不存在超过218步的可达棋局位置",
    "chinese_summary": "本文详细介绍了作者为明确证明白方在可达的国际象棋局面中不可能存在超过 218 步合法走法而进行的探索。这个问题最初由 Nenad Petrović 提出，他在 1964 年创造了一个有 218 步走法的局面。\n\n作者是一位计算机科学家，试图利用计算机和数学优化技术来解决这个问题。由于可能的局面数量极其庞大，最初尝试使用暴力破解的方法被认为不可行。然后，作者使用求解器（Gurobi）采用整数规划方法，但即使经过简化并放宽某些国际象棋规则（例如，王车易位、牵制、将军、吃过路兵），计算成本仍然很高。\n\n为了进一步完善搜索，作者引入了“作弊国际象棋”，允许使用部分棋子和走法来建立上限。这最初导致了不切实际的场景，例如分数棋子遍布棋盘，从而导致走法数量虚高。然后添加了冗余约束，以限制棋子从同一方向移动到同一格子上。\n\n最终，Gurobi 求解器使用改进后的模型找到了 12 个代表性局面，每个局面都有 218 步走法，证实了 218 是白方在可达的国际象棋局面中可能存在的最大合法走法数。作者还证实了没有升变的情况下 144 步走法记录的最优性。所使用的代码在 Github 上免费提供，并为爱好者提出了未来可以解决的问题，例如寻找具有最多吃子、逼和或将军的局面。"
  },
  {
    "id": "45387374",
    "title": "Context is the bottleneck for coding agents now",
    "url": "https://runnercode.com/blog/context-is-the-bottleneck-for-coding-agents-now",
    "summary": "The article argues that the primary bottleneck preventing coding agents from replacing software developers is not intelligence, but a lack of sufficient context. While recent advancements show AI achieving superhuman performance in programming competitions (like ICPC), these environments provide complete context, unlike real-world software development.\n\nCurrent coding agents can handle simple tasks (a few lines of code or a single commit) reliably, but struggle with larger tasks like major features, refactors, or entire codebases on existing projects. Failures often stem from insufficient context rather than a lack of intelligence.\n\nThe article outlines the context a coding agent needs, ranging from basic access to code, documentation, and runtime execution, to more subtle understandings like codebase organization, architectural patterns, historical decisions, development practices, and business requirements. Unlike simple \"access\" to files, these subtle contexts require \"understanding\" and synthesis from scattered, sometimes conflicting, information.\n\nUltimately, the article suggests that progress requires providing agents with access to more context, including sophisticated preprocessing to make it usable. It also acknowledges the continued need for human developers to fill in contextual gaps and emphasizes the importance of agents learning to identify when they lack sufficient context and need to ask for guidance.\n",
    "chinese_title": "上下文是目前编码代理的瓶颈。",
    "chinese_summary": "文章认为，阻碍编码智能体取代软件开发者的主要瓶颈并非智能，而是缺乏足够的上下文。虽然最近的进展表明，人工智能在编程竞赛（如ICPC）中表现出超人的性能，但这些环境提供了完整的上下文，这与现实世界的软件开发不同。\n\n当前的编码智能体可以可靠地处理简单的任务（几行代码或单个提交），但在处理更大的任务时，例如主要功能、重构或现有项目中的整个代码库，则会遇到困难。失败通常源于上下文不足，而不是缺乏智能。\n\n文章概述了编码智能体所需的上下文，范围从对代码、文档和运行时执行的基本访问，到对代码库组织、架构模式、历史决策、开发实践和业务需求等更微妙的理解。与简单地“访问”文件不同，这些微妙的上下文需要从分散的、有时是相互冲突的信息中进行“理解”和综合。\n\n最终，文章建议，进步需要为智能体提供更多的上下文访问权限，包括复杂的预处理以使其可用。文章还承认，仍然需要人类开发者来填补上下文空白，并强调智能体学习识别何时缺乏足够的上下文并需要寻求指导的重要性。"
  },
  {
    "id": "45388380",
    "title": "Process Tracing Projects",
    "url": "https://github.com/oils-for-unix/oils/wiki/Process-Tracing-Projects",
    "summary": "This document, titled \"Process Tracing Projects,\" is a collection of links and descriptions of various projects focused on tracing and profiling processes, particularly boot processes and shell scripts. The author encourages contributions to the page with similar projects.\n\nKey projects highlighted include:\n\n*   **Traceboot:** A precise and lightweight tracing tool for boot and shell scripts, leveraging ftrace events for low-overhead monitoring and microsecond precision. It uses Perfetto (Google Chrome tracing UI) for visualizations.\n*   **Tracexec:** A TUI for tracing execve and pre-exec behavior, useful for debugging build systems, understanding shell scripts, and reverse engineering proprietary software.\n*   **Timep:** A next-generation profiler and flamegraph-generator for Bash code, although the author is skeptical of its efficiency claims due to its reliance on fragile Bash mechanisms.\n*   **Exploring Linux command-line space time:** A project by Fabien Sanglard visualizing command-line activity, utilizing the Linux kernel netlink interface.\n*   **Real-Time Build Visualizer:** A project using syscall snooping to visualize slow builds.\n\nThe document also refers to a related resource, \"Process Tracing Tips and Tools,\" and mentions the possibility of surveys and comparisons of these projects. The author is interested in improving upon existing tools, possibly with the Oils shell.\n",
    "chinese_title": "过程追踪项目",
    "chinese_summary": "流程跟踪项目\n\n本文档名为“流程跟踪项目”，汇集了专注于跟踪和分析进程（尤其是启动进程和 Shell 脚本）的各种项目的链接和描述。作者鼓励贡献类似的项目到本页面。\n\n重点项目包括：\n\n*   **Traceboot：** 一款精确且轻量级的启动和 Shell 脚本跟踪工具，利用 ftrace 事件进行低开销监控和微秒级精度。它使用 Perfetto (Google Chrome 跟踪 UI) 进行可视化。\n*   **Tracexec：** 一款用于跟踪 execve 和 pre-exec 行为的 TUI，可用于调试构建系统、理解 Shell 脚本和逆向工程专有软件。\n*   **Timep：** 一款面向 Bash 代码的下一代分析器和火焰图生成器，尽管作者对其效率声明持怀疑态度，因为它依赖于脆弱的 Bash 机制。\n*   **探索 Linux 命令行空间时间：** Fabien Sanglard 的一个项目，可视化命令行活动，利用 Linux 内核 netlink 接口。\n*   **实时构建可视化工具：** 一个使用系统调用监听来可视化缓慢构建的项目。\n\n该文档还提到了一个相关资源“流程跟踪技巧和工具”，并提到了对这些项目进行调查和比较的可能性。作者有兴趣改进现有工具，可能使用 Oils shell。"
  },
  {
    "id": "45353394",
    "title": "The Early Television Foundation and Museum",
    "url": "https://www.earlytelevision.org/index.html",
    "summary": "The Early Television Foundation and Museum is dedicated to preserving and showcasing the history of early television technology, from the mechanical systems of the 1920s to the introduction of color TV in the 1950s. The museum's collection encompasses mechanical TV, early electronic TV, postwar TV (American, British/European, and international), and early color TV, alongside related broadcast equipment, picture tubes, antennas, accessories, and test equipment.\n\nThe museum relies on donations and memberships to operate. Memberships offer benefits like free admission, discounted convention fees, and access to the monthly newsletter, \"What's New in Old TVs.\" They currently have 252 members and are encouraging renewals and new sign-ups.\n\nUpcoming events include online meetings, a farmers market appearance, and a Fall Swapmeet featuring an auction and sweepstakes drawing. The sweepstakes offers a chance to win vintage television sets, with ticket sales supporting the museum's operations.\n\nRecent additions to the museum's collection include a Garod 15TZ6, ATC Kinet, General Electric GM-295, Westinghouse H840CK15, Sony Chromatron KV-7010U, and JVC TM-L450TU LCCS Video Monitor/Receiver.\n\nThe museum is located in Hilliard, OH, and is open on Saturdays and Sundays. They welcome comments and suggestions through their website or by contacting them directly. They also have a good stock of NOS and used CRTs, flybacks, yokes, and transformers for sale.\n",
    "chinese_title": "早期电视基金会和博物馆",
    "chinese_summary": "早期电视基金会和博物馆致力于保存和展示早期电视技术的发展历史，从20世纪20年代的机械系统到20世纪50年代彩色电视的引入。博物馆的藏品包括机械电视、早期电子电视、战后电视（美国、英国/欧洲和国际）、早期彩色电视，以及相关的广播设备、显像管、天线、配件和测试设备。\n\n博物馆的运作依赖于捐款和会员资格。会员可享受免费入场、折扣会议费以及阅读每月通讯《旧电视有什么新玩意》等福利。他们目前拥有252名会员，并鼓励续订和新的注册。\n\n即将举行的活动包括在线会议、农贸市场亮相以及秋季跳蚤市场，其中包含拍卖和抽奖活动。抽奖活动提供了赢取老式电视机的机会，门票销售用于支持博物馆的运营。\n\n博物馆最近新增的藏品包括Garod 15TZ6、ATC Kinet、General Electric GM-295、Westinghouse H840CK15、Sony Chromatron KV-7010U和JVC TM-L450TU LCCS视频监视器/接收器。\n\n博物馆位于俄亥俄州希利亚德市，每周六和周日开放。他们欢迎通过其网站或直接联系他们提出意见和建议。他们还有大量NOS和二手CRT、回扫变压器、偏转线圈和变压器出售。"
  },
  {
    "id": "45382397",
    "title": "My Deus Ex lipsyncing fix mod",
    "url": "https://www.joewintergreen.com/my-deus-ex-lipsyncing-fix-mod-making-of/",
    "summary": "This article details the making of a mod to fix the broken lip-syncing and blinking in the original Deus Ex. The author, noticing the jerky and inconsistent mouth movements, investigated the game's Unrealscript and discovered a flawed frame rate check was causing the game to instantly snap between visemes instead of smoothly blending them. This check was intended to disable blending on low framerate systems but was implemented incorrectly.\n\nThe author's fix involved correcting the frame rate check and increasing the tween time, the duration of the blend between visemes, to 0.35 seconds. This created a smoother, more natural transition between mouth shapes. Furthermore, the author bypassed a `bIsSpeaking` check to ensure the mouth also closed smoothly at the end of dialogue lines, rather than snapping shut. Blinking speed was also significantly slowed down to make it visible.\n\nWhile the mod improved the lip-syncing, a core issue remained: the game's phoneme updates (the signals for which mouth shape to display) were infrequent and inconsistent, meaning the mouth shape often lagged behind the audio. This limitation is due to the phoneme extraction process likely happening in the game's inaccessible C++ code, and the author believes truly fixing it would require more frequent phoneme updates. The article also speculates that the original blending speed was likely tuned for a higher frequency of phoneme updates before optimization led to reduced processing. The author concludes by noting the duplication of the lip-sync function between the player and NPC classes.\n",
    "chinese_title": "我的《杀出重围》口型修复Mod",
    "chinese_summary": "本文详细介绍了如何制作一个Mod来修复初代《杀出重围》中损坏的口型同步和眨眼问题。作者注意到游戏中口型动作的生硬和不一致，调查了游戏的Unrealscript，发现一个有缺陷的帧率检查导致游戏在音素之间瞬间切换，而不是平滑过渡。这个检查本意是在低帧率系统上禁用过渡，但实现方式不正确。\n\n作者的修复方法包括纠正帧率检查，并将音素之间的过渡时间（tween time）增加到0.35秒。这使得口型之间的过渡更加平滑自然。此外，作者还绕过了一个`bIsSpeaking`检查，以确保嘴巴在对话结束时也能平滑闭合，而不是突然闭上。眨眼速度也被显著放慢，使其可见。\n\n虽然这个Mod改善了口型同步，但一个核心问题仍然存在：游戏中的音素更新（显示哪种口型的信号）不频繁且不一致，这意味着口型经常滞后于音频。这个限制是由于音素提取过程可能发生在游戏无法访问的C++代码中，作者认为真正修复它需要更频繁的音素更新。文章还推测，最初的过渡速度可能是在优化导致处理减少之前，针对更高的音素更新频率进行调整的。作者最后指出，玩家和NPC类之间的口型同步功能存在重复。"
  },
  {
    "id": "45375845",
    "title": "Improved Gemini 2.5 Flash and Flash-Lite",
    "url": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "summary": "Google has released improved versions of Gemini 2.5 Flash and Flash-Lite models, available on Google AI Studio and Vertex AI, focusing on enhanced quality and efficiency. Key improvements include:\n\n*   **Gemini 2.5 Flash-Lite:** This model has been updated based on better instruction following, reduced verbosity (50% reduction in output tokens, hence costs), and stronger multimodal and translation capabilities (audio transcription, image understanding, and translation quality). The model string to test is gemini-2.5-flash-lite-preview-09-2025.\n*   **Gemini 2.5 Flash:** This version focuses on better agentic tool use (demonstrating a 5% gain on SWE-Bench Verified compared to the last release) and is more efficient, achieving higher quality outputs while using fewer tokens (24% reduction). The model string to test is gemini-2.5-flash-preview-09-2025.\n\nTo simplify access to the latest models, Google is introducing \"-latest\" aliases (gemini-flash-latest, gemini-flash-lite-latest) that will always point to the most recent model versions. A 2-week notice will be given before updating or deprecating a specific version behind the aliases.\n\nFor applications requiring stability, using \"gemini-2.5-flash\" and \"gemini-2.5-flash-lite\" is recommended. The new releases are previews, intended for testing and feedback to shape future stable releases.\n",
    "chinese_title": "改进版 Gemini 2.5 Flash 和 Flash-Lite",
    "chinese_summary": "谷歌发布了Gemini 2.5 Flash和Flash-Lite模型改进版本，可在Google AI Studio和Vertex AI上使用，重点在于增强质量和效率。主要改进包括：\n\n*   **Gemini 2.5 Flash-Lite：** 该模型已更新，基于更好的指令遵循、更少的冗余（输出token减少50%，因此降低了成本）以及更强的多模态和翻译能力（音频转录、图像理解和翻译质量）。用于测试的模型字符串为gemini-2.5-flash-lite-preview-09-2025。\n*   **Gemini 2.5 Flash：** 此版本专注于更好的代理工具使用（在SWE-Bench Verified上比上次发布版本提高了5%），并且效率更高，在使用更少token的情况下实现了更高质量的输出（减少24%）。用于测试的模型字符串为gemini-2.5-flash-preview-09-2025。\n\n为了简化对最新模型的访问，谷歌引入了“-latest”别名（gemini-flash-latest, gemini-flash-lite-latest），它们将始终指向最新的模型版本。在更新或弃用别名后面的特定版本之前，将提前2周发出通知。\n\n对于需要稳定性的应用程序，建议使用“gemini-2.5-flash”和“gemini-2.5-flash-lite”。新版本均为预览版，旨在用于测试和反馈，以塑造未来的稳定版本。"
  },
  {
    "id": "45387485",
    "title": "Better health conversations: Research on a \"wayfinding\" AI agent based on Gemini",
    "url": "https://research.google/blog/towards-better-health-conversations-research-insights-on-a-wayfinding-ai-agent-based-on-gemini/",
    "summary": "This Google Research article introduces \"Wayfinding AI,\" a novel research AI agent based on Gemini, designed to improve health information access through proactive conversational guidance. Recognizing that online health information can be overwhelming and impersonal, the Wayfinding AI aims to mimic the context-seeking approach of a doctor by asking clarifying questions to understand a user's specific needs and goals, rather than simply providing a single answer to an initial query.\n\nUser studies involving 163 participants revealed that people often struggle to articulate their health concerns effectively. Participants preferred the \"deferred-answer\" approach of the Wayfinding AI, perceiving it as more personal and reassuring. This approach involved the AI asking clarifying questions before providing information.\n\nThe Wayfinding AI was designed with three core principles: proactive conversational guidance, best-effort answers at each turn, and transparent reasoning. It also utilizes a two-column interface to clearly separate the interactive conversation from the informational content.\n\nA randomized study with 130 participants comparing the Wayfinding AI to a baseline Gemini model showed a preference for the Wayfinding AI. Users found it more helpful, relevant, better at understanding their goals, and more tailored to their specific needs. Conversations with the Wayfinding AI were also longer and more in-depth, particularly when discussing symptoms. The study demonstrates that a human-centered, conversational AI approach is a promising direction for improving health information access and empowering individuals to navigate their health journeys.\n",
    "chinese_title": "更好的健康对话：基于 Gemini 的“寻路”AI 代理研究",
    "chinese_summary": "谷歌研究文章介绍了一种名为“寻路AI”的新型研究型人工智能代理，该代理基于Gemini，旨在通过主动式对话引导来改善健康信息的获取。 寻路AI认识到在线健康信息可能令人不知所措且缺乏个性化，因此旨在模仿医生的情境式询问方法，通过提出澄清问题来理解用户的具体需求和目标，而不是简单地为初始查询提供单一答案。\n\n一项涉及163名参与者的用户研究表明，人们常常难以有效地表达他们的健康问题。参与者更喜欢寻路AI的“延迟回答”方法，认为这种方法更个性化且令人安心。这种方法涉及AI在提供信息之前提出澄清问题。\n\n寻路AI的设计基于三个核心原则：主动式对话引导、每次轮询时提供最佳解答以及透明的推理过程。它还采用双栏界面，以清晰地区分互动对话和信息内容。\n\n一项对130名参与者进行的随机研究，将寻路AI与基线Gemini模型进行了比较，结果显示用户更偏爱寻路AI。用户发现它更有帮助、更相关、更擅长理解他们的目标，并且更符合他们的特定需求。与寻路AI的对话也更长且更深入，尤其是在讨论症状时。该研究表明，以人为本的对话式AI方法是改善健康信息获取和赋能个人自主管理健康之旅的一个有前景的方向。"
  },
  {
    "id": "45382645",
    "title": "A platform-jumping prince – History of Prince of Persia's 1990s Ports",
    "url": "https://www.jordanmechner.com/en/latest-news/#a-platform-jumping-prince",
    "summary": "Jordan Mechner, the creator of Prince of Persia, reflects on the various ports of his iconic game from the early 1990s, discussing their development and significance. He highlights the original Apple II version as closest to his heart, given his sole programming involvement, but acknowledges the DOS/Windows version as the most widely remembered due to its enhanced graphics and sound.\n\nHe details the Amiga port by Dan Gorlin, a game development hero of his, and the unfortunate non-development of a Commodore 64 version. Mechner also delves into the Macintosh port, subcontracted to Presage Software, which faced delays due to evolving Mac models. Ironically, these delays proved beneficial, leading to a combined Mac/PC release that revitalized the game's popularity. He notes that the Mac version's visual style even influenced the sequel.\n\nMechner touches upon the numerous other console and computer ports, but singles out the Super Nintendo version developed by Arsys as a standout. He describes his surprise and delight at playing this expanded version, which felt like a brand new game with added levels, enemies, and music. He marvels at how the SNES version gave him his first taste of what it felt like to play and enjoy a PoP game developed by others.\n\nMechner concludes by suggesting that the most beloved version of Prince of Persia is often the one played during one's formative years. He also plugs his two books documenting the creation of the game: his journals and a graphic novel.\n",
    "chinese_title": "平台跳跃王子——波斯王子90年代移植版历史",
    "chinese_summary": "《波斯王子》之父乔丹·麦肯纳回顾了20世纪90年代初他标志性游戏的各种移植版本，讨论了它们的开发和意义。他强调最初的Apple II版本最贴近他的内心，因为他独自参与了编程，但承认DOS/Windows版本由于其增强的图形和声音而最为人们所铭记。\n\n他详细介绍了丹·戈林（他游戏开发英雄）的Amiga移植版本，以及Commodore 64版本不幸未能开发的情况。麦肯纳还深入研究了外包给Presage Software的Macintosh移植版本，该版本因不断发展的Mac型号而面临延误。具有讽刺意味的是，这些延误最终证明是有益的，促成了Mac/PC联合发布，从而重振了游戏的受欢迎程度。他指出，Mac版本的视觉风格甚至影响了续集。\n\n麦肯纳提到了许多其他主机和电脑移植版本，但特别指出了Arsys开发的Super Nintendo版本，认为它是一个亮点。他描述了他玩这个扩展版本时的惊喜和喜悦，它感觉像一个全新的游戏，增加了关卡、敌人和音乐。他惊叹于SNES版本如何让他第一次体验到玩和享受其他人开发的《波斯王子》游戏的感觉。\n\n麦肯纳最后表示，《波斯王子》最受喜爱的版本往往是在人们成长时期玩过的版本。他还宣传了他记录游戏创作过程的两本书：他的日记和一本图像小说。"
  },
  {
    "id": "45388054",
    "title": "Ubuntu 25.10's Rust Coreutils Is Causing Major Breakage for Some Executables",
    "url": "https://www.phoronix.com/news/Ubuntu-25.10-Coreutils-Makeself",
    "summary": "Ubuntu 25.10's recent transition to Rust Coreutils from GNU Coreutils is causing significant breakage, particularly with Makeself archives, according to an article published on September 26, 2025. The author, Michael Larabel, discovered the issue while running benchmarks, specifically Unigine and GravityMark, which were failing due to MD5 checksum errors. These errors occurred despite using previously validated benchmark files.\n\nThe problem stems from subtle differences in the `md5sum` implementation between Rust Coreutils and GNU Coreutils. Benchmarks and other programs that rely on Makeself archives, which utilize the `md5sum` command, are now encountering errors in Ubuntu 25.10.\n\nThe author confirmed the issue by replacing Rust Coreutils with GNU Coreutils, which resolved the MD5 errors. Further investigation revealed other users reporting similar problems with Makeself files, including those used by VirtualBox. With Ubuntu 25.10 due for release in less than two weeks, this breakage presents a significant problem. It remains to be seen whether the Rust Coreutils issue can be resolved before the launch to prevent these errors from impacting users who rely on Makeself archives and scripts dependent on GNU Coreutils' `md5sum` behavior.\n",
    "chinese_title": "Ubuntu 25.10的Rust Coreutils正在导致一些可执行文件出现重大问题",
    "chinese_summary": "Ubuntu 25.10 由 GNU Coreutils 迁移至 Rust Coreutils 引发重大问题，特别是 Makeself 归档文件，据 2025 年 9 月 26 日发表的文章称。作者 Michael Larabel 在运行基准测试（特别是 Unigine 和 GravityMark）时发现了这个问题，由于 MD5 校验和错误而失败。 尽管使用了之前验证过的基准测试文件，但仍然发生了这些错误。\n\n问题源于 Rust Coreutils 和 GNU Coreutils 之间 `md5sum` 实现的细微差异。 依赖于使用 `md5sum` 命令的 Makeself 归档文件的基准测试和其他程序现在在 Ubuntu 25.10 中遇到错误。\n\n作者通过将 Rust Coreutils 替换为 GNU Coreutils 证实了该问题，从而解决了 MD5 错误。 进一步调查显示，其他用户也报告了 Makeself 文件存在类似问题，包括 VirtualBox 使用的文件。 距离 Ubuntu 25.10 发布不到两周，这种破坏性问题非常严重。 Rust Coreutils 问题是否能在发布前得到解决，以防止这些错误影响依赖 Makeself 归档文件以及依赖 GNU Coreutils `md5sum` 行为的脚本的用户，仍有待观察。"
  },
  {
    "id": "45375477",
    "title": "ChatGPT Pulse",
    "url": "https://openai.com/index/introducing-chatgpt-pulse/",
    "summary": "Okay, I have accessed the article at the provided URL (https://openai.com/index/introducing-chatgpt-pulse/). Here's a summary:\n\nChatGPT Pulse is a new feature designed to enhance the user experience by providing a more dynamic and contextual understanding of trending topics and breaking news directly within ChatGPT conversations. It aims to bridge the gap between ChatGPT's core capabilities as a language model and the ever-evolving information landscape.\n\nThe main benefit of ChatGPT Pulse is its ability to detect and summarize trending topics as they emerge. This allows users to stay informed about current events and access relevant information without leaving their ChatGPT conversation. It works by identifying keywords and phrases that are rapidly gaining traction and then synthesizing this information into concise and informative summaries.\n\nUsers can engage with Pulse by asking general questions about trending topics or by simply observing when Pulse proactively flags potentially relevant information within a conversation. The feature is designed to be minimally intrusive, only offering summaries when it detects a significant trend related to the current discussion.\n\nOpenAI has emphasized that ChatGPT Pulse is still under development and will be continuously improved. User feedback is actively being sought to refine the accuracy, relevance, and overall usability of the feature. They are also implementing safeguards to minimize the spread of misinformation and ensure that summaries are presented in a neutral and objective manner. Ultimately, the goal is to make ChatGPT an even more valuable and informative tool for users seeking to understand the world around them.\n",
    "chinese_title": "ChatGPT脉搏",
    "chinese_summary": "好的，我已访问提供的URL上的文章 (https://openai.com/index/introducing-chatgpt-pulse/)。以下是摘要：\n\nChatGPT Pulse 是一项新功能，旨在通过在 ChatGPT 对话中直接提供对热门话题和突发新闻更动态和更具背景的理解，从而增强用户体验。它旨在弥合 ChatGPT 作为语言模型的核心能力与不断发展的信息环境之间的差距。\n\nChatGPT Pulse 的主要优势在于它能够检测和总结正在兴起的热门话题。这使用户能够随时了解时事并访问相关信息，而无需离开他们的 ChatGPT 对话。它的工作原理是识别迅速受到关注的关键词和短语，然后将这些信息综合成简洁而翔实的摘要。\n\n用户可以通过询问关于热门话题的常规问题，或者仅仅通过观察 Pulse 何时主动在对话中标记潜在的相关信息来与 Pulse 互动。该功能的设计尽可能地减少干扰，仅在检测到与当前讨论相关的重大趋势时才提供摘要。\n\nOpenAI 强调 ChatGPT Pulse 仍在开发中，并将不断改进。他们正在积极寻求用户反馈，以提高该功能的准确性、相关性和整体可用性。他们还在实施保障措施，以尽量减少错误信息的传播，并确保以中立和客观的方式呈现摘要。最终，目标是使 ChatGPT 成为对寻求了解周围世界的用户来说更有价值和信息丰富的工具。"
  },
  {
    "id": "45381010",
    "title": "Investigating a Forged PDF",
    "url": "https://mjg59.dreamwidth.org/73317.html",
    "summary": "This short article, titled \"Investigating a Forged PDF,\" presents a CAPTCHA check. The purpose of the CAPTCHA is to validate user requests, implying the document or the process it's related to is attempting to prevent automated bot activity. The user has been \"semi-randomly\" selected for this validation, meaning the system is not applying the CAPTCHA to every request, but rather using a selective method. Ultimately, the article describes a security measure likely implemented within a potentially fraudulent PDF document or associated process. The document is attempting to confirm the user is human before allowing them to proceed. The title suggests a deeper investigation into the PDF's authenticity or malicious intent might be warranted.\n",
    "chinese_title": "调查伪造的PDF",
    "chinese_summary": "调查伪造的PDF：验证码检查"
  },
  {
    "id": "45373081",
    "title": "Cloudflare Email Service: private beta",
    "url": "https://blog.cloudflare.com/email-service/",
    "summary": "Cloudflare is launching a private beta of its new Cloudflare Email Service, a unified developer experience for sending and receiving transactional emails directly from Cloudflare Workers. This service combines the existing Email Routing product with a new Email Sending capability, aiming to simplify email management for developers.\n\nThe key benefits include:\n\n*   **Simplified Email Sending:** Developers can send emails directly from Workers with a simple binding, eliminating the need to manage API keys and secrets.\n*   **Improved Deliverability:** Tight integration with DNS ensures proper configuration of SPF, DKIM, and DMARC records for domain verification and improved deliverability, plus global delivery for low latency.\n*   **Developer-Friendly Workflow:** Emulation for local testing, clear observability over emails with bounce rates and delivery events, and support for existing email frameworks like React Email.\n*   **End-to-End Solution:** Combining Email Sending with Email Routing allows for powerful workflows like parsing incoming emails with Workers AI, creating support tickets, and processing invoices, all within Cloudflare.\n*   **Future Potential:** Email Service will be essential for the next generation of AI agents, background tasks, and automated workflows.\n\nEmail Sending will require a paid Workers subscription. Email Routing remains free and will be integrated into the new email sending APIs. The private beta is scheduled to launch in November. Interested parties can sign up for the waitlist.\n",
    "chinese_title": "Cloudflare 邮件服务：私有测试版",
    "chinese_summary": "Cloudflare即将推出新的Cloudflare邮件服务私有测试版，这是一个统一的开发者体验，用于直接从Cloudflare Workers发送和接收事务性邮件。此服务结合了现有的邮件路由产品和新的邮件发送功能，旨在简化开发者的邮件管理。\n\n主要优势包括：\n\n*   **简化邮件发送：** 开发者可以通过简单的绑定直接从Workers发送邮件，无需管理API密钥和凭据。\n*   **提高送达率：** 与DNS的紧密集成确保正确配置SPF、DKIM和DMARC记录，以进行域名验证并提高送达率，加上全球交付以实现低延迟。\n*   **开发者友好的工作流程：** 本地测试的模拟、对邮件清晰的可观测性（包括退信率和送达事件），以及对现有邮件框架（如React Email）的支持。\n*   **端到端解决方案：** 将邮件发送与邮件路由相结合，可以实现强大的工作流程，例如使用Workers AI解析接收到的邮件、创建支持工单和处理发票，所有这些都在Cloudflare内部完成。\n*   **未来潜力：** 邮件服务对于下一代AI代理、后台任务和自动化工作流程至关重要。\n\n邮件发送将需要付费的Workers订阅。邮件路由仍然免费，并将集成到新的邮件发送API中。私有测试版计划于11月推出。有兴趣者可以注册候补名单。"
  },
  {
    "id": "45387796",
    "title": "Flagship mobile phone with hardware kill switches for privacy",
    "url": "https://news.itsfoss.com/murena-powered-hiroh-phone/",
    "summary": "The article announces the HIROH Phone, a new privacy-focused flagship smartphone resulting from a collaboration between Murena and HIROH. It boasts hardware kill switches that physically disconnect the cameras and microphones, and a software kill switch to disable wireless communications. The phone runs Murena's /e/OS, a de-Googled operating system, providing a Google-free experience while still allowing users to install mainstream apps.\n\nThe HIROH Phone features flagship-level specifications, including a MediaTek Dimensity 8300 SoC, 16 GB of RAM, and 512 GB of storage. Other specifications include a 6.67\" AMOLED display with Gorilla Glass Victus, a 108MP main camera, 32MP front camera, and a 5,000 mAh battery with 33W fast charging. It supports 5G, Wi-Fi 6E, Bluetooth 5.3, USB Type-C, and NFC.\n\nThe HIROH Phone (Powered by Murena) is currently available for pre-sale with a €/$ 99 deposit, securing a discounted purchase price of €/$ 999 (from a retail price of €/$ 1,199). Shipping is expected in January or February 2026 to countries where Murena products are sold. The first 500 buyers can acquire a Limited Edition Platinum Model. The article also mentions the Murena Fairphone 6 (Gen. 6) as another device focused on ethical hardware and a de-Googled OS.\n",
    "chinese_title": "具备硬件开关以保护隐私的旗舰手机",
    "chinese_summary": "文章宣布推出HIROH手机，这是一款全新的注重隐私的旗舰智能手机，由Murena和HIROH合作开发。它配备了可物理断开摄像头和麦克风的硬件禁用开关，以及可禁用无线通信的软件禁用开关。该手机运行Murena的/e/OS，这是一个去谷歌化的操作系统，提供无谷歌体验，同时仍然允许用户安装主流应用程序。\n\nHIROH手机具有旗舰级的规格，包括联发科天玑8300 SoC、16 GB的RAM和512 GB的存储空间。其他规格包括带有康宁大猩猩玻璃Victus的6.67英寸AMOLED显示屏、108MP主摄像头、32MP前置摄像头以及具有33W快速充电的5,000 mAh电池。它支持5G、Wi-Fi 6E、蓝牙5.3、USB Type-C和NFC。\n\nHIROH手机（由Murena提供支持）目前正在预售，需支付99欧/美元的押金，以确保以折扣价999欧/美元购买（零售价为1,199欧/美元）。预计将于2026年1月或2月运往Murena产品销售的国家。前500名购买者可以获得限量版铂金型号。文章还提到了Murena Fairphone 6 (Gen. 6)，这是另一款专注于道德硬件和去谷歌化操作系统的设备。"
  },
  {
    "id": "45377641",
    "title": "Ollama Web Search",
    "url": "https://ollama.com/blog/web-search",
    "summary": "This article announces the availability of a new web search API in Ollama, released on September 24, 2025. This feature allows models to access real-time information, reducing hallucinations and improving accuracy. Ollama offers a free tier for individual users, with paid subscriptions for higher rate limits.\n\nThe web search is accessible through a REST API and is integrated into Ollama's Python and JavaScript libraries. The article provides code examples for using the API with cURL, Python, and JavaScript, demonstrating how to search for information on the web.\n\nFurthermore, the article details how to build a mini search agent using Ollama's web search and web fetch capabilities, exemplified with Alibaba's Qwen3 model. It highlights two engine updates: enhanced model scheduling (September 23, 2025), improving memory management and GPU utilization, and a multimodal engine (May 15, 2025) adding vision support. The web_fetch API is also explained, including code snippets in Python, Javascript and cURL.\n\nFinally, it discusses integrations with tools like MCP Server, Cline, Codex, and Goose, and instructs users to sign up for an Ollama account to get started. The article emphasizes that full context lengths (~32000 tokens) are recommended for optimal performance with search agents.\n",
    "chinese_title": "Ollama 网页搜索",
    "chinese_summary": "Ollama 新增网络搜索 API，于 2025 年 9 月 24 日发布。此功能使模型能够访问实时信息，减少幻觉并提高准确性。Ollama 为个人用户提供免费层级，付费订阅可获得更高的速率限制。\n\n网络搜索可通过 REST API 访问，并已集成到 Ollama 的 Python 和 JavaScript 库中。文章提供了使用 cURL、Python 和 JavaScript 调用 API 的代码示例，演示了如何搜索网络信息。\n\n此外，文章还详细介绍了如何使用 Ollama 的网络搜索和网页抓取功能构建迷你搜索代理，并以阿里巴巴的 Qwen3 模型为例。文章重点介绍了两个引擎更新：增强的模型调度（2025 年 9 月 23 日），提高了内存管理和 GPU 利用率，以及多模态引擎（2025 年 5 月 15 日），增加了视觉支持。文章还解释了 web_fetch API，包括 Python、JavaScript 和 cURL 中的代码片段。\n\n最后，文章讨论了与 MCP Server、Cline、Codex 和 Goose 等工具的集成，并指导用户注册 Ollama 帐户以开始使用。文章强调，建议使用完整上下文长度（约 32000 个 token）以获得搜索代理的最佳性能。"
  },
  {
    "id": "45376605",
    "title": "Athlon 64: How AMD turned the tables on Intel",
    "url": "https://dfarq.homeip.net/athlon-64-how-amd-turned-the-tables-on-intel/",
    "summary": "In a retrospective piece written in 2025, Dave Farquhar revisits AMD's pivotal Athlon 64 CPU launch in 2003, highlighting how it revolutionized the x86 architecture and forced Intel's hand.\n\nIntel, burdened by legacy x86 architecture and pursuing its own 64-bit architecture (Itanium), was hesitant to extend x86 to 64 bits, envisioning a fresh start and potential monopoly. However, AMD, facing potential obsolescence if Itanium succeeded, took a gamble by creating a 64-bit CPU backward compatible with 32-bit x86 software.\n\nThe Athlon 64 proved a hit because it allowed for a seamless transition to 64-bit computing while maintaining excellent 32-bit performance. Its superior performance and lower power consumption compared to Intel chips made it attractive, even to companies like Dell initially resistant to using AMD processors.\n\nUltimately, the Athlon 64's success led Intel to abandon Itanium and clone AMD's 64-bit implementation, named Intel64. This marked a turning point, establishing AMD as a true innovator and competitor in the CPU market, setting the stage for the ongoing back-and-forth competition between the two companies. The Athlon 64 moment showed how AMD innovated and changed the market.\n",
    "chinese_title": "速龙64：AMD如何扭转乾坤击败英特尔",
    "chinese_summary": "在2025年的一篇回顾性文章中，戴夫·法夸尔回顾了AMD在2003年发布的具有关键意义的速龙64 CPU，重点介绍了它如何革新了x86架构并迫使英特尔采取行动。\n\n英特尔受困于传统的x86架构，并追求其自身的64位架构（安腾），因此不愿将x86扩展到64位，而是设想一个全新的开始和潜在的垄断。然而，如果安腾成功，AMD面临被淘汰的风险，因此冒险创建了一款与32位x86软件向后兼容的64位CPU。\n\n速龙64证明非常成功，因为它允许无缝过渡到64位计算，同时保持了出色的32位性能。与英特尔芯片相比，其卓越的性能和更低的功耗使其具有吸引力，甚至对最初抵制使用AMD处理器的戴尔等公司也是如此。\n\n最终，速龙64的成功导致英特尔放弃了安腾，并克隆了AMD的64位实现，命名为Intel64。这标志着一个转折点，确立了AMD作为CPU市场中真正的创新者和竞争者的地位，为两家公司之间持续的拉锯战奠定了基础。速龙64时刻表明了AMD如何创新并改变了市场。"
  },
  {
    "id": "45336775",
    "title": "Pairing with Claude Code to rebuild my startup's website",
    "url": "https://blog.nseldeib.com/p/pairing-with-claude-code-to-rebuild",
    "summary": "Nadia Eldeib, a non-engineer founder, details her experience rebuilding her startup's website using Claude Code and an MCP server, showcasing the potential of AI-assisted development. Despite challenges like inconsistent response quality and occasional missteps from Claude, she successfully implemented new designs with high fidelity without needing extensive coding knowledge or hiring additional developers.\n\nHer workflow mimicked standard software development practices, including branching, pull requests, code reviews (with Claude acting as a CTO), testing, and deployment. She highlighted specific issues encountered, such as spammy, unused hashed files generated by the Figma Dev Mode MCP server, Claude stopping mid-task, and Claude heading in the wrong direction, and how she addressed them. Strategies included deleting unused files, renaming files with semantic names, using \"go on\" prompts when Claude stalled, rolling back to previous working versions, and utilizing GitHub Copilot for error details.\n\nNadia emphasizes the importance of frequent commits and PRs for managing Claude's actions and enabling rollbacks. She concludes that using Claude was a powerful and transformative experience, but requires careful oversight and sanity-checking to prevent errors. She notes that AI shines in accelerating execution while humans are critical for setting direction, ensuring code quality, and addressing complex architectural considerations. Nadia also underscores the importance of human review and validation, especially before deploying changes to production code.\n",
    "chinese_title": "与 Claude Code 合作重构我的创业公司网站",
    "chinese_summary": "非工程师创始人 Nadia Eldeib 详述了她使用 Claude Code 和 MCP 服务器重建初创公司网站的经验，展示了 AI 辅助开发的潜力。尽管面临诸如响应质量不稳定和 Claude 偶尔出错等挑战，她还是成功地以高保真度实现了新的设计，而无需大量的编码知识或雇用额外的开发人员。\n\n她的工作流程模仿了标准的软件开发实践，包括分支、拉取请求、代码审查（Claude 扮演首席技术官的角色）、测试和部署。她重点介绍了遇到的具体问题，例如 Figma Dev Mode MCP 服务器生成的垃圾、未使用的哈希文件，Claude 中途停止任务，以及 Claude 朝错误的方向前进，以及她如何解决这些问题。策略包括删除未使用的文件、使用语义名称重命名文件、在 Claude 停止时使用“继续”提示、回滚到以前的工作版本，以及利用 GitHub Copilot 获取错误详情。\n\nNadia 强调了频繁提交和 PR 对于管理 Claude 的操作和启用回滚的重要性。她总结说，使用 Claude 是一次强大而具有变革意义的体验，但需要仔细的监督和理智检查以防止错误。她指出，AI 在加速执行方面表现出色，而人类对于设定方向、确保代码质量和解决复杂的架构问题至关重要。Nadia 还强调了人工审查和验证的重要性，尤其是在将更改部署到生产代码之前。"
  },
  {
    "id": "45380699",
    "title": "Redis is fast – I'll cache in Postgres",
    "url": "https://dizzy.zone/2025/09/24/Redis-is-fast-Ill-cache-in-Postgres/",
    "summary": "This article compares Redis and Postgres for caching, specifically in the context of a simple HTTP server. The author ran benchmarks on a Kubernetes cluster, limiting both Redis and Postgres to 2 CPUs and 8GiB of memory. The experiment involved seeding both caches with 30 million entries and then running GET, SET, and mixed workloads using `k6` to measure requests per second, latency, CPU, and memory usage.\n\nThe results consistently showed that Redis outperformed Postgres in terms of requests per second and latency across all workloads. Redis was often bottlenecked by the HTTP server's CPU, while Postgres was consistently bottlenecked by its own CPU. The use of unlogged tables in Postgres significantly improved write performance compared to standard tables due to skipping the write-ahead log.\n\nDespite Redis's superior performance, the author concludes that Postgres is still a viable option for caching, particularly when a database is already required for the project. The convenience of avoiding an additional dependency outweighs the performance difference in many cases. The author also notes that Postgres achieved a substantial 7425 requests per second, which is sufficient for many projects. The article advocates for using an interface for the cache, allowing for easy switching between Redis and Postgres as needed.\n",
    "chinese_title": "Redis很快——我会在Postgres中做缓存。",
    "chinese_summary": "本文比较了Redis和Postgres用于缓存的性能，具体场景为一个简单的HTTP服务器。作者在Kubernetes集群上进行了基准测试，将Redis和Postgres都限制为2个CPU和8GiB内存。实验包括用3000万条条目填充两个缓存，然后使用`k6`运行GET、SET和混合工作负载，以测量每秒请求数、延迟、CPU和内存使用率。\n\n结果始终表明，在所有工作负载中，Redis在每秒请求数和延迟方面都优于Postgres。Redis通常受HTTP服务器CPU的瓶颈限制，而Postgres则始终受自身CPU的瓶颈限制。由于跳过了预写日志，在Postgres中使用未记录表显著提高了写入性能，相比于标准表。\n\n尽管Redis的性能更优越，但作者得出结论，Postgres仍然是缓存的可行选择，尤其是在项目已经需要数据库的情况下。避免额外依赖的便利性在许多情况下超过了性能差异。作者还指出，Postgres达到了可观的每秒7425个请求，这对于许多项目来说已经足够了。文章提倡使用缓存接口，以便根据需要轻松切换Redis和Postgres。"
  },
  {
    "id": "45352633",
    "title": "A history of ARM, part 1: Building the first chip (2022)",
    "url": "https://arstechnica.com/gadgets/2022/09/a-history-of-arm-part-1-building-the-first-chip/",
    "summary": "In 1983, Acorn Computers, riding high on the success of the BBC Micro, faced increasing competition. Sophie Wilson and Steve Furber sought a more powerful CPU to compete with IBM and Apple, but were dissatisfied with existing options like Intel's 80286 and Motorola's 68000. The prospect of creating their own CPU seemed daunting until a visit to the Western Design Center inspired them.\n\nAcorn management, particularly Hermann Hauser, supported their endeavor and introduced them to RISC (reduced instruction set computing). RISC simplifies the CPU design by reducing the number of instructions, enabling faster clock speeds and pipelining. Wilson's design used a \"load and store\" architecture and a three-stage pipeline. While requiring more instructions overall, RISC's simplicity allowed for faster execution and efficient pipelining. This approach contrasted with complex CPUs like the Intel 80286, which had a vast instruction set.\n\nThe development of the ARM (Acorn RISC Machine) took 18 months. Furber focused on chip layout, while Wilson designed the instruction set. An emulator written in BASIC helped validate the design. The ARM V1, with only 27,000 transistors, outperformed competitors in benchmarks, exceeding Intel and Motorola chips.\n\nRemarkably, the first ARM chip worked on its first attempt, a testament to the team's dedication and design simplicity. Its low power consumption (0.1 watts), a result of conservative design to avoid overheating, was an unexpected but significant advantage. However, the company faced challenges, and BBC Micro sales declined due to cheaper computers and the rise of PCs, but the ARM chip was a feat of engineering with impact for decades to come.\n",
    "chinese_title": "ARM历史，第一部分：构建首个芯片 (2022)",
    "chinese_summary": "1983年，在BBC Micro大获成功的背景下，Acorn电脑公司面临日益激烈的竞争。为了与IBM和苹果竞争，Sophie Wilson和Steve Furber寻求更强大的CPU，但对英特尔的80286和摩托罗拉的68000等现有选择并不满意。在参观了西部设计中心之后，他们开始考虑自行创建CPU，尽管这一想法看似令人望而却步。\n\nAcorn管理层，特别是Hermann Hauser，支持他们的努力，并向他们介绍了RISC（精简指令集计算）。RISC通过减少指令数量来简化CPU设计，从而实现更快的时钟速度和流水线操作。Wilson的设计采用了“加载和存储”架构以及三级流水线。虽然总体上需要更多的指令，但RISC的简单性允许更快的执行和高效的流水线操作。这种方法与拥有庞大指令集的英特尔80286等复杂CPU形成对比。\n\nARM（Acorn RISC Machine）的开发历时18个月。Furber专注于芯片布局，而Wilson设计了指令集。用BASIC编写的模拟器帮助验证了设计。ARM V1只有27,000个晶体管，但在基准测试中表现优于竞争对手，超过了英特尔和摩托罗拉的芯片。\n\n令人惊奇的是，第一块ARM芯片在第一次尝试时就成功了，这证明了团队的奉献精神和设计的简洁性。其低功耗（0.1瓦），是为避免过热而采取保守设计的结果，这是一个意想不到但却意义重大的优势。然而，该公司面临挑战，由于更便宜的电脑和PC的兴起，BBC Micro的销量下降，但ARM芯片是一项工程壮举，其影响将持续数十年。"
  },
  {
    "id": "45345447",
    "title": "Road to ZK Implementation: Nethermind Client's Path to Proofs",
    "url": "https://www.nethermind.io/blog/road-to-zk-implementation-nethermind-clients-path-to-proofs",
    "summary": "This article, \"Road to ZK Implementation: Nethermind Client’s Path to Proofs,\" details Nethermind's progress in making its Ethereum execution client ZK-ready, essential for improving performance, modularity, and trustless verification in Ethereum-compatible chains and L2 sequencers.\n\nNethermind is systematically incorporating ZK capabilities by enabling its execution logic to compile into zkVMs (like Zisk, SP1, and RISC0) and generate proofs of execution. Completed milestones include execution witness capture (capturing all state accessed during block execution), stateless block replay using only the witness, creation of a minimal EVM binary, and RISC-V64 compilation. The RISC-V64 compilation involved overcoming challenges in .NET runtime, the C# compiler, and ensuring compatibility with musl and static binaries.\n\nThe next steps involve integrating with Zisk to generate the first succinct proofs of block execution. Following that, Nethermind plans to extend compatibility with RISC-V32 environments and integrate with popular zkVMs like RISC0 and SP1.\n\nNethermind emphasizes its proven reliability and performance in production, which it's extending into the zero-knowledge realm. The company aims to support a wide range of zkVMs to meet the evolving needs of sequencers and Ethereum-compatible chains. By adopting Nethermind, users can future-proof their infrastructure with ZK-ready capabilities.\n",
    "chinese_title": "通往ZK实现的道路：Nethermind客户端的证明之路",
    "chinese_summary": "通往ZK实现的道路：Nethermind客户端的证明之路\n\n本文详述了Nethermind在使其以太坊执行客户端具备ZK能力方面的进展，这对于提高以太坊兼容链和L2排序器的性能、模块化和无需信任的验证至关重要。\n\nNethermind正系统性地整合ZK能力，方法是使其执行逻辑编译成zkVM（如Zisk、SP1和RISC0），并生成执行证明。已完成的里程碑包括执行见证捕获（捕获区块执行期间访问的所有状态）、仅使用见证的无状态区块重放、创建最小EVM二进制文件以及RISC-V64编译。RISC-V64编译涉及克服.NET运行时、C#编译器中的挑战，并确保与musl和静态二进制文件的兼容性。\n\n下一步是与Zisk集成，以生成第一个简洁的区块执行证明。之后，Nethermind计划扩展与RISC-V32环境的兼容性，并与流行的zkVM（如RISC0和SP1）集成。\n\nNethermind强调其在生产中经过验证的可靠性和性能，并将其扩展到零知识领域。该公司旨在支持广泛的zkVM，以满足排序器和以太坊兼容链不断变化的需求。通过采用Nethermind，用户可以通过具备ZK能力的设施来面向未来。"
  },
  {
    "id": "45387154",
    "title": "JWST peers deep into the heart of star formation in our Milky Way galaxy",
    "url": "https://www.space.com/astronomy/james-webb-space-telescope/james-webb-space-telescope-peers-deep-into-the-heart-of-star-formation-in-our-milky-way-galaxy",
    "summary": "The James Webb Space Telescope (JWST) has captured detailed images of Sagittarius B2, a highly active star-forming region near the center of the Milky Way galaxy, using both its NIRCam and MIRI instruments. These observations reveal a vibrant landscape of star formation, characterized by dense molecular gas, cosmic dust, and newly born stars.\n\nSagittarius B2, despite containing only a fraction of the galactic center's molecular gas, produces a disproportionately large number of stars, making it an anomaly. The JWST's infrared capabilities allow it to penetrate the obscuring dust and provide unprecedented detail, helping scientists understand the factors that drive and inhibit star formation in this region.\n\nThe NIRCam images reveal stars amid hazy nebulosity, while the MIRI images penetrate deeper, showing extensive dusty nebulosity illuminated by young, massive stars. Researchers aim to use these observations to understand the history of star formation in Sagittarius B2 and compare it to the rest of the galactic center. This knowledge could shed light on why star formation is relatively sluggish at the heart of our galaxy.\n\nFurthermore, the study of Sagittarius B2's intense star formation could provide insights into the conditions of the early universe when the first stars formed, as the observed conditions are believed to be similar. Ultimately, the JWST's observations contribute to understanding the processes governing star formation both within our galaxy and on a cosmic scale.\n",
    "chinese_title": "韦伯望远镜深入观测银河系恒星形成核心区域",
    "chinese_summary": "詹姆斯·韦伯太空望远镜（JWST）利用其近红外相机（NIRCam）和中红外仪器（MIRI）捕捉到了人马座B2的详细图像，这是一个位于银河系中心附近的高度活跃的恒星形成区域。这些观测揭示了一个充满活力的恒星形成景观，其特征是密集的分子气体、宇宙尘埃和新生的恒星。\n\n人马座B2虽然仅包含银河系中心分子气体的一小部分，但产生的恒星数量却不成比例地多，这使其成为一个特例。 JWST的红外能力使其能够穿透遮蔽的尘埃并提供前所未有的细节，从而帮助科学家了解驱动和抑制该区域恒星形成的因素。\n\n近红外相机（NIRCam）图像揭示了朦胧星云中的恒星，而中红外仪器（MIRI）图像则穿透得更深，显示了由年轻、大质量恒星照亮的大量尘埃星云。研究人员旨在利用这些观测来了解人马座B2的恒星形成历史，并将其与银河系中心的其余部分进行比较。这些知识可能有助于阐明为什么在我们星系的中心恒星形成相对缓慢。\n\n此外，对人马座B2强烈恒星形成的研究可以深入了解早期宇宙中第一批恒星形成时的条件，因为观察到的条件被认为与之相似。 最终，JWST的观测有助于理解控制银河系内部和宇宙尺度上恒星形成的过程。"
  },
  {
    "id": "45387528",
    "title": "Today is Stanislav Petrov day",
    "url": "https://en.wikipedia.org/wiki/1983_Soviet_nuclear_false_alarm_incident",
    "summary": "This Wikipedia article commemorates Stanislav Petrov Day, referencing the incident on September 26, 1983, when Soviet Lieutenant Colonel Stanislav Petrov, on duty at the Serpukhov-15 bunker, prevented a potential nuclear war. The Soviet early warning system Oko reported a missile attack from the United States, indicating the launch of five intercontinental ballistic missiles. Petrov, suspecting a false alarm due to the relatively small number of missiles reported and the system's questionable reliability, defied protocol and did not immediately relay the information up the chain of command.\n\nHis suspicion proved correct, as the alarm was later determined to be caused by a rare alignment of sunlight on high-altitude clouds impacting the satellites. Had Petrov followed protocol, the Soviet Union might have launched a retaliatory nuclear strike based on faulty data, leading to a full-scale nuclear war.\n\nThe incident occurred during a period of heightened tension between the U.S. and the Soviet Union, with the deployment of Pershing II missiles in Europe and the execution of Operation RYaN, reflecting Soviet fears of a surprise American attack. Despite initially being praised, Petrov was later reprimanded for paperwork errors and received no reward, allegedly due to the embarrassment the incident caused his superiors and the scientists responsible for the flawed system. His actions, however, are widely credited with averting a global catastrophe.\n",
    "chinese_title": "今天是斯坦尼斯拉夫·彼得罗夫日。",
    "chinese_summary": "本维基百科条目纪念斯坦尼斯拉夫·彼得罗夫日，并提及1983年9月26日发生的事件：苏联中校斯坦尼斯拉夫·彼得罗夫在谢尔普霍夫-15号地堡值班时，阻止了一场潜在的核战争。当时，苏联的早期预警系统“奥科”报告称，美国发起了导弹袭击，显示有五枚洲际弹道导弹发射。彼得罗夫怀疑是误报，因为报告的导弹数量相对较少，且系统可靠性存疑，因此他违抗了协议，没有立即将信息向上级汇报。\n\n事实证明他的怀疑是正确的，警报后来被确定是由阳光在高空云层上的罕见排列影响卫星造成的。如果彼得罗夫遵循协议，苏联可能会基于错误的数据发动核报复打击，从而导致全面核战争。\n\n该事件发生在美国和苏联之间关系高度紧张时期，欧洲部署了潘兴II导弹，并实施了RYaN行动，反映了苏联对美国突然袭击的担忧。彼得罗夫最初受到赞扬，但后来因文书错误而受到训斥，并没有得到任何奖励，据称是因为该事件让他的上级和负责该 flawed 系统的科学家感到尴尬。然而，他的行动被广泛认为避免了一场全球性灾难。"
  },
  {
    "id": "45346538",
    "title": "Cosmic simulations that once needed supercomputers now run on a laptop",
    "url": "https://www.sciencedaily.com/releases/2025/09/250918225001.htm",
    "summary": "Astronomers can now run complex cosmic simulations that once required supercomputers on a standard laptop, thanks to a new tool called Effort.jl. This emulator mimics the behavior of complex cosmological models like EFTofLSS, delivering accurate results, sometimes with finer detail, in minutes rather than the extensive time and resources demanded by the original models.\n\nEffort.jl leverages neural networks and incorporates existing physical knowledge to drastically reduce computation time without sacrificing reliability. It learns from the model's outputs and generalizes to new parameter combinations, effectively anticipating the model's output for new inputs. The emulator's design incorporates pre-existing knowledge of parameter change effects, further reducing the need for extensive training.\n\nValidation has shown that Effort.jl's accuracy aligns closely with the original models, both on simulated and real data, proving its reliability as a shortcut. It can even include previously trimmed analysis sections, increasing its usefulness.\n\nThe development of Effort.jl is crucial for analyzing the exponentially growing astronomical datasets from current and upcoming surveys like DESI and Euclid, which promise to deepen our understanding of the Universe's large-scale structure.\n",
    "chinese_title": "曾经需要超级计算机才能运行的宇宙模拟，现在笔记本电脑就能运行了。",
    "chinese_summary": "借助名为Effort.jl的新工具，天文学家现在可以在标准笔记本电脑上运行过去需要超级计算机才能完成的复杂宇宙模拟。该模拟器模仿了EFTofLSS等复杂宇宙学模型的行为，能够在几分钟内提供准确的结果，有时甚至具有更精细的细节，而原始模型则需要大量的时间和资源。\n\nEffort.jl利用神经网络并结合现有的物理知识，在不牺牲可靠性的前提下，大幅缩短了计算时间。它从模型的输出中学习并推广到新的参数组合，从而有效地预测模型对新输入的输出。该模拟器的设计融入了对参数变化影响的预先知识，进一步减少了对大量训练的需求。\n\n验证表明，Effort.jl的准确性与原始模型非常吻合，无论是在模拟数据还是真实数据上，都证明了其作为捷径的可靠性。它甚至可以包含先前修剪的分析部分，从而提高了其效用。\n\nEffort.jl的开发对于分析来自当前和未来巡天（如DESI和Euclid）呈指数增长的天文数据集至关重要，这些巡天有望加深我们对宇宙大尺度结构的理解。"
  },
  {
    "id": "45381631",
    "title": "Bit is all we need: binary normalized neural networks",
    "url": "https://arxiv.org/abs/2509.07025",
    "summary": "This arXiv paper, titled \"1 bit is all we need: binary normalized neural networks,\" introduces a novel approach to significantly reduce the memory footprint of large neural network models, particularly for language and image tasks. The authors, Eduardo Lobo Lustoda Cabral, Paulo Pirozelli, and Larissa Driemeier, propose \"binary normalized layers\" where all parameters (kernel weights and biases) are constrained to be either 0 or 1. These layers can be implemented in various neural network architectures, including fully connected, convolutional, and attention-based layers.\n\nThe paper demonstrates the effectiveness of this approach by configuring models with binary normalized layers for multiclass image classification and language decoding (next token prediction). The results show that these binary models achieve performance comparable to their 32-bit counterparts, while requiring 32 times less memory.\n\nThe authors highlight that binary normalized layers are easily implementable using 1-bit arrays on existing hardware, without needing specialized hardware. This advancement promises to enable the deployment of large neural networks on resource-constrained devices like mobile phones or CPUs, opening new possibilities for broader accessibility and utilization of these powerful models. The paper includes detailed information, with 14 pages, 2 figures, 5 tables, and 8 algorithms.\n",
    "chinese_title": "比特即所需：二元归一化神经网络",
    "chinese_summary": "这篇arXiv论文，题为“1 bit is all we need: 二元归一化神经网络”，提出了一种大幅减少大型神经网络模型内存占用的新方法，尤其适用于语言和图像任务。作者Eduardo Lobo Lustoda Cabral、Paulo Pirozelli和Larissa Driemeier提出了“二元归一化层”，其中所有参数（内核权重和偏置）都被限制为0或1。这些层可以在各种神经网络架构中实现，包括全连接层、卷积层和基于注意力的层。\n\n该论文通过配置具有二元归一化层的模型来进行多类图像分类和语言解码（下一个token预测），证明了这种方法的有效性。结果表明，这些二元模型实现了与其32位模型相当的性能，同时所需内存减少了32倍。\n\n作者强调，二元归一化层可以使用现有的硬件上的1位数组轻松实现，而无需专门的硬件。这一进步有望在移动电话或CPU等资源受限的设备上部署大型神经网络，为更广泛地访问和利用这些强大的模型开辟了新的可能性。该论文包含详细信息，共14页，包含2个图、5个表和8个算法。"
  },
  {
    "id": "45353986",
    "title": "Walking around the compiler",
    "url": "https://bernsteinbear.com/blog/walking-around/",
    "summary": "Max Bernstein's \"Walking around the compiler\" advocates for developers to actively explore and understand the output of their software projects, especially compilers and other data transformation tools, rather than solely focusing on the code itself. He draws a parallel to Vicki Boykis's concept of \"walking around the app,\" extending it to encompass the generated code, IR, or other outputs that reflect the compiler's behavior.\n\nThe article emphasizes the value of inspecting these outputs for unexpected patterns, inefficiencies, or bugs that might not be apparent from the code alone. He provides an example of a peephole optimization opportunity in PyPy IR that was discovered by manually inspecting the IR and then turned into a test case.\n\nBernstein highlights the importance of accessible and user-friendly tools for exploration, citing Matthew Godbolt's Compiler Explorer as a prime example. He argues that such tools lower the barrier to entry, facilitate rapid feedback, and foster mechanical sympathy – a deep understanding of how the compiler works. He also laments the lack of comparable tools for terminal or editor environments.\n\nFinally, he advises developers to examine the optimized IR of frequently used functions in their applications, suggesting that regular inspection can reveal hidden issues or opportunities for improvement, even if the compiler itself is functioning correctly. He concludes by stressing the importance of investing in tooling to enhance understanding and improve developer experience, drawing a parallel to Boykis's emphasis on loving your tools.\n",
    "chinese_title": "漫游编译器",
    "chinese_summary": "Max Bernstein 的《漫步编译器》提倡开发者积极探索和理解软件项目（特别是编译器和其他数据转换工具）的输出结果，而不是仅仅关注代码本身。他将此与 Vicki Boykis 的“漫步应用”概念进行类比，并将其扩展到包含生成的代码、IR 或其他反映编译器行为的输出。\n\n文章强调了检查这些输出的价值，以便发现仅从代码中可能无法察觉的意外模式、低效率或错误。他提供了一个通过手动检查 PyPy IR 发现的窥孔优化机会的例子，并将其转化为测试用例。\n\nBernstein 强调了易于访问和用户友好的探索工具的重要性，并以 Matthew Godbolt 的 Compiler Explorer 为例。他认为，此类工具降低了入门门槛，促进了快速反馈，并培养了机械共情——对编译器工作原理的深刻理解。他还感叹缺乏用于终端或编辑器环境的类似工具。\n\n最后，他建议开发者检查应用程序中常用函数的优化 IR，表明即使编译器本身运行正常，定期检查也可以揭示隐藏的问题或改进机会。他最后强调了投资工具以增强理解和改善开发者体验的重要性，并将其与 Boykis 强调热爱你的工具相提并论。"
  },
  {
    "id": "45384617",
    "title": "Show HN: A little notebook for learning linear algebra with Python",
    "url": "https://little-book-of.github.io/linear-algebra/books/en-US/lab.html",
    "summary": "This \"Show HN\" post presents a collection of interactive Python notebooks designed to teach linear algebra concepts using NumPy and Matplotlib. The first chapter, \"Vectors, scalars, and geometry,\" covers fundamental building blocks: scalars (plain numbers) and vectors (lists of numbers represented as arrows). It demonstrates how to define and manipulate scalars and vectors using NumPy, and how to visualize vectors as arrows using Matplotlib.\n\nThe notebooks delve into vector notation, components, and arrow representation, emphasizing accessing individual components and visualizing multiple vectors simultaneously. It explores vector addition and scalar multiplication, illustrating the tip-to-tail method for addition and the stretching/shrinking effect of scalar multiplication. The notebooks further explain linear combinations, which are created by combining vector addition and scalar multiplication, and introduces the concept of span, showing what region of space can be reached with linear combinations.\n\nThe notebooks also explain how to calculate the length (norm) of a vector using the Pythagorean theorem and NumPy, and the distance between two vectors. The final section introduces the dot product, demonstrating its algebraic and geometric definitions, its relation to the angle between vectors, and its use in computing projections. Throughout, the content provides step-by-step code walkthroughs with examples, interactive exercises (\"Try It Yourself\"), and visual representations to facilitate understanding and build intuition.\n",
    "chinese_title": "Show HN: 用Python学习线性代数的小笔记本",
    "chinese_summary": "此“Show HN”帖子展示了一系列交互式Python笔记本，旨在使用NumPy和Matplotlib教授线性代数概念。第一章“向量、标量和几何”涵盖了基本构建块：标量（普通数字）和向量（表示为箭头的数字列表）。它演示了如何使用NumPy定义和操作标量和向量，以及如何使用Matplotlib将向量可视化为箭头。\n\n这些笔记本深入探讨了向量表示法、分量和箭头表示，强调访问各个分量和同时可视化多个向量。它探讨了向量加法和标量乘法，用图示说明了加法的首尾相接法以及标量乘法的拉伸/收缩效果。这些笔记本还进一步解释了线性组合，线性组合是通过结合向量加法和标量乘法创建的，并介绍了张成的概念，展示了可以使用线性组合到达的空间区域。\n\n这些笔记本还解释了如何使用勾股定理和NumPy计算向量的长度（范数）以及两个向量之间的距离。最后一部分介绍了点积，展示了它的代数和几何定义、它与向量之间角度的关系以及它在计算投影中的应用。始终贯穿其中的内容都提供了带有示例的逐步代码演练、交互式练习（“自己尝试”）和可视化表示，以帮助理解和建立直觉。"
  },
  {
    "id": "45350736",
    "title": "A story about hunting zombie tasks in a distributed environment",
    "url": "https://getbruin.com/blog/zombie-tasks/",
    "summary": "This article, published on January 22, 2024, focuses on the technical process of exporting Firebase data to BigQuery. The key takeaway is that moving Firebase data to BigQuery enables users to leverage that data more effectively. While the article itself is described only by its title and this initial sentence, we can infer that it will likely cover the steps and considerations involved in the export process. The piece likely details a method or methods for extracting data from Firebase and loading it into BigQuery, possibly including:\n\n*   **Configuration steps:** Setting up the necessary integrations between Firebase and BigQuery.\n*   **Data schema considerations:** How Firebase data structures are mapped or transformed for BigQuery.\n*   **Data export methods:** Options like scheduled exports or real-time streaming.\n*   **Potential use cases:** Examples of how analyzing Firebase data in BigQuery can be beneficial.\n*   **Troubleshooting tips:** Addressing common challenges encountered during the export process.\n\nEssentially, the article aims to guide users through a practical guide on integrating Firebase and BigQuery for enhanced data analysis.\n",
    "chinese_title": "分布式环境下猎杀僵尸任务的故事",
    "chinese_summary": "本文发表于2024年1月22日，重点介绍将Firebase数据导出到BigQuery的技术流程。主要内容是，将Firebase数据迁移到BigQuery能帮助用户更有效地利用这些数据。尽管本文仅通过标题和这句话进行描述，但我们可以推断，它很可能会涵盖导出过程所涉及的步骤和注意事项。文章可能详细介绍从Firebase提取数据并将其加载到BigQuery的一种或多种方法，可能包括：\n\n*   **配置步骤：** 设置Firebase和BigQuery之间必要的集成。\n*   **数据模式考虑：** Firebase数据结构如何映射或转换为BigQuery的数据结构。\n*   **数据导出方法：** 诸如计划导出或实时流式传输等选项。\n*   **潜在用例：** 在BigQuery中分析Firebase数据如何带来益处的示例。\n*   **故障排除技巧：** 解决导出过程中遇到的常见挑战。\n\n本质上，本文旨在指导用户完成将Firebase和BigQuery集成的实用指南，以增强数据分析。"
  },
  {
    "id": "45377748",
    "title": "Can a model trained on satellite data really find brambles on the ground?",
    "url": "https://toao.com/blog/can-we-really-see-brambles-from-space",
    "summary": "This article details a field test of a model developed by Gabriel Mahler to map brambles, a key habitat component for hedgehogs, using satellite data (TESSERA embeddings) and iNaturalist data. The model, an ensemble of logistic regression and a KNN classifier, was tested around Cambridge to see if it could accurately predict locations with high concentrations of brambles.\n\nThe test, conducted by Gabriel, Anil, Shane, and the author, involved using the model's predictions overlaid on a map to guide their search. They started at Milton Community Centre and then moved to Milton Country Park, finding significant amounts of bramble in areas the model predicted with high confidence. They observed the model was particularly good at identifying large, uncovered bramble patches, but less accurate for smaller brambles under partial cover, likely due to the limitations of remote sensing data.\n\nThe team continued their validation in a residential area, finding brambles in an empty plot and another large patch on Fen Road, as predicted. Finally, they visited Bramblefields, a local nature reserve appropriately named for its abundance of brambles, again confirming the model's accuracy. The author concluded the model performed surprisingly well for its simplicity. The team also considered the potential for a mobile phone-based active learning setup to improve the model further with real-time field data.\n",
    "chinese_title": "用卫星数据训练的模型真的能找到地面上的荆棘丛吗？",
    "chinese_summary": "本文详细介绍了 Gabriel Mahler 开发的模型的实地测试，该模型利用卫星数据（TESSERA 嵌入）和 iNaturalist 数据来绘制黑莓丛的分布图，黑莓丛是刺猬的关键栖息地组成部分。该模型是逻辑回归和 KNN 分类器的集成，在剑桥周边进行了测试，以验证其是否能准确预测黑莓丛高密度分布的地点。\n\n这项由 Gabriel、Anil、Shane 和作者进行的测试，使用了模型预测结果叠加在地图上的方式来指导搜索。他们从米尔顿社区中心出发，然后转移到米尔顿乡村公园，在模型高置信度预测的区域发现了大量的黑莓丛。他们观察到该模型尤其擅长识别大型、无遮盖的黑莓丛，但对于部分遮盖下的小型黑莓丛的识别准确度较低，这可能是由于遥感数据的局限性造成的。\n\n该团队继续在住宅区进行验证，如预测的那样，在一个空地上和芬路上的另一大片区域发现了黑莓丛。最后，他们参观了 Bramblefields，这是一个当地自然保护区，顾名思义，这里盛产黑莓丛，再次证实了模型的准确性。作者得出结论，该模型以其简单性而言表现出乎意料地好。该团队还考虑了基于手机的主动学习设置的潜力，以利用实时现场数据进一步改进该模型。"
  },
  {
    "id": "45372113",
    "title": "Resurrect the Old Web",
    "url": "https://stevedylandev.bearblog.dev/resurrect-the-old-web/",
    "summary": "This article advocates for a return to the \"old web\" of blogs and RSS feeds as a way to escape the addictive and often unsatisfying nature of modern social media. Inspired by a news story about middle schoolers using landline phones for connection, the author argues that the early days of the internet were more fulfilling because they focused on genuine human connection rather than algorithms and ads.\n\nThe author proposes using personal blogs and RSS feeds to create a more intimate and controlled online experience. They emphasize that a \"blog\" can be anything from serious writing to casual sharing of thoughts and interesting finds, similar to what one might share with friends. The core idea is connection and building a network through hyperlinks, reminiscent of old web rings.\n\nTo kickstart this movement, the author is launching a \"bear blog\" with a dedicated feeds page showcasing the blogs they are following. They encourage readers to create their own blogs, subscribe to RSS feeds, and link to other blogs they enjoy. The author also provides a list of blogs they are currently subscribed to and recommends RSS readers like Feeder.co and NetNewsWire. The author concludes that resurrecting the old web is a viable alternative to the \"social media dopamine machine\" and encourages collective effort in fostering a more authentic online community.\n",
    "chinese_title": "复兴旧网",
    "chinese_summary": "本文倡导回归博客和RSS订阅的“旧互联网”，以此摆脱现代社交媒体令人沉迷且常常令人不满的本质。受一则关于中学生使用固定电话进行连接的新闻报道启发，作者认为早期的互联网更加令人满足，因为它专注于真正的人际连接，而不是算法和广告。\n\n作者建议使用个人博客和RSS订阅来创建更亲密和可控的在线体验。他们强调，“博客”可以是严肃的写作，也可以是随意的思想和有趣发现的分享，类似于与朋友分享的内容。核心理念是通过超链接进行连接和构建网络，让人想起旧时的网站联盟。\n\n为了启动这场运动，作者正在创建一个“熊博客”，并附带一个专门的订阅页面，展示他们正在关注的博客。他们鼓励读者创建自己的博客，订阅RSS订阅源，并链接到他们喜欢的其他博客。作者还提供了他们目前订阅的博客列表，并推荐了像Feeder.co和NetNewsWire这样的RSS阅读器。作者最后总结说，复兴旧互联网是“社交媒体多巴胺机器”的可行替代方案，并鼓励大家共同努力，培养一个更真实的在线社区。"
  },
  {
    "id": "45387210",
    "title": "College student's \"time travel\" AI experiment",
    "url": "https://arstechnica.com/information-technology/2025/08/ai-built-from-1800s-texts-surprises-creator-by-mentioning-real-1834-london-protests/",
    "summary": "Hayk Grigorian, a computer science student, developed TimeCapsuleLLM, a small AI language model trained solely on Victorian-era (1800-1875) London texts. Surprisingly, when prompted with \"It was the year of our Lord 1834,\" the AI generated text referencing protests and Lord Palmerston, which Grigorian later verified as historically accurate events linked to the Poor Law Amendment Act of 1834.\n\nWhile AI language models synthesizing information isn't new, this instance is notable because a small, hobbyist-built model reconstructed a coherent historical moment without explicit training on the 1834 protests. It connected the year to relevant events and figures based on patterns within 6.25GB of Victorian-era writing.\n\nGrigorian uses \"Selective Temporal Training\" (STT) to avoid modern data contamination, training the model from scratch with over 7,000 period books, legal documents, and newspapers. His models have improved over time, with the latest version beginning to recall historical facts rather than hallucinating them.\n\nThis type of project, termed \"Historical Large Language Models\" (HLLMs), offers historians and digital humanities researchers opportunities to interact with linguistic patterns of the past. While not always factually accurate, they can be stylistically insightful. Grigorian plans to explore models for other cities and invites collaboration, making his code and models publicly available. The article concludes with the idea that the model's accurate historical reference is a refreshing \"factcident,\" the opposite of AI hallucination.\n",
    "chinese_title": "大学生的“穿越”AI实验",
    "chinese_summary": "计算机科学学生Hayk Grigorian开发了TimeCapsuleLLM，一个仅用维多利亚时代（1800-1875）伦敦文本训练的小型AI语言模型。令人惊讶的是，当提示“那是公元1834年”时，该AI生成的文本引用了抗议活动和帕麦斯顿勋爵，Grigorian后来证实这些都是与1834年《济贫法修正案》相关的历史事件。\n\n虽然AI语言模型综合信息并不新鲜，但这次的案例值得关注，因为一个小型、业余爱好者构建的模型在没有接受关于1834年抗议活动的明确训练的情况下，重建了一个连贯的历史时刻。它基于6.25GB维多利亚时代写作中的模式，将这一年份与相关事件和人物联系起来。\n\nGrigorian使用“选择性时间训练”(STT)来避免现代数据污染，用超过7000本时期的书籍、法律文件和报纸从头开始训练模型。他的模型随着时间的推移而有所改进，最新版本开始回忆历史事实，而不是产生幻觉。\n\n这类项目被称为“历史大型语言模型”(HLLMs)，为历史学家和数字人文研究人员提供了与过去语言模式互动的机会。虽然并非总是事实准确，但它们在风格上可能具有深刻的见解。Grigorian计划探索其他城市的模型，并邀请合作，公开了他的代码和模型。文章最后指出，该模型准确的历史参考是一个令人耳目一新的“事实意外”，是AI幻觉的反面。"
  },
  {
    "id": "45367046",
    "title": "Do YC after you graduate: Early decision for students",
    "url": "https://www.ycombinator.com/early-decision",
    "summary": "Y Combinator (YC) offers an \"Early Decision\" program for students who want to complete their degree before launching a startup. Students apply to YC while still in school and, if accepted, reserve a spot in a future batch after graduation. They receive funding immediately upon acceptance.\n\nThe program allows students to \"lock in\" their startup plans and avoid the typical job/internship search during their final year. Even those uncertain about starting a company immediately are encouraged to apply as there's no penalty. Early Decision is available even for students who are not in their final year of school.\n\nThe typical timeline involves applying in the fall of the final year and joining the summer batch after graduation. The application and interview process are the same as for regular YC applications. To apply, students select \"A batch after Winter 2026\" on the application and indicate their preferred batch.\n\nYC created Early Decision to provide students with an alternative to traditional job applications and encourage them to \"bet on themselves\" by starting a company after their education.\n",
    "chinese_title": "毕业后做YC：学生提前录取",
    "chinese_summary": "Y Combinator（YC）为希望在完成学业后创办初创公司的学生提供“提前录取”计划。学生在校期间即可申请 YC，如果被录取，将保留毕业后未来批次的席位，并在录取后立即获得资金。\n\n该计划允许学生“锁定”他们的创业计划，避免在最后一年进行典型的求职/实习搜索。即使那些不确定是否立即创办公司的人，也被鼓励申请，因为没有惩罚。即使是不在最后一学年的学生也可以申请提前录取。\n\n典型的流程是在最后一年的秋季申请，并在毕业后加入夏季批次。申请和面试流程与常规 YC 申请相同。要申请，学生需要在申请表上选择“2026 年冬季批次之后的批次”，并注明他们首选的批次。\n\nYC 创建提前录取计划是为了给学生提供传统求职之外的选择，并鼓励他们在完成学业后通过创办公司来“押注自己”。"
  },
  {
    "id": "45344250",
    "title": "Wild performance tricks",
    "url": "https://davidlattimore.github.io/posts/2025/09/02/rustforge-wild-performance-tricks.html",
    "summary": "David Lattimore's blog post summarizes performance optimization techniques used in the Wild linker, initially presented at RustForge. The post focuses on optimizations rather than linker benchmarks.\n\nKey tricks include:\n\n1.  **Mutable slicing for thread sharing:** Using `split_off_mut` to divide a `Vec` of `SymbolId` into mutable slices, enabling parallel processing of object resolutions with Rayon. Each thread operates on a specific object's symbols stored contiguously in memory for better cache locality.\n\n2.  **Parallel Vec initialization:** Employing the `sharded-vec-writer` crate to initialize a `Vec` in parallel, avoiding the overhead of a single thread filling it with placeholder values.\n\n3.  **Atomic to non-atomic in-place conversion:** Converting a `Vec<SymbolId>` to `Vec<AtomicSymbolId>` for random writes (resolving duplicate symbols). This conversion reuses the existing heap allocation and eliminates the loop by leveraging Rust's optimization for `Vec` consumption and collection, and by matching the in-memory representation of the structs.\n\n4.  **Buffer reuse:** Avoiding excessive heap allocation by reusing `Vec` memory with a custom `reuse_vec` function that clears and converts `Vec` types (with a compile-time check of size and alignment).\n\n5.  **Deallocation on a separate thread:** Offloading memory deallocation to another thread (using rayon::spawn) for large allocations, potentially improving performance.\n\n6.  **Bonus: Stripping lifetime with non-trivial Drop:** Converting types with non-static lifetimes by replacing references with MaybeUninit to safely move `Vec` deallocation to another thread.\n\nThe post emphasizes avoiding `unsafe` code where possible and provides assembly code snippets to demonstrate optimization effectiveness.\n",
    "chinese_title": "狂野表演技巧",
    "chinese_summary": "David Lattimore的博客文章总结了Wild链接器中使用的性能优化技术，这些技术最初在RustForge上展示。该文章侧重于优化而非链接器基准测试。\n\n关键技巧包括：\n\n1. **用于线程共享的可变切片：** 使用`split_off_mut`将`SymbolId`的`Vec`分割成可变切片，从而利用Rayon并行处理对象解析。每个线程操作存储在内存中连续的特定对象的符号，以获得更好的缓存局部性。\n\n2. **并行Vec初始化：** 采用`sharded-vec-writer` crate并行初始化`Vec`，避免单线程填充占位符值的开销。\n\n3. **原子到非原子原地转换：** 将`Vec<SymbolId>`转换为`Vec<AtomicSymbolId>`以进行随机写入（解决重复符号）。此转换重用现有的堆分配，并通过利用Rust对`Vec`消耗和收集的优化，以及匹配结构体的内存表示来消除循环。\n\n4. **缓冲区重用：** 通过使用自定义的`reuse_vec`函数（具有大小和对齐的编译时检查）来清除和转换`Vec`类型，从而避免过多的堆分配，并重用`Vec`内存。\n\n5. **在单独线程上进行释放：** 将大分配的内存释放卸载到另一个线程（使用rayon::spawn），从而可能提高性能。\n\n6. **奖励：使用非平凡Drop剥离生命周期：** 通过用MaybeUninit替换引用来转换具有非静态生命周期的类型，以安全地将`Vec`释放移动到另一个线程。\n\n该文章强调尽可能避免`unsafe`代码，并提供汇编代码片段来演示优化的有效性。"
  },
  {
    "id": "45388000",
    "title": "Birmingham city council delays fix to disastrous Oracle system once more",
    "url": "https://www.theregister.com/2025/09/24/uk_mega_council_delays_fix/",
    "summary": "Birmingham City Council has further delayed the implementation of its vital Income Management System (IMS), part of a disastrous Oracle system rollout that could now cost £170 million. The IMS was intended to fix issues stemming from a flawed Banking Reconciliation System (BRS) introduced during the initial Oracle Fusion go-live in April 2022, which replaced a functioning SAP system.\n\nThe Oracle implementation has been plagued with problems, including customized modifications that failed, leading to the council being declared effectively bankrupt in September 2023 due to the ERP disaster and outstanding equal pay claims. The council is now working to reimplement Oracle from scratch, targeting an April 2026 go-live.\n\nThe IMS, initially slated for a March 2025 launch, was first pushed back to April, then September, and now November due to concerns about the original design's validity. Council members expressed frustration over the delays, escalating costs, and being informed of problems through the media before official channels. Testing of the IMS revealed unacceptable failure rates and severe deficits.\n\nThe overall Oracle project budget has ballooned from an initial £19.965 million to £170 million. A central government commissioner overseeing Birmingham's financial recovery urged caution and prioritizing quality over speed in the implementation.\n",
    "chinese_title": "伯明翰市议会再次推迟修复灾难性的Oracle系统",
    "chinese_summary": "伯明翰市议会再次推迟了其重要的收入管理系统（IMS）的实施，该系统是灾难性的Oracle系统推广的一部分，现在可能耗资1.7亿英镑。 IMS旨在解决2022年4月首次Oracle Fusion上线期间引入的有缺陷的银行对账系统（BRS）所产生的问题，该系统取代了一个运行正常的SAP系统。\n\nOracle的实施一直问题缠身，包括定制修改失败，导致市议会因ERP灾难和未支付的同工同酬索赔于2023年9月被宣布实际上破产。市议会目前正在从头开始重新实施Oracle，目标是在2026年4月上线。\n\nIMS最初计划于2025年3月启动，但由于担心原始设计的有效性，先是推迟到4月，然后是9月，现在是11月。 市议会成员对延误、不断上涨的成本以及在官方渠道之前通过媒体得知问题表示沮丧。 IMS的测试显示了不可接受的失败率和严重的赤字。\n\n整个Oracle项目预算已从最初的1996.5万英镑膨胀到1.7亿英镑。 监督伯明翰财政复苏的中央政府专员敦促谨慎行事，并在实施过程中优先考虑质量而不是速度。"
  },
  {
    "id": "45381813",
    "title": "Writing Memory Safe JIT Compilers",
    "url": "https://medium.com/graalvm/writing-truly-memory-safe-jit-compilers-f79ad44558dd",
    "summary": "I am able to access the article link and here's a summary:\n\nThe article \"Writing Truly Memory Safe JIT Compilers\" discusses the challenges and solutions for building JIT (Just-In-Time) compilers that are completely memory safe. It argues that traditional JIT compilers, often written in languages like C++, are susceptible to memory safety vulnerabilities (e.g., buffer overflows, use-after-free) which can be exploited by malicious code running within the interpreted language.\n\nThe core argument is that to achieve true memory safety, the JIT compiler itself must be written in a memory-safe language. The article highlights GraalVM and its Truffle framework as a solution to this problem. Truffle allows developers to implement language interpreters and JIT compilers in Java (or other JVM languages), leveraging the JVM's inherent memory safety features.\n\nThe article emphasizes the benefits of using Truffle/GraalVM, including:\n\n*   **Automatic Memory Management:** The JVM's garbage collector prevents memory leaks and dangling pointers.\n*   **Type Safety:** Java's strong type system helps prevent type-related errors that can lead to memory corruption.\n*   **Security:** Reduced attack surface due to the elimination of common memory safety vulnerabilities in the JIT compiler itself.\n*   **Performance:** GraalVM's advanced optimization techniques can result in JIT compilers that are competitive with, or even outperform, those written in C++.\n\nIn essence, the article promotes using a memory-safe language and framework like Truffle/GraalVM to build JIT compilers, as it significantly enhances the security and reliability of the entire system by mitigating the risk of memory safety exploits within the JIT compiler component. This approach ensures that even if the interpreted language contains vulnerabilities, the JIT compiler itself remains secure.\n",
    "chinese_title": "编写内存安全 JIT 编译器",
    "chinese_summary": "我已访问文章链接，以下是摘要：\n\n文章《编写真正内存安全的JIT编译器》探讨了构建完全内存安全的JIT（即时）编译器的挑战和解决方案。 文章认为，传统的JIT编译器，通常用C++等语言编写，容易受到内存安全漏洞（例如，缓冲区溢出、释放后使用）的影响，这些漏洞可能被解释语言中运行的恶意代码利用。\n\n核心论点是，要实现真正的内存安全，JIT编译器本身必须用内存安全的语言编写。 文章重点介绍了GraalVM及其Truffle框架作为解决此问题的方法。 Truffle允许开发人员使用Java（或其他JVM语言）来实现语言解释器和JIT编译器，从而利用JVM固有的内存安全特性。\n\n文章强调了使用Truffle/GraalVM的优点，包括：\n\n*   **自动内存管理：** JVM的垃圾收集器可防止内存泄漏和悬挂指针。\n*   **类型安全：** Java的强类型系统有助于防止可能导致内存损坏的类型相关错误。\n*   **安全性：** 由于消除了JIT编译器本身中常见的内存安全漏洞，因此减少了攻击面。\n*   **性能：** GraalVM的先进优化技术可以产生与用C++编写的JIT编译器具有竞争力甚至超越它们的JIT编译器。\n\n本质上，文章提倡使用像Truffle/GraalVM这样的内存安全语言和框架来构建JIT编译器，因为它通过减轻JIT编译器组件中的内存安全漏洞风险，从而显着提高了整个系统的安全性和可靠性。 这种方法确保即使解释语言包含漏洞，JIT编译器本身仍然安全。"
  },
  {
    "id": "45387593",
    "title": "Micro Men(2009) – movie about the creation of ARM",
    "url": "https://www.youtube.com/watch?v=XH5L-iTIbP8",
    "summary": "The provided text isn't an article but rather boilerplate information commonly found at the bottom of YouTube pages. It lists:\n\n*   **Legal and Policy Information:** This includes copyright notices, contact information for news outlets, terms of service, privacy policies, safety guidelines, and information about advertising and development partnerships.\n\n*   **YouTube Functions:** It mentions how YouTube operates, opportunities for content creators, and testing of new features.\n\n*   **Specific Content or Agreements:** It mentions NFL Sunday Ticket and the copyright held by Google LLC for 2025, indicating potential content or licensing agreements.\n\nThe inclusion of \"Micro Men (2009) – movie about the creation of ARM\" as a title suggests that the YouTube page might be related to that movie, but the provided text itself doesn't provide any information about the movie. It's purely standard YouTube footer content.\n",
    "chinese_title": "微型计算机（2009）— 关于ARM诞生的电影",
    "chinese_summary": "提供的文本并非文章，而是常见于YouTube页面底部的样板信息。它列出了：\n\n*   **法律和政策信息：** 包括版权声明、新闻媒体的联系方式、服务条款、隐私政策、安全指南以及关于广告和开发合作伙伴的信息。\n\n*   **YouTube功能：** 提到YouTube的运作方式、内容创作者的机会以及新功能的测试。\n\n*   **特定内容或协议：** 提到NFL Sunday Ticket以及Google LLC拥有的2025年版权，表明潜在的内容或许可协议。\n\n将“Micro Men (2009) – 关于ARM创建的电影”作为标题表明该YouTube页面可能与该电影相关，但提供的文本本身并未提供关于该电影的任何信息。这纯粹是标准的YouTube页脚内容。"
  },
  {
    "id": "45371309",
    "title": "The Wind, a Pole, and the Dragon",
    "url": "https://entropicthoughts.com/the-wind-a-pole-and-the-dragon",
    "summary": "This article dissects a bizarre, machine-translated plea for help from a Japanese user struggling with a Shibboleth installation. The author highlights the difficulty in deciphering the nonsensical output, pinpointing phrases like \"goat-time,\" \"vomit,\" and \"the wind, a pole, and the dragon\" as particularly problematic.\n\nThe author successfully decodes some of the translation errors. \"Vomit\" likely refers to an error being thrown or output, and \"lumber\" probably represents logs. \"Goat-time\" is speculated to mean runtime. The author, with the help of LLMs, believes \"spank\" is a mistranslation of \"hit\" meaning \"execute,\" and \"skill\" a mistranslation of \"experience.\"\n\nUsing these interpretations, the author reconstructs a more coherent meaning: the user repeatedly encounters errors during runtime installation. They suspect the real error is hidden within the runtime logs and question if the issue stems from an interaction with the runtime or their own lack of experience.\n\nThe article concludes by focusing on the most perplexing element: \"the wind, a pole, and the dragon.\" Despite LLM suggestions involving configurations, dependencies, or speed/complexity metaphors, the author remains baffled by its meaning and invites readers to offer insights. The \"insult to father's stones\" phrase is also discussed with two possible interpretations: an idiomatic expression of frustration or, more interestingly, a reference to software dependencies.\n",
    "chinese_title": "风，杆，与龙",
    "chinese_summary": "本文剖析了一则离奇的机翻求助，一位日本用户正努力安装Shibboleth，却苦于难以理解其机器翻译的输出。作者强调了破译这些无稽之谈的难度，并指出诸如“山羊时间”、“呕吐”和“风，杆，龙”等短语尤其令人困惑。\n\n作者成功解码了一些翻译错误。“呕吐”可能指抛出或输出的错误，“木材”可能代表日志。“山羊时间”被推测为运行时。作者在LLM的帮助下，认为“spank”是“hit”（意为“执行”）的错误翻译，“skill”是“experience”（意为“经验”）的错误翻译。\n\n通过这些解读，作者重构了一个更连贯的含义：用户在运行时安装过程中反复遇到错误。他们怀疑真正的错误隐藏在运行时日志中，并质疑问题是源于与运行时的交互，还是源于他们自身缺乏经验。\n\n文章最后聚焦于最令人费解的元素：“风，杆，龙”。尽管LLM提出了涉及配置、依赖项或速度/复杂性隐喻的建议，但作者仍然对其含义感到困惑，并邀请读者提供见解。“侮辱父亲的石头”一词也得到了讨论，有两种可能的解释：一种是沮丧的习语表达，另一种是更有趣的解释，指的是软件依赖项。"
  },
  {
    "id": "45385920",
    "title": "'Independent' auditors overvalue credits of carbon projects, study finds",
    "url": "https://news.mongabay.com/2025/09/independent-auditors-overvalue-credits-of-carbon-projects-study-finds/",
    "summary": "This article discusses a study questioning the independence and effectiveness of auditors in the voluntary carbon credit market, particularly within Verra, the largest carbon credit registry. The study found that auditors often fail to identify flaws in carbon credit projects, leading to overvalued credits that don't accurately represent actual emission reductions, thus undermining climate mitigation efforts.\n\nResearchers and experts argue that the system inherently creates conflicts of interest. Auditors are paid by project developers, potentially biasing their assessments, while registries like Verra benefit from a higher volume of credits. This structure incentivizes the approval of more credits, regardless of their validity.\n\nThe article highlights concerns about the complexity of carbon credit projects, making audits subjective, and the potential for flawed methodologies that lead to inflated emission reduction claims. Some experts believe the entire system needs fundamental reform, including excluding ineffective project types and addressing methodology and auditing issues.\n\nThe article also mentions that Verra has taken some actions to address these issues, such as suspending auditors and implementing a performance monitoring program. However, some argue for more significant structural changes, such as a random selection of independent auditors paid from a global fund, incentivizing them to find issues. Overall, the article paints a concerning picture of a carbon market struggling with credibility due to compromised auditing practices, ultimately hindering effective climate action.\n",
    "chinese_title": "研究发现，“独立”审计师高估了碳项目的信用额度。",
    "chinese_summary": "该文章探讨了一项研究，该研究质疑自愿碳信用市场中审计师的独立性和有效性，尤其是在最大的碳信用注册机构Verra内部。研究发现，审计师经常未能识别出碳信用项目中的缺陷，导致碳信用被高估，无法准确代表实际的减排量，从而破坏了气候减缓的努力。\n\n研究人员和专家认为，该系统本身就存在利益冲突。审计师由项目开发商支付报酬，这可能会使他们的评估产生偏差，而像Verra这样的注册机构则受益于更高的碳信用交易量。这种结构鼓励批准更多的碳信用，而不管其有效性如何。\n\n该文章强调了对碳信用项目复杂性的担忧，这使得审计具有主观性，以及可能存在缺陷的方法导致虚报减排量的情况。一些专家认为，整个系统需要进行根本性的改革，包括排除无效的项目类型，并解决方法和审计问题。\n\n该文章还提到，Verra已经采取了一些行动来解决这些问题，例如暂停审计师资格和实施绩效监控计划。然而，一些人主张进行更重大的结构性变革，例如从全球基金中随机选择独立审计师并向其支付报酬，以激励他们发现问题。总的来说，该文章描绘了一幅令人担忧的景象，即碳市场因受损的审计实践而面临信誉危机，最终阻碍了有效的气候行动。"
  },
  {
    "id": "45374500",
    "title": "ChatControl: EU wants to scan all private messages, even in encrypted apps",
    "url": "https://metalhearf.fr/posts/chatcontrol-wants-your-private-messages/",
    "summary": "The EU's proposed ChatControl (CSAR) regulation aims to combat child sexual abuse material (CSAM) by mandating messaging platforms, email providers, social media, and even gaming platforms to scan users' private messages and images, including those in encrypted apps like Signal and WhatsApp.\n\nThe system relies on client-side scanning, analyzing content on users' devices before encryption, effectively bypassing end-to-end encryption. It scans for known illegal content, potentially illegal content using AI, and grooming behavior through text analysis. Flagged content is automatically reported to authorities without human verification.\n\nCritics argue ChatControl constitutes mass surveillance, violates privacy, and reverses the presumption of innocence. Technical experts highlight the high rate of false positives, potentially overwhelming law enforcement and wrongly accusing innocent individuals. They also note the ease with which determined actors can circumvent the system using techniques like layered encryption, external platforms, or custom messaging clients.\n\nOver 600 cryptographers have signed an open letter stating that ChatControl is technically unfeasible and a danger to democracy. The authors also state that the EU Commission has based their CSAR proposal primarily on claims from industry players rather than independent research, as it would create a profitable market for surveillance companies. The legislation also includes exemptions for government accounts.\n",
    "chinese_title": "聊天控制：欧盟欲扫描所有私人信息，包括加密应用内的信息",
    "chinese_summary": "欧盟提出的聊天控制（CSAR）法规旨在打击儿童性虐待材料（CSAM），通过强制消息平台、电子邮件提供商、社交媒体，甚至游戏平台扫描用户的私人消息和图像，包括Signal和WhatsApp等加密应用程序中的消息和图像。\n\n该系统依赖于客户端扫描，在加密前分析用户设备上的内容，从而有效地绕过端到端加密。它扫描已知的非法内容，使用人工智能扫描潜在的非法内容，并通过文本分析扫描诱骗行为。标记的内容会自动报告给当局，无需人工验证。\n\n批评者认为聊天控制构成大规模监控，侵犯隐私，并颠覆了无罪推定原则。技术专家强调了高误报率，可能使执法部门不堪重负，并错误地指控无辜个人。他们还指出，坚定的行动者可以很容易地使用分层加密、外部平台或自定义消息客户端等技术来规避该系统。\n\n超过600名密码学家签署了一封公开信，声明聊天控制在技术上不可行，并且对民主构成威胁。作者还表示，欧盟委员会的CSAR提案主要基于行业参与者的声明，而不是独立研究，因为它将为监控公司创造一个有利可图的市场。该立法还包括政府账户的豁免。"
  },
  {
    "id": "45371283",
    "title": "The Theatre of Pull Requests and Code Review",
    "url": "https://meks.quest/blogs/the-theatre-of-pull-requests-and-code-review",
    "summary": "Meks McClure summarizes Saša Jurić's \"Tell Me a Story\" talk from Goatmire Elixir Conf, focusing on improving code review through better Pull Requests (PRs). The article emphasizes that large, complex PRs lead to superficial reviews and potential issues. Jurić advocates for returning unreviewable PRs to the author, prioritizing understanding over quick approvals.\n\nA key takeaway is creating PRs that can be reviewed in 5-10 minutes by mid-to-senior developers. This involves reducing scope, aiming for under 300 lines of code changes per PR. Furthermore, the article highlights the importance of \"story-telling commits.\" Instead of generic messages, commit messages should explain the rationale behind changes, allowing reviewers to follow the developer's thought process.\n\nThe article illustrates this with an example PR broken down into thoughtful commits. It also highlights the benefits of fixup commits and interactive rebasing for maintaining a clean and coherent commit history. A clean history, where each commit compiles, simplifies debugging and identifying the source of bugs using tools like `git bisect`.\n\nUltimately, focused PRs with clear commit histories lead to faster development cycles, valuable feedback, and higher-quality code. The author encourages readers to focus on smaller PRs and descriptive commit messages to improve code review and aid future debugging efforts.\n",
    "chinese_title": "代码审查的舞台剧",
    "chinese_summary": "Meks McClure总结了Saša Jurić在Goatmire Elixir Conf上的“Tell Me a Story”演讲，重点在于通过更好的Pull Requests (PRs)来改进代码审查。文章强调大型、复杂的PR会导致肤浅的审查和潜在的问题。Jurić主张将无法审查的PR退回给作者，优先考虑理解而不是快速批准。\n\n一个关键要点是创建中高级开发人员可以在5-10分钟内完成审查的PR。这包括缩小范围，目标是每个PR的代码更改少于300行。此外，文章强调了“讲故事式提交”的重要性。提交消息不应是通用的，而应解释更改背后的原理，以便审查人员能够理解开发人员的思路。\n\n文章用一个分解为深思熟虑的提交的PR示例来说明这一点。它还强调了fixup提交和交互式变基的好处，以维护干净且连贯的提交历史。一个干净的历史，即每个提交都可编译，简化了调试，并可以使用`git bisect`等工具识别错误的来源。\n\n最终，重点明确的PR和清晰的提交历史可以带来更快的开发周期、有价值的反馈和更高质量的代码。作者鼓励读者关注较小的PR和描述性的提交消息，以改进代码审查并帮助未来的调试工作。"
  },
  {
    "id": "45346259",
    "title": "Reverse-Engineering the LCD Display Interface of the Nest 2nd Gen Thermostat",
    "url": "https://sett.homes/blogs/updates/the-lcd-display-reverse-engineering-the-display-interface",
    "summary": "This article details the author's journey of reverse-engineering the LCD display interface of a Nest 2nd Gen thermostat. The process began with disassembling the thermostat and identifying the LCD module's part number: TM025ZDZ02.\n\nAfter struggling to find the exact datasheet, the author located one for a similar module, TM025ZDZ01, made by Shanghai Tianma Micro-Electronics, revealing a 2.48\" round display with 320x320 resolution and a 3-wire SPI interface. To interface with the tiny FPC connector, a custom breakout board was designed and manufactured.\n\nThe main challenge was understanding and implementing the non-standard \"3-wire 9-bit SPI\" protocol. This involved addressing bus contention with a current-limiting resistor on the shared SDA line and figuring out how to send 9-bit frames with hardware typically designed for 8-bit transfers.\n\nThe author used the datasheet of the similar TM025ZDZ01, documentation of the 3-wire SPI protocol, and the Samsung S6D05A1's datasheet (the Driving IC for the display) to construct a Toit program that initializes the display. The program involved a specific sequence of commands and data writes, gleaned from combining information from all of these datasheets, including commands for resetting the display, setting pixel format, and turning the display on. Hardware connections were made between the ESP32C6 and the display breakout board, and a resistor placed between SDA and the MCU. The code includes sections for command/data setting and initialization sequences.\n",
    "chinese_title": "Nest 第二代恒温器 LCD 显示接口逆向工程",
    "chinese_summary": "本文详细介绍了作者对Nest第二代恒温器LCD显示屏接口进行逆向工程的历程。该过程始于拆解恒温器并确定LCD模块的零件编号：TM025ZDZ02。\n\n在努力寻找确切的数据手册后，作者找到了上海天马微电子制造的类似模块TM025ZDZ01的数据手册，其中显示了一个2.48英寸圆形显示屏，分辨率为320x320，并具有3线SPI接口。为了与微小的FPC连接器连接，设计并制造了一个定制的 breakout 板。\n\n主要的挑战是理解和实现非标准的“三线9位SPI”协议。这涉及到使用限流电阻解决共享SDA线路上的总线争用问题，以及弄清楚如何使用通常为8位传输设计的硬件发送9位帧。\n\n作者使用了类似TM025ZDZ01的数据手册、三线SPI协议的文档以及三星S6D05A1（显示屏的驱动IC）的数据手册，构建了一个Toit程序来初始化显示屏。该程序涉及一系列特定的命令和数据写入，这些信息是从所有这些数据手册中提取的，包括用于重置显示屏、设置像素格式和打开显示屏的命令。ESP32C6和显示屏 breakout 板之间进行了硬件连接，并在SDA和MCU之间放置了一个电阻。代码包括命令/数据设置和初始化序列部分。"
  },
  {
    "id": "45376895",
    "title": "Redox OS Development Priorities for 2025/26",
    "url": "https://www.redox-os.org/news/development-priorities-2025-09/",
    "summary": "This article outlines the development priorities for Redox OS in 2025/26, focusing on three main variants: \"Hosted Redox\" for web services in VMs, \"Redox Server\" for edge and cloud computing, and \"Redox Desktop\" as a daily driver.\n\nKey development priorities include:\n\n*   **Building Redox on Redox:** Enabling self-hosting for faster and more pleasant development, requiring improvements in network performance, compiler reliability, the build system, and debugging tools.\n\n*   **Compliance and Compatibility:** Aiming for near-POSIX compliance to facilitate porting Linux applications, with a focus on compliance testing and Rust compatibility.\n\n*   **Programming Language and Build System Support:** Expanding support for various programming languages beyond Rust and C/C++, addressing runtime challenges and porting essential build tools.\n\n*   **Performance:** Continuing to improve performance, especially in disk I/O and the network stack, and establishing performance benchmarks.\n\n*   **Security:** Implementing Capability-Based Security to enhance resource access control and creating a sandboxed desktop environment.\n\n*   **Hardware Support:** Focusing on drivers for \"recommended\" hardware for servers and desktops, partnering with vendors to optimize drivers.\n\n*   **COSMIC, Wayland, and GPU Acceleration:** Supporting Wayland for COSMIC Desktop compatibility and working on GPU acceleration.\n\nThe article also highlights ways to contribute, including donations to fund development and documentation efforts, direct contributions to the project, and applying for grants for Redox-related projects.\n",
    "chinese_title": "2025/26年度 Redox 操作系统开发重点",
    "chinese_summary": "本文概述了 Redox OS 在 2025/26 年的发展重点，主要关注三个变体：“Hosted Redox”用于虚拟机中的 Web 服务，“Redox Server”用于边缘和云计算，以及“Redox Desktop”作为日常使用系统。\n\n主要发展重点包括：\n\n*   **基于 Redox 构建 Redox：** 实现自托管，以实现更快更愉快的开发，需要改进网络性能、编译器可靠性、构建系统和调试工具。\n\n*   **合规性和兼容性：** 旨在实现接近 POSIX 的合规性，以促进 Linux 应用程序的移植，重点是合规性测试和 Rust 兼容性。\n\n*   **编程语言和构建系统支持：** 扩展对 Rust 和 C/C++ 之外的各种编程语言的支持，解决运行时挑战并移植必要的构建工具。\n\n*   **性能：** 继续提高性能，尤其是在磁盘 I/O 和网络堆栈方面，并建立性能基准。\n\n*   **安全性：** 实施基于能力的安全性，以增强资源访问控制，并创建一个沙盒化的桌面环境。\n\n*   **硬件支持：** 专注于服务器和桌面“推荐”硬件的驱动程序，与供应商合作优化驱动程序。\n\n*   **COSMIC、Wayland 和 GPU 加速：** 支持 Wayland 以实现 COSMIC Desktop 兼容性，并致力于 GPU 加速。\n\n本文还强调了贡献的方式，包括捐款以资助开发和文档工作、直接为项目做贡献以及申请与 Redox 相关的项目的资助。"
  },
  {
    "id": "45372335",
    "title": "Demand for human radiologists is at an all-time high",
    "url": "https://www.worksinprogress.news/p/why-ai-isnt-replacing-radiologists",
    "summary": "Despite the rise of AI in radiology, demand for human radiologists is at an all-time high. While AI models can outperform humans on standardized tests and detect diseases with speed and accuracy, several factors prevent them from replacing radiologists entirely.\n\nFirstly, AI struggles to replicate its benchmark performance in real-world hospital settings. Models are often trained on specific datasets and may not perform well outside of those conditions, especially with images from different hospitals or with subtle variations in disease presentation.\n\nSecondly, regulatory and legal hurdles limit the widespread adoption of fully autonomous AI radiology models. The FDA has stricter requirements for autonomous tools, and insurers are hesitant to cover them due to concerns about malpractice liability.\n\nThirdly, AI only replaces a small part of a radiologist's job. Radiologists spend a significant portion of their time on activities other than diagnostics, such as communicating with patients and other clinicians.\n\nThe article also highlights the issue of \"islands of automation,\" where many individual AI models exist for specific tasks, but lack the comprehensive understanding and adaptability of human radiologists. Furthermore, the piece touches on historical failures of AI in radiology, specifically regarding computer-aided diagnosis for mammograms, emphasizing the importance of clinical performance over benchmark results. The article concludes that while AI has potential, it needs to overcome these hurdles and adapt to societal needs and rules to fully realize its benefits in radiology.\n",
    "chinese_title": "对人类放射科医生的需求处于历史最高水平。",
    "chinese_summary": "尽管人工智能在放射学领域兴起，但对人类放射科医生的需求仍处于历史最高水平。虽然人工智能模型在标准化测试中可以超越人类，并能快速准确地检测疾病，但有几个因素阻碍了它们完全取代放射科医生。\n\n首先，人工智能难以在现实世界的医院环境中复制其基准性能。这些模型通常在特定的数据集上进行训练，可能无法在这些条件之外表现良好，尤其是在来自不同医院的图像或疾病表现存在细微差异的情况下。\n\n其次，监管和法律障碍限制了完全自主的人工智能放射学模型的广泛应用。美国食品药品监督管理局对自主工具的要求更为严格，保险公司也因担心医疗事故责任而犹豫是否承保。\n\n第三，人工智能只取代了放射科医生工作的一小部分。放射科医生的大部分时间都花在诊断以外的活动上，例如与患者和其他临床医生的沟通。\n\n文章还强调了“自动化孤岛”的问题，即存在许多用于特定任务的独立人工智能模型，但缺乏人类放射科医生所具有的全面理解和适应能力。此外，文章还提到了人工智能在放射学领域的历史失败案例，特别是关于乳腺X线摄影的计算机辅助诊断，强调了临床表现的重要性高于基准结果。文章总结认为，虽然人工智能具有潜力，但它需要克服这些障碍，并适应社会需求和规则，才能充分实现其在放射学领域的优势。"
  },
  {
    "id": "45382434",
    "title": "Evanston orders Flock to remove reinstalled cameras",
    "url": "https://evanstonroundtable.com/2025/09/24/flock-safety-reinstalls-evanston-cameras/",
    "summary": "Evanston, Illinois, ordered Flock Safety to remove license plate reader cameras that the company had reinstalled without the city's authorization. This occurred after the city had previously terminated its contract with Flock due to concerns about data access by U.S. Customs and Border Protection and out-of-state law enforcement agencies for immigration-related searches, violating state law.\n\nFlock initially removed 15 of 18 stationary cameras after the contract termination notice on August 26th, but reinstalled them by Tuesday. The city issued a cease-and-desist order, and Flock committed to removing them again. The city had concerns with the initial installation of the cameras in late 2022 and early 2023, but approved a five-year contract extension in January 2024 which the city intends to terminate and Flock is challenging.\n\nThe reinstalled cameras were mostly put back in their original locations, with some using different \"Standard\" models lacking solar panels. Furthermore, data from Flock's transparency portal suggests the cameras may not have been fully deactivated after the initial shutdown order. The number of vehicles detected in the last 30 days has not decreased as rapidly as it should have if the cameras were truly inactive, hinting at continued data collection. The city claims they were unaware of the re-activation.\n",
    "chinese_title": "埃文斯顿市命令Flock公司移除重新安装的摄像头。",
    "chinese_summary": "伊利诺伊州埃文斯顿市已下令Flock Safety公司移除其未经授权重新安装的车牌识别摄像头。此前，该市因担心美国海关与边境保护局以及外州执法机构出于移民相关的搜索目的访问数据，违反州法律，已终止与Flock的合同。\n\nFlock最初在8月26日合同终止通知后移除了18个固定摄像头中的15个，但于周二重新安装了它们。该市发布了停止令，Flock承诺再次移除这些摄像头。该市对2022年末和2023年初首次安装这些摄像头表示担忧，但在2024年1月批准了一项为期五年的合同延期，该市打算终止该延期，Flock正在对此提出异议。\n\n重新安装的摄像头大多被放回原来的位置，其中一些使用了缺少太阳能电池板的不同“标准”型号。此外，来自Flock透明度门户网站的数据表明，这些摄像头在最初的关闭命令后可能并未完全停用。如果摄像头确实处于非活动状态，那么过去30天内检测到的车辆数量的减少速度本应更快，这暗示着数据仍在持续收集。该市声称他们并不知晓摄像头的重新激活。"
  },
  {
    "id": "45347072",
    "title": "Brutalita Sans: An Experimental Font and Font Editor",
    "url": "https://brutalita.com/",
    "summary": "\"Brutalita Sans: An Experimental Font and Font Editor\" introduces a project centered around the creation of both a font, Brutalita Sans, and the font editor used to design it. The article likely delves into the experimental nature of the font itself, possibly highlighting its unconventional design elements and inspirations. It's reasonable to assume the article will discuss the aesthetic choices behind Brutalita Sans, possibly mentioning its stylistic influences and target use cases.\n\nFurthermore, the article will explore the development and functionality of the custom font editor. This likely includes details about its unique features, any specific design considerations implemented, and how it facilitated the creation of Brutalita Sans. The emphasis on \"experimental\" suggests the font editor might incorporate unusual or innovative approaches to font design and manipulation. The article could also cover the challenges faced in developing both the font and the editor, and the potential impact of this project on the wider field of typography and font design. In essence, it presents a dual-faceted project where the font acts as both the creation and the testing ground for its custom-built editor.\n",
    "chinese_title": "Brutalita Sans：一种实验字体与字体编辑器",
    "chinese_summary": "Brutalita Sans：实验字体与字体编辑器 介绍了一个以创建字体Brutalita Sans及其设计所用的字体编辑器为中心的项目。文章很可能深入探讨字体本身的实验性质，可能会强调其非常规的设计元素和灵感。 可以合理地假设文章将讨论Brutalita Sans背后的美学选择，可能会提及它的风格影响和目标用例。\n\n此外，文章还将探讨自定义字体编辑器的开发和功能。 这可能包括关于其独特功能、所实施的任何特定设计考虑因素以及它如何促进Brutalita Sans的创建的详细信息。 对“实验”的强调表明，字体编辑器可能包含用于字体设计和操作的非同寻常的或创新的方法。 文章还可能涵盖开发字体和编辑器所面临的挑战，以及该项目对更广泛的排版和字体设计领域可能产生的影响。 本质上，它提出了一个双重项目，字体既是创作，又是其定制编辑器的试验场。"
  },
  {
    "id": "45378666",
    "title": "Illiteracy Is a Policy Choice",
    "url": "https://www.theargumentmag.com/p/illiteracy-is-a-policy-choice",
    "summary": "Kelsey Piper's article, \"Illiteracy Is a Policy Choice,\" argues that widespread illiteracy in the US, particularly in blue states, is a result of policy failures, not unavoidable circumstance. She highlights the \"Mississippi Miracle,\" where strategic reforms have dramatically improved reading scores, surpassing wealthier, more educated states like California.\n\nPiper emphasizes that Mississippi, along with Louisiana, Alabama, and Tennessee, achieved these improvements by adopting three key strategies: implementing phonics-based reading curricula backed by scientific research, providing targeted teacher training on these specific curricula, and establishing clear accountability measures. These accountability measures included standardized tests and third-grade retention policies for students who cannot read proficiently.\n\nThe article criticizes blue states for failing to adopt these proven strategies, attributing this inaction to political awkwardness, ideological biases, and complacency regarding school performance. The author suggests that there is a reluctance to acknowledge and learn from successes in predominantly red states.\n\nPiper concludes by urging parents to demand these reforms from local school boards and emphasizes the need for a centralized, state-driven effort to implement these changes effectively. She argues that universal literacy is achievable and that failing to pursue these reforms condemns countless children to a life of limited opportunities.\n",
    "chinese_title": "文盲是一种政策选择",
    "chinese_summary": "Kelsey Piper's article, \"Illiteracy Is a Policy Choice,\" argues that widespread illiteracy in the US, particularly in blue states, is a result of policy failures, not unavoidable circumstance. She highlights the \"Mississippi Miracle,\" where strategic reforms have dramatically improved reading scores, surpassing wealthier, more educated states like California.\n\nPiper emphasizes that Mississippi, along with Louisiana, Alabama, and Tennessee, achieved these improvements by adopting three key strategies: implementing phonics-based reading curricula backed by scientific research, providing targeted teacher training on these specific curricula, and establishing clear accountability measures. These accountability measures included standardized tests and third-grade retention policies for students who cannot read proficiently.\n\nThe article criticizes blue states for failing to adopt these proven strategies, attributing this inaction to political awkwardness, ideological biases, and complacency regarding school performance. The author suggests that there is a reluctance to acknowledge and learn from successes in predominantly red states.\n\nPiper concludes by urging parents to demand these reforms from local school boards and emphasizes the need for a centralized, state-driven effort to implement these changes effectively. She argues that universal literacy is achievable and that failing to pursue these reforms condemns countless children to a life of limited opportunities.\n"
  },
  {
    "id": "45379325",
    "title": "RedoxFS is the default filesystem of Redox OS, inspired by ZFS",
    "url": "https://doc.redox-os.org/book/redoxfs.html",
    "summary": "RedoxFS is the default filesystem for Redox OS, designed as a microkernel-friendly alternative to ZFS, which proved incompatible with Redox's architecture. It's also a replacement for TFS. Key features include copy-on-write functionality, data/metadata checksums, transparent encryption, standard Unix file attributes, and large file/directory size and quantity limits (up to 193TiB and 4 billion, respectively).\n\nNotably, RedoxFS supports disk encryption fully within the Redox bootloader, enabling booting from encrypted partitions. Its MIT license allows it to be used on GPL-licensed systems like Linux.\n\nUsers can create, mount, and edit RedoxFS image files using the `redoxfs` tooling, installable via `cargo install redoxfs`. The process involves creating an image file using `fallocate` and initializing it with `redoxfs-mkfs`. The image can then be mounted to a directory using `redoxfs [image] [directory]` and unmounted with `fusermount3 ./redox-img`. The tooling also works with Linux FUSE.\n",
    "chinese_title": "RedoxFS是Redox OS的默认文件系统，其设计灵感来源于ZFS。",
    "chinese_summary": "RedoxFS is the default filesystem for Redox OS, designed as a microkernel-friendly alternative to ZFS, which proved incompatible with Redox's architecture. It's also a replacement for TFS. Key features include copy-on-write functionality, data/metadata checksums, transparent encryption, standard Unix file attributes, and large file/directory size and quantity limits (up to 193TiB and 4 billion, respectively).\n\nNotably, RedoxFS supports disk encryption fully within the Redox bootloader, enabling booting from encrypted partitions. Its MIT license allows it to be used on GPL-licensed systems like Linux.\n\nUsers can create, mount, and edit RedoxFS image files using the `redoxfs` tooling, installable via `cargo install redoxfs`. The process involves creating an image file using `fallocate` and initializing it with `redoxfs-mkfs`. The image can then be mounted to a directory using `redoxfs [image] [directory]` and unmounted with `fusermount3 ./redox-img`. The tooling also works with Linux FUSE.\n"
  },
  {
    "id": "45370304",
    "title": "Raspberry Pi 500+",
    "url": "https://www.raspberrypi.com/news/the-ultimate-all-in-one-pc-raspberry-pi-500-plus-on-sale-now-at-200/",
    "summary": "生成摘要时出错",
    "chinese_title": "Raspberry Pi 500+",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45377030",
    "title": "Tracing JITs in the Real World CPython Core Dev Sprint",
    "url": "https://antocuni.eu/2025/09/24/tracing-jits-in-the-real-world--cpython-core-dev-sprint/",
    "summary": "生成摘要时出错",
    "chinese_title": "Tracing JITs in the Real World CPython Core Dev Sprint",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45372286",
    "title": "Data Viz Color Palette Generator (For Charts and Dashboards)",
    "url": "https://www.learnui.design/tools/data-color-picker.html",
    "summary": "生成摘要时出错",
    "chinese_title": "Data Viz Color Palette Generator (For Charts and Dashboards)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45350646",
    "title": "Hundreds plunge into Chicago River in first open-water swim in nearly a century",
    "url": "https://chicago.suntimes.com/outdoors/2025/09/21/swim-chicago-river-race-outdoors",
    "summary": "生成摘要时出错",
    "chinese_title": "Hundreds plunge into Chicago River in first open-water swim in nearly a century",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45340278",
    "title": "Identity Types",
    "url": "https://bartoszmilewski.com/2025/09/22/identity-types/",
    "summary": "生成摘要时出错",
    "chinese_title": "Identity Types",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45370882",
    "title": "Some interesting stuff I found on IX LANs",
    "url": "https://blog.benjojo.co.uk/post/ixp-bad-broadcast-packets-interesting",
    "summary": "生成摘要时出错",
    "chinese_title": "Some interesting stuff I found on IX LANs",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45374474",
    "title": "Gemini Robotics 1.5 brings AI agents into the physical world",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/",
    "summary": "生成摘要时出错",
    "chinese_title": "Gemini Robotics 1.5 brings AI agents into the physical world",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45331372",
    "title": "Aerospace Structures",
    "url": "https://eaglepubs.erau.edu/introductiontoaerospaceflightvehicles/chapter/aerospace-structures/",
    "summary": "生成摘要时出错",
    "chinese_title": "Aerospace Structures",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45381590",
    "title": "Exploit allows for takeover of fleets of Unitree robots",
    "url": "https://spectrum.ieee.org/unitree-robot-exploit",
    "summary": "生成摘要时出错",
    "chinese_title": "Exploit allows for takeover of fleets of Unitree robots",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45385545",
    "title": "Shoplifters could soon be chased down by drones",
    "url": "https://www.technologyreview.com/2025/09/25/1124088/shoplifters-could-soon-be-chased-down-by-drones/",
    "summary": "生成摘要时出错",
    "chinese_title": "Shoplifters could soon be chased down by drones",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45387596",
    "title": "Nisar First Images from NASA",
    "url": "https://www.nasa.gov/news-release/nasa-isro-satellite-sends-first-radar-images-of-earths-surface/",
    "summary": "生成摘要时出错",
    "chinese_title": "Nisar First Images from NASA",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45372289",
    "title": "Video models are zero-shot learners and reasoners",
    "url": "https://video-zero-shot.github.io/",
    "summary": "生成摘要时出错",
    "chinese_title": "Video models are zero-shot learners and reasoners",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45378871",
    "title": "New Quasi-Moon Discovered Orbiting Earth, but It's Been Around for Decades",
    "url": "https://explorersweb.com/new-quasi-moon-discovered-orbiting-earth-but-its-been-around-for-decades/",
    "summary": "生成摘要时出错",
    "chinese_title": "New Quasi-Moon Discovered Orbiting Earth, but It's Been Around for Decades",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45374064",
    "title": "Amazon fined $2.5B for using deceptive methods to sign up consumers for Prime",
    "url": "https://www.ftc.gov/news-events/news/press-releases/2025/09/ftc-secures-historic-25-billion-settlement-against-amazon",
    "summary": "生成摘要时出错",
    "chinese_title": "Amazon fined $2.5B for using deceptive methods to sign up consumers for Prime",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45381013",
    "title": "The Digital Markets Act: time for a reset",
    "url": "https://blog.google/around-the-globe/google-europe/the-digital-markets-act-time-for-a-reset/",
    "summary": "生成摘要时出错",
    "chinese_title": "The Digital Markets Act: time for a reset",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45387512",
    "title": "Noyb WIN: Austrian authority forbids unlawful credit scoring by KSV1870",
    "url": "https://noyb.eu/en/noyb-win-austrian-authority-forbids-unlawful-credit-scoring-ksv1870",
    "summary": "生成摘要时出错",
    "chinese_title": "Noyb WIN: Austrian authority forbids unlawful credit scoring by KSV1870",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45381584",
    "title": "Cloudflare Data Platform",
    "url": "https://blog.cloudflare.com/cloudflare-data-platform/",
    "summary": "生成摘要时出错",
    "chinese_title": "Cloudflare Data Platform",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45355746",
    "title": "What Happens to Artists' Studios After They Die?",
    "url": "https://www.nytimes.com/2025/09/22/t-magazine/artist-studio-legacy-posthumous.html",
    "summary": "生成摘要时出错",
    "chinese_title": "What Happens to Artists' Studios After They Die?",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45377572",
    "title": "Implementing UI translation in SumatraPDF, a C++ Windows application",
    "url": "https://blog.kowalczyk.info/a-vn0v/implementing-ui-translation-in-sumatrapdf-a-c-windows-application.html",
    "summary": "生成摘要时出错",
    "chinese_title": "Implementing UI translation in SumatraPDF, a C++ Windows application",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45387422",
    "title": "Felony charges after South Carolina high school filled \"fart spray\" for weeks",
    "url": "https://arstechnica.com/culture/2025/09/felony-charges-after-south-carolina-high-school-filled-with-fart-spray-for-weeks/",
    "summary": "生成摘要时出错",
    "chinese_title": "Felony charges after South Carolina high school filled \"fart spray\" for weeks",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45368899",
    "title": "Pablo Picasso's poetry",
    "url": "https://news.artnet.com/art-world/art-bites-picasso-poetry-2669332",
    "summary": "生成摘要时出错",
    "chinese_title": "Pablo Picasso's poetry",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45350690",
    "title": "Find SF parking cops",
    "url": "https://walzr.com/sf-parking/",
    "summary": "生成摘要时出错",
    "chinese_title": "Find SF parking cops",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45342121",
    "title": "800 Years of English Handwriting",
    "url": "https://artsandculture.google.com/story/800-years-of-english-handwriting/eAURodcOgMzFIw",
    "summary": "生成摘要时出错",
    "chinese_title": "800 Years of English Handwriting",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45373564",
    "title": "Microsoft blocks Israel’s use of its tech in mass surveillance of Palestinians",
    "url": "https://www.theguardian.com/world/2025/sep/25/microsoft-blocks-israels-use-of-its-technology-in-mass-surveillance-of-palestinians",
    "summary": "生成摘要时出错",
    "chinese_title": "Microsoft blocks Israel’s use of its tech in mass surveillance of Palestinians",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45337059",
    "title": "Effect Systems vs. Print Debugging: A Pragmatic Solution",
    "url": "https://blog.flix.dev/blog/effect-systems-vs-print-debugging/",
    "summary": "生成摘要时出错",
    "chinese_title": "Effect Systems vs. Print Debugging: A Pragmatic Solution",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45366474",
    "title": "Snapdragon X2 Elite ARM Laptop CPU",
    "url": "https://www.qualcomm.com/products/mobile/snapdragon/laptops-and-tablets/snapdragon-x2-elite",
    "summary": "生成摘要时出错",
    "chinese_title": "Snapdragon X2 Elite ARM Laptop CPU",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45366867",
    "title": "Helium Browser",
    "url": "https://helium.computer/",
    "summary": "生成摘要时出错",
    "chinese_title": "Helium Browser",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45348665",
    "title": "New Element Web and Desktop apps",
    "url": "https://element.io/blog/new-element-web-and-desktop-apps-have-distinct-element-x-vibes/",
    "summary": "生成摘要时出错",
    "chinese_title": "New Element Web and Desktop apps",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45381826",
    "title": "The Death of YMCA Housing and What Japanese Internet Cafés Can Teach Us",
    "url": "https://www.governance.fyi/p/young-man-theres-not-a-place-you",
    "summary": "生成摘要时出错",
    "chinese_title": "The Death of YMCA Housing and What Japanese Internet Cafés Can Teach Us",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45376977",
    "title": "Electron-based apps cause system-wide lag on macOS 26 Tahoe",
    "url": "https://github.com/electron/electron/issues/48311",
    "summary": "生成摘要时出错",
    "chinese_title": "Electron-based apps cause system-wide lag on macOS 26 Tahoe",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45369768",
    "title": "Knotty: A domain-specific language for knitting patterns",
    "url": "https://t0mpr1c3.github.io/knotty/index.html",
    "summary": "生成摘要时出错",
    "chinese_title": "Knotty: A domain-specific language for knitting patterns",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45365878",
    "title": "SonyShell – An effort to “SSH into my Sony DSLR”",
    "url": "https://github.com/goudvuur/sonyshell",
    "summary": "生成摘要时出错",
    "chinese_title": "SonyShell – An effort to “SSH into my Sony DSLR”",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45378323",
    "title": "Windows ML is generally available",
    "url": "https://blogs.windows.com/windowsdeveloper/2025/09/23/windows-ml-is-generally-available-empowering-developers-to-scale-local-ai-across-windows-devices/",
    "summary": "生成摘要时出错",
    "chinese_title": "Windows ML is generally available",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45362697",
    "title": "Terence Tao: The role of small organizations in society has shrunk significantly",
    "url": "https://mathstodon.xyz/@tao/115259943398316677",
    "summary": "生成摘要时出错",
    "chinese_title": "Terence Tao: The role of small organizations in society has shrunk significantly",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45358940",
    "title": "Huntington's disease treated for first time",
    "url": "https://www.bbc.com/news/articles/cevz13xkxpro",
    "summary": "生成摘要时出错",
    "chinese_title": "Huntington's disease treated for first time",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "45387000",
    "title": "Proton Mail Rebuilds Mobile Apps from Scratch, Adds Offline Mode",
    "url": "https://cyberinsider.com/proton-mail-rebuilds-mobile-apps-from-scratch-adds-offline-mode/",
    "summary": "生成摘要时出错",
    "chinese_title": "Proton Mail Rebuilds Mobile Apps from Scratch, Adds Offline Mode",
    "chinese_summary": "生成摘要时出错"
  }
]