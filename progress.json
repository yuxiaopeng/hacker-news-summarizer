[
  {
    "id": "44962066",
    "title": "Show HN: I was curious about spherical helix, ended up making this visualization",
    "url": "https://visualrambling.space/moving-objects-in-3d/",
    "summary": "This \"Show HN\" post presents an interactive visualization and explanation of how to move objects in 3D space, specifically along a spherical helix path. The author, Damar, takes the reader through a progressive understanding of 3D movement, starting with basic concepts like x, y, and z coordinates and how mathematical functions (parametric equations) can be used to control an object's position over time.\n\nThe article builds from simple examples, demonstrating how to create oscillations along a single axis using cosine functions, then progressing to a 2D circle by coordinating x and y positions with cosine and sine waves. It further evolves into a 2D spiral by multiplying the cosine and sine functions by a factor that increases over time, effectively growing the circle's radius.\n\nFinally, the author introduces the spherical helix, explaining that it requires a z-coordinate and employs sine functions to modulate the growth of the x and y coordinates, creating a helix that wraps around a sphere. The visualization allows users to follow the object's path.\n\nThe post concludes by summarizing that by defining x, y, and z coordinates as functions of time, one can create complex and seemingly chaotic paths that are, in reality, defined by precise mathematical equations. It links to the Wikipedia article on parametric equations for further learning. The author invites readers to follow them on Twitter for more similar articles.\n",
    "chinese_title": "Show HN: 我好奇球形螺旋线，最终做了这个可视化",
    "chinese_summary": "此 \"Show HN\" 帖子展示了一个交互式可视化，并解释了如何在 3D 空间中移动物体，特别是沿着球形螺旋路径移动。作者 Damar 带领读者逐步理解 3D 运动，从基本的 x、y 和 z 坐标等概念开始，以及如何使用数学函数（参数方程）来控制物体随时间变化的位置。\n\n文章从简单的例子开始，演示了如何使用余弦函数在单个轴上创建振荡，然后通过协调 x 和 y 位置与余弦和正弦波来发展成一个 2D 圆。它进一步演变为 2D 螺旋，通过将余弦和正弦函数乘以一个随时间增加的因子，有效地增大圆的半径。\n\n最后，作者介绍了球形螺旋，解释说它需要一个 z 坐标，并使用正弦函数来调节 x 和 y 坐标的增长，从而创建一个环绕球体的螺旋。该可视化允许用户跟随物体的路径。\n\n帖子总结说，通过将 x、y 和 z 坐标定义为时间的函数，可以创建复杂且看似混乱的路径，而这些路径实际上是由精确的数学方程定义的。它链接到维基百科上关于参数方程的文章，以供进一步学习。作者邀请读者在 Twitter 上关注他们，以获取更多类似的文章。"
  },
  {
    "id": "44963594",
    "title": "Crash Cows",
    "url": "https://beza1e1.tuxen.de/lore/crash_cows.html",
    "summary": "In the 1980s, a Soviet computer system routing train cars at a railroad station near Sverdlovsk was experiencing unexplained crashes, always occurring at night. Sergei, a programmer, investigated the issue. He discovered the crashes coincided with shipments of live cattle from northern Ukraine and western Russia destined for a local slaughterhouse.\n\nFurther investigation revealed the cattle were highly contaminated with radiation from the Chernobyl disaster. The proximity of the contaminated train cars to the computer caused random bit flips in the machine's memory, leading to the system failures. The Soviet government planned to mix this contaminated meat with uncontaminated meat from other regions to dilute the radiation levels.\n\nSergei, horrified by this discovery, promptly filed for immigration, recognizing the severity of the situation. The computer crashes eventually ceased as radiation levels decreased naturally over time.\n",
    "chinese_title": "撞牛",
    "chinese_summary": "20世纪80年代，在斯维尔德洛夫斯克附近的一个火车站，一套苏联计算机系统在调度火车车厢时，总是会在夜间发生不明原因的崩溃。程序员谢尔盖调查了这个问题。他发现崩溃与从乌克兰北部和俄罗斯西部运往当地屠宰场的活牛有关。\n\n进一步调查显示，这些牛受到切尔诺贝利灾难的严重辐射污染。受污染的车厢靠近计算机导致机器内存中出现随机位翻转，从而导致系统故障。苏联政府计划将这些受污染的肉与其他地区未受污染的肉混合，以稀释辐射水平。\n\n谢尔盖对此感到震惊，意识到事态严重，立即申请移民。随着辐射水平随时间自然下降，计算机崩溃最终停止。"
  },
  {
    "id": "44962059",
    "title": "Gemma 3 270M re-implemented in pure PyTorch for local tinkering",
    "url": "https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/12_gemma3",
    "summary": "This GitHub repository, \"LLMs-from-scratch\" by rasbt, focuses on re-implementing the Gemma 3 270M model, a powerful language model, in pure PyTorch. The key takeaway is that this re-implementation allows for local experimentation and tinkering with a state-of-the-art language model without the need for complex frameworks or cloud resources.\n\nThe project offers a valuable educational resource for understanding the inner workings of large language models. By providing a clean, PyTorch-based implementation, it simplifies the complexities often associated with LLMs, making it easier for researchers, students, and hobbyists to:\n\n*   **Understand the architecture:** Explore the specific components and configurations of the Gemma 3 270M model.\n*   **Experiment with modifications:** Adapt and modify the model's architecture, training procedures, or inference methods.\n*   **Learn PyTorch:** Gain practical experience with PyTorch by working with a real-world LLM example.\n*   **Run locally:** Execute the model on personal hardware, avoiding the need for expensive cloud infrastructure.\n\nThe repository has garnered significant attention, indicated by the large number of forks (9.3k) and stars (66.2k), highlighting the community's interest in accessible and educational resources for understanding and working with large language models from the ground up.\n",
    "chinese_title": "Gemma 3 270M 的纯 PyTorch 本地调试重制版",
    "chinese_summary": "rasbt 的 GitHub 仓库 \"LLMs-from-scratch\" 专注于用纯 PyTorch 重新实现强大的语言模型 Gemma 3 270M。其主要意义在于，这种重新实现允许在本地进行实验和调整最先进的语言模型，而无需复杂的框架或云资源。\n\n该项目为理解大型语言模型的内部运作提供了宝贵的教育资源。通过提供一个干净的、基于 PyTorch 的实现，它简化了通常与 LLM 相关的复杂性，使研究人员、学生和爱好者更容易：\n\n*   **理解架构：** 探索 Gemma 3 270M 模型的特定组件和配置。\n*   **实验性修改：** 调整和修改模型的架构、训练程序或推理方法。\n*   **学习 PyTorch：** 通过使用实际的 LLM 示例获得 PyTorch 的实践经验。\n*   **本地运行：** 在个人硬件上执行模型，避免对昂贵的云基础设施的需求。\n\n该仓库已引起广泛关注，大量的 Fork (9.3k) 和 Star (66.2k) 表明了社区对易于访问和具有教育意义的资源，以便从头开始理解和使用大型语言模型的兴趣。"
  },
  {
    "id": "44962969",
    "title": "OPA maintainers and Styra employees hired by Apple",
    "url": "https://blog.openpolicyagent.org/note-from-teemu-tim-and-torin-to-the-open-policy-agent-community-2dbbfe494371",
    "summary": "Here's a summary of the Open Policy Agent (OPA) blog post:\n\nThe post is a message from Teemu Mäki-Hokkonen, Tim Hinrichs, and Torin Sandall, key contributors and maintainers of the Open Policy Agent (OPA) project, to the OPA community. They announce their departure from Styra, the company they co-founded and which heavily supports OPA development, to join Apple.\n\nThe main point of the announcement is to reassure the OPA community that this change will not negatively impact the project. They emphasize their continued commitment to OPA and its open-source nature. They state that they will continue to be involved with OPA development and community engagement, albeit in a new capacity at Apple.\n\nThey highlight that Styra remains committed to OPA and that the company's ongoing investment in the project will ensure its continued growth and success. They acknowledge Styra's significant contributions to OPA and express confidence in the existing Styra team's ability to continue driving the project forward.\n\nIn short, the announcement is about key OPA figures moving to Apple while emphasizing the continued health and stability of the OPA project thanks to ongoing commitment from themselves and Styra. They reassure the community that OPA remains a priority.\n",
    "chinese_title": "OPA维护者和Styra雇员被苹果公司聘用",
    "chinese_summary": "以下是Open Policy Agent (OPA) 博客文章的摘要：\n\n这篇文章是Open Policy Agent (OPA) 项目的主要贡献者和维护者 Teemu Mäki-Hokkonen, Tim Hinrichs 和 Torin Sandall 写给OPA社区的消息。他们宣布将离开他们共同创立并大力支持OPA开发的Styra公司，加入苹果公司。\n\n该公告的主要目的是让OPA社区放心，这一变化不会对该项目产生负面影响。他们强调了他们对OPA及其开源性质的持续承诺。他们表示，他们将继续参与OPA的开发和社区互动，尽管是以苹果公司的新身份。\n\n他们强调Styra仍然致力于OPA，并且该公司对该项目的持续投资将确保其持续增长和成功。他们承认Styra对OPA的重大贡献，并对现有Styra团队继续推动该项目前进的能力表示信心。\n\n简而言之，该公告是关于OPA的关键人物加入苹果公司，同时强调OPA项目的持续健康和稳定，这要归功于他们自己和Styra的持续承诺。他们向社区保证OPA仍然是首要任务。"
  },
  {
    "id": "44962869",
    "title": "Closer to the Metal: Leaving Playwright for CDP",
    "url": "https://browser-use.com/posts/playwright-to-cdp",
    "summary": "In this blog post from August 20, 2025, Nick Sweeting discusses the decision to move away from Playwright for AI browser automation and adopt the Chrome DevTools Protocol (CDP) directly. The article argues that while Playwright and similar libraries are useful for simplifying QA and automation scripts, they can obscure important details about browser behavior, a critical issue for AI browser agents.\n\nThe author explains that using raw CDP offers increased speed for element extraction and screenshots, as well as new asynchronous reaction capabilities and cross-origin iframe support. Playwright's architecture introduces a second network hop via a Node.js server, adding latency.\n\nThe post then presents a brief history of browser automation, from PhantomJS to modern tools like Puppeteer, Playwright, and Selenium. It details how Playwright works, highlighting its client-server model and potential drawbacks like state inconsistencies between the browser, Node.js relay, and Python client. Specific \"sharp edges\" of Playwright, such as crashing during full-page screenshots and difficulties with handling alerts, file uploads, and crashed tabs, are also mentioned.\n\nFinally, the article delves into case studies of changes implemented with the CDP switch, including the development of the `cdp-use` library for Python type bindings and a new event-driven architecture powered by `bubus` to monitor CDP events. This event-driven architecture allows the agent to react to spontaneous events like downloads or crashes without scattering retry logic throughout the code. The creation of \"super-selectors\" for DOM nodes is introduced to properly handle elements across targets and frames.\n",
    "chinese_title": "更贴近底层：放弃Playwright，选择CDP",
    "chinese_summary": "在2025年8月20日的这篇博文中，Nick Sweeting讨论了放弃Playwright进行AI浏览器自动化，转而直接采用Chrome DevTools协议（CDP）的决定。文章认为，虽然Playwright和类似的库对于简化QA和自动化脚本很有用，但它们可能会掩盖关于浏览器行为的重要细节，而这对于AI浏览器代理来说是一个关键问题。\n\n作者解释说，使用原始CDP可以提高元素提取和屏幕截图的速度，以及提供新的异步反应能力和跨域iframe支持。Playwright的架构通过Node.js服务器引入了第二个网络跃点，增加了延迟。\n\n文章随后简要介绍了浏览器自动化的历史，从PhantomJS到Puppeteer、Playwright和Selenium等现代工具。它详细介绍了Playwright的工作原理，强调了其客户端-服务器模型以及潜在的缺点，例如浏览器、Node.js中继和Python客户端之间的状态不一致。文章还提到了Playwright的特定“尖锐问题”，例如在全页屏幕截图期间崩溃以及处理警报、文件上传和崩溃选项卡的困难。\n\n最后，文章深入探讨了使用CDP切换后实施的变更的案例研究，包括开发用于Python类型绑定的`cdp-use`库以及由`bubus`驱动的新事件驱动架构，以监视CDP事件。这种事件驱动的架构使代理能够对自发事件（如下载或崩溃）做出反应，而无需在整个代码中分散重试逻辑。文章还介绍了用于DOM节点的“超级选择器”的创建，以正确处理跨目标和框架的元素。"
  },
  {
    "id": "44963724",
    "title": "An Update on Pytype",
    "url": "https://github.com/google/pytype",
    "summary": "Pytype, a Python type checker developed at Google, will no longer be supported after Python 3.12. Originally created in 2012 to provide compile-time checking for Google's Python developers, pytype has relied on a bytecode-based design that has proven difficult to maintain and adapt to new typing features and PEPs due to the inherent instability of bytecode.\n\nInstead of continuing pytype's development, Google will shift its focus to exploring new typing approaches and frameworks better aligned with the needs of its Python user base. The announcement emphasizes the robustness of the current Python typing ecosystem, recommending users investigate alternative solutions such as mypy, pyright, and others.\n\nThe team expresses gratitude to all contributors, especially Rebecca Chen, Martin DeMello, Teddy Sudol, and Matthias Kramm, for their work on pytype. Rebecca Chen is particularly acknowledged for her significant contributions to Python's type system through her involvement with the typing council. While pytype's development is ending, Google remains committed to the Python typing space.\n",
    "chinese_title": "Pytype 更新",
    "chinese_summary": "谷歌开发的Python类型检查器Pytype将在Python 3.12之后停止支持。Pytype最初于2012年创建，旨在为谷歌的Python开发者提供编译时检查，但由于字节码固有的不稳定性，其基于字节码的设计已被证明难以维护和适应新的类型特性和PEP。\n\n谷歌将不再继续开发Pytype，而是将重点转移到探索新的类型方法和框架，以更好地满足其Python用户群的需求。该公告强调了当前Python类型生态系统的稳健性，建议用户研究诸如mypy、pyright等替代解决方案。\n\n该团队对所有贡献者表示感谢，特别是Rebecca Chen、Martin DeMello、Teddy Sudol和Matthias Kramm对Pytype所做的工作。Rebecca Chen因其参与类型委员会，为Python类型系统做出的重大贡献而受到特别表彰。虽然Pytype的开发即将结束，但谷歌仍然致力于Python类型领域。"
  },
  {
    "id": "44963693",
    "title": "14.ai (YC W24) is hiring eng (TS/Effect) in SF to build the AI-native Zendesk",
    "url": "https://14.ai/careers",
    "summary": "14.ai (YC W24), building an AI-native Zendesk, is hiring a Founding Engineer in San Francisco. They are a small, customer-focused team that values security, reliability, performance, and pragmatism. Their customers range from startups to enterprises. They are backed by Y Combinator, SV Angel, basecase, and founders of companies like Vercel, Slack, Dropbox, Replit, and Algolia.\n\nThe Founding Engineer will directly engage with customers and work across their entire stack, which includes TypeScript, Postgres, Vite, Next.js, and Effect. The work involves areas like concurrent systems, modular service infrastructure, agent orchestration, text processing, RAG, database optimization, LLM engineering, telemetry, and CI/CD.\n\nRequirements include strong experience in web technologies, particularly JavaScript/TypeScript, and shipping code to production. A passion for building products from the ground up and a desire to join a founding team are essential. The role is based in San Francisco, or requires relocation. Bonus points for experience deploying LLMs to production and prior experience founding a company or building a high-impact project.\n",
    "chinese_title": "14.ai (YC W24) 正在旧金山招聘工程师（技术支持/效果），打造 AI 原生的 Zendesk。",
    "chinese_summary": "14.ai (YC W24) 正在招聘创始工程师，地点位于旧金山。他们正在构建一个 AI 原生的 Zendesk。他们是一支小型的、以客户为中心的团队，重视安全性、可靠性、性能和实用主义。他们的客户范围从初创公司到企业。他们获得了 Y Combinator、SV Angel、basecase 以及 Vercel、Slack、Dropbox、Replit 和 Algolia 等公司创始人的支持。\n\n创始工程师将直接与客户互动，并参与整个技术栈的工作，包括 TypeScript、Postgres、Vite、Next.js 和 Effect。工作涉及并发系统、模块化服务基础设施、代理编排、文本处理、RAG、数据库优化、LLM 工程、遥测和 CI/CD 等领域。\n\n要求包括扎实的 Web 技术经验，尤其是 JavaScript/TypeScript，以及将代码发布到生产环境的经验。对从头开始构建产品充满热情，并渴望加入创始团队至关重要。该职位位于旧金山，或需要搬迁。具备将 LLM 部署到生产环境的经验以及之前创立公司或构建高影响力项目的经验者优先考虑。"
  },
  {
    "id": "44961847",
    "title": "Improvements to OCaml code editing: the basics of a refactor engine",
    "url": "https://tarides.com/blog/2025-08-20-internship-report-refactoring-tools-coming-to-merlin/",
    "summary": "This article summarizes an internship project focused on improving OCaml code editing through refactoring tools, specifically within the Merlin editor. The core contribution is the implementation of an \"expression extraction to toplevel\" refactoring command. This command allows developers to select an expression within their code and automatically move it into a newly generated `let` binding at the top level of the scope.\n\nThe article demonstrates the command's functionality with examples, including extracting constants, expressions (handling potential side effects by using thunks), and expressions dependent on variables. In the latter case, the tool intelligently identifies free variables and creates a function with those variables as arguments. A real-world scenario is also showcased, involving the extraction of markup pretty print logic.\n\nThe article explains how the command is integrated into editors via the Language Server Protocol (LSP) using both code actions (simpler, more universal) and custom requests (for features like custom name input). The next steps involve creating a refactoring toolbox library within Merlin for building more refactoring actions. Several pull requests related to the implementation are also mentioned. Finally, the article thanks contributors and promotes Tarides' open-source efforts and commercial opportunities.\n",
    "chinese_title": "OCaml 代码编辑改进：重构引擎基础",
    "chinese_summary": "本文总结了一个实习项目，该项目专注于通过重构工具，特别是Merlin编辑器中的重构工具，来改进OCaml代码编辑。核心贡献是实现了“表达式提取到顶层”的重构命令。该命令允许开发者选择代码中的一个表达式，并自动将其移动到作用域顶层新生成的`let`绑定中。\n\n本文通过示例演示了该命令的功能，包括提取常量、表达式（通过使用thunk来处理潜在的副作用）以及依赖于变量的表达式。在后一种情况下，该工具智能地识别自由变量，并创建一个以这些变量为参数的函数。文章还展示了一个真实场景，涉及提取标记漂亮打印逻辑。\n\n本文解释了如何通过语言服务器协议 (LSP) 将该命令集成到编辑器中，既使用了代码操作（更简单、更通用），也使用了自定义请求（用于自定义名称输入等功能）。下一步是在Merlin中创建一个重构工具箱库，用于构建更多的重构操作。文章还提到了与实现相关的几个拉取请求。最后，文章感谢了贡献者，并推广了Tarides的开源工作和商业机会。"
  },
  {
    "id": "44963135",
    "title": "Show HN: Luminal – Open-source, search-based GPU compiler",
    "url": "https://github.com/luminal-ai/luminal",
    "summary": "Luminal is an open-source, search-based GPU compiler and deep learning library written in Rust, aiming for high performance and simplicity. Its core is built around 12 primitive ops, compiled into complex GPU kernels for speed. It uses search-based compilation to discover optimizations, including things like Flash Attention, automatically. This approach allows it to remain small and potentially outperform larger frameworks with hand-written kernels.\n\nLuminal emphasizes ahead-of-time compilation, similar to XLA and tinygrad, where the entire neural network is represented as a static computation graph. This enables global knowledge for compilers, facilitating aggressive kernel fusion, shape-specific kernels, and device/datatype handling through compilers.\n\nCurrently, Luminal supports Metal and CUDA for Macs and Nvidia GPUs, with both full and half precision. Full training support with graph-based autograd is available. Examples include implementations of Llama 3, Phi 3, Whisper, and Yolo v8.\n\nThe project is undergoing a transition to \"2.0,\" which introduces large-scale kernel search, simplifying the compiler stack. The roadmap includes expanding the search space, improving CUDA parity with Metal, adding Blackwell intrinsics, building a ROCm backend, benchmarking against other libraries, and implementing distributed data/pipeline/tensor parallelism. The goal is to surpass PyTorch 2.0 performance on LLM inference and training. Luminal is licensed under Apache 2.0 or MIT.\n",
    "chinese_title": "Show HN: Luminal – 开源的、基于搜索的 GPU 编译器",
    "chinese_summary": "Luminal：一个基于搜索的 Rust 开源 GPU 编译器和深度学习库，旨在实现高性能和简洁性。它的核心围绕 12 个原始操作构建，编译成复杂的 GPU 内核以提高速度。它使用基于搜索的编译来发现优化，包括像 Flash Attention 这样的技术，并且是自动化的。 这种方法使其保持小巧，并有可能胜过具有手写内核的较大框架。\n\nLuminal 强调提前编译，类似于 XLA 和 tinygrad，其中整个神经网络表示为一个静态计算图。这使得编译器能够获得全局知识，从而促进积极的内核融合、特定于形状的内核，以及通过编译器处理设备/数据类型。\n\n目前，Luminal 支持 Mac 和 Nvidia GPU 的 Metal 和 CUDA，支持全精度和半精度。提供基于图的自动微分的完整训练支持。示例包括 Llama 3、Phi 3、Whisper 和 Yolo v8 的实现。\n\n该项目正在过渡到“2.0”，这将引入大规模内核搜索，从而简化编译器堆栈。路线图包括扩展搜索空间、提高 CUDA 与 Metal 的对等性、添加 Blackwell 内在函数、构建 ROCm 后端、与其他库进行基准测试，以及实现分布式数据/流水线/张量并行性。目标是在 LLM 推理和训练方面超越 PyTorch 2.0 的性能。Luminal 在 Apache 2.0 或 MIT 许可下获得许可。"
  },
  {
    "id": "44960316",
    "title": "Tidewave Web: in-browser coding agent for Rails and Phoenix",
    "url": "https://tidewave.ai/blog/tidewave-web-phoenix-rails",
    "summary": "Tidewave Web is a new in-browser coding agent designed to streamline web development for Rails and Phoenix applications. Unlike traditional coding agents, Tidewave operates directly within the developer's environment, providing shared context by understanding the UI state, framework, and code. This eliminates the constant back-and-forth and translation required with other AI tools.\n\nKey features include: direct access to UI state and mapping to code, deep integration with Rails/Phoenix allowing code execution, database queries, and log monitoring; collaborative browser testing with a point-and-click interface; and easy integration by adding a package and connecting a GitHub Copilot or Anthropic account.\n\nThe core benefit of Tidewave is its ability to create a shared context between the developer, the AI agent, and the web application. This allows the agent to handle tedious tasks, like generating CSV export features, by automatically querying the database, accessing models, and testing in the browser.\n\nTidewave Web is available as a package for Rails and Phoenix, requiring a Copilot subscription or Anthropic API key. A free trial is available, with a paid subscription unlocking unlimited messages. The initial release focuses on web app integration, with React support and other frameworks like Django, Flask, and Next.js on the roadmap.\n\nDashbit, the creators of Tidewave, envision a future where AI developer tools are tailored to specific domains, understanding their unique runtimes and workflows. Tidewave Web is the first step in that direction.\n",
    "chinese_title": "潮汐波Web：Rails和Phoenix的浏览器内编码助手",
    "chinese_summary": "Tidewave Web是一款全新的浏览器内编码助手，旨在简化Rails和Phoenix应用程序的Web开发。与传统的编码助手不同，Tidewave直接在开发者的环境中运行，通过理解UI状态、框架和代码来提供共享上下文。这消除了与其他AI工具之间反复的沟通和翻译。\n\n主要功能包括：直接访问UI状态并映射到代码；与Rails/Phoenix深度集成，允许代码执行、数据库查询和日志监控；通过点击界面进行协作式浏览器测试；以及通过添加软件包并连接GitHub Copilot或Anthropic帐户轻松集成。\n\nTidewave的核心优势在于它能够在开发者、AI助手和Web应用程序之间创建共享上下文。这使得助手能够处理繁琐的任务，例如生成CSV导出功能，方法是自动查询数据库、访问模型并在浏览器中进行测试。\n\nTidewave Web以Rails和Phoenix软件包的形式提供，需要Copilot订阅或Anthropic API密钥。提供免费试用版，付费订阅可解锁无限消息。初始版本侧重于Web应用程序集成，React支持以及Django、Flask和Next.js等其他框架也已列入路线图。\n\nTidewave的创建者Dashbit设想未来AI开发者工具将针对特定领域进行定制，了解其独特的运行时和工作流程。Tidewave Web是朝着这个方向迈出的第一步。"
  },
  {
    "id": "44957443",
    "title": "AGENTS.md – Open format for guiding coding agents",
    "url": "https://agents.md/",
    "summary": "AGENTS.md is a new open format designed to provide coding agents with the detailed instructions they need to effectively work on a project, complementing the human-focused information found in README.md. It aims to provide a clear, predictable location for build steps, testing procedures, code conventions, and other agent-specific guidance that might be too detailed or irrelevant for a typical README.\n\nThe core benefits of AGENTS.md are providing precise instructions for AI coding agents, keeping README files concise, and ensuring compatibility with a growing ecosystem of AI tools (like Codex, AmpJules, Cursor, and Factory). It is designed to work across many agents, ensuring a single definition can be utilized by various tools.\n\nAGENTS.md files are simple Markdown, allowing for flexible structuring. Best practices involve adding sections for project overview, build and test commands, code style, testing, and security considerations. For large monorepos, nested AGENTS.md files in subprojects are supported, with the closest file taking precedence.\n\nThe AGENTS.md project emerged from collaboration between OpenAI, Google, Cursor, and Factory, and it is committed to maintaining and evolving it as an open format for the entire developer community. Agents will attempt to automatically execute relevant programmatic checks and fix failures before finishing a task if the testing commands are listed in the AGENTS.md file.\n",
    "chinese_title": "AGENTS.md – 指导代码代理的开放格式",
    "chinese_summary": "AGENTS.md 是一种新的开放格式，旨在为编码代理提供详细的指令，使其能够有效地处理项目，补充 README.md 中以人为本的信息。它旨在为构建步骤、测试程序、代码约定和其他代理特定的指南提供清晰、可预测的位置，这些指南可能对于典型的 README 来说过于详细或无关紧要。\n\nAGENTS.md 的核心优势在于为 AI 编码代理提供精确的指令，保持 README 文件的简洁，并确保与不断增长的 AI 工具生态系统（如 Codex、AmpJules、Cursor 和 Factory）的兼容性。它旨在跨多个代理工作，确保单个定义可以被各种工具使用。\n\nAGENTS.md 文件是简单的 Markdown，允许灵活的结构化。最佳实践包括添加项目概述、构建和测试命令、代码风格、测试和安全考虑等部分。对于大型单体仓库，支持子项目中嵌套的 AGENTS.md 文件，以最接近的文件为优先。\n\nAGENTS.md 项目源于 OpenAI、Google、Cursor 和 Factory 之间的合作，并致力于将其维护和发展成为整个开发者社区的开放格式。如果 AGENTS.md 文件中列出了测试命令，代理将在完成任务之前尝试自动执行相关的程序检查并修复故障。"
  },
  {
    "id": "44943666",
    "title": "How to Think About GPUs",
    "url": "https://jax-ml.github.io/scaling-book/gpus/",
    "summary": "This article provides a deep dive into the architecture and function of NVIDIA GPUs, particularly focusing on their use in machine learning. It compares GPUs, like the H100 and B200, to Google's TPUs, highlighting the similarities and differences.\n\nGPUs consist of Streaming Multiprocessors (SMs), each containing a Tensor Core (for matrix multiplication), a Warp Scheduler (vector arithmetic unit), and fast on-chip cache (SMEM). Unlike TPUs, GPUs have many (over 100) relatively independent SMs, allowing for parallel task execution. Each SM is further divided into subpartitions, including CUDA Cores (ALUs) for vector operations and the Tensor Core for dominant FLOPs performance.\n\nThe article details the memory hierarchy, from Registers within each subpartition, SMEM, L2 Cache shared by all SMs, and finally HBM (main GPU memory). It explains how CUDA Cores operate on a SIMT model, providing flexibility at the cost of potential performance degradation if warps diverge.\n\nThe piece includes a table summarizing specs of various GPU generations (V100, A100, H100, H200, B200), covering SM counts, memory capacities, and FLOPs/bandwidth numbers.  It also provides a comparative overview of GPU and TPU components, underscoring the modularity of GPUs versus the integrated design of TPUs. Finally, it notes that GPUs offer generality while TPUs offer performance. The article concludes with a quiz.\n",
    "chinese_title": "如何思考GPU",
    "chinese_summary": "本文深入探讨了英伟达GPU的架构和功能，特别关注其在机器学习中的应用。它将H100和B200等GPU与谷歌的TPU进行了比较，突出了它们的异同。\n\nGPU由流式多处理器（SM）组成，每个SM包含一个张量核心（用于矩阵乘法）、一个 Warp 调度器（矢量算术单元）和快速片上缓存（SMEM）。与TPU不同，GPU具有许多（超过100个）相对独立的SM，从而可以并行执行任务。每个SM进一步划分为子分区，包括用于矢量运算的CUDA核心（ALU）和用于提供主要FLOPs性能的张量核心。\n\n本文详细介绍了内存层次结构，从每个子分区中的寄存器、SMEM、所有SM共享的L2缓存，到最终的HBM（主GPU内存）。它解释了CUDA核心如何以SIMT模型运行，这种模型提供了灵活性，但如果warps发散，可能会导致性能下降。\n\n文章包含一个表格，总结了各种GPU世代（V100、A100、H100、H200、B200）的规格，涵盖了SM数量、内存容量以及FLOPs/带宽数字。它还提供了GPU和TPU组件的比较概述，强调了GPU的模块化与TPU的集成设计。最后，它指出GPU提供通用性，而TPU提供性能。文章最后附有测验。"
  },
  {
    "id": "44963430",
    "title": "Digg.com Is Back",
    "url": "https://www.digg.com/",
    "summary": "Digg.com is relaunching as a community platform focused on human connection. The platform aims to prioritize authentic community experiences and genuine interaction, placing \"humanity at the core\" and leveraging technology to enhance these connections. Unlike its previous iterations, Digg is now adopting a human-first approach to its design and functionality. Currently, access to the platform is invite-only, and prospective users are encouraged to join a waitlist. The emphasis is on building a community from the ground up, with strong consideration for fostering real relationships and meaningful engagement among its members.\n",
    "chinese_title": "Digg.com回归",
    "chinese_summary": "Digg.com重启为社区平台，聚焦人际连接。该平台旨在优先考虑真实的社区体验和真诚的互动，将“人性置于核心”，并利用技术来增强这些连接。与之前的版本不同，Digg现在对其设计和功能采用以人为本的方法。目前，访问该平台仅限邀请，鼓励潜在用户加入等候名单。重点是从头开始构建社区，并高度重视培养其成员之间的真实关系和有意义的互动。"
  },
  {
    "id": "44962767",
    "title": "Show HN: What country you would hit if you went straight where you're pointing",
    "url": "https://apps.apple.com/us/app/leascope/id6608979884",
    "summary": "This \"Show HN\" post promotes a free educational app called \"What country you would hit if you went straight where you're pointing.\" The app, developed by Ben Gross, uses historical map data from André Ourednik's Historical Basemaps project to determine the country you would reach if you traveled in a straight line from your current location.\n\nThe app is available for iPhone, iPad, Mac (with Apple M1 chip or later), and Apple Vision and requires iOS 17.5, iPadOS 17.5, macOS 14.5, or visionOS 1.2 or later. It's a small download (14.7 MB) and is rated 4+ for age appropriateness.\n\nA key selling point is that the developer, Ben Gross, explicitly states the app does not collect any user data, addressing privacy concerns. The app description highlights \"general improvements\" in the latest version (2.5). The post also includes links to App Support and the Privacy Policy. Finally, it suggests other similar apps that users might find interesting.\n",
    "chinese_title": "Show HN: 如果你朝你指的方向一直走，你会到达哪个国家？",
    "chinese_summary": "这款“Show HN”帖子推广一款名为“笔直走会撞到哪个国家？”的免费教育应用。该应用由Ben Gross开发，利用André Ourednik的Historical Basemaps项目中的历史地图数据，确定你从当前位置直线行走会到达的国家。\n\n该应用适用于iPhone、iPad、Mac（配备Apple M1芯片或更高版本）和Apple Vision，需要iOS 17.5、iPadOS 17.5、macOS 14.5或visionOS 1.2或更高版本。它下载量很小（14.7 MB），年龄适宜性评级为4+。\n\n一个关键的卖点是开发者Ben Gross明确声明该应用不收集任何用户数据，解决了隐私问题。应用描述强调了最新版本（2.5）中的“通用改进”。该帖子还包含应用支持和隐私政策的链接。最后，它还推荐了用户可能感兴趣的其他类似应用。"
  },
  {
    "id": "44939456",
    "title": "MapLibre Tile: A next generation geospatial format optimized for rendering",
    "url": "https://arxiv.org/abs/2508.10791",
    "summary": "This arXiv article introduces MapLibre Tile (MLT), a new vector tile format designed to improve upon the existing Mapbox Vector Tile (MVT) format. The authors, Markus Tremmel and Roland Zink, argue that MVT, while widely adopted, is outdated and doesn't fully leverage advancements in geospatial data acquisition and processing.\n\nMLT is presented as a ground-up redesign addressing MVT's limitations. The paper highlights key benefits demonstrated through experiments simulating user sessions on basemap datasets. These benefits include significantly improved compression ratios (up to three times better on encoded tilesets, and over six times better on large tiles) and faster decoding speeds (up to three times faster) compared to MVT. The format also enhances processing performance.\n\nBeyond performance improvements, MLT introduces new functionalities and is designed to support the next generation of map renderers, aiming to offload processing to the GPU. This shift is intended to overcome limitations imposed by the slowing pace of Moore's Law.\n\nThe article is categorized under Information Theory (cs.IT) and provides links to download the paper in PDF and HTML formats, along with a BibTeX citation. It also includes links to various external tools for exploring related research, code repositories, and interactive demos.\n",
    "chinese_title": "MapLibre瓦片：一种为渲染优化的下一代地理空间格式",
    "chinese_summary": "本文介绍了一种新的矢量瓦片格式 MapLibre Tile (MLT)，旨在改进现有的 Mapbox Vector Tile (MVT) 格式。作者 Markus Tremmel 和 Roland Zink 认为，MVT 虽然已被广泛采用，但已过时，未能充分利用地理空间数据获取和处理方面的进步。\n\nMLT 被认为是针对 MVT 局限性的彻底重新设计。该论文重点介绍了通过模拟用户在底图数据集上的会话实验所展示的关键优势。这些优势包括显著提高的压缩率（编码瓦片集上高达三倍，大型瓦片上超过六倍）和更快的解码速度（高达三倍），与 MVT 相比。该格式还增强了处理性能。\n\n除了性能改进之外，MLT 还引入了新功能，并旨在支持下一代地图渲染器，旨在将处理任务转移到 GPU。这种转变旨在克服摩尔定律放缓带来的限制。\n\n本文归类于信息论 (cs.IT)，并提供 PDF 和 HTML 格式的论文下载链接以及 BibTeX 引用。它还包括各种外部工具的链接，用于探索相关研究、代码存储库和交互式演示。"
  },
  {
    "id": "44939874",
    "title": "Show HN: Strudel Flow, a pattern sequencer built with Strudel and React Flow",
    "url": "https://github.com/xyflow/strudel-flow",
    "summary": "Strudel Flow is a visual drum machine and pattern sequencer built using Strudel.cc, React Flow, Tailwind CSS, and shadcn/ui. It allows users to create complex musical patterns by connecting instrument nodes to effect nodes using a drag-and-drop interface.\n\nKey features include a variety of node types: instruments (Pad Node, Beat Machine, Arpeggiator, Chord Node, Polyrhythm, Custom Node), synths (Drum Sounds, Sample Select), and audio effects (Gain, PostGain, Distortion, LPF, Pan, Phaser, Crush, Jux, FM, Room) and time effects (Fast, Slow, Late, Attack, Release, Sustain, Reverse, Palindrome, Mask, Ply).\n\nUsers can create patterns by activating steps within nodes, adjusting tempo, applying row modifiers for step-specific effects, and chaining nodes together. Step modifiers include options for speed manipulation (Fast, Slow), repetition (Replicate), and duration extension (Elongate).\n\nThe application offers performance controls such as global play/pause (spacebar), independent group controls, live pattern editing with real-time updates, and pattern preview displaying the generated Strudel code. Keyboard shortcuts streamline the workflow.\n\nThe project is structured into `components`, `nodes` (including `instruments`, `effects`, and `synths`), `ui`, `workflow`, `edges`, `data`, `hooks`, `lib`, `store`, and `types` directories. It leverages Strudel.cc for its audio engine, React Flow for the visual node-based interface, shadcn CLI for UI components, and Zustand for state management.\n",
    "chinese_title": "Show HN: Strudel Flow，一个用 Strudel 和 React Flow 构建的模式音序器",
    "chinese_summary": "Strudel Flow 是一个可视化鼓机和音序器，它使用 Strudel.cc、React Flow、Tailwind CSS 和 shadcn/ui 构建。它允许用户通过拖放界面连接乐器节点和效果节点来创建复杂的音乐模式。\n\n主要功能包括各种节点类型：乐器（Pad 节点、节拍机、琶音器、和弦节点、复节奏、自定义节点）、合成器（鼓声、采样选择）和音频效果（增益、后增益、失真、低通滤波器、声像、相位器、压缩、Jux、FM、房间）以及时间效果（快、慢、延迟、启动、释放、延音、反向、回文、遮罩、层叠）。\n\n用户可以通过激活节点内的步进、调整速度、应用行修饰符来实现步进特定的效果以及将节点链接在一起来创建模式。步进修饰符包括速度控制选项（快、慢）、重复（复制）和持续时间扩展（延长）。\n\n该应用程序提供诸如全局播放/暂停（空格键）、独立组控制、实时模式编辑（实时更新）和显示生成的 Strudel 代码的模式预览等性能控制。键盘快捷键简化了工作流程。\n\n该项目被组织成 `components`、`nodes`（包括 `instruments`、`effects` 和 `synths`）、`ui`、`workflow`、`edges`、`data`、`hooks`、`lib`、`store` 和 `types` 目录。它利用 Strudel.cc 作为其音频引擎，React Flow 用于可视化基于节点的界面，shadcn CLI 用于 UI 组件，Zustand 用于状态管理。"
  },
  {
    "id": "44963226",
    "title": "Show HN: Anchor Relay – A faster, easier way to get Let's Encrypt certificates",
    "url": "https://anchor.dev/relay",
    "summary": "Anchor Relay aims to simplify and secure the process of obtaining Let's Encrypt certificates, particularly for homelabs, self-hosted environments, untrusted networks (like IoT), and internal networks. It offers a faster and easier approach to browser-trusted HTTPS certificates.\n\nKey features include acting as an ACME API front for Let's Encrypt, handling DNS delegation for challenge records, and providing fine-grained access control. A major benefit is eliminating the need to expose port 80 or forward HTTP traffic for certificate validation, instead relying on outbound-only connections. This enhances security and reduces complexity.\n\nAnchor Relay is designed for developers and users who want to secure their services without exposing their infrastructure directly to the internet or managing API credentials across multiple tools. It integrates seamlessly with popular tools like Certbot and Caddy, making the transition and usage effortless. By requiring only a one-time DNS configuration, Anchor Relay simplifies the management of certificates and enhances security.\n",
    "chinese_title": "Show HN: Anchor Relay – 更快更便捷地获取 Let's Encrypt 证书",
    "chinese_summary": "Anchor Relay旨在简化并安全化获取Let's Encrypt证书的流程，尤其适用于家庭实验室、自托管环境、不可信网络（如物联网）和内部网络。它为浏览器信任的HTTPS证书提供了一种更快更简便的方法。\n\n其主要功能包括作为Let's Encrypt的ACME API前端、处理挑战记录的DNS委派以及提供细粒度的访问控制。一个主要优点是无需暴露端口80或转发HTTP流量进行证书验证，而是依赖于仅出站连接。这增强了安全性并降低了复杂性。\n\nAnchor Relay专为希望在不将基础设施直接暴露于互联网或跨多个工具管理API凭证的情况下保护其服务的开发者和用户而设计。它与Certbot和Caddy等常用工具无缝集成，使过渡和使用变得轻松。通过仅需要一次性的DNS配置，Anchor Relay简化了证书管理并增强了安全性。"
  },
  {
    "id": "44950972",
    "title": "Ordered Insertion Optimization in OrioleDB",
    "url": "https://www.orioledb.com/blog/batch-inserts",
    "summary": "OrioleDB's new batch page insertion optimization addresses performance bottlenecks caused by multiple sessions attempting to insert data into the same B-tree leaf page, leading to lock contention and inefficient sleep/wake cycles. The core idea is to enable the session holding the page lock to insert data for itself and waiting neighboring sessions, effectively creating a \"group commit\" for page inserts.\n\nInstead of queuing for a lock, waiting processes now publish their intended tuple (key, payload, meta-information) into shared memory and link it to the page's \"wait list.\" The lock holder then scans this list, collects tuples belonging to the page, and inserts them alongside its own, before releasing the lock. This reduces lock handovers as one process performs multiple inserts. Waiting processes upon waking often find their tuple already inserted.\n\nBenchmarks simulating an IoT workload (time-ordered data) demonstrated significant improvements. While OrioleDB beta12 was slower than PostgreSQL with few connections, the batch page insertion optimization boosted performance by almost 2X starting at 64 concurrent connections, significantly reducing lock wait times. The optimization is most effective for workloads with skewed keys, time-based ordering, or append-heavy OLTP scenarios. The optimization will be included in the OrioleDB beta13 release.\n",
    "chinese_title": "OrioleDB中有序插入优化",
    "chinese_summary": "OrioleDB 新批处理页面插入优化解决了多个会话尝试将数据插入到同一 B 树叶子页面时导致的性能瓶颈，从而减少了锁竞争和低效的睡眠/唤醒循环。 其核心思想是允许持有页面锁的会话为自身和等待中的相邻会话插入数据，从而有效地为页面插入创建“组提交”。\n\n等待进程现在不再排队等待锁，而是将其预期元组（键、有效负载、元信息）发布到共享内存并将其链接到页面的“等待列表”。 然后，锁持有者扫描此列表，收集属于该页面的元组，并将其与自己的元组一起插入，然后再释放锁。 这减少了锁的切换，因为一个进程执行多个插入。 等待进程醒来时，通常会发现其元组已被插入。\n\n模拟物联网工作负载（按时间排序的数据）的基准测试表明性能得到了显著提升。 虽然 OrioleDB beta12 在连接数较少时比 PostgreSQL 慢，但从 64 个并发连接开始，批处理页面插入优化将性能提高了近 2 倍，从而显著减少了锁等待时间。 该优化对于具有倾斜键、基于时间的排序或追加繁重的 OLTP 场景的工作负载最为有效。 该优化将包含在 OrioleDB beta13 版本中。"
  },
  {
    "id": "44937819",
    "title": "The Block Stacking Problem",
    "url": "https://sites.pitt.edu/~jdnorton/Goodies/block_stacking/block_stacking.html",
    "summary": "This article, \"The Block Stacking Problem,\" explores the counterintuitive physics of stacking blocks at a table's edge to maximize horizontal extension. The author, John D. Norton, presents three puzzles related to this problem: how a stack can extend beyond the table with the last block unsupported, why there's no limit to this extension with enough blocks, and the paradoxical behavior of an infinite stack.\n\nThe article explains the principles of balance, including moments and center of mass, crucial for understanding the stability of these stacks. It demonstrates that a stack is stable as long as its center of mass is supported by the blocks beneath or the table. The stability of a four-block stack is analyzed step-by-step, showing how each sub-stack's center of mass is positioned for support.\n\nThe article also discusses the general formula for displacement in an n-block stack, confirming that the displacement of the topmost block can be unbounded. Logarithmic approximation offers a simple formula and insights on the fraction of blocks past the table edge and mass distribution.\n\nFinally, the article addresses the \"infinite stack\" puzzle. While finite stacks can extend arbitrarily far, taking the limit to infinity leads to surprising results. Depending on how the limit is approached, the infinite stack either disappears entirely or collapses to a stack that doesn't extend beyond the table edge, contrasting with the expectations based on finite stacks. The author aims to provide an intuitive understanding of the stack's behavior and the peculiarities of dealing with infinity.\n",
    "chinese_title": "堆积木问题",
    "chinese_summary": "本文《积木堆叠问题》探讨了在桌边堆叠积木以最大化水平延伸的反直觉物理现象。作者约翰·D·诺顿提出了与此问题相关的三个谜题：在最后一个积木不受支撑的情况下，堆叠体如何延伸到桌子之外；如果有足够的积木，这种延伸为什么没有限制；以及无限堆叠体的悖论行为。\n\n文章解释了平衡原理，包括力矩和质心，这对于理解这些堆叠体的稳定性至关重要。文章表明，只要堆叠体的质心由下面的积木或桌子支撑，该堆叠体就是稳定的。文章逐步分析了四块积木堆叠体的稳定性，展示了每个子堆叠体的质心是如何定位以获得支撑的。\n\n文章还讨论了n块积木堆叠体中位移的一般公式，证实了最顶层积木的位移可以是无界的。对数近似提供了一个简单的公式，并揭示了积木超出桌子边缘的比例以及质量分布。\n\n最后，文章探讨了“无限堆叠体”的谜题。虽然有限的堆叠体可以任意延伸，但将极限推到无穷大会导致令人惊讶的结果。根据接近极限的方式，无限堆叠体要么完全消失，要么坍塌成一个不延伸到桌子边缘的堆叠体，这与基于有限堆叠体的预期形成对比。作者旨在提供对堆叠体行为以及处理无穷大时特性的直观理解。"
  },
  {
    "id": "44962844",
    "title": "AWS in 2025: The Stuff You Think You Know That's Now Wrong",
    "url": "https://www.lastweekinaws.com/blog/aws-in-2025-the-stuff-you-think-you-know-thats-now-wrong/",
    "summary": "Corey Quinn's article \"AWS in 2025: The Stuff You Think You Know That's Now Wrong\" highlights outdated information cloud professionals might still be using about AWS. He emphasizes that AWS has evolved significantly, and many long-held assumptions are no longer accurate.\n\nThe article details changes across several key AWS services:\n\n*   **EC2:** Security groups and IAM roles can be changed without instance shutdown. Live migration is common. Instance reliability is improved. Spot instance pricing is more stable. Dedicated instances are rarely needed. Public AMI block access is now default.\n*   **S3:** Read-after-write consistency is standard. Object key randomization is unnecessary. ACLs are deprecated. Public access blocking and transparent encryption are default for new buckets. Glacier is integrated into S3 storage classes, and restore fees/speeds are improved.\n*   **Networking:** Public IPv4 addresses now cost money. Better alternatives to VPC peering (Transit Gateway, VPC sharing, etc.) exist. VPC Lattice and Tailscale simplify networking. CloudFront updates are faster. Cross-AZ data transfer fees vary by load balancer type. Network Load Balancers now support security groups. Zone IDs can be aligned with Resource Access Manager.\n*   **Lambda:** Timeouts, container image support, RAM limits, shared storage, and `/tmp` storage have increased. Invoking a Lambda in a VPC is faster, and cold starts are less problematic.\n*   **EFS:** IO performance can be adjusted independent of capacity.\n*   **EBS:** New volumes have full performance. Snapshot restores may be slow on first read. Volumes can be attached to multiple EC2 instances concurrently (io1).\n*   **DynamoDB:** Empty fields are now supported. Performance is more reliable. On-demand pricing is often preferable.\n*   **Cost Savings:** Reserved Instances are being phased out in favor of Savings Plans. EC2 charges by the second. Cost Anomaly Detector is effective and free. Compute Optimizer is trustworthy. Trusted Advisor remains questionable.\n*   **Authentication:** IAM roles are preferred over IAM users. IAM Identity Center replaces AWS SSO.\n*   **Miscellaneous:** us-east-1 is more stable. Deprecations are increasing. CloudWatch data consistency is improved. AWS accounts can be closed from the root organization account.\n\nThe article encourages readers to update their AWS knowledge and avoid relying on outdated practices.\n",
    "chinese_title": "2025年的AWS：你以为你知道，但现在错了的东西",
    "chinese_summary": "Corey Quinn：《2025年的AWS：你以为你知道但现在已经错了的事情》强调了云专业人士可能仍在使用的关于AWS的过时信息。他强调AWS已经发生了重大演变，许多长期存在的假设不再准确。\n\n文章详细介绍了几个关键AWS服务的变化：\n\n*   **EC2：** 安全组和IAM角色可以在不关闭实例的情况下更改。实时迁移很常见。实例可靠性得到提高。Spot实例定价更加稳定。专用实例很少需要。公开AMI阻止访问现在是默认设置。\n*   **S3：** 读取后写入一致性是标准配置。对象键随机化是不必要的。ACL已被弃用。公开访问阻止和透明加密是新存储桶的默认设置。Glacier已集成到S3存储类中，恢复费用/速度得到提高。\n*   **网络：** 公共IPv4地址现在需要付费。存在VPC对等连接的更好替代方案（Transit Gateway、VPC共享等）。VPC Lattice和Tailscale简化了网络。CloudFront更新速度更快。跨可用区数据传输费用因负载均衡器类型而异。网络负载均衡器现在支持安全组。区域ID可以与资源访问管理器对齐。\n*   **Lambda：** 超时、容器镜像支持、RAM限制、共享存储和`/tmp`存储已增加。在VPC中调用Lambda的速度更快，冷启动的问题也更少。\n*   **EFS：** IO性能可以独立于容量进行调整。\n*   **EBS：** 新卷具有完整性能。快照恢复在首次读取时可能很慢。卷可以并发连接到多个EC2实例（io1）。\n*   **DynamoDB：** 现在支持空字段。性能更加可靠。按需定价通常更可取。\n*   **成本节约：** 预留实例正逐步淘汰，取而代之的是Savings Plans。EC2按秒收费。成本异常检测器有效且免费。Compute Optimizer值得信赖。Trusted Advisor仍然存在疑问。\n*   **身份验证：** IAM角色优先于IAM用户。IAM Identity Center取代了AWS SSO。\n*   **杂项：** us-east-1更加稳定。弃用正在增加。CloudWatch数据一致性得到提高。AWS账户可以从根组织账户关闭。\n\n文章鼓励读者更新他们的AWS知识，避免依赖过时的实践。"
  },
  {
    "id": "44939873",
    "title": "Show HN: Typed-arrow – compile‑time Arrow schemas for Rust",
    "url": "https://github.com/tonbo-io/typed-arrow",
    "summary": "`typed-arrow` is a Rust library that provides compile-time Arrow schema definitions, offering a strongly-typed and efficient way to work with Arrow data structures. It leverages Rust's type system to map Rust types directly to arrow-rs builders and arrays, avoiding runtime DataType switching and enabling monomorphized column construction for improved performance.\n\nKey features and benefits include:\n\n*   **Compile-time safety:** Type mismatches are caught during compilation, ensuring data integrity.\n*   **Performance:** Zero runtime dynamic dispatch due to monomorphization.\n*   **Interoperability:** Direct usage of `arrow-array` and `arrow-schema` types.\n*   **ORM-like APIs:** Provides ergonomic ways to build and manipulate Arrow data.\n*   **Record derive macro:** Simplifies schema creation for structs with named fields.\n*   **Support for nested types:** Handles Lists, Structs, Maps, and Unions.\n*   **Dictionary encoding:** Offers dictionary columns with various key and value types.\n*   **Timestamp handling:** Supports timestamps with and without timezones.\n*   **Metadata support:** Allows adding schema-level and field-level metadata.\n*   **Comprehensive data type coverage:** Supports a wide range of Arrow data types, including primitives, strings/binary, temporal types, decimals, and nested structures.\n\nThe library offers several examples demonstrating its usage, covering various data types and scenarios. It uses traits like `Record`, `ColAt`, `ArrowBinding`, `BuildRows`, and `SchemaMeta` for schema definition and data manipulation.\n",
    "chinese_title": "Show HN: Typed-arrow – Rust 的编译时 Arrow schema",
    "chinese_summary": "`typed-arrow` 是一个 Rust 库，它提供编译时 Arrow schema 定义，从而提供了一种强类型且高效的方式来处理 Arrow 数据结构。 它利用 Rust 的类型系统将 Rust 类型直接映射到 arrow-rs builders 和 arrays，避免了运行时 DataType 切换，并实现了单态化列构造，从而提高了性能。\n\n主要特性和优点包括：\n\n*   **编译时安全：** 类型不匹配在编译期间被捕获，确保数据完整性。\n*   **性能：** 由于单态化，零运行时动态分发。\n*   **互操作性：** 直接使用 `arrow-array` 和 `arrow-schema` 类型。\n*   **ORM 类似 API：** 提供符合人体工程学的方式来构建和操作 Arrow 数据。\n*   **Record derive 宏：** 简化了具有命名字段的结构体的 schema 创建。\n*   **支持嵌套类型：** 处理列表、结构体、映射和联合体。\n*   **字典编码：** 提供具有各种键和值类型的字典列。\n*   **时间戳处理：** 支持带和不带时区的时间戳。\n*   **元数据支持：** 允许添加 schema 级别和字段级别的元数据。\n*   **全面的数据类型覆盖：** 支持广泛的 Arrow 数据类型，包括原始类型、字符串/二进制类型、时间类型、十进制类型和嵌套结构。\n\n该库提供了几个示例，演示了它的用法，涵盖了各种数据类型和场景。 它使用诸如 `Record`、`ColAt`、`ArrowBinding`、`BuildRows` 和 `SchemaMeta` 等 trait 来进行 schema 定义和数据操作。"
  },
  {
    "id": "44963391",
    "title": "Best Options for Using AI in Chip Design",
    "url": "https://semiengineering.com/best-options-for-using-ai-in-chip-design/",
    "summary": "This Semiconductor Engineering article, \"Best Options For Using AI In Chip Design,\" explores how AI is being implemented in chip design, featuring insights from experts at Cadence, Siemens EDA, Synopsys, Baya Systems, ChipAgents, and Keysight.\n\nThe discussion highlights that narrowly defined verticals, like automotive and high-performance computing, offer the best opportunities for AI in chip design due to their specific requirements. AI's role is evolving, with potential for both short-term productivity gains through debug analysis and longer-term disruptive changes like autonomous workflows. The experts envision a progression from current L1 assistance to fully autonomous L5 workflows, raising questions about the future role of junior engineers.\n\nA key point is the idea of \"EDA tools for agents,\" trained on natural language, which can leverage parallelism and speed more effectively than humans. The conversation delves into making AI-driven tools more \"legible\" to engineers, allowing for efficient review and understanding of AI-generated solutions. This includes providing more information and feedback to engineers during the design process, regardless of experience level.\n\nThe experts also addressed concerns about inexperienced engineers relying too heavily on AI. The consensus is that AI should assist, not replace, human expertise, and that providing knowledge assistants and clear explanations can accelerate learning for junior engineers. The potential for AI to create higher levels of abstraction in design and facilitate better knowledge sharing was also emphasized.\n",
    "chinese_title": "芯片设计中人工智能的最佳选择",
    "chinese_summary": "这篇《半导体工程》文章“在芯片设计中使用人工智能的最佳方案”探讨了人工智能在芯片设计中的应用，并收录了Cadence、Siemens EDA、Synopsys、Baya Systems、ChipAgents和Keysight等公司专家的见解。\n\n讨论强调，像汽车和高性能计算等定义明确的垂直领域，由于其特定的需求，为人工智能在芯片设计中提供了最佳机会。人工智能的角色正在演变，既有潜力通过调试分析获得短期生产力提升，也有可能带来像自主工作流程这样的长期颠覆性变革。专家们设想，从目前的L1辅助发展到完全自主的L5工作流程，引发了人们对初级工程师未来角色的疑问。\n\n一个关键点是“面向代理的EDA工具”的概念，这些工具通过自然语言进行训练，可以比人类更有效地利用并行性和速度。对话深入探讨了如何使人工智能驱动的工具对工程师来说更“易读”，从而可以高效地审查和理解人工智能生成的解决方案。这包括在设计过程中向工程师提供更多信息和反馈，无论经验水平如何。\n\n专家们还探讨了对缺乏经验的工程师过度依赖人工智能的担忧。共识是，人工智能应该辅助，而不是取代人类的专业知识，并且提供知识助手和清晰的解释可以加速初级工程师的学习。人工智能在设计中创建更高层次抽象以及促进更好知识共享的潜力也得到了强调。"
  },
  {
    "id": "44961172",
    "title": "Sequoia Backs Zed's Vision for Collaborative Coding",
    "url": "https://zed.dev/blog/sequoia-backs-zed",
    "summary": "Zed, the developer of the world's fastest IDE, has secured $32M in Series B funding led by Sequoia Capital, bringing their total funding to over $42M. This funding will be used to develop DeltaDB, a new type of operation-based version control system designed to revolutionize collaborative coding with both humans and AI agents.\n\nThe core problem Zed aims to solve is the limitations of current snapshot-based version control systems (like Git) which constrain conversations about code by separating them from the code itself and making them difficult to keep up-to-date. DeltaDB will track every operation, not just commits, using CRDTs to synchronize changes in real-time. This fine-grained change tracking will allow for character-level permalinks, enabling persistent and contextualized discussions directly within the codebase, even across code transformations.\n\nZed envisions an IDE where humans and AI agents can collaborate seamlessly, with all edits, discussions, and insights linked to the evolving code, creating a living history of the software's development. This system will provide AI agents with the context needed to make more informed edits.\n\nDeltaDB will interoperate with Git and, like Zed, will be open-source with an optional paid service. Zed is actively hiring across engineering and product design to bring this collaborative future to life.\n",
    "chinese_title": "红杉资本支持Zed的协作编码愿景",
    "chinese_summary": "世界最快IDE的开发者Zed获红杉资本领投的3200万美元B轮融资，融资总额超过4200万美元。这笔资金将用于开发DeltaDB，一种新型的、基于操作的版本控制系统，旨在革新人类和AI智能体之间的协同编码。\n\nZed旨在解决的核心问题是当前基于快照的版本控制系统（如Git）的局限性，这些局限性通过将代码对话与代码本身分离，并使其难以保持最新状态，从而限制了代码对话。DeltaDB将跟踪每一次操作，而不仅仅是提交，并使用CRDT实时同步更改。这种细粒度的更改跟踪将允许字符级别的永久链接，从而在代码库中直接实现持久的、情境化的讨论，即使跨越代码转换也是如此。\n\nZed设想了一种IDE，人类和AI智能体可以在其中无缝协作，所有编辑、讨论和见解都与不断演进的代码相关联，从而创建软件开发的鲜活历史。该系统将为AI智能体提供做出更明智编辑所需的上下文。\n\nDeltaDB将与Git互操作，并且像Zed一样，将采用开源模式，并提供可选的付费服务。Zed正在积极招聘工程和产品设计方面的人才，以实现这个协作的未来。"
  },
  {
    "id": "44963292",
    "title": "Phone Searches at the US Border Hit a Record High",
    "url": "https://www.wired.com/story/phone-searches-at-the-us-border-hit-a-record-high/",
    "summary": "US Customs and Border Protection (CBP) officials are conducting phone and electronic device searches at the border at record levels. From April to June 2025, CBP searched 14,899 devices, a 16.7% increase over the previous high from January-March 2022. This rise coincides with increased border security measures under the second Trump administration, including a larger budget for Homeland Security and Immigration and Customs Enforcement.\n\nCritics, like the ACLU, express concern that these searches, conducted without warrants, have a chilling effect on travelers, potentially impacting those critical of the administration or professionals with sensitive data. While the CBP argues device searches affect a tiny percentage of travelers (less than 0.01%), concerns remain.\n\nThe article distinguishes between \"basic\" searches, involving manual inspection of a device, and \"advanced\" searches, utilizing forensics tools to extract extensive data. While advanced searches have remained relatively stable, the CBP is seeking to acquire more advanced forensics tools, signaling a potential shift towards more intrusive searches.\n\nTravelers, regardless of citizenship status, can have their devices searched at the border, where Fourth Amendment protections are limited. Refusal to unlock a device can lead to seizure or, for foreign visitors, detention or deportation.\n",
    "chinese_title": "美国边境手机搜查数量创历史新高",
    "chinese_summary": "美国海关与边境保护局（CBP）官员正在边境以前所未有的程度搜查手机和电子设备。2025年4月至6月，CBP搜查了14899台设备，比2022年1月至3月的前一个高峰期增长了16.7%。此次增长与特朗普第二任政府下加强边境安全措施同时发生，包括国土安全部以及移民和海关执法局获得了更大的预算。\n\n包括美国公民自由联盟（ACLU）在内的批评人士表示担忧，这些未经搜查令进行的搜查对旅行者产生了寒蝉效应，可能会影响到那些对政府持批评态度的人士或拥有敏感数据的专业人士。虽然CBP辩称设备搜查仅影响到极小比例的旅行者（不到0.01%），但担忧依然存在。\n\n文章区分了“基本”搜查（涉及手动检查设备）和“高级”搜查（利用取证工具提取大量数据）。虽然高级搜查相对稳定，但CBP正在寻求获得更先进的取证工具，这预示着可能会转向更具侵入性的搜查。\n\n无论公民身份如何，旅行者的设备都可能在边境被搜查，因为第四修正案的保护在那里受到限制。拒绝解锁设备可能导致设备被没收，或者对于外国访客，可能导致拘留或驱逐出境。"
  },
  {
    "id": "44956915",
    "title": "How to Draw a Space Invader",
    "url": "https://muffinman.io/blog/invaders/",
    "summary": "This article details the process of creating a \"Space Invader Generator,\" from its conception as a side project using a 3D vector renderer to its release as a code challenge. The author emphasizes problem-solving before coding, detailing their initial research and hand-drawn pixel art designs. They then explain the algorithm behind the generator, which leverages vector graphics and geometric principles to create unique invaders.\n\nThe generation process involves creating a body polygon by randomly selecting top and bottom points and mirroring generated vertices, adding tentacles and horns using a \"fat line\" algorithm, and then converting the vector shapes into a pixelated form by checking if pixel centers fall within the shapes. Eyes are added from a predefined set, and colors are generated using the OKLCH color space for consistent lightness.\n\nThe article further explains how the invaders are animated by slightly altering tentacle and horn mid-lines and shifting eye positions. The effect of grid size on the invader's appearance is also discussed. Finally, the author touches upon the technical aspects of creating the interactive blog post, including the use of Anime.js for animation and a build process for the JavaScript code. They conclude by encouraging readers to experiment with the generator and check out their previous interactive post about drawing SVG ropes.\n",
    "chinese_title": "如何画太空侵略者",
    "chinese_summary": "本文详细介绍了如何创建“太空侵略者生成器”的过程，从最初设想的利用 3D 向量渲染器的副项目到最终发布为代码挑战。作者强调先解决问题再编写代码，详细介绍了他们的初步研究和手绘像素艺术设计。 然后，他们解释了生成器背后的算法，该算法利用向量图形和几何原理来创建独特的侵略者。\n\n生成过程包括：通过随机选择顶部和底部点并镜像生成的顶点来创建身体多边形；使用“粗线”算法添加触手和角；然后通过检查像素中心是否落在形状内，将矢量形状转换为像素化形式。眼睛从预定义的集合中添加，颜色使用 OKLCH 色彩空间生成，以保持一致的亮度。\n\n文章进一步解释了如何通过稍微改变触手和角的中线以及移动眼睛位置来使侵略者动画化。 还讨论了网格大小对入侵者外观的影响。 最后，作者提到了创建交互式博客文章的技术方面，包括使用 Anime.js 进行动画处理以及 JavaScript 代码的构建过程。 他们最后鼓励读者尝试生成器，并查看他们之前关于绘制 SVG 绳索的互动帖子。"
  },
  {
    "id": "44959833",
    "title": "Mirrorshades: The Cyberpunk Anthology (1986)",
    "url": "https://www.rudyrucker.com/mirrorshades/HTML/",
    "summary": "\"Mirrorshades: The Cyberpunk Anthology\" is a collection of stories representing a new science fiction movement that emerged in the 1980s: Cyberpunk. Edited by Bruce Sterling, the anthology showcases writers who embrace and integrate high technology with modern pop underground culture.\n\nSterling argues that cyberpunk, despite writers' reservations about the label, is a definitive product of the Eighties, deeply rooted in SF tradition while simultaneously reacting against it. Cyberpunk acknowledges precursors from the New Wave and harder SF traditions, emphasizing literary craftsmanship and innovative ideas.\n\nThe \"Mirrorshades\" title is a reference to a movement icon, reflecting the themes of rebellion and technology. Recurring themes within cyberpunk include body and mind invasion through advanced technology, and the integration of technology into daily life. Cyberpunk merges counterculture, technological advancement, and street-level anarchy.\n\nSterling posits that cyberpunk is a pop phenomenon, reflecting the overlapping worlds of hackers and rockers, and integrating technology and counterculture, marking a departure from earlier science fiction's often distanced view of technology. Key characteristics of cyberpunk are its visceral approach to technology, its focus on personal technology, and its fascination with the interzones where street culture adapts technology for its own purposes.\n",
    "chinese_title": "镜面阴影：赛博朋克选集 (1986)",
    "chinese_summary": "《镜面阴影：赛博朋克选集》是一部收录了代表 20 世纪 80 年代兴起的新科幻运动——赛博朋克作品的故事集。该选集由布鲁斯·斯特林编辑，展示了那些拥抱并将高科技与现代流行地下文化相结合的作家。\n\n斯特林认为，尽管作家们对这个标签有所保留，但赛博朋克是八十年代的明确产物，它深深扎根于科幻传统，同时又对它做出反应。赛博朋克承认新浪潮和更硬科幻传统的先驱，强调文学技巧和创新思想。\n\n“镜面阴影”这个标题指的是一种运动标志，反映了叛逆和技术的主题。赛博朋克中反复出现的主题包括通过先进技术对身体和思想的入侵，以及技术融入日常生活。赛博朋克融合了反主流文化、技术进步和街头无政府状态。\n\n斯特林认为，赛博朋克是一种流行现象，反映了黑客和摇滚乐手重叠的世界，并将技术和反主流文化融合在一起，标志着它与早期科幻小说中常常对技术保持距离的观点有所不同。赛博朋克的关键特征是对技术的发自内心的处理方式、对个人技术的关注以及对街头文化为自身目的而改造技术的过渡地带的迷恋。"
  },
  {
    "id": "44959092",
    "title": "Databricks is raising a Series K Investment at >$100B valuation",
    "url": "https://www.databricks.com/company/newsroom/press-releases/databricks-raising-series-k-investment-100-billion-valuation",
    "summary": "Databricks announced it is raising a Series K investment round at a valuation exceeding $100 billion. Existing investors are expected to back the round. The company intends to use the capital to accelerate its AI strategy, specifically expanding Agent Bricks, investing in Lakebase (its new database offering), and fueling global growth.\n\nCEO Ali Ghodsi emphasized the strong investor interest driven by the momentum of Databricks' AI products, which are used by large businesses to create AI apps and agents from their data. The company is seeing unprecedented demand for these AI solutions, transforming data into valuable assets.\n\nThis investment follows recent partnerships with major players like Microsoft, Google Cloud, Anthropic, SAP, and Palantir. Databricks' Data Intelligence Platform, used by over 15,000 customers globally, enables organizations to democratize data access and leverage it for analytics and AI applications. The platform is built on an open-source foundation and helps companies increase revenue, reduce costs, and manage risk. Databricks was founded by the creators of Lakehouse, Apache Spark™, Delta Lake, MLflow, and Unity Catalog.\n",
    "chinese_title": "Databricks正以超1000亿美元估值进行K轮融资。",
    "chinese_summary": "Databricks宣布以超过1000亿美元的估值进行K轮融资。现有投资者预计将支持本轮融资。该公司计划利用这笔资金加速其人工智能战略，特别是扩展Agent Bricks，投资Lakebase（其新的数据库产品），并推动全球增长。\n\n首席执行官Ali Ghodsi强调，Databricks的人工智能产品势头强劲，吸引了大量投资者，这些产品被大型企业用于从其数据创建人工智能应用程序和代理。该公司看到对这些人工智能解决方案的需求空前，将数据转化为有价值的资产。\n\n在此次投资之前，Databricks最近与微软、谷歌云、Anthropic、SAP和Palantir等主要公司建立了合作关系。Databricks的数据智能平台被全球超过15000家客户使用，使组织能够普及数据访问并将其用于分析和人工智能应用。该平台建立在开源基础上，可帮助公司增加收入、降低成本并管理风险。Databricks由Lakehouse、Apache Spark™、Delta Lake、MLflow和Unity Catalog的创建者创立。"
  },
  {
    "id": "44958400",
    "title": "Modern CI is too complex and misdirected (2021)",
    "url": "https://gregoryszorc.com/blog/2021/04/07/modern-ci-is-too-complex-and-misdirected/",
    "summary": "This article argues that modern CI systems, like GitHub Actions and GitLab CI, have become overly complex and are essentially reinventing build systems. The author posits that these CI systems are too focused on being domain-specific platforms for CI, when they should instead be general-purpose compute platforms capable of handling both CI and build tasks.\n\nThe core argument is that a sufficiently complex CI system becomes indistinguishable from a build system, and vice versa. Both provide compute resources, artifact exchange, caching, and dependency management. The author believes CI's redundancy leads to fragmented build logic and the need to manage two complex systems instead of one.\n\nThe article advocates for unifying CI and build systems, allowing developers to leverage the full power of the CI system locally for ad-hoc jobs without needing to push changes to a remote server.\n\nThe author criticizes CI offerings like GitHub Actions for tightly coupling opinionated configuration mechanisms (YAML files) with a remote execution service, making them more \"products\" than true \"platforms.\"  They praise GitLab Pipelines for features like dynamic child pipelines, but note the lack of a generic API to schedule arbitrary compute.\n\nThe author highlights Mozilla's Taskcluster as a counterexample. Taskcluster is presented as a truly generic CI platform with a flexible API for defining tasks, enabling users to build their own configuration frontends and leverage advanced security features like fine-grained access control. Taskcluster's superior security model is compared favorably against Github Actions and Gitlab CI which are portrayed as \"data exfiltration and software supply chain vulnerability factories\" by comparison.\n",
    "chinese_title": "现代CI过于复杂且误入歧途（2021）",
    "chinese_summary": "本文认为，GitHub Actions和GitLab CI等现代CI系统已经变得过于复杂，本质上是在重新发明构建系统。作者认为这些CI系统过于专注于成为特定领域的CI平台，而它们应该成为能够处理CI和构建任务的通用计算平台。\n\n核心论点是，一个足够复杂的CI系统与构建系统变得难以区分，反之亦然。两者都提供计算资源、工件交换、缓存和依赖管理。作者认为CI的冗余导致构建逻辑碎片化，需要管理两个复杂的系统而不是一个。\n\n本文提倡统一CI和构建系统，允许开发者在本地充分利用CI系统的强大功能进行临时任务，而无需将更改推送到远程服务器。\n\n作者批评了像GitHub Actions这样的CI产品，因为它们将主观的配置机制（YAML文件）与远程执行服务紧密结合，使其更像是“产品”而非真正的“平台”。他们赞扬了GitLab Pipelines的动态子管道等功能，但指出缺乏用于调度任意计算的通用API。\n\n作者强调了Mozilla的Taskcluster作为反例。Taskcluster被认为是一个真正通用的CI平台，具有灵活的API用于定义任务，使用户能够构建自己的配置前端，并利用高级安全功能，如细粒度的访问控制。Taskcluster卓越的安全模型与Github Actions和Gitlab CI相比更胜一筹，后者被描述为“数据泄露和软件供应链漏洞工厂”。"
  },
  {
    "id": "44957454",
    "title": "Copilot broke audit logs, but Microsoft won't tell customers",
    "url": "https://pistachioapp.com/blog/copilot-broke-your-audit-log",
    "summary": "This article details a vulnerability found in Microsoft's M365 Copilot where it could access files without generating corresponding audit logs, making it possible to access information undetected. The author discovered that by asking Copilot not to provide a file link, its access wouldn't be logged, potentially impacting security and legal compliance.\n\nThe author reported the vulnerability to Microsoft through their MSRC portal. While Microsoft eventually fixed the issue, classifying it as \"important,\" they decided not to publicly disclose it or issue a CVE, arguing users didn't need to take action. This means customers are unaware their audit logs may be inaccurate.\n\nThe author criticizes Microsoft's handling of the report, citing deviations from their outlined process and a lack of transparency.  The author argues that the ease of exploiting the vulnerability makes non-disclosure a disservice to customers, especially those in regulated industries who rely on accurate audit logs for compliance with regulations like HIPAA. The article implies this incident raises concerns about Microsoft's overall transparency regarding security vulnerabilities in Copilot.\n",
    "chinese_title": "Copilot 破坏审计日志，但微软拒绝告知客户",
    "chinese_summary": "微软M365 Copilot漏洞：访问文件不生成审计日志，引发安全和合规担忧"
  },
  {
    "id": "44953032",
    "title": "How we exploited CodeRabbit: From simple PR to RCE and write access on 1M repos",
    "url": "https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/",
    "summary": "In August 2025, a security researcher detailed how they achieved remote code execution (RCE) on CodeRabbit's production servers, leading to the potential exposure of sensitive data and access to numerous code repositories. The vulnerability was discovered after examining CodeRabbit, an AI code review tool used by over one million repositories on GitHub and GitLab.\n\nThe researcher found that CodeRabbit, which runs static analysis tools on pull requests, could be exploited via Rubocop, a Ruby static analyzer. By creating a pull request with a malicious `.rubocop.yml` file referencing an extension Ruby file (`ext.rb`) containing arbitrary code, they could execute code on CodeRabbit's servers. This allowed them to exfiltrate environment variables.\n\nThe extracted environment variables revealed a trove of sensitive information, including API keys for Anthropic and OpenAI, an Aperture agent key, a Courier auth token, encryption credentials, a GitLab personal access token, and most critically, CodeRabbit's GitHub App private key, client ID, and secret. This access granted the researcher read and write privileges to the one million repositories using CodeRabbit.\n\nThe vulnerability was promptly reported to CodeRabbit and remediated in January 2025. CodeRabbit disabled Rubocop, rotated all potentially compromised credentials, deployed a permanent fix within a secure sandbox, audited their systems, and implemented automated sandbox enforcement.\n",
    "chinese_title": "我们如何利用CodeRabbit：从简单PR到RCE和百万代码库的写入权限",
    "chinese_summary": "2025年8月，一位安全研究人员详细介绍了他们如何在CodeRabbit的生产服务器上实现远程代码执行(RCE)，导致敏感数据可能泄露并能访问大量代码仓库。该漏洞是在检查CodeRabbit后发现的，CodeRabbit是一个被GitHub和GitLab上超过一百万个代码仓库使用的AI代码审查工具。\n\n该研究人员发现，CodeRabbit会在拉取请求上运行静态分析工具，而它可以通过Ruby静态分析器Rubocop被利用。通过创建一个包含恶意`.rubocop.yml`文件的拉取请求，该文件引用一个包含任意代码的扩展Ruby文件(`ext.rb`)，他们可以在CodeRabbit的服务器上执行代码。这使他们能够提取环境变量。\n\n提取出的环境变量泄露了大量敏感信息，包括Anthropic和OpenAI的API密钥、一个Aperture代理密钥、一个Courier身份验证令牌、加密凭据、一个GitLab个人访问令牌，以及最关键的，CodeRabbit的GitHub App私钥、客户端ID和密钥。这种访问权限授予了该研究人员对使用CodeRabbit的一百万个代码仓库的读写权限。\n\n该漏洞已及时报告给CodeRabbit并在2025年1月得到修复。CodeRabbit禁用了Rubocop，轮换了所有可能被泄露的凭据，在一个安全的沙箱中部署了永久性修复程序，审计了他们的系统，并实施了自动沙箱执行。"
  },
  {
    "id": "44939165",
    "title": "The End of Handwriting",
    "url": "https://www.wired.com/story/the-end-of-handwriting/",
    "summary": "The article \"The End of Handwriting\" explores the perceived decline of handwriting in the digital age and its implications. While acknowledging the decreasing reliance on handwriting due to email, smartphones, and AI, the author argues that handwriting still holds significant value.\n\nExperts suggest that handwriting development is linked to fine motor skills and literacy acquisition. Research indicates that while digital natives may meet dexterity test expectations, their overall motor proficiency is lower, potentially impacting their readiness for handwriting. The article also highlights that learning handwriting has cognitive benefits, aiding reading comprehension and memory retention.\n\nThe piece addresses the concern of \"character amnesia,\" where over-reliance on typing leads to forgetting how to form letters, particularly prevalent in character-based languages.\n\nCounterintuitively, the rise of AI may lead to a handwriting renaissance. Schools are considering bringing back handwritten exams to combat plagiarism and ensure students demonstrate genuine understanding, as typing can be easily outsourced to AI.\n\nHowever, this potential resurgence comes with caveats. Poor handwriting could unfairly penalize students regardless of their cognitive abilities. The article ultimately concludes that handwriting isn't dying but may become a way to prove genuine understanding in an AI-dominated world.\n",
    "chinese_title": "手写的终结",
    "chinese_summary": "文章《手写的终结》探讨了数字时代手写日益衰落及其影响。虽然承认由于电子邮件、智能手机和人工智能的出现，人们对手写的依赖性正在降低，但作者认为手写仍然具有重要价值。\n\n专家认为，手写能力的发展与精细运动技能和识字能力密切相关。研究表明，虽然数字原住民可能达到灵巧性测试的预期，但他们的总体运动能力较低，可能影响他们对手写的准备程度。文章还强调，学习手写具有认知益处，有助于阅读理解和记忆保持。\n\n文章还提出了“文字失忆症”的担忧，即过度依赖打字会导致忘记如何书写文字，这在基于文字的语言中尤为普遍。\n\n出乎意料的是，人工智能的兴起可能会导致手写的复兴。学校正在考虑恢复手写考试，以打击抄袭并确保学生展示真正的理解，因为打字很容易外包给人工智能。\n\n然而，这种潜在的复兴也伴随着警告。糟糕的字迹可能会不公平地惩罚学生，而不管他们的认知能力如何。文章最终得出结论，手写并没有消亡，而可能成为在人工智能主导的世界中证明真正理解的一种方式。"
  },
  {
    "id": "44954524",
    "title": "D2 (text to diagram tool) now supports ASCII renders",
    "url": "https://d2lang.com/blog/ascii/",
    "summary": "D2 (text to diagram tool) version 0.7.1 introduces ASCII rendering capabilities, allowing users to generate diagrams as ASCII text. Any output file with the `.txt` extension will utilize this new renderer. This feature is particularly useful for embedding simple diagrams within source code comments, as demonstrated by the D2 Vim extension, which provides a live preview and code replacement functionality.\n\nThe ASCII renderer defaults to unicode characters for better box-drawing but can be switched to standard ASCII using the `--ascii-mode=standard` flag for maximum portability.\n\nIt's important to note that the ASCII renderer is currently in alpha stage and has limitations. Styling options, including animations, fonts, themes, double borders, and multiple features, are not supported. Certain elements like special text (Markdown, Latex, Code), images, icons, UML classes, and SQL tables cannot be rendered. The downscaling process may lead to uneven spacing in some cases. Also, certain shapes, like clouds and circles, are rendered as rectangles with icons in the top-left corner.\n\nDespite these limitations, users are encouraged to try out the ASCII renderer in the D2 Playground and report any issues encountered on GitHub.\n",
    "chinese_title": "D2（文本转图工具）现已支持 ASCII 渲染",
    "chinese_summary": "D2 (文本转图工具) 0.7.1 版本引入了 ASCII 渲染功能，允许用户生成 ASCII 文本图。任何扩展名为 `.txt` 的输出文件都将使用此新渲染器。此功能特别适用于在源代码注释中嵌入简单图，D2 Vim 扩展即是例证，它提供了实时预览和代码替换功能。\n\nASCII 渲染器默认使用 Unicode 字符以获得更好的框线效果，但可以使用 `--ascii-mode=standard` 标志切换到标准 ASCII 以实现最大的可移植性。\n\n需要注意的是，ASCII 渲染器目前处于 alpha 阶段，存在局限性。不支持样式选项，包括动画、字体、主题、双边框和多种功能。某些元素，如特殊文本（Markdown、Latex、Code）、图像、图标、UML 类和 SQL 表，无法渲染。缩放过程可能导致某些情况下间距不均匀。此外，某些形状（如云和圆形）会渲染为左上角带有图标的矩形。\n\n尽管存在这些限制，我们仍然鼓励用户在 D2 Playground 中尝试 ASCII 渲染器，并在 GitHub 上报告遇到的任何问题。"
  },
  {
    "id": "44957157",
    "title": "Tiny microbe challenges the definition of cellular life",
    "url": "https://nautil.us/a-rogue-new-life-form-1232095/",
    "summary": "Alice Sun's Nautilus article discusses the discovery of *Sukunaarchaeum mirabile*, a tiny archaeon with an exceptionally small genome that challenges the conventional definition of cellular life. Discovered accidentally by Takuro Nakayama and his team while studying microbes within a dinoflagellate, *Citharistes regius*, Sukunaarchaeum possesses only 238,000 base pairs, making it the archaeon with the smallest known genome.\n\nWhat sets it apart is its extreme metabolic dependence on its host. Unlike other archaea and bacteria, Sukunaarchaeum seems unable to perform basic metabolic functions on its own, relying entirely on *C. regius* for energy and nutrients. This level of dependence is unprecedented and blurs the lines between archaea and viruses. While viruses also rely on hosts, Sukunaarchaeum possesses ribosomes and can self-replicate, unlike viruses.\n\nBy analyzing marine genetic data, researchers identified similar sequences globally, suggesting a potentially vast, previously unknown archaeal lineage. Nakayama believes this discovery highlights the existence of \"microbial dark matter\"—unidentified microbes that challenge our understanding of life. Mart Krupovic, a virologist, finds the discovery remarkable, pointing to how much remains unknown about the microbial world.\n\nNakayama's future research aims to culture and isolate Sukunaarchaeum to study its biology and understand its unique survival strategy on the \"edge of life\".\n",
    "chinese_title": "挑战细胞生命定义的微小微生物",
    "chinese_summary": "爱丽丝·孙在《鹦鹉螺》杂志上发表的文章讨论了对*Sukunaarchaeum mirabile*的发现，这是一种基因组异常微小的古菌，挑战了细胞生命的传统定义。 *Sukunaarchaeum*是由中山拓郎及其团队在研究甲藻*Citharistes regius*中的微生物时意外发现的，仅拥有23.8万个碱基对，使其成为已知基因组最小的古菌。\n\n它的独特之处在于其对宿主的极端代谢依赖性。与其他古菌和细菌不同，*Sukunaarchaeum*似乎无法独立执行基本的代谢功能，完全依赖*C. regius*提供能量和营养。这种程度的依赖性是前所未有的，模糊了古菌和病毒之间的界限。虽然病毒也依赖宿主，但与病毒不同，*Sukunaarchaeum*拥有核糖体并且可以自我复制。\n\n通过分析海洋遗传数据，研究人员在全球范围内发现了相似的序列，表明可能存在一个巨大的、以前未知的古菌谱系。中山认为这一发现突显了“微生物暗物质”的存在——挑战我们对生命理解的未识别微生物。病毒学家Mart Krupovic认为这一发现非常了不起，并指出微生物世界仍有许多未知之处。\n\n中山未来的研究旨在培养和分离*Sukunaarchaeum*，以研究其生物学，并了解其在“生命边缘”独特的生存策略。"
  },
  {
    "id": "44963179",
    "title": "FEMA Now Requires Disaster Victims to Have an Email Address",
    "url": "https://www.wired.com/story/fema-now-requires-disaster-victims-to-have-an-email-address/",
    "summary": "FEMA now requires disaster survivors to have an email address to register for federal aid, a policy change effective August 12th that departs from previous practice and is raising concerns. FEMA states this move aims to streamline communication and transition to digital payments. However, FEMA employees fear this requirement will disproportionately impact vulnerable populations with limited internet access, particularly low-income individuals and racial/ethnic minorities.\n\nThe article highlights the potential exclusion of those who can't easily obtain or manage email accounts, citing NTIA data showing significant percentages of households, especially in Missouri and Tennessee (where FEMA workers reported issues), lacking internet access. One FEMA worker reported seeing a colleague turn away an applicant without an email address.\n\nWhile FEMA argues that most Americans have email and online accounts are the most effective way to stay informed, concerns are raised about the elderly and those with limited digital literacy struggling to navigate the online system.\n\nThe change is occurring alongside other shifts, like phasing out door-to-door surveys, raising concerns about access to aid for the most vulnerable. Current and former FEMA employees agree the system is outdated and needs improvements, but worry that requiring an email address will create a barrier for those most in need of disaster assistance.\n",
    "chinese_title": "联邦紧急事务管理局现在要求灾民提供电子邮件地址",
    "chinese_summary": "联邦紧急事务管理局现要求灾难幸存者必须拥有电子邮件地址才能注册联邦援助，这项政策变更自8月12日起生效，与之前的做法不同，并引发担忧。 联邦紧急事务管理局表示，此举旨在简化沟通并过渡到数字支付。 然而，联邦紧急事务管理局雇员担心，这项要求将对互联网接入有限的弱势群体，特别是低收入个人和种族/族裔少数群体，产生不成比例的影响。\n\n文章强调了那些无法轻易获得或管理电子邮件账户的人可能被排除在外的问题，并引用了美国国家电信和信息管理局（NTIA）的数据，该数据显示，很大比例的家庭，尤其是在密苏里州和田纳西州（联邦紧急事务管理局工作人员报告问题的地方），缺乏互联网接入。 一位联邦紧急事务管理局工作人员报告说，他看到一位同事拒绝了一位没有电子邮件地址的申请人。\n\n虽然联邦紧急事务管理局辩称，大多数美国人都有电子邮件，并且在线账户是保持知情的最佳方式，但人们对老年人和那些数字素养有限的人难以操作在线系统表示担忧。\n\n这项变革正与其他转变同时发生，比如逐步取消挨家挨户的调查，引发了人们对最弱势群体获得援助的担忧。 现任和前任联邦紧急事务管理局雇员都认为该系统已经过时，需要改进，但担心要求提供电子邮件地址会为那些最需要灾难援助的人制造障碍。"
  },
  {
    "id": "44938718",
    "title": "Fast and observable background job processing for .NET",
    "url": "https://github.com/mikasjp/BusyBee",
    "summary": "BusyBee is a high-performance .NET background job processing library that leverages native channels for efficiency. It offers a simple, configurable, and observable solution for managing background tasks, including built-in OpenTelemetry support for monitoring and tracing.\n\nKey features include:\n\n*   **High Performance:** In-memory queues built on .NET channels for fast processing.\n*   **Configurability:** Offers unbounded or bounded queues with various overflow strategies (Wait, Ignore, ThrowException, DiscardOldest, DiscardNewest), global and per-job timeouts, and configurable parallel processing.\n*   **Observability:** Provides job execution logging, OpenTelemetry tracing, and detailed metrics like job counts, execution times, and wait times.\n*   **Developer-Friendly:** Features a fluent configuration API, dependency injection support, cancellation token support, and rich job context.\n\nConfiguration is straightforward, allowing customization of queue behavior, timeouts, and parallelism. Jobs receive a context with information like a unique ID, timing details, and access to registered services. OpenTelemetry integration enables monitoring and analysis.\n\nThe library offers extensibility through custom `IJobFailureHandler` and `IJobTimeoutHandler` implementations. It also provides guidance on handling long-running jobs, including the importance of cancellation and progress logging. Best practices emphasize job idempotency, appropriate timeouts, monitoring, and cancellation handling.\n\nThe library welcomes contributions. A demo app provides a complete example including a Web API, OpenTelemetry setup, Seq logging, and Prometheus integration.\n",
    "chinese_title": ".NET快速且可观测的后台任务处理",
    "chinese_summary": "BusyBee是一个高性能的 .NET 后台作业处理库，它利用原生通道来提高效率。它提供了一个简单、可配置和可观察的解决方案来管理后台任务，包括内置的 OpenTelemetry 支持，用于监控和追踪。\n\n主要特性包括：\n\n*   **高性能：** 基于 .NET 通道的内存队列，用于快速处理。\n*   **可配置性：** 提供无界或有界队列，具有各种溢出策略（等待、忽略、抛出异常、丢弃最旧、丢弃最新），全局和每个作业的超时，以及可配置的并行处理。\n*   **可观察性：** 提供作业执行日志记录、OpenTelemetry 追踪，以及详细的指标，如作业计数、执行时间和等待时间。\n*   **开发者友好：** 具有流畅的配置 API、依赖注入支持、取消令牌支持和丰富的作业上下文。\n\n配置非常简单，允许自定义队列行为、超时和并行性。作业会收到一个包含唯一 ID、计时细节以及对已注册服务的访问权限的上下文。OpenTelemetry 集成支持监控和分析。\n\n该库通过自定义 `IJobFailureHandler` 和 `IJobTimeoutHandler` 实现提供可扩展性。它还提供了处理长时间运行作业的指导，包括取消和进度记录的重要性。最佳实践强调作业幂等性、适当的超时、监控和取消处理。\n\n该库欢迎贡献。一个演示应用程序提供了一个完整的示例，包括 Web API、OpenTelemetry 设置、Seq 日志记录和 Prometheus 集成。"
  },
  {
    "id": "44939423",
    "title": "How I Made Ruby Faster Than Ruby",
    "url": "https://noteflakes.com/articles/2025-08-18-how-to-make-ruby-faster",
    "summary": "This article details the author's journey of optimizing the performance of P2, a Ruby HTML templating library. P2 differentiates itself by compiling template source code into efficient Ruby code, avoiding runtime interpretation.\n\nInitially, P2 was faster than Papercraft but slower than ERubi. Through a contribution from byroot, the author identified key areas for improvement in P2's code generation. The original code generated interpolated strings, used a costly rescue clause, and produced non-frozen strings.\n\nThe author then rewrote the compiler to:\n\n*   Separate HTML generation, pushing static and dynamic parts separately.\n*   Remove the rescue clause and handle backtrace translation in the `Proc#render` method.\n*   Add the `# frozen_string_literal: true` magic comment to freeze static HTML strings, reducing allocation.\n*   Switch from `CGI.escape_html` to `ERB::Escape.html_escape` for faster HTML escaping.\n\nThese changes resulted in significant performance gains, bringing P2's speed on par with compiled ERB and ERubi templates. Benchmarks showed P2 now performing similarly to ERB/ERubi and drastically faster (approximately 10x) than non-compiled templating approaches like Papercraft and Phlex.\n\nThe author concludes that these optimizations highlight Ruby's potential for high performance when code is written efficiently. They advocate for adopting the Ruby-to-Ruby compilation technique for other DSLs and applications.\n",
    "chinese_title": "我是如何让Ruby比Ruby更快的",
    "chinese_summary": "本文详细介绍了作者优化 Ruby HTML 模板库 P2 性能的历程。P2 的独特之处在于它将模板源代码编译为高效的 Ruby 代码，避免了运行时解释。\n\n最初，P2 比 Papercraft 快，但比 ERubi 慢。通过 byroot 的贡献，作者确定了 P2 代码生成中需要改进的关键领域。原始代码生成内插字符串，使用昂贵的 rescue 子句，并生成非冻结字符串。\n\n然后，作者重写了编译器，以：\n\n* 分离 HTML 生成，分别推送静态和动态部分。\n* 删除 rescue 子句，并在 `Proc#render` 方法中处理回溯转换。\n* 添加 `# frozen_string_literal: true` 魔术注释来冻结静态 HTML 字符串，从而减少分配。\n* 从 `CGI.escape_html` 切换到 `ERB::Escape.html_escape`，以实现更快的 HTML 转义。\n\n这些更改带来了显著的性能提升，使 P2 的速度与编译后的 ERB 和 ERubi 模板相当。基准测试表明，P2 现在的性能与 ERB/ERubi 类似，并且比 Papercraft 和 Phlex 等非编译模板方法快得多（大约 10 倍）。\n\n作者得出结论，这些优化突显了 Ruby 在高效编写代码时具有的高性能潜力。他们提倡将 Ruby 到 Ruby 的编译技术应用于其他 DSL 和应用程序。"
  },
  {
    "id": "44960594",
    "title": "Show HN: Project management system for Claude Code",
    "url": "https://github.com/automazeio/ccpm",
    "summary": "Claude Code PM is a project management system designed to improve software development workflows using Claude Code, GitHub issues, Git worktrees, and parallel AI agents. It addresses common team challenges like context loss, parallel work conflicts, requirements drift, and hidden progress.\n\nThe system promotes spec-driven development with full traceability, moving from PRDs to epics, GitHub issues, and production code. Key features include persistent context, parallel agent execution, GitHub integration (using issues as the single source of truth), agent specialization, and complete audit trails.\n\nThe workflow consists of five phases: Product Planning (creating PRDs), Implementation Planning (converting PRDs to epics), Task Decomposition (breaking epics into actionable tasks), GitHub Synchronization (pushing epics and tasks as issues), and Execution (specialized agents implementing tasks).  Commands like `/pm:prd-new`, `/pm:epic-oneshot`, and `/pm:issue-start` facilitate these phases.\n\nThe \"Parallel Execution System\" leverages multiple agents to work concurrently on different aspects of a single issue, optimizing velocity and context management. It aims to separate the strategic main conversation from the detailed implementation specifics handled by individual agents.\n\nTeams using the system report improvements in context switching, task parallelization, bug reduction, and feature delivery speed. The system is designed to integrate with existing GitHub workflows and tools, offering a collaborative protocol for humans and AI agents to work together at scale. Setup involves cloning the repository, initializing the PM system, and priming the context.\n",
    "chinese_title": "展示一下：用于Claude Code的项目管理系统",
    "chinese_summary": "Claude Code PM 是一款项目管理系统，旨在利用 Claude Code、GitHub Issues、Git Worktrees 和并行 AI 代理来改进软件开发工作流程。它解决了常见的团队挑战，例如上下文丢失、并行工作冲突、需求偏差和隐藏进度。\n\n该系统通过完整的可追溯性来促进规范驱动开发，从 PRD 到史诗、GitHub Issues 和生产代码。主要功能包括持久化上下文、并行代理执行、GitHub 集成（使用 Issues 作为单一真相来源）、代理专业化和完整的审计跟踪。\n\n该工作流程包含五个阶段：产品规划（创建 PRD）、实施规划（将 PRD 转换为史诗）、任务分解（将史诗分解为可执行的任务）、GitHub 同步（将史诗和任务推送到 Issues）以及执行（专门的代理实现任务）。`/pm:prd-new`、`/pm:epic-oneshot` 和 `/pm:issue-start` 等命令可促进这些阶段。\n\n“并行执行系统”利用多个代理同时处理单个 Issue 的不同方面，从而优化速度和上下文管理。它旨在将战略性的主要对话与由各个代理处理的详细实施细节分开。\n\n使用该系统的团队报告说，在上下文切换、任务并行化、错误减少和功能交付速度方面都有所改进。该系统旨在与现有的 GitHub 工作流程和工具集成，为人类和 AI 代理大规模协作提供协作协议。设置包括克隆存储库、初始化 PM 系统和启动上下文。"
  },
  {
    "id": "44953316",
    "title": "Emacs as your video-trimming tool",
    "url": "https://xenodium.com/emacs-as-your-video-trimming-tool",
    "summary": "This article discusses using Emacs as a video-trimming tool, inspired by a blog post from Marcin 'mbork' Borkowski. The author, motivated by their own \"graphical\" seeker in Ready Player Mode, created `video-trimmer-mode`—a simple Emacs tool for video trimming. The tool leverages `ffmpeg` for the actual video processing and is approximately 300 lines of code. The author opted to share the code's location in their Emacs configuration repository instead of including the entire snippet in the article, allowing for ongoing tweaks and updates. Finally, the author promotes their work as an independent developer, encouraging readers to support their efforts through sponsorship, blog creation, or purchasing their macOS/iOS apps. The article concludes with a mention of LMNO.lol, along with privacy policy and terms of service links.\n",
    "chinese_title": "使用 Emacs 进行视频剪辑",
    "chinese_summary": "本文探讨了使用 Emacs 作为视频剪辑工具的方法，其灵感来自 Marcin 'mbork' Borkowski 的一篇博文。作者受 Ready Player Mode 中自带的“图形化”进度条的启发，创建了 `video-trimmer-mode`——一个简单的 Emacs 视频剪辑工具。该工具利用 `ffmpeg` 进行实际的视频处理，代码大约 300 行。作者选择分享代码在其 Emacs 配置文件仓库中的位置，而不是在文章中包含整个代码片段，以便进行持续的调整和更新。最后，作者以独立开发者的身份推广自己的工作，鼓励读者通过赞助、创建博客或购买其 macOS/iOS 应用来支持他们的努力。文章最后提及了 LMNO.lol，并附带隐私政策和服务条款链接。"
  },
  {
    "id": "44963715",
    "title": "Is the A.I. Sell-Off the Start of Something Bigger?",
    "url": "https://www.nytimes.com/2025/08/20/business/dealbook/ai-dip-blip-palantir-nvidia.html",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "人工智能抛售是更大趋势的开端吗？",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44938667",
    "title": "Rails Charts Using ECharts from Apache",
    "url": "https://github.com/railsjazz/rails_charts",
    "summary": "This article introduces the `rails_charts` gem, a Ruby on Rails library that simplifies the creation of various chart types using the Apache ECharts library. It offers a straightforward interface, inspired by Chartkick, but with expanded chart options and customization capabilities.\n\nThe gem supports area, line, bar, donut, pie, radar, calendar, candlestick, funnel, gauge, parallel, sankey, scatter, stacked bar, and custom charts. Installation instructions are provided for Sprockets, Webpack/esbuild, and Importmaps.\n\nKey features include customizable options like width, height, theme, CSS classes, IDs, and inline styles. It also allows direct access to Apache ECharts options for advanced configurations, including JavaScript function integration for tooltips.\n\nThe article includes code examples for each chart type, showcasing how to generate them with minimal code and options customization. It emphasizes that each chart comes with default configurations that can be overriden.\n\nThe article concludes with a call for contributions, outlining potential areas for improvement like Turbo Streams support, improved documentation, and examples of handling different data structures. It also provides instructions on how to upgrade the underlying ECharts library and setup the development environment.\n",
    "chinese_title": "使用 Apache ECharts 的 Rails 图表",
    "chinese_summary": "本文介绍 `rails_charts` gem，一个 Ruby on Rails 库，它简化了使用 Apache ECharts 库创建各种图表类型。它提供了一个直观的界面，灵感来自 Chartkick，但具有更广泛的图表选项和自定义功能。\n\n该 gem 支持面积图、折线图、柱状图、甜甜圈图、饼图、雷达图、日历图、K 线图、漏斗图、仪表盘图、平行坐标图、桑基图、散点图、堆叠柱状图和自定义图表。提供了针对 Sprockets、Webpack/esbuild 和 Importmaps 的安装说明。\n\n主要功能包括可自定义的选项，如宽度、高度、主题、CSS 类、ID 和内联样式。它还允许直接访问 Apache ECharts 选项以进行高级配置，包括用于工具提示的 JavaScript 函数集成。\n\n本文包含每种图表类型的代码示例，展示了如何以最少的代码和选项定制生成它们。它强调每个图表都带有可以覆盖的默认配置。\n\n本文最后呼吁大家贡献力量，概述了潜在的改进领域，例如 Turbo Streams 支持、改进的文档以及处理不同数据结构的示例。它还提供了有关如何升级底层 ECharts 库和设置开发环境的说明。"
  },
  {
    "id": "44958020",
    "title": "The value of hitting the HN front page",
    "url": "https://www.mooreds.com/wordpress/archives/3530",
    "summary": "This article discusses the value and limitations of hitting the Hacker News (HN) front page, based on the author's extensive experience on the platform. While a top-ranking HN post can drive significant traffic, it's primarily for brand awareness and doesn't typically result in high conversion rates (e.g., sales, sign-ups).\n\nThe author emphasizes the importance of the comments section. HN provides valuable feedback from a knowledgeable audience, which should be carefully considered and engaged with. Don't dismiss or take offense at comments, but instead use them to understand how your work is perceived.\n\nFurthermore, the author notes that a successful HN post can lead to follow-on traffic from other platforms (newsletters, social media) as people discover and share the content. Identifying these sources and engaging with them can be beneficial. Also, expect a thank you if you post something that hits the front page from somebody else.\n\nThe author stresses that HN shouldn't be viewed as a marketing plan or a source of reliable traffic, as the platform is unpredictable. It's also important to remember that HN's user base isn't representative of the broader market, so feedback should be considered within that context. In summary, HN is useful for brand awareness and gathering feedback from a specific tech-savvy audience, but not as a direct driver of conversions or a reliable source of traffic.\n",
    "chinese_title": "登上HN首页的价值",
    "chinese_summary": "本文基于作者在 Hacker News (HN) 平台的丰富经验，探讨了登上 HN 首页的价值和局限性。 虽然 HN 排名靠前的帖子可以带来巨大的流量，但它主要用于品牌宣传，通常不会带来很高的转化率（例如，销售额、注册量）。\n\n作者强调了评论区的重要性。 HN 提供了来自知识渊博的受众的宝贵反馈，应仔细考虑并与之互动。 不要忽视或冒犯评论，而是利用它们来了解你的作品是如何被感知的。\n\n此外，作者指出，一篇成功的 HN 帖子可以引导来自其他平台（新闻通讯、社交媒体）的后续流量，因为人们会发现并分享内容。 识别这些来源并与它们互动可能是有益的。 此外，如果你发布的帖子登上了首页，预计会收到别人的感谢。\n\n作者强调，不应将 HN 视为营销计划或可靠流量的来源，因为该平台是不可预测的。 同样重要的是要记住，HN 的用户群并不代表更广泛的市场，因此应在该背景下考虑反馈。 总之，HN 有助于品牌宣传和收集来自特定技术受众的反馈，但不能作为转化的直接驱动力或可靠的流量来源。"
  },
  {
    "id": "44939654",
    "title": "Customizing Lisp REPLs",
    "url": "https://aartaka.me/customize-repl.html",
    "summary": "Artyom Bologov advocates for customizing existing Common Lisp REPLs instead of using proxy REPLs, emphasizing portability and leveraging existing tools. He argues that proxy REPLs reinvent functionality already present, in an incompatible way, while native REPLs can be incrementally improved for universal benefit.\n\nThe article details several methods for enhancing native REPLs. First, customizing the prompt with the \"Trivial Toplevel Prompt\" library for displaying process name, package, command number, and debug level. Second, using \"Trivial Toplevel Commands\" to create custom REPL commands, such as shell invocation or directory listing, making the REPL more interactive. Third, utilizing reader macros to extend Lisp syntax, offering flexibility without altering the underlying REPL.\n\nThe author also touches upon GUI debuggers, recognizing their limitations compared to implementation-native debuggers, which offer deeper integration and more powerful debugging features like disassembly, variable alteration, and simulated returns. He recommends using Readline/rlwrap for line editing, completions, and keybindings to enhance the REPL experience non-invasively. Finally, he suggests managing libraries with git submodules for version pinning and offline access, integrating them into the project with ASDF.\n\nWhile acknowledging the convenience of proxy REPLs like CIEL in providing features such as pre-loaded libraries and error prettification, Bologov highlights their drawbacks, including the loss of native capabilities and implementation-specific customization options. He concludes by urging readers to utilize and customize native REPLs to achieve a more personalized and ergonomic Lisp development environment.\n",
    "chinese_title": "定制 Lisp REPL",
    "chinese_summary": "阿尔乔姆·博洛戈夫提倡定制现有的 Common Lisp REPL，而不是使用代理 REPL，强调可移植性和利用现有工具。他认为代理 REPL 以不兼容的方式重新发明了已有的功能，而原生 REPL 可以逐步改进，从而实现普遍受益。\n\n本文详细介绍了增强原生 REPL 的几种方法。首先，使用 \"Trivial Toplevel Prompt\" 库自定义提示符，以显示进程名称、包、命令编号和调试级别。其次，使用 \"Trivial Toplevel Commands\" 创建自定义 REPL 命令，例如 shell 调用或目录列表，使 REPL 更具交互性。第三，利用读取器宏来扩展 Lisp 语法，在不改变底层 REPL 的情况下提供灵活性。\n\n作者还提到了 GUI 调试器，并认识到它们与实现原生调试器相比的局限性，后者提供更深入的集成和更强大的调试功能，如反汇编、变量修改和模拟返回。他建议使用 Readline/rlwrap 进行行编辑、补全和按键绑定，以非侵入方式增强 REPL 体验。最后，他建议使用 git 子模块管理库，以进行版本固定和离线访问，并使用 ASDF 将它们集成到项目中。\n\n虽然博洛戈夫承认像 CIEL 这样的代理 REPL 在提供预加载库和错误美化等功能方面的便利性，但他强调了它们的缺点，包括失去原生功能和特定于实现的自定义选项。他最后敦促读者利用和定制原生 REPL，以实现更加个性化和符合人体工程学的 Lisp 开发环境。"
  },
  {
    "id": "44963666",
    "title": "The Four Stages of Objective-Smalltalk",
    "url": "https://blog.metaobject.com/2019/12/the-4-stages-of-objective-smalltalk.html",
    "summary": "Marcel Weiher outlines the four stages of Objective-Smalltalk's development, each building upon the last and offering increasing value.\n\n**Stage 1: WebScript 2/\"Shasta\"** This stage aims to create a clean, Smalltalk-like scripting language free from the syntactic baggage inherited from Objective-C's integration with C. This language, reminiscent of WebScript, focuses on being a highly interactive and malleable scripting environment, ideal for tweaking and interacting with running applications.\n\n**Stage 2: Objective-C without the C** This stage focuses on creating a native, AOT-compiled version of the scripting language from Stage 1 to replace Objective-C, providing a smoother integration between scripting and \"programming.\" The ease of moving code between the scripting and compiled environments would be maintained.\n\n**Stage 3: Architecture Oriented Programming** This stage goes beyond simple object-oriented programming by leveraging Objective-Smalltalk's malleability to explore and implement architectural concepts directly within the language. Weiher focuses on incorporating three popular architectural styles: object-oriented, Unix pipes and filters, and REST, aligning them with existing language elements.\n\n**Stage 4: Architecture Oriented Metaprogramming** The final stage aims to allow users to define and refine their own architectural styles within the language itself, moving beyond hard-coded frameworks and enabling truly customizable architectural paradigms.\n\nWeiher concludes that each stage is independently valuable and becomes even more powerful when combined with subsequent stages. He also acknowledges the need to return to Stage 4 to complete the implementation.\n",
    "chinese_title": "Objective-Smalltalk的四个阶段",
    "chinese_summary": "马塞尔·韦赫概述了Objective-Smalltalk的四个发展阶段，每个阶段都建立在前一个阶段的基础上，并提供更高的价值。\n\n**第一阶段：WebScript 2/\"Shasta\"** 这一阶段旨在创建一个干净、类似于Smalltalk的脚本语言，摆脱从Objective-C与C集成中继承的语法负担。这种语言让人想起WebScript，专注于成为一个高度互动和可塑的脚本环境，非常适合调整和与运行中的应用程序交互。\n\n**第二阶段：没有C的Objective-C** 这一阶段的重点是创建第一阶段脚本语言的本地、AOT编译版本，以取代Objective-C，从而提供脚本和“编程”之间更平滑的集成。脚本环境和编译环境之间代码迁移的便利性将得以保持。\n\n**第三阶段：面向架构的编程** 这一阶段超越了简单的面向对象编程，通过利用Objective-Smalltalk的可塑性来探索和实现语言内部的架构概念。韦赫专注于整合三种流行的架构风格：面向对象、Unix管道和过滤器以及REST，并将它们与现有的语言元素对齐。\n\n**第四阶段：面向架构的元编程** 最后一个阶段旨在允许用户在语言本身中定义和改进自己的架构风格，超越硬编码框架，并实现真正可定制的架构范例。\n\n韦赫总结说，每个阶段都具有独立的价值，并且与后续阶段结合使用时会变得更加强大。他还承认需要返回到第四阶段才能完成实施。"
  },
  {
    "id": "44939902",
    "title": "Gaussian Processes for Machine Learning (2006) [pdf]",
    "url": "https://gaussianprocess.org/gpml/chapters/RW.pdf",
    "summary": "\"Gaussian Processes for Machine Learning\" (2006) is a comprehensive exploration of Gaussian Processes (GPs) as a powerful tool for various machine learning tasks. The book covers both theoretical foundations and practical applications, making it valuable for researchers and practitioners alike.\n\nThe book begins by introducing the core concepts of Bayesian modeling and provides a roadmap for the rest of the text. It then delves into specific applications, starting with regression and classification, explaining how GPs can be applied to these problems, including detailed coverage of the Laplace approximation and Expectation Propagation for GP classification. It covers covariance functions, exploring different types and how to construct new ones. It discusses eigenfunction analysis of kernels and kernels for non-vectorial inputs.\n\nModel selection and hyperparameter adaptation are covered extensively, including Bayesian model selection and cross-validation methods. The book examines the relationships between GPs and other machine learning models, such as Reproducing Kernel Hilbert Spaces, Spline Models, Support Vector Machines, and Relevance Vector Machines. Theoretical perspectives such as the equivalent kernel, asymptotic analysis, and PAC-Bayesian analysis are also discussed. The book addresses the challenge of large datasets by presenting approximation methods like reduced-rank approximations and sparse GP techniques, including Subset of Regressors and the Nyström method.\n\nFinally, the book concludes with a discussion of further issues and conclusions, covering topics such as multiple outputs, non-Gaussian likelihoods, derivative observations, uncertain inputs, mixtures of Gaussian Processes, global optimization, and latent variable models. The appendices provide essential mathematical background and discuss Gaussian Markov Processes.\n",
    "chinese_title": "机器学习的高斯过程 (2006) [pdf]",
    "chinese_summary": "高斯过程在机器学习中的应用 (2006) 是一本全面探索高斯过程（GPs）作为各种机器学习任务强大工具的书籍。本书涵盖了理论基础和实际应用，对研究人员和从业者都具有价值。\n\n本书首先介绍贝叶斯建模的核心概念，并为本书的其余部分提供路线图。然后深入研究具体的应用，从回归和分类开始，解释如何将GPs应用于这些问题，包括对拉普拉斯近似和期望传播进行GP分类的详细介绍。本书涵盖了协方差函数，探索了不同的类型以及如何构建新的协方差函数。书中讨论了核函数的特征函数分析和非矢量输入的核函数。\n\n本书广泛介绍了模型选择和超参数调整，包括贝叶斯模型选择和交叉验证方法。本书研究了GPs与其他机器学习模型之间的关系，例如再生核希尔伯特空间、样条模型、支持向量机和相关向量机。还讨论了诸如等价核、渐近分析和PAC-贝叶斯分析等理论视角。本书通过介绍降秩近似和稀疏GP技术（包括回归子集和Nyström方法）等近似方法来解决大型数据集的挑战。\n\n最后，本书以对进一步问题和结论的讨论结尾，涵盖了诸如多输出、非高斯似然、导数观测、不确定输入、高斯过程混合、全局优化和潜在变量模型等主题。附录提供了必要的数学背景，并讨论了高斯马尔可夫过程。"
  },
  {
    "id": "44963512",
    "title": "A proposal for inline LLM instructions in HTML based on llms.txt",
    "url": "https://vercel.com/blog/a-proposal-for-inline-llm-instructions-in-html",
    "summary": "This article proposes a new convention for embedding instructions for AI agents directly within HTML using `<script type=\"text/llms.txt\">`. The problem it addresses is how to inform AI agents, like code assistants, about how to access protected resources, such as preview deployments behind authentication.\n\nThe article highlights Vercel's use case, where protected preview deployments prevent AI agents from directly accessing them. While Vercel provides mechanisms like an MCP server with functions like `get_access_to_vercel_url`, the agents need a way to discover these resources.\n\nThe proposed solution leverages the emerging `llms.txt` standard for AI-targeted content by embedding instructions in HTML using a `<script>` tag with the custom type \"text/llms.txt\". Browsers will ignore this tag, ensuring no impact on rendering, while LLMs can parse the instructions. The article emphasizes the benefits: ease of implementation, no need for formal standardization, and compatibility with existing LLM capabilities.\n\nThe article also provides a real-world example of how Vercel uses this approach to instruct agents on how to obtain an authentication bypass token and access protected deployments. It highlights potential use cases beyond authentication, such as directing agents to MCP services for error investigation. The authors encourage developers to start using the convention immediately.\n",
    "chinese_title": "基于 llms.txt 的 HTML 内联 LLM 指令提案",
    "chinese_summary": "本文提出了一种新的约定，即使用 `<script type=\"text/llms.txt\">` 将 AI 代理的指令直接嵌入到 HTML 中。它解决的问题是，如何告知 AI 代理（例如代码助手）如何访问受保护的资源，例如需要身份验证的预览部署。\n\n文章重点介绍了 Vercel 的用例，其中受保护的预览部署阻止 AI 代理直接访问。虽然 Vercel 提供了诸如具有 `get_access_to_vercel_url` 等功能的 MCP 服务器之类的机制，但代理需要一种发现这些资源的方法。\n\n该解决方案利用新兴的 `llms.txt` 标准，通过使用自定义类型为 \"text/llms.txt\" 的 `<script>` 标签将指令嵌入到 HTML 中，从而针对 AI 内容。浏览器将忽略此标签，确保对渲染没有影响，而 LLM 可以解析这些指令。文章强调了其优势：易于实施，无需正式标准化，并且与现有 LLM 功能兼容。\n\n文章还提供了一个真实的例子，说明 Vercel 如何使用这种方法来指示代理如何获取身份验证绕过令牌并访问受保护的部署。它强调了超越身份验证的潜在用例，例如将代理定向到 MCP 服务以进行错误调查。作者鼓励开发人员立即开始使用此约定。"
  },
  {
    "id": "44956730",
    "title": "The forgotten meaning of \"jerk\"",
    "url": "https://languagehat.com/the-forgotten-meaning-of-jerk/",
    "summary": "The article discusses the semantic shift in the word \"jerk,\" from its original meaning of \"fool\" or \"simpleton\" to its current meaning of \"obnoxious person.\" The author, languagehat, was prompted by an article by Ben Lindbergh who noticed this change, questioning if \"jerk\" had always meant \"asshole.\"\n\nLindbergh highlights how even people who previously used \"jerk\" in its original sense have seemingly forgotten this usage, citing examples from Dave Barry's writing where the meaning evolves over time. The author also shares their own experience of initially believing \"jerk\" always meant \"asshole\" but later recalling using it in the \"dummy\" sense.\n\nThe comments section further explores the evolution and regional differences of the word. Commenters debate when they first encountered the word and its different meanings, with some remembering the \"fool\" meaning and others only knowing the \"obnoxious\" meaning. The discussion delves into the etymology of \"jerk,\" including its possible connections to \"jerk off\" and \"soda jerk,\" and how these connections may have influenced its meaning. A commenter also notes Sondheim's lyrics for \"Gee, Officer Krupke!\" as a transitional use of \"jerk\".\n",
    "chinese_title": "“混蛋”被遗忘的含义",
    "chinese_summary": "这篇文章探讨了“jerk”一词的语义转变，从最初“傻瓜”或“笨蛋”的意思演变为现在“令人讨厌的人”的意思。作者languagehat受到Ben Lindbergh文章的启发，Lindbergh注意到了这一变化，并质疑“jerk”是否一直意味着“混蛋”。\n\nLindbergh强调，即使是以前用“jerk”的原始含义的人似乎也忘记了这种用法，他引用了Dave Barry的写作中的例子，说明了该词的含义如何随着时间推移而演变。作者还分享了自己的经历，最初认为“jerk”一直意味着“混蛋”，但后来回忆起自己曾用它来表示“傻瓜”。\n\n评论区进一步探讨了这个词的演变和地域差异。评论者们争论他们第一次遇到这个词是什么时候，以及它的不同含义，有些人记得“傻瓜”的含义，而另一些人只知道“令人讨厌”的含义。讨论深入探讨了“jerk”的词源，包括其可能与“jerk off”和“soda jerk”的联系，以及这些联系如何影响了它的含义。一位评论者还指出，Sondheim为《Gee, Officer Krupke!》创作的歌词是“jerk”的过渡用法。"
  },
  {
    "id": "44939849",
    "title": "Intel Foundry Demonstrates First Arm-Based Chip on 18A Node",
    "url": "https://hothardware.com/news/intel-foundry-demos-deer-creek-falls-reference-soc",
    "summary": "In August 2025, Intel Foundry demonstrated its 18A process by showcasing \"Deer Creek Falls,\" a reference System-on-Chip (SoC) featuring Arm-based cores and ecosystem IPs. The video, briefly available on YouTube, revealed a three-tier CPU core configuration (energy-efficient, power-optimized, and high-performance) typical of Arm SoCs. The SoC explicitly uses AArch64 architecture, confirming its Arm-based nature.\n\nIntel's motivation for manufacturing an Arm SoC is likely to attract external customers for its foundry services, particularly given the prevalence of Arm chip designs. The demonstration contradicts rumors that Intel Foundry lacked the necessary performance optimization tools for external customers, potentially addressing concerns about the difficulty of implementing designs on Intel's process.\n\nWhile Deer Creek Falls utilizes the 18A process (already closed off to external customers), it may serve as proof of Intel's capabilities to attract customers for the upcoming 14A node. Apple and NVIDIA are reportedly evaluating Intel's 14A node, and securing a contract with either company would be a major victory for Intel Foundry, which needs external customers to avoid potentially pausing development on future nodes.\n",
    "chinese_title": "英特尔代工展示基于18A节点的首款Arm芯片",
    "chinese_summary": "2025年8月，英特尔代工展示了其18A工艺，推出了名为“鹿溪瀑布”的参考级片上系统(SoC)，该系统采用基于Arm的内核和生态系统IP。一段短暂出现在YouTube上的视频揭示了Arm SoC典型的三层CPU核心配置（节能、功率优化和高性能）。该SoC明确使用了AArch64架构，证实了其基于Arm的特性。\n\n英特尔制造Arm SoC的动机很可能是为了吸引其代工服务的外部客户，特别是考虑到Arm芯片设计的普及。此次演示驳斥了英特尔代工缺乏必要性能优化工具以服务外部客户的传言，并可能解决了人们对在英特尔工艺上实现设计困难的担忧。\n\n虽然“鹿溪瀑布”采用了18A工艺（已不对外部客户开放），但它可能作为英特尔能力的证明，以吸引客户使用即将推出的14A节点。据报道，苹果和英伟达正在评估英特尔的14A节点，与任何一家公司达成合同都将是英特尔代工的一大胜利，后者需要外部客户来避免可能暂停未来节点开发的局面。"
  },
  {
    "id": "44922362",
    "title": "How Figma’s multiplayer technology works (2019)",
    "url": "https://www.figma.com/blog/how-figmas-multiplayer-technology-works/",
    "summary": "This brief article, titled \"How Figma’s multiplayer technology works (2019),\" highlights the launch of Figma's multiplayer editing feature in September 2016. While the title suggests a deeper dive into the technical aspects, the actual text focuses primarily on announcing the feature's public release.\n\nThe key takeaway is the announcement itself: Figma introduced real-time collaborative editing capabilities, allowing multiple users to work on the same design file simultaneously. The article positions this as a significant update and a feature that users had been eagerly anticipating.\n\nAlthough the title alludes to explaining the technology behind the multiplayer functionality, the content doesn't deliver on this promise. It simply marks the occasion of the feature's public availability, categorizing the announcement under \"Product updates,\" \"Engineering,\" and \"News\" within Figma. Therefore, the main information is simply that Figma launched its much-desired multiplayer editing functionality in September 2016.\n",
    "chinese_title": "Figma多人协作技术原理 (2019)",
    "chinese_summary": "这篇题为“Figma多人协作技术原理（2019）”的短文，重点介绍了Figma于2016年9月发布的多人编辑功能。虽然标题暗示会深入探讨技术层面，但实际内容主要侧重于宣布该功能的公开发布。\n\n关键信息是这项发布本身：Figma推出了实时协作编辑功能，允许多个用户同时处理同一个设计文件。文章将其定位为一次重大更新，也是用户一直热切期盼的功能。\n\n尽管标题暗示会解释多人协作功能背后的技术，但内容并未兑现这一承诺。它只是标志着该功能公开发布的时刻，并将此公告归类于Figma内部的“产品更新”、“工程”和“新闻”之下。因此，主要信息仅仅是Figma于2016年9月发布了其广受欢迎的多人编辑功能。"
  },
  {
    "id": "44951200",
    "title": "Show HN: I've made an easy to extend and flexible JavaScript logger",
    "url": "https://github.com/inshinrei/halua",
    "summary": "This \"Show HN\" post introduces Halua, a JavaScript package designed to provide flexible control over logging, metrics, and potentially other related functionalities. Key takeaways include:\n\n*   **Purpose:** Halua aims to offer a comprehensive logging solution within JavaScript applications.\n*   **Features:** It supports multiple output formats, specifically mentioning Text, JSON, and Console handlers.\n*   **Extensibility:** A core benefit is its ease of extension, allowing developers to create and integrate custom handlers tailored to specific needs.\n*   **Documentation:** A \"Tour of Halua\" provides introductory documentation explaining basic concepts.\n*   **Installation:** The package can be easily installed using npm with the command `npm i halua`.\n",
    "chinese_title": "Show HN：我做了一个易于扩展且灵活的JavaScript日志记录器",
    "chinese_summary": "此“Show HN”帖子介绍 Halua，一个旨在为 JavaScript 提供灵活的日志、指标以及潜在的其他相关功能控制的 JavaScript 包。要点包括：\n\n*   **目的：** Halua 旨在提供 JavaScript 应用程序中全面的日志解决方案。\n*   **特性：** 它支持多种输出格式，特别是文本、JSON 和控制台处理程序。\n*   **可扩展性：** 一个核心优势是其易于扩展，允许开发人员创建和集成针对特定需求定制的自定义处理程序。\n*   **文档：** “Halua 之旅”提供了介绍基本概念的入门文档。\n*   **安装：** 可以使用 npm 轻松安装该包，命令为 `npm i halua`。"
  },
  {
    "id": "44954823",
    "title": "AnduinOS",
    "url": "https://www.anduinos.com/",
    "summary": "AnduinOS is a free and open-source, Ubuntu-based Linux distribution designed for ease of use, especially for users new to Linux. It boasts a user-friendly GNOME desktop environment, a small 2.0GB ISO size for easy installation, and compatibility with Ubuntu's extensive software ecosystem. A key design principle is privacy, with no user data collection, tracking, or profiling.\n\nAnduinOS offers two versions: LTS (Long Term Support) and Standard. The LTS version, based on Ubuntu 24.04 with Gnome 46 and Linux kernel 6.11, is recommended for users seeking stability and long-term support until April 2029. The Standard version, based on Ubuntu 25.04 with Gnome 48 and Linux kernel 6.14, aims for users with newer hardware who desire the latest features, with support until January 2026. Standard uses Flatpak for managing graphic applications, enhancing security and stability.\n\nAnduinOS can be used for a variety of purposes, from everyday computing and development to server applications and learning. User testimonials highlight its clean design, user-friendliness, performance improvements over Windows, and suitability for privacy-conscious users. The operating system emphasizes ease of use, particularly for Windows migrants. Support is available through GitHub Discussions, with reliance on Ubuntu's vast documentation and expertise. The project is funded by user donations and welcomes community contributions through Revolt and GitHub.\n",
    "chinese_title": "安度因操作系统",
    "chinese_summary": "AnduinOS 是一款免费开源的、基于 Ubuntu 的 Linux 发行版，专为易用性而设计，尤其适合 Linux 新手。它拥有用户友好的 GNOME 桌面环境，仅 2.0GB 的 ISO 镜像大小方便安装，并且兼容 Ubuntu 庞大的软件生态系统。其核心设计原则是隐私，不收集、追踪或分析用户数据。\n\nAnduinOS 提供两个版本：LTS（长期支持版）和标准版。LTS 版本基于 Ubuntu 24.04，采用 Gnome 46 和 Linux kernel 6.11，推荐给寻求稳定性和长期支持的用户，支持至 2029 年 4 月。标准版基于 Ubuntu 25.04，采用 Gnome 48 和 Linux kernel 6.14，面向拥有较新硬件并渴望最新功能的用户，支持至 2026 年 1 月。标准版使用 Flatpak 管理图形应用程序，增强了安全性和稳定性。\n\nAnduinOS 可用于各种用途，从日常计算和开发到服务器应用程序和学习。用户评价强调了其简洁的设计、用户友好性、优于 Windows 的性能改进以及对注重隐私用户的适用性。该操作系统强调易用性，特别是对于 Windows 迁移用户。支持通过 GitHub Discussions 提供，并依赖 Ubuntu 庞大的文档和专业知识。该项目由用户捐款资助，并欢迎通过 Revolt 和 GitHub 进行社区贡献。"
  },
  {
    "id": "44926143",
    "title": "Tiny, removable \"mini SSD\" could eventually be a big deal for gaming handhelds",
    "url": "https://arstechnica.com/gadgets/2025/08/tiny-removable-mini-ssd-could-eventually-be-a-big-deal-for-gaming-handhelds/",
    "summary": "This Ars Technica article discusses the potential of \"Mini SSDs\" as a fast, removable storage solution for gaming handhelds, addressing the increasing storage demands of modern games. Currently, microSD Express cards are the standard, but their performance often lags behind internal SSDs.\n\nBiwin's Mini SSD, a tiny 15x17mm card, aims to bridge this gap with read speeds up to 3,700MB/s using a PCIe 4.0 interface.  The cards, ranging from 500GB to 2TB, are inserted via a tray similar to a SIM card. Chinese gaming portables, such as the GPD Win 5 and OneXPlayer Super X, are already advertising support for this technology.\n\nThe article highlights the growing size of games, driven by higher-resolution textures, audio files, and extensive localization. Games like *The Last of Us Part 1* and *Cyberpunk 2077* exemplify this trend, with audio and language files significantly contributing to the overall install size. The Mac App Store version of *Cyberpunk 2077* is a particularly striking example, requiring 159GB due to including all voiceovers in every supported language.\n\nThe Mini SSD, while not a ratified standard, attempts to solve the problem of needing fast, easily upgradable storage for portable systems.  The article concludes that whether it's the Mini SSD, an improved microSD Express, or another format, the need for faster and more convenient storage solutions for gaming is evident.\n",
    "chinese_title": "微型可拆卸“迷你固态硬盘”最终可能对掌上游戏机意义重大",
    "chinese_summary": "Ars Technica 文章探讨了“迷你 SSD”作为游戏掌机快速、可移动存储解决方案的潜力，以应对现代游戏日益增长的存储需求。目前，microSD Express 卡是标准配置，但其性能通常落后于内置 SSD。\n\n佰维的迷你 SSD 是一种微型 15x17 毫米卡，旨在通过 PCIe 4.0 接口实现高达 3,700MB/s 的读取速度，从而弥补这一差距。这些卡容量从 500GB 到 2TB 不等，通过类似于 SIM 卡的托盘插入。 中国游戏掌机，如 GPD Win 5 和 OneXPlayer Super X，已经开始宣传对该技术的支持。\n\n文章强调了由于更高分辨率的纹理、音频文件和广泛的本地化，游戏体积日益增长。 《最后生还者第一部》和《赛博朋克2077》等游戏体现了这一趋势，音频和语言文件对整体安装大小贡献巨大。《赛博朋克2077》的 Mac App Store 版本就是一个特别引人注目的例子，由于包含所有支持语言的配音，因此需要 159GB 的空间。\n\n迷你 SSD 虽然不是一项获得批准的标准，但它试图解决便携式系统对快速、易于升级的存储的需求问题。 文章总结说，无论是迷你 SSD、改进的 microSD Express 还是其他格式，游戏对更快、更便捷的存储解决方案的需求都是显而易见的。"
  },
  {
    "id": "44925066",
    "title": "Graphene capacitors achieve rapid, high-depth modulation of terahertz waves",
    "url": "https://phys.org/news/2025-08-graphene-capacitors-rapid-high-depth.html",
    "summary": "Researchers at the University of Cambridge have developed a new method using graphene capacitors to rapidly and effectively control terahertz radiation, a challenging part of the electromagnetic spectrum. This innovation promises significant advancements in communications, imaging, and sensing technologies.\n\nThe team created tunable capacitors using ultra-small graphene patches within metamaterials, arrays of tiny resonators. Unlike previous methods that dampened resonance to modulate terahertz waves, this approach shifts the resonance, allowing for greater control. The graphene patches, less than a micron wide, act as tunable capacitors at the nanoscale. The device design reflects signals from its back surface, enhancing performance.\n\nThis novel design achieves a modulation depth exceeding 99.99% at speeds of 30 MHz, a combination previously unattainable. This significantly outperforms existing modulator technologies and can be adapted for use across the terahertz range.\n\nThe researchers believe their design can be applied to other metamaterial-based modulators, potentially influencing future technologies reliant on resonator performance. With ongoing research focused on terahertz communications systems, these findings represent a significant step toward next-generation communication technologies beyond 5G and 6G.\n",
    "chinese_title": "石墨烯电容器实现太赫兹波的快速高深度调制",
    "chinese_summary": "剑桥大学研究人员开发了一种利用石墨烯电容器快速有效控制太赫兹辐射的新方法，太赫兹辐射是电磁波谱中一个具有挑战性的部分。这项创新有望在通信、成像和传感技术方面取得重大进展。\n\n该团队在超材料（微型谐振器阵列）中利用超小型石墨烯贴片创建了可调电容器。与以往通过抑制谐振来调制太赫兹波的方法不同，这种方法通过移动谐振来实现更强的控制。这些宽度小于一微米的石墨烯贴片在纳米尺度上充当可调电容器。该设备设计通过反射其背面信号来增强性能。\n\n这种新颖的设计实现了超过 99.99% 的调制深度，速度高达 30 MHz，这是以前无法实现的组合。这大大优于现有的调制器技术，并可以适用于整个太赫兹范围。\n\n研究人员认为，他们的设计可以应用于其他基于超材料的调制器，从而可能影响未来依赖谐振器性能的技术。随着目前的研究重点集中在太赫兹通信系统上，这些发现代表着朝着超越 5G 和 6G 的下一代通信技术迈出了重要一步。"
  },
  {
    "id": "44958752",
    "title": "Type-machine",
    "url": "https://arthi-chaud.github.io/posts/type-machine/",
    "summary": "This article introduces `type-machine`, a Haskell library leveraging Template Haskell to enhance record type manipulation and simulate structural subtyping, drawing inspiration from TypeScript's type-transformers.  The library provides functions to derive record types and generate typeclasses for structural subtyping.\n\nThe core features revolve around the `type_` function, which derives types using a `TM Type` computation, and type-transformers like `pick`, `omit`, `record`, `intersection`, and `apply` to manipulate record structures. Infix operators `<:>` and `<::>` streamline the application of these transformers.  `defineIs` generates typeclasses with getters, setters, and transformation functions for each field, while `deriveIs` creates instances for these typeclasses.\n\nThe article highlights the benefits in web API development, allowing the derivation of user-facing models (UserResponse, UserForm) from database models (UserRecord).  While acknowledging limitations like the need for `DuplicateRecordFields`, the single-constructor constraint, and desired improvements like a `defineConstraint` function, the library demonstrates superior runtime performance compared to heterogeneous lists for record modeling.  Microbenchmarks show `type-machine` to be significantly faster in both build and traversal times than `extensible` and `superrecord`. The author welcomes feedback and contributions.\n",
    "chinese_title": "打字机",
    "chinese_summary": "本文介绍了`type-machine`，一个利用Template Haskell的Haskell库，旨在增强记录类型操作并模拟结构子类型，其灵感来源于TypeScript的类型转换器。该库提供函数来派生记录类型，并为结构子类型生成类型类。\n\n其核心功能围绕`type_`函数展开，该函数使用`TM Type`计算来派生类型，并使用诸如`pick`、`omit`、`record`、`intersection`和`apply`等类型转换器来操作记录结构。 中缀运算符`<:>`和`<::>`简化了这些转换器的应用。 `defineIs`为每个字段生成带有getter、setter和转换函数的类型类，而`deriveIs`则为这些类型类创建实例。\n\n文章重点介绍了在Web API开发中的优势，允许从数据库模型（UserRecord）派生面向用户的模型（UserResponse，UserForm）。 虽然承认了诸如需要`DuplicateRecordFields`、单构造函数约束以及对诸如`defineConstraint`函数的需求等限制，但该库在记录建模方面表现出比异构列表更优越的运行时性能。 微基准测试表明，在构建和遍历时间方面，`type-machine`比`extensible`和`superrecord`快得多。 作者欢迎反馈和贡献。"
  },
  {
    "id": "44949895",
    "title": "Custom telescope mount using harmonic drives and ESP32",
    "url": "https://www.svendewaerhert.com/blog/telescope-mount/",
    "summary": "Sven De Waerhert details his journey of building a custom telescope mount using harmonic drives and an ESP32 microcontroller, driven by a desire for better astrophotography than he could achieve with a basic tracker. Frustrated with the high cost of commercial mounts, he leveraged newly acquired PCB design skills and open-source resources.\n\nThe project involved extensive research into harmonic drives, stepper motors, and open-source FOC implementations. He designed a custom PCB for motor control, power delivery via USB-C, and future expansion capabilities. The RA and DEC axes utilize integrated motors with harmonic drives for precise tracking.\n\nThe build integrates with OnStepX firmware for telescope mount control, addressing initial WiFi instability issues. Manufacturing was handled by JLCPCB, with minor adjustments needed during assembly.\n\nDespite initial challenges with polar alignment, software configuration, and a costly mistake with the first PCB revision, the mount achieved 1-2 arcsecond precision, suitable for 30-second exposures with a 600mm lens.\n\nWhile the total project cost reached approximately €1,700 (estimated €800 for a single unit), the primary motivation was not cost savings but the learning experience and the satisfaction of building a functional, custom telescope mount. The project significantly improved his skills in PCB design, FreeCAD modeling, and astrophotography techniques. The article emphasizes the value of the hands-on experience and the deep understanding gained by building the mount from scratch.\n",
    "chinese_title": "使用谐波驱动和ESP32的定制望远镜赤道仪",
    "chinese_summary": "Sven De Waerhert 详述了他使用谐波减速器和 ESP32 微控制器构建定制望远镜赤道仪的历程，其动力源于渴望获得比基本跟踪器更好的天文摄影效果。由于对商业赤道仪的高昂价格感到沮丧，他利用了新获得的 PCB 设计技能和开源资源。\n\n该项目涉及对谐波减速器、步进电机和开源 FOC 实现的广泛研究。他设计了一款定制 PCB，用于电机控制、通过 USB-C 供电以及未来的扩展功能。赤经和赤纬轴采用集成了谐波减速器的集成电机，以实现精确跟踪。\n\n该构建集成了 OnStepX 固件，用于望远镜赤道仪控制，解决了最初的 WiFi 不稳定问题。制造由 JLCPCB 负责，组装过程中需要进行少量调整。\n\n尽管在极轴对齐、软件配置和第一版 PCB 的昂贵错误方面存在最初的挑战，但该赤道仪实现了 1-2 角秒的精度，适用于使用 600 毫米镜头进行 30 秒的曝光。\n\n虽然项目总成本达到约 1,700 欧元（估计单个设备为 800 欧元），但主要动机不是节省成本，而是学习经验以及构建功能性定制望远镜赤道仪的满足感。该项目显着提高了他在 PCB 设计、FreeCAD 建模和天文摄影技术方面的技能。文章强调了动手经验的价值以及通过从头开始构建赤道仪获得的深刻理解。"
  },
  {
    "id": "44956581",
    "title": "Drunken Bishop (2023)",
    "url": "https://re.factorcode.org/2023/08/drunken-bishop.html",
    "summary": "This article explains the \"Drunken Bishop\" algorithm used by OpenSSH to visually represent public key fingerprints, making it easier for users to identify changes. The algorithm, a type of \"random art,\" transforms a key's hash into an ASCII art image on a grid.\n\nThe author details how the algorithm works: it starts at the center of a grid, and each 2-bit chunk of the hash determines a diagonal movement direction for a \"bishop.\" The bishop moves around the grid, incrementing a counter in each visited cell, though movement is blocked by the grid's edges. The starting and ending positions are specifically marked.\n\nThe article then provides a Factor programming language implementation of the algorithm, including constants for grid dimensions and the ASCII symbols used for rendering the grid based on the counter values in each cell. A code snippet demonstrates how to convert a hexadecimal string into bytes and then use the `drunken-bishop.` function to generate the visual representation.\n\nFinally, the author notes that this functionality is available in the \"drunken-bishop\" vocabulary in recent development versions of the Factor language.\n",
    "chinese_title": "醉汉主教 (2023)",
    "chinese_summary": "本文解释了 OpenSSH 使用的“醉汉主教”算法，该算法以可视方式表示公钥指纹，使用户更容易识别更改。该算法是一种“随机艺术”，将密钥的哈希值转换为网格上的 ASCII 艺术图像。\n\n作者详细介绍了该算法的工作原理：它从网格的中心开始，哈希值的每 2 位块决定了“主教”的对角线移动方向。主教在网格上移动，递增每个访问单元格中的计数器，但移动会被网格边缘阻挡。起始位置和结束位置被特别标记。\n\n文章随后提供了该算法的 Factor 编程语言实现，包括网格尺寸的常量和用于基于每个单元格中的计数器值渲染网格的 ASCII 符号。代码片段演示了如何将十六进制字符串转换为字节，然后使用 `drunken-bishop.` 函数生成可视化表示。\n\n最后，作者指出，此功能在 Factor 语言的最新开发版本中的“drunken-bishop”词汇表中可用。"
  },
  {
    "id": "44953575",
    "title": "Why Semantic Layers Matter (and how to build one with DuckDB)",
    "url": "https://motherduck.com/blog/semantic-layer-duckdb-tutorial/",
    "summary": "This article, \"Why Semantic Layers Matter — and How to Build One with DuckDB,\" explores the value of semantic layers in data analytics and demonstrates how to build a basic one using YAML, Python, Ibis, and DuckDB. It starts by outlining situations where a semantic layer is not necessary, such as when dealing with simple analytics, a single consumer, or pre-processed metrics.\n\nThe article then dives into the reasons for using a semantic layer: unified metric definitions across tools, caching for ad hoc queries, unified access-level security, dynamic query rewriting for complex analytics, and providing context for LLMs. The author highlights that semantic layers bridge the gap between business needs and data sources, particularly benefiting larger enterprises with numerous KPIs.\n\nThe practical example focuses on a simple semantic layer using YAML definitions for metrics and dimensions, and Ibis for query translation to DuckDB. It uses the NYC Taxi Dataset to illustrate the concepts. The article showcases how to explore the data with DuckDB commands like `COUNT` and `DESCRIBE`, and then demonstrates how semantic layers define calculated measures and dimensions. It clarifies the difference between persistent datasets and ad hoc aggregations, arguing that the latter necessitates a semantic layer.\n\nThe article emphasizes that while this example is basic, more advanced semantic layers offer APIs, security controls, and caching layers. It also references external resources for further exploration of semantic layers and related concepts.\n",
    "chinese_title": "为什么语义层很重要（以及如何使用 DuckDB 构建一个）",
    "chinese_summary": "语义层为何重要 — 以及如何使用 DuckDB 构建一个\n\n本文探讨了语义层在数据分析中的价值，并演示了如何使用 YAML、Python、Ibis 和 DuckDB 构建一个基本的语义层。文章首先概述了不需要语义层的情况，例如处理简单分析、单个消费者或预处理指标时。\n\n随后，文章深入探讨了使用语义层的原因：跨工具的统一指标定义、即席查询的缓存、统一的访问级别安全性、复杂分析的动态查询重写以及为 LLM 提供上下文。作者强调，语义层弥合了业务需求和数据源之间的差距，尤其有利于拥有大量 KPI 的大型企业。\n\n该实践示例侧重于一个简单的语义层，使用 YAML 定义指标和维度，并使用 Ibis 将查询转换为 DuckDB。它使用纽约出租车数据集来说明这些概念。文章展示了如何使用 DuckDB 命令（如 `COUNT` 和 `DESCRIBE`）来探索数据，然后演示了语义层如何定义计算度量和维度。文章阐明了持久数据集和临时聚合之间的区别，并认为后者需要语义层。\n\n文章强调，虽然此示例很简单，但更高级的语义层提供 API、安全控制和缓存层。文章还引用了外部资源，以便进一步探索语义层和相关概念。"
  },
  {
    "id": "44955459",
    "title": "CRDT: Text Buffer",
    "url": "https://madebyevan.com/algos/crdt-text-buffer/",
    "summary": "This article presents a CRDT (Conflict-free Replicated Data Type) algorithm for collaboratively editing text strings, similar to those used in libraries like Yjs and Automerge.  The core idea involves assigning each character a unique identifier based on the creator's site, a clock, and a parent pointer.  Insertions are tracked by setting the parent pointer to the character immediately preceding the insertion point.  Character order is determined via a pre-order tree traversal, with ordering among siblings resolved by a counter and site ID. Deletions are handled by adding the character's identifier to a \"deleted set,\" essentially creating a tombstone.\n\nThe article highlights key optimizations: merging successive inserts from the same site into memory blocks, storing these blocks contiguously in a pre-sorted array, and representing delete sets using range-based representation for consecutive deletes.\n\nThe article lists benefits like reasonable memory usage and O(log n) performance for queries and updates. It also points out drawbacks: the complexity of splitting and merging logic, the need for fuzz testing, and the \"grow-only\" nature where deletions don't reduce metadata size.  Addressing data removal while maintaining consistency across peers is noted as a significant challenge. The article concludes with references to other resources on CRDT text buffers.\n",
    "chinese_title": "CRDT：文本缓冲区",
    "chinese_summary": "本文介绍了一种用于协同编辑文本字符串的 CRDT (无冲突复制数据类型) 算法，类似于 Yjs 和 Automerge 等库中使用的算法。其核心思想是基于创建者的站点、时钟和父指针为每个字符分配一个唯一标识符。插入操作通过将父指针设置为紧接插入点之前的字符来跟踪。字符顺序通过前序树遍历确定，兄弟节点之间的顺序通过计数器和站点 ID 解决。删除操作通过将字符的标识符添加到“已删除集合”来处理，本质上是创建一个墓碑。\n\n本文重点介绍了关键优化：将来自同一站点的连续插入合并到内存块中，将这些块连续存储在预排序的数组中，以及使用基于范围的表示来表示连续删除的删除集合。\n\n本文列出了诸如合理的内存使用和查询及更新的 O(log n) 性能等优点。它还指出了缺点：拆分和合并逻辑的复杂性、需要模糊测试，以及删除操作不会减少元数据大小的“只增长”性质。在保持对等体之间一致性的同时解决数据删除问题被认为是一个重大挑战。本文最后引用了有关 CRDT 文本缓冲区的其他资源。"
  },
  {
    "id": "44955576",
    "title": "Show HN: OpenAI/reflect – Physical AI Assistant that illuminates your life",
    "url": "https://github.com/openai/openai-reflect",
    "summary": "\"Reflect\" is a hackathon project from OpenAI, aiming to create a physical AI assistant that interacts with the user through sound, light, and color, avoiding screens. It uses the user's phone as the central source of information and key for interacting with the device, keeping it stateless.\n\nThe device focuses on reflecting on past events (using calendar information), preparing for future events (like suggesting study sessions for upcoming tests), assisting with productivity (playing music, answering questions), and being location-aware (adapting behavior based on the room). The project prioritizes being easy to modify, affordable, and accessible.\n\nCurrently, Reflect is designed for the M5Stack CoreS3 ESP32S3 loT Development Kit microcontroller and LIFX Color A19 lights. Setup involves installing esp-idf, cloning the repository, and flashing the code to the device. Once connected to the device's WiFi access point, users can access a webpage to start a session and debug audio streams. The provided video demonstrates the device's functionality. The code is offered as-is with no guarantees and should be used with caution.\n",
    "chinese_title": "Show HN: OpenAI/reflect – 照亮你生活的物理AI助手",
    "chinese_summary": "Reflect：OpenAI的无屏AI助手原型，利用用户的手机作为信息中心，通过声音、光线和色彩与用户交互，反思过去、准备未来、提高效率并感知位置。项目易修改、低成本、易获取。目前，Reflect基于M5Stack CoreS3 ESP32S3 loT开发套件和LIFX Color A19灯。设置包括安装esp-idf，克隆仓库，并将代码刷入设备。连接到设备WiFi热点后，用户可以通过网页开始会话并调试音频流。视频演示了设备的功能。代码按原样提供，不作任何保证，请谨慎使用。"
  },
  {
    "id": "44939939",
    "title": "Why we still build with Ruby in 2025",
    "url": "https://www.getlago.com/blog/why-we-still-build-with-ruby-in-2025",
    "summary": "This short piece, titled \"Why we still build with Ruby in 2025,\" focuses on the billing benefits of using the Lago platform, specifically for Ruby-based projects. The central argument is that Lago eliminates billing concerns, regardless of whether users opt for the premium or open-source version.\n\nIt highlights two options: Lago Premium and Lago Open Source. Lago Premium is presented as the ideal solution for teams that require control and flexibility, inviting readers to book a demo. Lago Open Source is positioned as the best choice for smaller projects, encouraging users to deploy the open-source version.\n\nThe core message is that Lago offers a reliable and worry-free billing solution for Ruby development in 2025, allowing developers to concentrate on building and project success instead of managing billing complexities. The piece suggests that Lago's either premium or open-source approach provides viable and dependable billing solutions.\n",
    "chinese_title": "2025年我们为什么还要用Ruby",
    "chinese_summary": "题为“2025年我们为何依旧使用Ruby构建”的短文，重点介绍了使用Lago平台，特别是针对基于Ruby的项目，在账单方面的优势。核心论点是，无论用户选择高级版还是开源版，Lago都能消除账单方面的顾虑。\n\n文中强调了两个选项：Lago高级版和Lago开源版。 Lago高级版被认为是需要控制和灵活性的团队的理想解决方案，并邀请读者预订演示。 Lago开源版则定位为较小项目的最佳选择，鼓励用户部署开源版本。\n\n核心信息是，Lago在2025年为Ruby开发提供了一个可靠且无忧的账单解决方案，使开发人员能够专注于构建和项目成功，而不是管理复杂的账单。 该文表明，Lago的高级版或开源版方法都提供了可行且可靠的账单解决方案。"
  },
  {
    "id": "44962771",
    "title": "Home Depot Sued for 'Secretly' Using Facial Recognition at Self-Checkouts",
    "url": "https://petapixel.com/2025/08/20/home-depot-sued-for-secretly-using-facial-recognition-technology-on-self-checkout-cameras/",
    "summary": "A Home Depot customer, Benjamin Jankowski, has filed a proposed class action lawsuit against the retail giant, alleging the company is secretly using facial recognition technology at its self-checkout kiosks in Illinois stores. Jankowski claims that during a recent visit to a Chicago Home Depot, he noticed a green box appearing around his face on the self-checkout screen, leading him to believe his facial features were being recorded without his consent.\n\nThe lawsuit contends that Home Depot's \"computer vision\" technology, implemented in 2024 to reduce theft, captures and stores shoppers' facial geometry, violating the Illinois Biometric Information Privacy Act (BIPA). BIPA requires companies to inform individuals about biometric data collection, explain its use, and obtain written consent – all of which Jankowski claims Home Depot failed to do.\n\nJankowski seeks to represent other Illinois shoppers whose facial data was allegedly scanned without consent. He is requesting the court to award damages of $1,000 per negligent BIPA violation and $5,000 per willful violation. The lawsuit draws parallels to the Rite Aid case, where the company was banned from using facial recognition technology for five years due to its inaccurate and harmful application.\n",
    "chinese_title": "家得宝因在自助结账处“秘密”使用面部识别技术而被起诉",
    "chinese_summary": "本杰明·扬科夫斯基作为家得宝的顾客，对这家零售业巨头提起了一项拟议的集体诉讼，指控该公司秘密在其伊利诺伊州门店的自助结账机上使用面部识别技术。扬科夫斯基声称，最近一次在芝加哥家得宝购物时，他注意到自助结账屏幕上他的脸周围出现了一个绿色框，这让他相信自己的面部特征在未经同意的情况下被记录下来。\n\n该诉讼称，家得宝于2024年实施的“计算机视觉”技术，旨在减少盗窃，该技术会捕捉并存储购物者的面部几何数据，违反了伊利诺伊州生物识别信息隐私法（BIPA）。BIPA要求公司告知个人关于生物识别数据的收集，解释其用途，并获得书面同意——扬科夫斯基声称家得宝未能做到所有这些。\n\n扬科夫斯基寻求代表其他据称在未经同意的情况下被扫描面部数据的伊利诺伊州购物者。他请求法院判决每项疏忽违反BIPA的行为赔偿1000美元，每项故意违反行为赔偿5000美元。该诉讼将此案与来德爱(Rite Aid)案件相提并论，在该案中，由于来德爱公司对面部识别技术的不准确和有害应用，该公司被禁止使用该技术五年。"
  },
  {
    "id": "44958145",
    "title": "We’re Not So Special: A new book challenges human exceptionalism",
    "url": "https://democracyjournal.org/magazine/78/were-not-so-special/",
    "summary": "Cass R. Sunstein reviews Christine Webb's \"The Arrogant Ape,\" which challenges the notion of human exceptionalism and argues that it negatively impacts science, the environment, and human life. Webb contends that humans wrongly use themselves as the baseline for measuring other species, leading to a skewed understanding of their abilities and experiences (umwelt). She highlights scientific findings revealing the diverse and remarkable senses and cognitive capabilities of animals like hummingbirds, elephants, owls, and dogs, demonstrating how human-centric tests often underestimate them.\n\nWebb criticizes studying animals in artificial, stressful lab conditions, which skews results about their behavior. She focuses on animal emotions and empathy, providing evidence of consolation among chimpanzees. Webb rejects the \"so like us\" approach, advocating for appreciation of each species' unique qualities and capabilities.\n\nSunstein notes that Webb's work offers a scientific and ethical argument for protecting animal well-being, going beyond simply acknowledging their capacity to suffer. She advocates for a \"capabilities approach,\" promoting and protecting the unique potential of each species.\n\nUltimately, Webb argues that human exceptionalism is not only unscientific but also harmful, contributing to the ecological crisis and mistreatment of animals. She calls for humility, awe, and a re-enchantment of the world, urging a shift in perspective to appreciate and respect the inherent value and capabilities of all living beings. Her book, while not a policy manual, inspires a fundamental rethinking of humanity's relationship with the animal world.\n",
    "chinese_title": "我们并非如此特别：一本新书挑战人类独特性",
    "chinese_summary": "卡斯·R·桑斯坦评克里斯汀·韦伯《傲慢的猿猴》：该书挑战了人类例外论的观点，并认为它对科学、环境和人类生活产生了负面影响。韦伯认为，人类错误地将自己作为衡量其他物种的基准，导致对其能力和体验（环境）的理解产生偏差。她强调了科学发现，揭示了蜂鸟、大象、猫头鹰和狗等动物多样且非凡的感官和认知能力，证明了以人类为中心的测试往往低估了它们。\n\n韦伯批评在人为的、有压力的实验室条件下研究动物，这会歪曲关于它们行为的结果。她关注动物的情感和同情心，提供了黑猩猩之间互相安慰的证据。韦伯反对“与我们相似”的方法，主张欣赏每个物种的独特品质和能力。\n\n桑斯坦指出，韦伯的著作为保护动物福祉提供了科学和伦理论据，超越了仅仅承认它们承受痛苦的能力。她提倡一种“能力方法”，促进和保护每个物种的独特潜力。\n\n最终，韦伯认为人类例外论不仅不科学，而且有害，导致了生态危机和对动物的虐待。她呼吁谦逊、敬畏和对世界的重新迷恋，敦促转变视角，以欣赏和尊重所有生物的内在价值和能力。她的书虽然不是政策手册，但激发了对人类与动物世界关系的根本性反思。"
  },
  {
    "id": "44938622",
    "title": "Geotoy – Shadertoy for 3D Geometry",
    "url": "https://3d.ameo.design/geotoy",
    "summary": "The article introduces \"Geotoy,\" described as \"Shadertoy for 3D Geometry.\" It appears to be a platform or tool that allows users to create and share 3D geometric designs, similar to how Shadertoy enables the creation and sharing of shaders.\n\nThe content then lists a series of projects or examples created using Geotoy, identified by the author prefix \"ameo\". These examples showcase a diverse range of 3D geometries, including:\n\n*   3D Hilbert Curve\n*   Various landscapes and terrain (FBM Terrain, Terraced Floating Island)\n*   Organic shapes (Torus Knot, Dandelion, Roots, Bumpy Sphere)\n*   Abstract forms (Abstract Hourglass)\n*   Representational objects (Birdbath, Concrete Tetrapod, Extruded Clay Bowl, Superellipse Dominos, Dark Souls Tree)\n*   And other creative geometries (Power Line, Woven WIP, Fancy Shader Props).\n\nThe final line \"author: ameo\" likely indicates that all the listed examples are created by the same author, \"ameo\". In summary, Geotoy allows the creation and sharing of 3D geometry, as shown by the diverse projects of author \"ameo\".\n",
    "chinese_title": "Geotoy – 3D几何体的 Shadertoy",
    "chinese_summary": "文章介绍了“Geotoy”，称其为“3D几何体的Shadertoy”。它似乎是一个平台或工具，允许用户创建和分享3D几何设计，类似于Shadertoy实现创建和分享着色器的方式。\n\n内容随后列出了一系列使用Geotoy创建的项目或示例，并以作者前缀“ameo”标识。这些示例展示了各种各样的3D几何体，包括：\n\n*   3D希尔伯特曲线\n*   各种景观和地形（FBM地形，阶梯式浮岛）\n*   有机形状（环面纽结，蒲公英，根，凹凸球体）\n*   抽象形式（抽象沙漏）\n*   具象物体（鸟浴池，混凝土四脚体，拉伸粘土碗，超椭圆多米诺骨牌，黑暗之魂树）\n*   以及其他创意几何体（输电线，编织WIP，花式着色器道具）。\n\n最后一行“作者：ameo”可能表示所有列出的示例均由同一作者“ameo”创建。总而言之，Geotoy允许创建和共享3D几何体，作者“ameo”的各种项目就证明了这一点。"
  },
  {
    "id": "44939460",
    "title": "The new geography of stolen goods",
    "url": "https://www.economist.com/interactive/britain/2025/08/17/the-new-geography-of-stolen-goods",
    "summary": "The article \"The new geography of stolen goods\" details how Britain has become a leading exporter of stolen goods, including cars, phones, and agricultural equipment. This is facilitated by encrypted communications, weak export controls, and rising demand for goods in Africa and Asia, creating a global criminal enterprise dubbed \"Grand Theft Global Inc.\"\n\nVehicle thefts in Britain have surged, with many cars ending up in West Africa, often routed through the Democratic Republic of Congo, which serves as an entry point to a wider African market. London is now Europe’s \"phone-snatching capital,\" with stolen phones typically ending up in the Huaqiangbei market in Shenzhen, China, where they are either resold or broken down for parts. Russian sanctions have also led to an increase in the theft of GPS kits from British farms.\n\nSeveral factors contribute to the growth of this criminal enterprise: lax export controls, the ability to conduct business covertly online, the increasing cost of goods relative to incomes, and the under-resourcing of police forces. Border agencies primarily focus on imports, making it easier to export stolen goods undetected.\n\nThe article points out that countries benefiting from the trade, like China, lack incentive to curb it, while African countries often lack the enforcement capability. The gains from trade and globalization facilitate the transport of stolen goods. This highlights the need for increased international cooperation to combat this growing criminal enterprise.\n",
    "chinese_title": "失窃物品的新地理学",
    "chinese_summary": "失窃商品的新地理：英国沦为销赃中心\n\n文章《失窃商品的新地理》详细描述了英国如何成为失窃商品（包括汽车、手机和农业设备）的主要出口国。加密通信、薄弱的出口管制以及非洲和亚洲对商品日益增长的需求为此提供了便利，从而催生了一个被称为“全球盗窃公司”的全球犯罪企业。\n\n英国的汽车盗窃案激增，许多汽车最终流向西非，通常经由刚果民主共和国，该国是进入更广阔非洲市场的入口。伦敦现在是欧洲的“抢手机之都”，被盗手机通常最终流向中国深圳的华强北市场，在那里它们被转售或拆解成零件。俄罗斯的制裁也导致英国农场GPS套件的盗窃案增加。\n\n导致这一犯罪企业增长的因素有几个：宽松的出口管制、在线秘密开展业务的能力、相对于收入而言不断上涨的商品成本，以及警力不足。边境机构主要关注进口，使得出口被盗商品更容易而不被发现。\n\n文章指出，像中国这样从贸易中受益的国家缺乏遏制它的动机，而非洲国家往往缺乏执法能力。贸易和全球化带来的收益促进了被盗商品的运输。 这突显了加强国际合作以打击这一日益增长的犯罪企业的必要性。"
  },
  {
    "id": "44938354",
    "title": "The joy of recursion, immutable data, & pure functions: Making mazes with JS",
    "url": "https://jrsinclair.com/articles/2025/joy-of-immutable-data-recursion-pure-functions-javascript-mazes/",
    "summary": "This article by James Sinclair explores building mazes using JavaScript to illustrate the concepts of recursion, immutable data, and pure functions. It argues that while maze generation isn't directly practical, it's a manageable and interesting challenge for learning these coding principles.\n\nThe article begins by outlining a step-by-step process for manually creating a maze on a grid. Then, it translates this manual process into an algorithm. The code then proceeds to construct an immutable data structure, specifically a `Point` class using memoization and object freezing, to ensure objects are not modified after creation. The benefits of this approach, particularly with how it allows for easy comparison using `===`, are discussed.\n\nThe article then dives into coding the maze-building algorithm, emphasizing pure functions and recursion. It covers initializing the maze state with a grid of unconnected rooms and a randomly selected starting room, including a custom pseudo-random number generator to maintain function purity. Finally, it sets the stage for writing the recursive maze generation function by highlighting the importance of tracking state (current room, grid, and random number seed) and defining clear exit conditions, mirroring the considerations when writing loops.\n",
    "chinese_title": "递归的乐趣，不可变数据和纯函数：用JS制作迷宫",
    "chinese_summary": "詹姆斯·辛克莱的这篇文章探讨了如何使用JavaScript构建迷宫，以阐释递归、不可变数据和纯函数的概念。它认为，虽然迷宫生成并非直接实用，但对于学习这些编码原则来说，是一个可控且有趣的挑战。\n\n文章首先概述了在网格上手动创建迷宫的逐步过程，然后将这个手动过程转化为算法。接着，代码构建了一个不可变的数据结构，具体来说，使用记忆化和对象冻结构建了一个`Point`类，以确保对象在创建后不会被修改。文章讨论了这种方法的好处，特别是它如何允许使用`===`轻松进行比较。\n\n之后，文章深入研究了迷宫构建算法的编码，强调了纯函数和递归。它涵盖了使用未连接房间的网格和一个随机选择的起始房间来初始化迷宫状态，包括使用自定义的伪随机数生成器来保持函数的纯净性。最后，文章为编写递归迷宫生成函数奠定了基础，强调了跟踪状态（当前房间、网格和随机数种子）以及定义清晰的退出条件的重要性，这与编写循环时的考虑因素类似。"
  },
  {
    "id": "44927953",
    "title": "Passive Microwave Repeaters",
    "url": "https://computer.rip/2025-08-16-passive-microwave-repeaters.html",
    "summary": "This article discusses passive microwave repeaters, a technology developed to overcome limitations of early microwave communication systems. Microwave radio revolutionized telecommunications by offering greater bandwidth and capacity compared to coaxial cables. However, microwave signals require a direct line of sight, posing challenges in mountainous regions or areas lacking readily accessible terrain.\n\nPassive microwave repeaters, essentially large flat reflectors, solve this problem by redirecting microwave signals, acting as \"mirrors\" for radio waves. These repeaters are especially beneficial for independent telephone companies and rural Bell Operating Companies that cannot afford the cost of active microwave relays.\n\nThe Kreitzberg brothers pioneered this technology through their company, Microflect, which built aluminum reflectors for installations in areas with challenging terrain, adverse weather, and limited access to utilities.\n\nThe article explains how passive repeaters work in two configurations: reflecting signals at a 90-degree angle to maneuver around obstacles or using two repeaters in a \"dogleg\" arrangement for straighter paths. Despite their passive nature, these repeaters can provide signal gain due to their large surface area, effectively collecting and re-emitting a larger cross-section of RF energy, similar to a large antenna focusing the signal. Their size is directly proportional to the amount of gain. Passive repeaters are categorized as far or near field. This innovative approach allowed for expanded microwave communication networks in difficult environments where active repeaters were impractical.\n",
    "chinese_title": "无源微波中继器",
    "chinese_summary": "本文探讨了无源微波中继器，这项技术旨在克服早期微波通信系统的局限性。与同轴电缆相比，微波无线电通过提供更大的带宽和容量，彻底改变了电信业。然而，微波信号需要直视路径，这给山区或缺乏易于到达的地形区域带来了挑战。\n\n无源微波中继器本质上是大型平面反射器，通过重定向微波信号来解决这个问题，充当无线电波的“镜子”。这些中继器尤其有利于那些无法负担有源微波中继成本的独立电话公司和农村贝尔运营公司。\n\nKreitzberg 兄弟通过他们的公司 Microflect 开创了这项技术，该公司为具有挑战性地形、恶劣天气以及公用设施接入受限地区的安装建造了铝制反射器。\n\n本文解释了无源中继器如何在两种配置下工作：以 90 度角反射信号以绕过障碍物，或者使用两个中继器以“狗腿”布置实现更直的路径。尽管它们是被动的，但这些中继器由于其大的表面积，可以提供信号增益，有效地收集和重新发射更大截面的射频能量，类似于大型天线聚焦信号。它们的大小与增益成正比。无源中继器分为远场或近场。这种创新方法使得在有源中继器不切实际的困难环境中扩展微波通信网络成为可能。"
  },
  {
    "id": "44952789",
    "title": "A renovation project in Turkey led to the discovery of a lost city (2023)",
    "url": "https://www.atlasobscura.com/articles/derinkuyu-turkey-underground-city-strange-maps",
    "summary": "In 1963, a man in Derinkuyu, Turkey, accidentally discovered a vast, multi-level underground city while renovating his basement. This rediscovered complex, now a major tourist attraction, is believed to have been built and used for centuries by various civilizations, including potentially the Hittites, Phrygians, or early Christians, starting as early as 2000 B.C.\n\nThe city, carved into the soft volcanic tuff rock characteristic of Cappadocia, could house up to 20,000 people and served primarily as a refuge from enemy armies and potentially as a temperature-controlled shelter from harsh weather. Evidence suggests it was extensively used during conflicts between the Byzantines and Arabs, the Mongol raids, and the Ottoman conquest.\n\nDerinkuyu boasts a sophisticated design, featuring over 15,000 ventilation shafts reaching deep into the city, as well as strategically placed rolling stones to seal it off. It includes living quarters, storage areas, dungeons, churches, and even space for livestock and wine production.\n\nThe local Greek population, who called the city Malakopia (\"soft place\"), continued to use it as a refuge into the early 20th century.  Following the Greco-Turkish War, they left the area in 1923 as part of a population exchange, abandoning the city until its rediscovery. The article highlights the city's impressive engineering, its historical significance as a refuge, and its modern-day role as a popular destination, encouraging readers to consider the undiscovered potential lurking in their own homes.\n",
    "chinese_title": "土耳其一处翻新工程发现失落之城（2023年）",
    "chinese_summary": "1963年，土耳其代林库尤的一个男子在翻新地下室时，意外发现了一座巨大的多层地下城市。这个被重新发现的建筑群现已成为主要的旅游景点，据信由包括赫梯人、弗里吉亚人或早期基督徒在内的多个文明建造并使用了数个世纪，最早可追溯到公元前2000年。\n\n这座城市开凿于卡帕多西亚特有的柔软火山凝灰岩中，可容纳多达2万人，主要用作躲避敌军的避难所，也可能用作抵御恶劣天气的温度可控的住所。有证据表明，在拜占庭和阿拉伯人、蒙古人入侵以及奥斯曼帝国征服期间，这座城市被广泛使用。\n\n代林库尤拥有精巧的设计，包括超过15,000个深入城市腹地的通风井，以及用于封锁城市的战略性滚动石。它包括起居区、储藏区、地牢、教堂，甚至还有牲畜和葡萄酒生产的空间。\n\n当地的希腊居民称这座城市为马拉科皮亚（意为“柔软的地方”），并在20世纪初继续将其用作避难所。在希腊土耳其战争之后，他们于1923年作为人口交换的一部分离开了该地区，放弃了这座城市，直到它被重新发现。文章突出了这座城市令人印象深刻的工程设计、作为避难所的历史意义以及作为热门旅游目的地的现代作用，鼓励读者思考潜伏在自己家中的未被发现的潜力。"
  },
  {
    "id": "44951862",
    "title": "Positron, a New Data Science IDE",
    "url": "https://posit.co/blog/positron-product-announcement-aug-2025/",
    "summary": "Posit PBC has announced Positron, a new, free, next-generation Integrated Development Environment (IDE) for data science, designed to unify exploration and production workflows for Python and R users. Building on 14+ years of experience with RStudio, Positron aims to provide a cohesive experience for coding, analyzing data, and creating interactive outputs, supporting modern scientific and data-driven work across languages and tools.\n\nKey features include a Variable & Data Frame Explorer, Multi-Session Console, Notebook Support, Positron Assistant (GenAI client), Plot Pane, Integrated Data App Workflow, Database Connection Pane, Push-Button Deployment to Posit Connect, Interpreter Management, extensive Extension Support via Open VSX, and Project Folder Templates.\n\nPositron is built on Code OSS, the same foundation as Visual Studio Code, allowing for customization through VSIX extensions while offering deeper integration of language-specific tools. Positron desktop is available for free on Windows, macOS, and Linux under the Elastic License 2.0. RStudio will continue to be maintained and updated, catering to R-focused users. Posit aims to make high-quality data science tools accessible to everyone. The Posit team encourages users to download Positron, explore the Quick Start guides, join the community on GitHub, and attend posit::conf(2025) to learn more.\n",
    "chinese_title": "正电子：一款全新的数据科学 IDE",
    "chinese_summary": "Posit PBC 发布 Positron，下一代免费数据科学 IDE，旨在统一 Python 和 R 用户的探索和生产工作流。Positron 基于 RStudio 超过 14 年的经验，致力于为编码、数据分析和交互式输出创建提供一致的体验，支持跨语言和工具的现代科学和数据驱动工作。\n\n主要功能包括变量和数据帧浏览器、多会话控制台、笔记本支持、Positron 助手（GenAI 客户端）、绘图面板、集成数据应用程序工作流、数据库连接面板、一键部署到 Posit Connect、解释器管理、通过 Open VSX 的广泛扩展支持以及项目文件夹模板。\n\nPositron 构建于 Code OSS 之上，与 Visual Studio Code 相同的基础，允许通过 VSIX 扩展进行自定义，同时提供更深入的特定语言工具集成。Positron 桌面在 Windows、macOS 和 Linux 上免费提供，采用 Elastic License 2.0 许可。RStudio 将继续维护和更新，以满足专注于 R 的用户的需求。Posit 致力于让每个人都能使用高质量的数据科学工具。Posit 团队鼓励用户下载 Positron，探索快速入门指南，加入 GitHub 上的社区，并参加 posit::conf(2025) 以了解更多信息。"
  },
  {
    "id": "44950091",
    "title": "PyPI Preventing Domain Resurrection Attacks",
    "url": "https://blog.pypi.org/posts/2025-08-18-preventing-domain-resurrections/",
    "summary": "生成摘要时出错",
    "chinese_title": "PyPI Preventing Domain Resurrection Attacks",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44921195",
    "title": "Candle Flame Oscillations as a Clock",
    "url": "https://cpldcpu.com/2025/08/13/candle-flame-oscillations-as-a-clock/",
    "summary": "生成摘要时出错",
    "chinese_title": "Candle Flame Oscillations as a Clock",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44951563",
    "title": "Without the futex, it's futile",
    "url": "https://h4x0r.org/futex/",
    "summary": "生成摘要时出错",
    "chinese_title": "Without the futex, it's futile",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44915897",
    "title": "Lazy-brush – smooth drawing with mouse or finger",
    "url": "https://lazybrush.dulnan.net",
    "summary": "生成摘要时出错",
    "chinese_title": "Lazy-brush – smooth drawing with mouse or finger",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44960864",
    "title": "Senate Probe Uncovers Allegations of Widespread Abuse in ICE Custody",
    "url": "https://www.wired.com/story/senate-probe-uncovers-widespread-abuse-in-ice-custody/",
    "summary": "生成摘要时出错",
    "chinese_title": "Senate Probe Uncovers Allegations of Widespread Abuse in ICE Custody",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44939502",
    "title": "Physically Based Rendering in Filament",
    "url": "https://google.github.io/filament/Filament.md.html#overview",
    "summary": "生成摘要时出错",
    "chinese_title": "Physically Based Rendering in Filament",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44950981",
    "title": "Critical Cache Poisoning Vulnerability in Dnsmasq",
    "url": "https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018288.html",
    "summary": "生成摘要时出错",
    "chinese_title": "Critical Cache Poisoning Vulnerability in Dnsmasq",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44962942",
    "title": "Passengers sue Delta, United over windowless 'window seats'",
    "url": "https://www.courthousenews.com/passengers-sue-delta-united-over-windowless-window-seats/",
    "summary": "生成摘要时出错",
    "chinese_title": "Passengers sue Delta, United over windowless 'window seats'",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44957933",
    "title": "The Future of JavaScript: What Awaits Us",
    "url": "https://jsdev.space/future-of-javascript/",
    "summary": "生成摘要时出错",
    "chinese_title": "The Future of JavaScript: What Awaits Us",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44962250",
    "title": "Git-worktree – Manage multiple working trees",
    "url": "https://git-scm.com/docs/git-worktree",
    "summary": "生成摘要时出错",
    "chinese_title": "Git-worktree – Manage multiple working trees",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44961048",
    "title": "CRLite in Firefox. Fast, private and secure (pick three)",
    "url": "https://blog.mozilla.org/en/firefox/crlite/",
    "summary": "生成摘要时出错",
    "chinese_title": "CRLite in Firefox. Fast, private and secure (pick three)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44954665",
    "title": "Notion releases offline mode",
    "url": "https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know",
    "summary": "生成摘要时出错",
    "chinese_title": "Notion releases offline mode",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44958543",
    "title": "Show HN: Hanaco Weather – A poetic weather SNS from the OS Yamato project",
    "url": "https://github.com/osyamato/os-yamato",
    "summary": "生成摘要时出错",
    "chinese_title": "Show HN: Hanaco Weather – A poetic weather SNS from the OS Yamato project",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44952672",
    "title": "As Alaska's salmon plummet, scientists home in on the killer",
    "url": "https://www.science.org/content/article/alaska-s-salmon-plummet-scientists-home-killer",
    "summary": "生成摘要时出错",
    "chinese_title": "As Alaska's salmon plummet, scientists home in on the killer",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44946996",
    "title": "OpenMower – An open source lawn mower",
    "url": "https://github.com/ClemensElflein/OpenMower",
    "summary": "生成摘要时出错",
    "chinese_title": "OpenMower – An open source lawn mower",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44948352",
    "title": "How to Build a Medieval Castle",
    "url": "https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/",
    "summary": "生成摘要时出错",
    "chinese_title": "How to Build a Medieval Castle",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44925570",
    "title": "One person was able to claim 20M IPs",
    "url": "https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/MMCCEQKA4UPGGWFWEBWLYKHTYCAOQIZS/#MMCCEQKA4UPGGWFWEBWLYKHTYCAOQIZS",
    "summary": "生成摘要时出错",
    "chinese_title": "One person was able to claim 20M IPs",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44955624",
    "title": "Perfect Freehand – Draw perfect pressure-sensitive freehand lines",
    "url": "https://www.perfectfreehand.com/",
    "summary": "生成摘要时出错",
    "chinese_title": "Perfect Freehand – Draw perfect pressure-sensitive freehand lines",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44963205",
    "title": "The State of Python 2025",
    "url": "https://blog.jetbrains.com/pycharm/2025/08/the-state-of-python-2025/",
    "summary": "生成摘要时出错",
    "chinese_title": "The State of Python 2025",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44957908",
    "title": "Why is it so hard for startups to compete with Cadence?",
    "url": "https://www.zach.be/p/why-is-it-so-hard-for-startups-to",
    "summary": "生成摘要时出错",
    "chinese_title": "Why is it so hard for startups to compete with Cadence?",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44921467",
    "title": "Guile bindings for Sway window manager",
    "url": "https://github.com/ebeem/guile-swayer",
    "summary": "生成摘要时出错",
    "chinese_title": "Guile bindings for Sway window manager",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44958459",
    "title": "Rough Numbers Between Consecutive Primes",
    "url": "https://arxiv.org/abs/2508.06463",
    "summary": "生成摘要时出错",
    "chinese_title": "Rough Numbers Between Consecutive Primes",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44924261",
    "title": "Netflix Revamps Tudum's CQRS Architecture with Raw Hollow In-Memory Object Store",
    "url": "https://www.infoq.com/news/2025/08/netflix-tudum-cqrs-raw-hollow/",
    "summary": "生成摘要时出错",
    "chinese_title": "Netflix Revamps Tudum's CQRS Architecture with Raw Hollow In-Memory Object Store",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44952185",
    "title": "\"Remove mentions of XSLT from the html spec\"",
    "url": "https://github.com/whatwg/html/pull/11563",
    "summary": "生成摘要时出错",
    "chinese_title": "\"Remove mentions of XSLT from the html spec\"",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44951287",
    "title": "Attention Is the New Big-O: A Systems Design Approach to Prompt Engineering",
    "url": "https://alexchesser.medium.com/attention-is-the-new-big-o-9c68e1ae9b27",
    "summary": "生成摘要时出错",
    "chinese_title": "Attention Is the New Big-O: A Systems Design Approach to Prompt Engineering",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44958421",
    "title": "Monoid-Augmented FIFOs, Deamortised",
    "url": "https://pvk.ca/Blog/2025/08/19/monoid-augmented-fifos/",
    "summary": "生成摘要时出错",
    "chinese_title": "Monoid-Augmented FIFOs, Deamortised",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44912881",
    "title": "In 2006, Hitachi developed a 0.15mm-sized RFID chip",
    "url": "https://www.hitachi.com/New/cnews/060206.html",
    "summary": "生成摘要时出错",
    "chinese_title": "In 2006, Hitachi developed a 0.15mm-sized RFID chip",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44937893",
    "title": "Staff disquiet as Alan Turing Institute faces identity crisis",
    "url": "https://www.theguardian.com/technology/2025/aug/18/shut-it-down-and-start-again-staff-disquiet-as-alan-turing-institute-faces-identity-crisis",
    "summary": "生成摘要时出错",
    "chinese_title": "Staff disquiet as Alan Turing Institute faces identity crisis",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44955457",
    "title": "Vendors that treat single sign-on as a luxury feature",
    "url": "https://sso.tax/",
    "summary": "生成摘要时出错",
    "chinese_title": "Vendors that treat single sign-on as a luxury feature",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44963078",
    "title": "Israeli official planned to meet decoy posing as 15-year-old in Las Vegas sting",
    "url": "https://www.8newsnow.com/investigators/israeli-official-planned-to-meet-decoy-posing-as-15-year-old-in-las-vegas-sex-sting-police/",
    "summary": "生成摘要时出错",
    "chinese_title": "Israeli official planned to meet decoy posing as 15-year-old in Las Vegas sting",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44950952",
    "title": "Vim Macros for Beancount",
    "url": "https://tangled.sh/@adam.tngl.sh/vim-beancounting",
    "summary": "生成摘要时出错",
    "chinese_title": "Vim Macros for Beancount",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44941580",
    "title": "Launch HN: Reality Defender (YC W22) – API for Deepfake and GenAI Detection",
    "url": "https://www.realitydefender.com/platform/api",
    "summary": "生成摘要时出错",
    "chinese_title": "Launch HN: Reality Defender (YC W22) – API for Deepfake and GenAI Detection",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44952942",
    "title": "9 Years of \"Learning to Code\" and I Still Couldn't Build a To-Do App",
    "url": "https://offpeaklog.bearblog.dev/learning-to-code/",
    "summary": "生成摘要时出错",
    "chinese_title": "9 Years of \"Learning to Code\" and I Still Couldn't Build a To-Do App",
    "chinese_summary": "生成摘要时出错"
  }
]