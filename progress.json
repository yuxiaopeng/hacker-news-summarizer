[
  {
    "id": "44387659",
    "title": "Google DeepMind Releases AlphaGenome",
    "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/",
    "summary": "Google DeepMind has released AlphaGenome, a new AI tool designed to comprehensively predict the impact of DNA sequence variations on gene regulation. This model analyzes up to 1 million DNA base pairs and predicts thousands of molecular properties, including gene start and end points, splicing, RNA production, and protein binding. It leverages data from ENCODE, GTEx, and other public consortia, covering gene regulation in human and mouse cells.\n\nAlphaGenome's key features include its ability to process long DNA sequences at high resolution, provide comprehensive multimodal predictions, efficiently score the impact of genetic variants, and model splice-junctions directly from sequence. It achieves state-of-the-art performance across various genomic prediction benchmarks.\n\nThe model's generality allows scientists to explore a variant's impact on multiple modalities simultaneously, accelerating hypothesis generation. Experts believe AlphaGenome can significantly aid in disease understanding, synthetic biology, and fundamental research by pinpointing disease causes, guiding synthetic DNA design, and mapping crucial functional elements of the genome.\n\nWhile AlphaGenome marks a significant advancement, it has limitations, including capturing the influence of very distant regulatory elements and the ability to fully capture cell- and tissue-specific patterns.  It is available for non-commercial research via an API, with plans for a future model release.  DeepMind encourages researchers to utilize the API, engage with the community forum, and provide feedback to improve the model's capabilities. The company emphasizes that AlphaGenome predictions are for research use only and not validated for clinical purposes.\n",
    "chinese_title": "谷歌DeepMind发布AlphaGenome",
    "chinese_summary": "谷歌DeepMind发布AlphaGenome，一种旨在全面预测DNA序列变异对基因调控影响的新型AI工具。该模型可分析多达100万个DNA碱基对，并预测数千种分子特性，包括基因起始和终止点、剪接、RNA产生和蛋白质结合。它利用来自ENCODE、GTEx和其他公共联盟的数据，覆盖人类和小鼠细胞中的基因调控。\n\nAlphaGenome的关键特性包括其能够以高分辨率处理长DNA序列、提供全面的多模态预测、高效评估遗传变异的影响以及直接从序列中建模剪接连接。它在各种基因组预测基准中实现了最先进的性能。\n\n该模型的通用性使科学家能够同时探索变异对多种模式的影响，从而加速假设生成。专家认为，AlphaGenome可以通过查明疾病原因、指导合成DNA设计以及绘制基因组的关键功能元件，显著帮助疾病理解、合成生物学和基础研究。\n\n尽管AlphaGenome标志着一项重大进展，但它也存在局限性，包括捕获非常遥远的调控元件的影响以及完全捕获细胞和组织特异性模式的能力。它通过API提供给非商业研究使用，并计划在未来发布模型。DeepMind鼓励研究人员利用API，参与社区论坛并提供反馈，以提高模型的功能。该公司强调，AlphaGenome的预测仅供研究使用，未经临床验证。"
  },
  {
    "id": "44388395",
    "title": "A Review of Aerospike Nozzles: Current Trends in Aerospace Applications",
    "url": "https://www.mdpi.com/2226-4310/12/6/519",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "Aerospike喷管综述：航空航天应用的当前趋势",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44388093",
    "title": "Show HN: I built an AI dataset generator",
    "url": "https://github.com/metabase/dataset-generator",
    "summary": "This \"Show HN\" post introduces an AI Dataset Generator, a tool designed to create realistic datasets for demos, learning, and dashboards. It leverages the OpenAI API (specifically GPT-4o) to define data schemas and business rules based on user-defined prompts, and then uses Faker for local data generation. Key features include a conversational prompt builder, real-time data preview, CSV/SQL export options, and one-click Metabase integration for data exploration.\n\nThe generator is built with Next.js, Tailwind CSS, and TypeScript, and requires Docker and an OpenAI API key to run. Users can clone the repository, configure their API key, and start the Next.js application to begin generating datasets. The workflow involves defining the dataset's characteristics, previewing a sample, and then exporting it as CSV or SQL.  A key advantage is cost-effectiveness: OpenAI API calls are only made during the data preview, incurring a small fee (~$0.05), while subsequent downloads are free.\n\nThe tool supports generating datasets in either a \"One Big Table\" (OBT) or a \"Star Schema\" format. Metabase integration simplifies data analysis by allowing users to explore their generated data within a Dockerized Metabase instance. The post also outlines the project structure and provides guidance on extending the generator with new business types or schema logic by modifying `lib/spec-prompts.ts`.\n",
    "chinese_title": "展示一下：我做了一个AI数据集生成器",
    "chinese_summary": "此“Show HN”帖子介绍了一个AI数据集生成器，该工具旨在为演示、学习和仪表板创建逼真的数据集。它利用OpenAI API（特别是GPT-4o）根据用户定义的提示来定义数据模式和业务规则，然后使用Faker进行本地数据生成。主要功能包括会话式提示构建器、实时数据预览、CSV/SQL导出选项和一键式Metabase集成，用于数据探索。\n\n该生成器使用Next.js、Tailwind CSS和TypeScript构建，需要Docker和一个OpenAI API密钥才能运行。用户可以克隆存储库，配置他们的API密钥，并启动Next.js应用程序以开始生成数据集。工作流程包括定义数据集的特征，预览样本，然后将其导出为CSV或SQL。一个关键优势是成本效益：OpenAI API调用仅在数据预览期间进行，产生少量费用（约0.05美元），而随后的下载是免费的。\n\n该工具支持生成“一张大表”（OBT）或“星型模式”格式的数据集。Metabase集成通过允许用户在Docker化的Metabase实例中探索他们生成的数据，简化了数据分析。该帖子还概述了项目结构，并提供了通过修改`lib/spec-prompts.ts`来使用新的业务类型或模式逻辑扩展生成器的指南。"
  },
  {
    "id": "44389202",
    "title": "Introducing Gemma 3n",
    "url": "https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/",
    "summary": "The article announces the full release of Gemma 3n, Google's next-generation open-source AI model designed for on-device performance. Building on the success of the initial Gemma release, Gemma 3n is a mobile-first architecture offering multimodal capabilities (image, audio, video, and text) optimized for edge devices.\n\nKey innovations include:\n\n*   **MatFormer Architecture:** A nested transformer architecture (Matryoshka Transformer) allowing for elastic inference, effectively containing smaller, fully functional versions within a larger model. This allows users to choose between pre-extracted models (E2B and E4B) for different performance levels or create custom sizes using a \"Mix-n-Match\" technique.\n*   **Per-Layer Embeddings (PLE):** Improves memory efficiency by allowing a significant portion of parameters to be loaded and computed efficiently on the CPU, reducing the memory footprint on the device's accelerator.\n*   **KV Cache Sharing:** Accelerates long-context processing, significantly improving time-to-first-token for streaming applications.\n*   **Enhanced Audio Understanding:** Integrated audio encoder based on the Universal Speech Model (USM) enabling Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST).\n*   **MobileNet-V5:** A new, highly efficient vision encoder providing state-of-the-art performance for multimodal tasks on edge devices with high throughput.\n\nGemma 3n is designed to be accessible, with support from various open-source tools and platforms. Google is also launching the Gemma 3n Impact Challenge, encouraging developers to build products with real-world impact using the model's on-device, offline, and multimodal capabilities. The article concludes with information on how to get started with Gemma 3n, including links to download the models, documentation, and integration guides.\n",
    "chinese_title": "Gemma 3n 发布",
    "chinese_summary": "文章宣布Gemma 3n全面发布：谷歌新一代面向设备端性能的开源AI模型。Gemma 3n建立在最初Gemma版本成功的基础之上，是一种移动优先的架构，提供针对边缘设备优化的多模态能力（图像、音频、视频和文本）。\n\n主要创新包括：\n\n*   **MatFormer架构：** 一种嵌套Transformer架构（俄罗斯套娃Transformer），允许弹性推理，有效地在一个更大的模型中包含更小的、功能完整的版本。这使得用户可以在不同性能级别之间选择预提取的模型（E2B和E4B），或者使用“Mix-n-Match”技术创建自定义尺寸。\n*   **逐层嵌入（PLE）：** 通过允许大部分参数在CPU上高效加载和计算，提高了内存效率，从而减少了设备加速器上的内存占用。\n*   **KV缓存共享：** 加速长上下文处理，显著提升流媒体应用程序的首次token响应时间。\n*   **增强的音频理解：** 集成了基于通用语音模型（USM）的音频编码器，支持自动语音识别（ASR）和自动语音翻译（AST）。\n*   **MobileNet-V5：** 一种新型、高效的视觉编码器，在边缘设备上为具有高吞吐量的多模态任务提供最先进的性能。\n\nGemma 3n旨在具有可访问性，并得到各种开源工具和平台的支持。谷歌还发起了Gemma 3n影响挑战赛，鼓励开发者利用该模型的设备端、离线和多模态能力构建具有实际影响的产品。文章最后提供了有关如何开始使用Gemma 3n的信息，包括下载模型、文档和集成指南的链接。"
  },
  {
    "id": "44387563",
    "title": "I built an ADHD app with interactive coping tools, noise mixer and self-test",
    "url": "https://www.adhdhelp.app/en",
    "summary": "The article promotes an ADHD app, \"ADHD Helper,\" designed to help individuals cope with common ADHD symptoms such as difficulty focusing, anxiety, irritability, overwhelm, hyperactivity, and forgetfulness. The app emphasizes that these are not signs of laziness or bad character, but rather a differently wired brain.\n\nADHD Helper offers several features to support users:\n\n*   **Interactive coping tools:** Mini self-help techniques based on CBT, DBT, and mindfulness, explained simply.\n*   **Audio affirmations:** Short, supportive recordings tailored to specific ADHD states.\n*   **Ambient sound mixer:** Atmospheric tracks (rain, fireplace, etc.) to help users focus by masking distracting noises.\n*   **Self-assessment:** A short test to assess symptoms and receive personalized recommendations.\n\nA premium version unlocks all 25 audio affirmations, provides early access to new content, offers an extended set of techniques, a mood journal, ambient mixer, personalized recommendations, and priority support. The app also includes a blog with articles discussing various aspects of ADHD, including personal experiences, the challenges of late diagnosis, and the potential of hyperfocus. The app encourages users to try the premium version free for 7 days and offers \"quests\" to help develop positive habits.\n",
    "chinese_title": "我开发了一个多动症应用程序，包含互动应对工具、噪音混合器和自我测试。",
    "chinese_summary": "该文章推广一款名为“ADHD助手”的ADHD应用程序，旨在帮助个人应对常见的ADHD症状，如注意力不集中、焦虑、易怒、不知所措、多动和健忘。该应用程序强调，这些不是懒惰或品行不端的表现，而是大脑的运作方式不同。\n\nADHD助手提供以下功能来支持用户：\n\n*   **互动应对工具：** 基于CBT、DBT和正念的迷你自助技巧，解释简单易懂。\n*   **音频肯定语：** 针对特定ADHD状态量身定制的简短、支持性录音。\n*   **环境声音混合器：** 大气音轨（雨声、壁炉声等），通过屏蔽分散注意力的噪音来帮助用户集中注意力。\n*   **自我评估：** 一个简短的测试，用于评估症状并获得个性化建议。\n\n高级版本解锁所有25个音频肯定语，提供对新内容的早期访问权限，提供更广泛的技巧集、情绪日记、环境混合器、个性化推荐和优先支持。该应用程序还包含一个博客，其中包含讨论ADHD各个方面的文章，包括个人经历、后期诊断的挑战以及超聚焦的潜力。该应用程序鼓励用户免费试用7天高级版本，并提供“任务”来帮助养成积极的习惯。"
  },
  {
    "id": "44388387",
    "title": "FLUX.1 Kontext [Dev] – Open Weights for Image Editing",
    "url": "https://bfl.ai/announcements/flux-1-kontext-dev",
    "summary": "Black Forest Labs (BFL) has released FLUX.1 Kontext [dev], an open-weight image editing model that rivals proprietary tools in performance while being accessible on consumer hardware. This 12B parameter model, licensed under the FLUX.1 Non-Commercial License, is available for research and non-commercial use.\n\nFLUX.1 Kontext [dev] excels in iterative editing, character preservation, and both local and global edits. It outperforms existing open and closed models on the KontextBench benchmark and in independent evaluations. The model supports popular inference frameworks like ComfyUI, HuggingFace Diffusers, and TensorRT. Ready-to-use API endpoints and code are available through partners like FAL and Replicate.\n\nBFL collaborated with NVIDIA to create optimized TensorRT weights for the Blackwell architecture, enhancing inference speed and reducing memory usage. BF16, FP8, and FP4 TensorRT variants are also available on Hugging Face.\n\nFor commercial use, BFL is launching a self-serve licensing portal with transparent terms for FLUX.1 Kontext [dev], FLUX.1 Tools [dev], and FLUX.1 [dev].\n\nThe FLUX.1 [dev] Non-Commercial License has been updated to clarify non-commercial purposes, require content filters/manual review, enforce content provenance compliance, and clarify usage restrictions.\n\nResources including model weights, code, API documentation, and licensing information are provided. BFL is also actively hiring.\n",
    "chinese_title": "FLUX.1 Kontext [开发] – 用于图像编辑的开放权重",
    "chinese_summary": "黑森林实验室（BFL）发布 FLUX.1 Kontext [dev]，一款性能媲美专有工具且可在消费级硬件上运行的开放权重图像编辑模型。这个拥有 120 亿参数的模型，采用 FLUX.1 非商业许可，可用于研究和非商业用途。\n\nFLUX.1 Kontext [dev] 擅长迭代编辑、角色保留以及局部和全局编辑。在 KontextBench 基准测试和独立评估中，其性能优于现有的开放和封闭模型。该模型支持 ComfyUI、HuggingFace Diffusers 和 TensorRT 等流行的推理框架。即用型 API 端点和代码可通过 FAL 和 Replicate 等合作伙伴获得。\n\nBFL 与 NVIDIA 合作，为 Blackwell 架构创建了优化的 TensorRT 权重，从而提高了推理速度并减少了内存使用。BF16、FP8 和 FP4 TensorRT 变体也可在 Hugging Face 上找到。\n\n对于商业用途，BFL 正在推出一个自助许可门户，其中包含 FLUX.1 Kontext [dev]、FLUX.1 Tools [dev] 和 FLUX.1 [dev] 的透明条款。\n\nFLUX.1 [dev] 非商业许可已更新，以明确非商业目的，要求内容过滤器/手动审查，强制执行内容溯源合规性，并明确使用限制。\n\n提供包括模型权重、代码、API 文档和许可信息在内的资源。BFL 也在积极招聘。"
  },
  {
    "id": "44381297",
    "title": "A new pyramid-like shape always lands the same side up",
    "url": "https://www.quantamagazine.org/a-new-pyramid-like-shape-always-lands-the-same-side-up-20250625/",
    "summary": "This Quanta Magazine article discusses the creation of the first physical model of a monostable tetrahedron – a pyramid-like shape that, regardless of its starting position, always lands on the same face.\n\nFor decades, mathematicians wondered if such a shape with a uniform weight distribution could exist. While initially disproven, the question remained intriguing with uneven weight distribution allowed. Gábor Domokos, known for his work on balancing problems, particularly the gömböc (a mono-monostatic shape), took on the challenge.\n\nIn 2023, Domokos and his team theoretically proved the possibility of a monostable tetrahedron. They then embarked on building it, a far more complex task. They used computer algorithms to find vertices for the tetrahedron and determined that three consecutive edges needed to form obtuse angles, and the center of mass had to be positioned within one of four \"loading zones.\"\n\nThe final model, made of lightweight carbon fiber and dense tungsten carbide, weighs 120 grams and measures 50 centimeters. Achieving the precise weight distribution required immense accuracy in engineering. After months of effort and overcoming unforeseen challenges (like a stray glob of glue), they successfully created a tetrahedron that consistently lands on its designated face.\n\nThe achievement highlights the importance of experimentation in mathematics and may have practical applications, such as in self-righting spacecraft design. The team hopes their work inspires further exploration of polyhedra and their properties.\n",
    "chinese_title": "一种新型金字塔形状的物体总是同一面朝上落地。",
    "chinese_summary": "Quanta杂志文章探讨了首个单稳态四面体物理模型的创建——这是一种金字塔状的形状，无论其起始位置如何，总是落在同一面上。\n\n几十年来，数学家们一直在思考是否存在具有均匀重量分布的这种形状。虽然最初被证明是不可能的，但在允许不均匀重量分布的情况下，这个问题仍然引人入胜。以平衡问题研究闻名的加博尔·多莫科斯（尤其以他的单单稳态形状“Gömböc”闻名）接受了这个挑战。\n\n2023年，多莫科斯及其团队从理论上证明了单稳态四面体的可能性。然后，他们开始了构建它的过程，这是一项更为复杂的任务。他们使用计算机算法来寻找四面体的顶点，并确定三个连续的边需要形成钝角，并且重心必须位于四个“加载区”之一内。\n\n最终的模型由轻质碳纤维和高密度碳化钨制成，重120克，尺寸为50厘米。实现精确的重量分布需要在工程上达到极高的精度。经过数月的努力并克服了未预料到的挑战（例如一滴意外的胶水），他们成功地创造了一个始终落在其指定面上的四面体。\n\n这项成就突出了实验在数学中的重要性，并且可能具有实际应用，例如在自扶正航天器设计中。该团队希望他们的工作能激发对多面体及其性质的进一步探索。"
  },
  {
    "id": "44387904",
    "title": "Access BMC UART on Supermicro X11SSH",
    "url": "https://github.com/zarhus/zarhusbmc/discussions/3",
    "summary": "This is a forum thread documenting 3mkusiak's successful attempt to access the BMC UART on a Supermicro X11SSH motherboard. The X11SSH lacks debug headers or probe points for easy UART access, requiring a more involved \"hacking\" approach.\n\n3mkusiak uses Keno Fisher's blog post as a starting point and leverages the X11SSH Gerber files (provided by Tim Ansell) and the AST2400 datasheet for reference. Initially, 3mkusiak traces the TX pin used by Keno but needs to identify the RX pin. After some work tracing the PCB layers using the Gerber files, 3mkusiak finds unpopulated pads suitable for soldering.\n\nWires are soldered to these pads, and the motherboard is reassembled. The experiment proves successful, granting UART access to the stock BMC firmware.\n\nA user, miczyg1, initially questions the need for this approach, suggesting the COM1 header, but 3mkusiak clarifies that the stock firmware lacks UART redirection, prompting the hardwiring solution to access the stock BMC firmware.\n\nThe project is completed within a day, and pietrushnic, a maintainer, congratulates 3mkusiak on the rapid success and announces that the achievement will be shared on social media. The thread ends with 3mkusiak considering the discussion concluded.\n",
    "chinese_title": "访问Supermicro X11SSH上的BMC UART",
    "chinese_summary": "这是一个论坛帖子，记录了 3mkusiak 成功访问 Supermicro X11SSH 主板上 BMC UART 的过程。由于 X11SSH 缺少调试头或探针点以便于 UART 访问，因此需要更深入的“破解”方法。\n\n3mkusiak 以 Keno Fisher 的博客文章作为起点，并参考了 X11SSH Gerber 文件（由 Tim Ansell 提供）和 AST2400 数据手册。最初，3mkusiak 追踪了 Keno 使用的 TX 引脚，但需要确定 RX 引脚。在利用 Gerber 文件追踪 PCB 层后，3mkusiak 找到适合焊接的未填充焊盘。\n\n电线焊接到这些焊盘上，然后重新组装主板。实验证明成功，允许访问原始 BMC 固件的 UART。\n\n用户 miczyg1 最初质疑这种方法的必要性，建议使用 COM1 接口，但 3mkusiak 澄清说原始固件缺少 UART 重定向，因此需要硬连线解决方案来访问原始 BMC 固件。\n\n该项目在一天内完成，维护者 pietrushnic 祝贺 3mkusiak 迅速成功，并宣布将在社交媒体上分享这一成果。帖子以 3mkusiak 认为讨论结束而告终。"
  },
  {
    "id": "44382834",
    "title": "Puerto Rico's Solar Microgrids Beat Blackout",
    "url": "https://spectrum.ieee.org/puerto-rico-solar-microgrids",
    "summary": "This article discusses how solar microgrids in Puerto Rico, specifically in the town of Adjuntas, are successfully providing electricity during widespread blackouts on the island. The microgrids, developed in collaboration with Oak Ridge National Laboratory, offer a resilient solution to Puerto Rico's persistent power interruptions. While these microgrids provide localized power, the article highlights a contrasting federal decision to redirect $365 million originally intended for solar energy projects toward broader grid improvements. This shift suggests a debate about the optimal approach to addressing Puerto Rico's energy crisis, weighing the benefits of decentralized, localized solar solutions against large-scale grid overhauls. The article emphasizes the importance of microgrids as a viable and reliable power source amidst Puerto Rico's ongoing energy challenges. Julia Tilton, a science and environmental journalist, authored the article.\n",
    "chinese_title": "波多黎各太阳能微电网战胜停电",
    "chinese_summary": "本文探讨了波多黎各的太阳能微电网，特别是在Adjuntas镇，如何在岛上大范围停电期间成功供电。这些微电网与橡树岭国家实验室合作开发，为波多黎各持续的电力中断提供了一个具有韧性的解决方案。尽管这些微电网提供了本地化的电力，但本文强调了一项对比鲜明的联邦决定，即将最初用于太阳能项目的3.65亿美元转移到更广泛的电网改进上。这种转变表明，对于解决波多黎各能源危机的最佳方法存在争议，权衡了分散式、本地化的太阳能解决方案与大规模电网改造的优缺点。本文强调了在波多黎各持续的能源挑战中，微电网作为一种可行且可靠的电力来源的重要性。该文章由科学和环境记者朱莉娅·蒂尔顿撰写。"
  },
  {
    "id": "44385981",
    "title": "Muvera: Making multi-vector retrieval as fast as single-vector search",
    "url": "https://research.google/blog/muvera-making-multi-vector-retrieval-as-fast-as-single-vector-search/",
    "summary": "This article introduces MUVERA, a novel algorithm that significantly accelerates multi-vector retrieval, making it as fast as single-vector search. Multi-vector models like ColBERT offer improved accuracy in information retrieval (IR) by representing data points with multiple embeddings, but their computational cost is high. MUVERA bridges this efficiency gap by transforming multi-vector retrieval into a single-vector maximum inner product search (MIPS) problem.\n\nMUVERA achieves this through fixed dimensional encodings (FDEs). It converts complex sets of multi-vectors into single, easier-to-handle vectors (FDEs) while preserving similarity information. It partitions the embedding space and maps vectors into FDEs, allowing for quick similarity comparisons using optimized MIPS algorithms. This initial retrieval is followed by a re-ranking step using the original Chamfer similarity for improved accuracy. Crucially, the FDE transformation is data-oblivious and provides theoretical guarantees on its approximation of Chamfer similarity.\n\nExperimental results on BEIR benchmarks demonstrate that MUVERA outperforms existing methods like PLAID. It achieves higher recall while retrieving significantly fewer candidate documents and reduces latency by 90% compared to PLAID. FDEs can also be effectively compressed, further reducing memory footprint. MUVERA offers a practical solution for real-world applications such as search engines and recommendation systems, promising faster and more efficient multi-vector retrieval. An open-source implementation of MUVERA is available on GitHub.\n",
    "chinese_title": "Muvera: 让多向量检索速度媲美单向量搜索",
    "chinese_summary": "本文介绍了一种名为MUVERA的新型算法，该算法能显著加速多向量检索，使其速度与单向量搜索一样快。诸如ColBERT之类的多向量模型通过用多个嵌入表示数据点，从而提高了信息检索（IR）的准确性，但其计算成本很高。MUVERA通过将多向量检索转换为单向量最大内积搜索（MIPS）问题来弥合了这种效率差距。\n\nMUVERA通过固定维度编码（FDE）来实现这一点。它将复杂的多向量集合转换为单个、更易于处理的向量（FDE），同时保留相似性信息。它对嵌入空间进行分区，并将向量映射到FDE中，从而可以使用优化的MIPS算法进行快速相似性比较。初始检索之后，使用原始的Chamfer相似度进行重新排序，以提高准确性。至关重要的是，FDE转换是数据无关的，并为Chamfer相似度的近似提供了理论保证。\n\n在BEIR基准上的实验结果表明，MUVERA优于现有方法（如PLAID）。它在检索显著更少的候选文档的同时实现了更高的召回率，并且与PLAID相比，延迟降低了90%。FDE还可以有效地压缩，从而进一步减少内存占用。MUVERA为搜索引擎和推荐系统等实际应用提供了一个实用的解决方案，有望实现更快、更高效的多向量检索。MUVERA的开源实现在GitHub上提供。"
  },
  {
    "id": "44374114",
    "title": "Some bits on malloc(0) in C being allowed to return NULL",
    "url": "https://utcc.utoronto.ca/~cks/space/blog/programming/CZeroSizeMallocSomeNotes",
    "summary": "Chris Siebenmann's page explains why visitors might encounter an \"old browser\" error when accessing his blog, \"Wandering Thoughts\" or CSpace. This is a deliberate anti-crawler measure implemented to combat a surge of high-volume web crawlers, particularly those scraping data for LLM training, which often use outdated browser user agents, especially old versions of Chrome.\n\nThe page acknowledges that legitimate users might be falsely flagged and provides instructions for them to contact the author (via his university email) with details about their browser and user agent string.\n\nA specific warning is given to users accessing the page through archive.today, archive.ph, and archive.is. These archiving services are flagged as problematic because their crawling behavior is indistinguishable from malicious actors, using old Chrome user agents, distributed IP addresses, and sometimes falsified reverse DNS entries mimicking Googlebot. The author recommends using archive.org instead, as it is a better-behaved and crawlable archival service.\n",
    "chinese_title": "C语言中malloc(0)被允许返回NULL的一些讨论",
    "chinese_summary": "克里斯·西本曼的页面解释了为什么访问者在访问他的博客“Wandering Thoughts”或 CSpace 时可能会遇到“旧浏览器”错误。这是一种有意的反爬虫措施，旨在应对大量网络爬虫的涌入，特别是那些为 LLM 训练抓取数据的爬虫，它们通常使用过时的浏览器用户代理，尤其是旧版本的 Chrome。\n\n该页面承认合法用户可能被错误地标记，并为他们提供了联系作者（通过他的大学电子邮件）的说明，以提供有关其浏览器和用户代理字符串的详细信息。\n\n特别警告访问 archive.today、archive.ph 和 archive.is 的用户。这些存档服务被标记为有问题，因为它们的爬取行为与恶意行为者无法区分，使用旧的 Chrome 用户代理、分布式 IP 地址，有时还会伪造模仿 Googlebot 的反向 DNS 条目。作者建议使用 archive.org 代替，因为它是一种行为更好且可爬取的存档服务。"
  },
  {
    "id": "44381252",
    "title": "-2000 Lines of code",
    "url": "https://www.folklore.org/Negative_2000_Lines_Of_Code.html",
    "summary": "This article from Folklore.org, titled \"-2000 Lines of Code,\" recounts a story about Bill Atkinson, a key implementer on the Lisa software team at Apple in early 1982. The Lisa managers attempted to track individual engineer productivity by the number of lines of code written each week. Atkinson, responsible for Quickdraw and the user interface, strongly disagreed with this metric. He believed that writing efficient and concise code was more important than simply generating large volumes of code.\n\nAtkinson had recently optimized Quickdraw's region calculation, rewriting the engine with a more efficient algorithm. This rewrite resulted in a six-fold performance increase and, importantly, a reduction of approximately 2,000 lines of code. When required to submit his lines of code count, Atkinson boldly entered \"-2000.\"\n\nThe story highlights the flawed logic of measuring software productivity solely by lines of code. It suggests that such a metric can incentivize poor coding practices and discourage optimization. While the manager's reaction is not explicitly stated, the story concludes that they eventually stopped requiring Atkinson to fill out the form, suggesting they recognized the ineffectiveness of their metric. The comments further reinforce the idea that relying on lines of code as a performance measure is a misguided approach in software development.\n",
    "chinese_title": "-两千行代码",
    "chinese_summary": "这篇来自Folklore.org的文章，题为《-2000行代码》，讲述了比尔·阿特金森的故事。阿特金森是1982年初苹果公司Lisa软件团队的关键执行者。Lisa的管理者试图通过每周编写的代码行数来追踪每位工程师的生产力。负责Quickdraw和用户界面的阿特金森强烈反对这一指标。他认为编写高效简洁的代码比简单地生成大量代码更重要。\n\n阿特金森最近优化了Quickdraw的区域计算，用更高效的算法重写了引擎。这次重写带来了六倍的性能提升，更重要的是，代码减少了大约2000行。当被要求提交代码行数时，阿特金森大胆地输入了“-2000”。\n\n这个故事突显了仅用代码行数衡量软件生产力的错误逻辑。它表明这种指标会激励不良的编码习惯，并阻碍优化。虽然管理者的反应没有明确说明，但故事的结尾暗示他们最终停止要求阿特金森填写表格，这表明他们认识到这种指标的无效性。评论进一步强化了这样一种观点，即在软件开发中，依赖代码行数作为绩效衡量标准是一种错误的途径。"
  },
  {
    "id": "44386887",
    "title": "Learnings from building AI agents",
    "url": "https://www.cubic.dev/blog/learnings-from-building-ai-agents",
    "summary": "Paul Sangle-Ferriere, cofounder of cubic, shares learnings from building an AI code review agent. Initially, the agent was too noisy, flooding pull requests with low-value comments and false positives. The initial architecture used a single, large prompt to analyze code changes, leading to issues like style mistakes being flagged as critical bugs, users losing trust, and opaque reasoning.\n\nTo improve, they implemented three major changes. First, they required the AI to provide explicit reasoning logs for its findings, allowing for better debugging and structured thinking. Second, they streamlined the agent's toolset, focusing on essential components like a simplified LSP and a basic terminal. This reduced distractions and improved precision. Third, they transitioned from generalized rules to specialized micro-agents, each focusing on a specific task like security, duplication, or editorial checks.\n\nThese changes resulted in a 51% reduction in false positives, a 50% reduction in median comments per pull request, and smoother review processes. The key lessons learned were: explicit reasoning improves clarity and debugging, simplifying the toolset enhances precision, and specializing with micro-agents reduces cognitive overload. These lessons are broadly applicable to designing effective AI systems.\n",
    "chinese_title": "构建AI智能体的经验与教训",
    "chinese_summary": "Paul Sangle-Ferriere (cubic 联合创始人) 分享了构建 AI 代码审查代理的经验教训。最初，该代理过于嘈杂，充斥着低价值评论和误报，淹没了 pull 请求。最初的架构使用单个大型 prompt 来分析代码更改，导致诸如样式错误被标记为严重错误、用户失去信任以及推理过程不透明等问题。\n\n为了改进，他们实施了三个主要改变。首先，他们要求 AI 为其发现提供明确的推理日志，以便更好地调试和结构化思考。其次，他们简化了代理的工具集，专注于基本组件，例如简化的 LSP 和基本终端。这减少了干扰并提高了精度。第三，他们从通用规则过渡到专门的微型代理，每个代理都专注于特定的任务，例如安全性、重复性或编辑检查。\n\n这些改变带来了 51% 的误报率降低、每个 pull 请求的评论中位数减少 50% 以及更顺畅的审查流程。关键的经验教训是：明确的推理提高了清晰度和调试能力，简化工具集增强了精度，而使用微型代理进行专门化则减少了认知超载。这些经验教训广泛适用于设计有效的 AI 系统。"
  },
  {
    "id": "44355409",
    "title": "The Business of Betting on Catastrophe",
    "url": "https://thereader.mitpress.mit.edu/the-business-of-betting-on-catastrophe/",
    "summary": "Susan Erikson's article, \"The Business of Betting on Catastrophe,\" explores the world of insurance-linked securities (ILS), focusing on the World Bank's pandemic bonds as an example of turning calamity into capital. These bonds were designed to raise money for pandemic response by having private investors speculate on the risk of a pandemic. Investors earn interest on their investment if no pandemic occurs but lose their principal if a predefined pandemic threshold is met.\n\nErikson's research, prompted by the bond's creation, led her to the reinsurance industry and its adoption of ILS in the 1990s to diversify portfolios against major weather events. ILS allows hedge funds and pensions to gamble on securitized risks. A key feature of ILS is the use of parametrics, which trigger payouts based on preset conditions (like wind speed in a hurricane), rather than actual damage assessment.\n\nThe article highlights the incentives for investors: the potential for significant returns for bearing the risk of a catastrophe. In the case of the World Bank's pandemic bonds, investors stood to gain a 40% return over three years if COVID-19 hadn't triggered the payout.\n\nErikson emphasizes that ILS investors aren't insuring a specific entity or asset but rather speculating on the risk itself, profiting (or losing) based on the occurrence and intensity of a catastrophe as defined by pre-set parameters. Despite being a niche market, ILS represents a booming $195 billion industry, offering investors unique diversification opportunities through the investability of pandemic and other catastrophic risks.\n",
    "chinese_title": "押注灾难的生意",
    "chinese_summary": "苏珊·埃里克森的文章《押注灾难的生意》探讨了保险连接证券（ILS）的世界，重点关注世界银行的疫情债券，以此为例说明如何将灾难转化为资本。这些债券旨在通过让私人投资者投机疫情风险来筹集应对疫情的资金。如果未发生疫情，投资者将获得投资利息，但如果达到预定义的疫情阈值，他们将损失本金。\n\n埃里克森的研究受到债券创建的推动，使她了解了再保险行业及其在 20 世纪 90 年代采用 ILS 来分散投资组合以应对重大天气事件的情况。 ILS 允许对冲基金和养老金对证券化的风险进行赌博。 ILS 的一个关键特征是参数的使用，参数会根据预设条件（如飓风中的风速）触发赔付，而不是实际的损害评估。\n\n该文章强调了投资者的动机：承担灾难风险带来的潜在巨额回报。就世界银行的疫情债券而言，如果 COVID-19 没有触发赔付，投资者本可以在三年内获得 40% 的回报。\n\n埃里克森强调，ILS 投资者不是为特定实体或资产提供保险，而是投机风险本身，根据预设参数定义的灾难的发生和强度来获利（或亏损）。尽管 ILS 只是一个小众市场，但它代表着一个蓬勃发展的 1950 亿美元的产业，通过疫情和其他灾难风险的可投资性，为投资者提供了独特的多元化机会。"
  },
  {
    "id": "44385562",
    "title": "Snow - Classic Macintosh emulator",
    "url": "https://snowemu.com/",
    "summary": "Snow is an open-source, hardware-level emulator written in Rust for classic Macintosh computers (those using Motorola 680x0 processors). Unlike some emulators, Snow aims for accurate hardware emulation instead of relying on ROM patching or system call interception. It currently supports emulating the Macintosh 128K, 512K, Plus, SE, Classic, and II models.\n\nThe emulator features a graphical user interface and offers debugging tools. While a limited online demo is available, the full software is available as \"bleeding edge\" builds, automatically generated as the project progresses. These builds are available for Windows 10+, MacOS 11.7 (Big Sur)+ (Universal architecture), and Linux (x86 64-bit).\n\nFor bug reports, users are directed to GitHub issues. For support or general discussion, the article suggests joining the #snow channel on the MartyPC and Friends Discord server. Further setup information and documentation can be found online.\n",
    "chinese_title": "雪 - 经典Macintosh模拟器",
    "chinese_summary": "Snow：一款用 Rust 编写的开源、硬件级经典 Macintosh 电脑（使用 Motorola 680x0 处理器）模拟器。与一些模拟器不同，Snow 的目标是精确的硬件模拟，而不是依赖 ROM 补丁或系统调用拦截。它目前支持模拟 Macintosh 128K、512K、Plus、SE、Classic 和 II 型号。\n\n该模拟器具有图形用户界面并提供调试工具。虽然有一个有限的在线演示版本，但完整的软件以“前沿”构建版本提供，这些版本会随着项目的进展自动生成。这些构建版本适用于 Windows 10+、MacOS 11.7 (Big Sur)+（通用架构）和 Linux (x86 64 位)。\n\n如需报告错误，用户请前往 GitHub issues。如需支持或一般讨论，文章建议加入 MartyPC and Friends Discord 服务器上的 #snow 频道。更多设置信息和文档可以在网上找到。"
  },
  {
    "id": "44376989",
    "title": "OpenAI charges by the minute, so speed up your audio",
    "url": "https://george.mand.is/2025/06/openai-charges-by-the-minute-so-make-the-minutes-shorter/",
    "summary": "This article details a method to reduce the cost and time associated with OpenAI audio transcriptions by speeding up the audio before processing. The author discovered this trick while trying to summarize a long talk by Andrej Karpathy.\n\nThe core idea is to use `ffmpeg` to increase the audio speed by 2x or 3x. Because OpenAI charges based on the duration of the audio (or audio tokens in the case of the `gpt-4o-transcribe` model), a shorter audio file translates to lower costs.\n\nThe author found that speeding up the audio to 2x or 3x had minimal impact on transcription quality, while significantly reducing input tokens (and thus cost) when using the `gpt-4o-transcribe` model. While output token costs remained the same, the overall cost was lower. The author provides concrete examples and calculations demonstrating the cost savings, showcasing up to a 23% reduction in cost. The author also provides a script to perform the process with `yt-dlp`, `ffmpeg`, and `curl` with `llm`.\n\nThe article also explores the psychological aspect of why this works: our brains and AI models can often fill in the gaps, even with slightly imperfect audio. It cautions against pushing the speed too far (4x resulted in unusable transcriptions). The author concludes that speeding up audio to 2x or 3x is a simple and effective way to save time and money on OpenAI transcriptions, highlighting the trade-off between fidelity and cost.\n",
    "chinese_title": "OpenAI按分钟收费，加快你的音频速度。",
    "chinese_summary": "通过加速音频来降低 OpenAI 音频转录成本和时间的技巧"
  },
  {
    "id": "44349332",
    "title": "What makes comprehensible input comprehensible?",
    "url": "https://cij-analysis.streamlit.app",
    "summary": "Since the article only displays the message \"You need to enable JavaScript to run this app,\" I cannot provide a summary of its content. To understand what makes comprehensible input comprehensible, I would need access to the actual text of the article.\n",
    "chinese_title": "什么使可理解性输入变得可理解？",
    "chinese_summary": "由于该文章只显示“您需要启用JavaScript才能运行此应用”的消息，我无法提供其内容摘要。 要理解是什么使可理解性输入变得可理解，我需要访问文章的实际文本。"
  },
  {
    "id": "44358148",
    "title": "Ambient Garden",
    "url": "https://ambient.garden",
    "summary": "Ambient Garden is a website (ambient.garden) offering an algorithmic audio landscape. Users can navigate this landscape by dragging to look around and clicking to travel to different areas. The website features an \"Autopilot\" option that allows for automatic exploration. Controls are also provided for pausing the audio and adjusting its playback speed.\n\nThe description highlights that the environment is algorithmic, meaning the audio is procedurally generated rather than being a fixed recording. This likely creates a dynamic and ever-changing sonic experience. The website emphasizes its audio focus and provides minimal information regarding the visuals, suggesting the primary experience is auditory.\n\nA loading screen is present indicating the site relies on dynamically loading or generating content, and links to \"About / Music\" provide more information on the project itself and likely the music composition and generation aspects.\n",
    "chinese_title": "氛围花园",
    "chinese_summary": "环境花园（ambient.garden）：一个算法音频景观网站。用户可以通过拖动来环顾四周，点击来前往不同区域，从而浏览这个景观。该网站提供“自动驾驶”选项，允许自动探索。同时还提供音频暂停和播放速度调节的控制功能。\n\n描述强调环境是算法生成的，这意味着音频是通过程序生成，而不是固定的录音。这很可能会创造一种动态且不断变化的声音体验。该网站强调其音频重点，并提供最少的视觉信息，表明主要的体验是听觉的。\n\n加载画面表明该网站依赖于动态加载或生成内容，链接到“关于/音乐”提供了关于项目本身以及音乐创作和生成方面的更多信息。"
  },
  {
    "id": "44354032",
    "title": "Modeling the World in 280 Characters",
    "url": "https://tympanus.net/codrops/2025/06/23/modeling-the-world-in-280-characters/",
    "summary": "Xor, a graphics programmer, shares his passion for creating compact shader programs, often referred to as \"tweet shaders,\" that fit within 280 characters. He uses a tool called Twigl.app to create these demos, optimizing for code size, performance, and artistic appeal.\n\nHis motivation stems from curiosity, learning, the challenge of code golfing, and community engagement. Shaders, which run on the GPU, process operations in parallel, making them ideal for generating real-time visuals. Tweet shaders are fragment shaders, operating on individual pixels to output color and opacity. Core inputs include fragment coordinates (FC), resolution (r), and time (t).\n\nXor prototypes in compact form, prioritizing code size reduction techniques like abbreviating names, minimizing initializations, avoiding `if` statements, and optimizing loop structures. He also utilizes function substitutions to further compress code.\n\nHe answers common questions, highlighting the usefulness of turbulence effects and the importance of patience and breaking down complex topics when learning the math behind shaders. Xor encourages beginners to explore game engines like GameMaker or Godot, or platforms like ShaderToy or compute.toys, to start learning shader programming. He credits key individuals like xygthop3, Inigo Quilez, and Fabrice Neyret for their contributions to his learning journey.\n",
    "chinese_title": "以280字建模世界",
    "chinese_summary": "Xor，一位图形程序员，分享了他对创作紧凑型着色器程序（通常被称为“推特着色器”，适合于280个字符内）的热情。他使用名为Twigl.app的工具来创建这些演示，并针对代码大小、性能和艺术吸引力进行优化。\n\n他的动力源于好奇心、学习、代码高尔夫的挑战以及社区参与。着色器在GPU上运行，并行处理操作，使其非常适合生成实时视觉效果。推特着色器是片段着色器，作用于单个像素以输出颜色和不透明度。核心输入包括片段坐标 (FC)、分辨率 (r) 和时间 (t)。\n\nXor 以紧凑的形式进行原型设计，优先考虑代码大小缩减技术，如缩写名称、最小化初始化、避免 `if` 语句和优化循环结构。他还利用函数替换来进一步压缩代码。\n\n他回答了常见问题，强调了湍流效应的实用性以及学习着色器背后数学知识时耐心和分解复杂主题的重要性。Xor 鼓励初学者探索像GameMaker或Godot这样的游戏引擎，或者像ShaderToy或compute.toys这样的平台，来开始学习着色器编程。他感谢 xygthop3、Inigo Quilez 和 Fabrice Neyret 等关键人物对他的学习之旅所做出的贡献。"
  },
  {
    "id": "44345681",
    "title": "Writing a basic Linux device driver when you know nothing about Linux drivers",
    "url": "https://crescentro.se/posts/writing-drivers/",
    "summary": "This article chronicles the author's journey of writing a Linux driver for a Nanoleaf Pegboard Desk Dock, a USB hub with RGB LEDs, despite having no prior experience in Linux driver development.\n\nThe author begins by identifying the device using `lsusb` and discovers that a generic HID driver already recognizes it. Faced with the option of creating a kernel driver or a userspace driver via `libusb`, they opt for the latter due to its lower complexity.\n\nThe process involves setting up `udev` rules to grant user permissions to access the device. The author then creates a basic Rust binary using the `rusb` crate to interact with the device.\n\nA common error encountered is being \"Busy\" when claiming an interface, which is resolved by detaching the kernel driver. The author then sends a command to set the pegboard to a solid red color using `write_interrupt` on the appropriate endpoint.\n\nThe article highlights the importance of understanding USB concepts like configurations, interfaces, and endpoints. It also notes the need to handle interrupt responses from the device to avoid firmware crashes. The author emphasizes the ease of writing to the device, stating that it's as simple as opening a pipe and writing to it.\n",
    "chinese_title": "当你对Linux驱动一无所知时，编写一个基本的Linux设备驱动程序",
    "chinese_summary": "本文记录了作者在没有Linux驱动开发经验的情况下，编写Nanoleaf Pegboard Desk Dock（一款带RGB LED的USB集线器）Linux驱动的历程。\n\n作者首先使用`lsusb`识别设备，发现一个通用的HID驱动已经识别了它。面对创建内核驱动或通过`libusb`创建用户空间驱动的选择，作者因后者复杂度较低而选择了后者。\n\n该过程包括设置`udev`规则以授予用户访问设备的权限。然后，作者使用`rusb` crate创建一个基本的Rust二进制文件来与设备交互。\n\n遇到的一个常见错误是声明接口时出现“Busy”，通过分离内核驱动程序来解决。然后，作者使用适当端点上的`write_interrupt`发送命令，将洞洞板设置为纯红色。\n\n本文强调了理解USB概念（如配置、接口和端点）的重要性。它还指出需要处理来自设备的中断响应，以避免固件崩溃。作者强调了写入设备的简易性，称其就像打开管道并写入一样简单。"
  },
  {
    "id": "44380185",
    "title": "Better Auth, by a self-taught Ethiopian dev, raises $5M from Peak XV, YC",
    "url": "https://techcrunch.com/2025/06/25/this-self-taught-ethiopian-dev-built-an-authentication-tool-and-got-into-yc/",
    "summary": "Bereket Engida, a self-taught programmer from Ethiopia, has created Better Auth, an open-source authentication framework that simplifies user management for developers. The startup recently secured $5 million in seed funding from prominent investors like Peak XV, Y Combinator, P1 Ventures, and Chapter One.\n\nEngida developed the entire product while in Ethiopia after becoming frustrated with the limitations and costs of existing authentication solutions like Auth0 and Firebase. He wanted a system that offered more customization, control over user data, and scalability.\n\nBetter Auth allows developers to implement authentication directly on their databases, keeping user data on-premise, a major draw for companies concerned about third-party data handling. Its TypeScript-based framework supports common permissions use cases and scales with plug-ins, enabling advanced features with minimal code.\n\nSince its launch on GitHub in September 2024, Better Auth has gained significant traction, with over 150,000 weekly downloads, 15,000 GitHub stars, and a thriving community. It has found particular popularity among AI startups needing custom authentication flows.\n\nCurrently free to use, Better Auth plans to focus on improving core features and launching a paid enterprise infrastructure that integrates with its open-source base, offering developers flexibility in hosting options. Engida also intends to build a small team to support the growing codebase and enterprise users.\n\nBetter Auth's success is seen as a significant achievement for an Ethiopian founder building a global product and inspires other ambitious developers in the region.\n",
    "chinese_title": "更好的身份验证服务，由一位自学成才的埃塞俄比亚开发者创建，获 Peak XV 和 YC 投资 500 万美元",
    "chinese_summary": "来自埃塞俄比亚的自学成才程序员Bereket Engida创建了Better Auth，这是一个开源身份验证框架，可简化开发人员的用户管理。这家初创公司最近获得了500万美元的种子轮融资，投资者包括Peak XV、Y Combinator、P1 Ventures和Chapter One等知名机构。\n\nEngida在埃塞俄比亚开发了整个产品，原因是现有的Auth0和Firebase等身份验证解决方案存在局限性和高成本。他想要一个提供更多定制、用户数据控制和可扩展性的系统。\n\nBetter Auth允许开发人员直接在其数据库上实施身份验证，将用户数据保留在本地，这对关注第三方数据处理的公司具有很大的吸引力。其基于TypeScript的框架支持常见的权限用例，并通过插件进行扩展，从而以最少的代码实现高级功能。\n\n自2024年9月在GitHub上发布以来，Better Auth已获得显著关注，每周下载量超过15万次，GitHub Stars达1.5万，并拥有蓬勃发展的社区。它在需要自定义身份验证流程的人工智能初创公司中尤其受欢迎。\n\n目前Better Auth可以免费使用，未来计划专注于改进核心功能并推出付费的企业级基础设施，该基础设施与其开源基础相结合，为开发人员提供灵活的托管选项。Engida还计划组建一支小团队来支持不断增长的代码库和企业用户。\n\nBetter Auth的成功被视为一位埃塞俄比亚创始人构建全球产品的重大成就，并激励了该地区其他有抱负的开发人员。"
  },
  {
    "id": "44348415",
    "title": "Structured Output with LangChain and Llamafile",
    "url": "https://blog.brakmic.com/structured-output-with-langchain-and-llamafile/",
    "summary": "This article demonstrates how to generate structured JSON outputs using Llamafile, a local executable LLM, and LangChain. Llamafile lacks the built-in structured output capabilities found in models like OpenAI.\n\nThe solution involves using LangChain's `JsonOutputParser` and `PromptTemplate`.  First, a Pydantic `BaseModel` (e.g., `Answer`) defines the structure of the desired JSON output. Then, `JsonOutputParser` is initialized with this model, and its formatting instructions are incorporated into a `PromptTemplate`.\n\nThe `PromptTemplate`, Llamafile instance (serving as the LLM), and `JsonOutputParser` are chained together using LangChain's Runnable Interface.  The chain processes the prompt through the LLM and then parses the output into the defined JSON structure.\n\nThe article provides code snippets illustrating how to define the data model, create the prompt, initialize the parser, build the chain, and invoke it.  It also includes a brief overview of Llamafile, emphasizing its ability to run locally and its usage with specific flags for server mode. Error handling, bypassing the parser, is also touched upon. The author tested this with Llama-3.2-1B-Instruct-Q8_0.llamafile on a MacBook Air. The source code is available in a linked repository.\n",
    "chinese_title": "使用 LangChain 和 Llamafile 的结构化输出",
    "chinese_summary": "使用Llamafile和LangChain生成结构化JSON输出"
  },
  {
    "id": "44361633",
    "title": "Real-world performance comparison of ebtree/cebtree/rbtree",
    "url": "http://wtarreau.blogspot.com/2025/06/real-world-performance-comparison-of.html",
    "summary": "This article presents a real-world performance comparison of three tree implementations: Elastic Binary Trees (ebtree), Compact Elastic Binary Trees (cebtree), and Red-Black Trees (rbtree), using the \"treebench\" utility. The tests analyze insert, lookup, and delete operation times with varying key types (u32/u64 timers, 64-bit randoms, short strings, real IPv4 addresses, real user-agents) and tree sizes (512 to 1M entries). The impact of key distribution and the use of multiple tree heads (1, 256, 65536) based on hashing are also investigated.\n\nKey findings:\n*   **Timers:** Ebtrees are significantly faster (3x) than rbtrees for insertion/deletion of timer-like keys due to better balance for regularly distributed keys. Cebtrees offer a memory-efficient alternative if raw performance is not critical.\n*   **64-bit Hashes:** Ebtrees are generally the best choice, with cebtrees not offering significant advantages unless space is paramount.  Hashing significantly improves insertion speed for all tree types.\n*   **Short Strings:** If ordering isn't required, hashing with a large number of buckets and using rbtrees provides the fastest lookups.  If ordering is required, ebtrees are better than cebtrees.\n*   **IPv4 Addresses:** No single implementation excels across the entire range due to poor address distribution. Hashing IPv4 keys before indexing is recommended.\n*   **User Agents:** Rbtrees are superior for large, mostly-similar strings. Cebtrees perform poorly in this scenario. Hashing the inputs is recommended if sorting is not a requirement.\n\nThe article concludes that prefix trees (ebtree and cebtree) are more sensitive to key distribution. For high performance with large keys, rbtrees or hashing are recommended if ordering is unnecessary.\n",
    "chinese_title": "ebtree/cebtree/rbtree 的实际性能比较",
    "chinese_summary": "本文利用\"treebench\"工具，对三种树实现的真实性能进行了比较，这三种树分别是：弹性二叉树（ebtree）、紧凑型弹性二叉树（cebtree）和红黑树（rbtree）。测试分析了插入、查找和删除操作的时间，使用了不同的键类型（u32/u64计时器、64位随机数、短字符串、真实IPv4地址、真实用户代理）和树的大小（512到100万条目）。还研究了键分布的影响以及基于哈希的多个树头（1、256、65536）的使用。\n\n主要发现：\n*   **计时器：** 由于对规则分布的键具有更好的平衡性，Ebtree在插入/删除类似计时器的键时比rbtree快得多（3倍）。如果原始性能不是关键，Cbtree提供了一种内存高效的替代方案。\n*   **64位哈希：** Ebtree通常是最佳选择，除非空间至关重要，否则cebtree没有提供显着的优势。哈希处理显着提高了所有树类型的插入速度。\n*   **短字符串：** 如果不需要排序，使用大量桶进行哈希处理并使用rbtree可以提供最快的查找速度。如果需要排序，ebtree比cebtree更好。\n*   **IPv4地址：** 由于地址分布不佳，没有一种单一的实现能够在整个范围内表现出色。建议在索引之前对IPv4键进行哈希处理。\n*   **用户代理：** 对于大型、大部分相似的字符串，Rbtree更胜一筹。在这种情况下，Cbtree的性能很差。如果不需要排序，建议对输入进行哈希处理。\n\n文章得出结论，前缀树（ebtree和cebtree）对键分布更为敏感。对于具有大键的高性能，如果不需要排序，建议使用rbtree或哈希处理。"
  },
  {
    "id": "44384610",
    "title": "LLM code generation may lead to an erosion of trust",
    "url": "https://jaysthoughts.com/aithoughts1",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "LLM代码生成可能导致信任侵蚀",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44384913",
    "title": "AccessOwl (YC S22) is hiring an Elixir Engineer to connect 100s of SaaS",
    "url": "https://www.ycombinator.com/companies/accessowl/jobs/1shGwy2-senior-software-engineer-elixir-focus",
    "summary": "AccessOwl, a Y Combinator (S22)-backed startup revolutionizing SaaS management, is seeking a Senior Software Engineer specializing in Elixir. The role is fully remote within ±3 hours of CET (Berlin), offering €70K - €95K EUR salary and 0.05%-0.10% equity.\n\nAccessOwl aims to simplify SaaS access, spending, and compliance by replacing outdated systems with an innovative approach leveraging RPA and agentic AI workflows. They're looking for someone with 5+ years of web development experience, proficient in Elixir and other languages, and who embraces AI for rapid iteration. The ideal candidate enjoys solving customer problems, breaking them into manageable parts, and contributes to modern engineering principles like TDD and continuous delivery.\n\nResponsibilities include advancing the AccessOwl platform, building integrations, contributing to cloud infrastructure, and actively participating in product discussions.\n\nThe company offers a flexible, remote-first environment, state-of-the-art tech stack (Elixir, Phoenix, LiveView), and yearly team retreats. AccessOwl is a profitable company focused on building a sustainable business and fostering an inclusive and ambitious team environment. To apply, candidates should include three sentences about what interests them in talking to AccessOwl.\n",
    "chinese_title": "AccessOwl（YC S22）正在招聘一名Elixir工程师，以连接数百个SaaS。",
    "chinese_summary": "AccessOwl，一家由 Y Combinator (S22) 支持、正在革新 SaaS 管理的初创公司，现招聘一位 Elixir 资深软件工程师。该职位为完全远程，工作时间需在欧洲中部时间 (柏林) ±3 小时内，提供 7 万欧元至 9.5 万欧元薪资以及 0.05%-0.10% 的股权。\n\nAccessOwl 旨在通过利用 RPA 和自主 AI 工作流的创新方法，取代过时的系统，从而简化 SaaS 访问、支出和合规性。他们正在寻找一位拥有 5 年以上 Web 开发经验、精通 Elixir 和其他语言，并拥抱 AI 以实现快速迭代的人才。理想的候选人应乐于解决客户问题，将其分解为可管理的部分，并为 TDD 和持续交付等现代工程原则做出贡献。\n\n职责包括推进 AccessOwl 平台发展、构建集成、为云基础设施做出贡献以及积极参与产品讨论。\n\n公司提供灵活的、远程优先的环境，最先进的技术栈（Elixir、Phoenix、LiveView），以及年度团队休假。AccessOwl 是一家盈利公司，专注于建立可持续发展的业务，并培养包容和雄心勃勃的团队环境。申请者请在求职信中包含三句话，说明是什么吸引您与 AccessOwl 交流。"
  },
  {
    "id": "44379606",
    "title": "What Problems to Solve (1966)",
    "url": "http://genius.cat-v.org/richard-feynman/writtings/letters/problems",
    "summary": "In a letter to a former student, Koichi Mano, Richard Feynman addresses the student's unhappiness with his current research in coherence theory and electromagnetic wave propagation in turbulent atmospheres. Feynman believes Mano's unhappiness stems from a misconstrued idea of what constitutes worthwhile scientific problems, likely influenced by his former professor.\n\nFeynman argues that the most valuable problems are those a scientist can realistically solve or contribute to. He advises Mano to focus on simpler, even seemingly trivial problems, where success is achievable. The pleasure of making progress and helping others, even in small ways, should not be undervalued.\n\nFeynman regrets assigning Mano a problem in the past, instead of allowing him to find his own, leading to a misconception about what's interesting and important – namely, problems one can actively work on and potentially solve.\n\nHe emphasizes that no problem is too small or insignificant if a scientist can make a tangible contribution. He illustrates this with a list of his own research endeavors, ranging from the mundane (friction, electroplating) to the complex (neutron diffusion, shock waves, flexagons, turbulence). He advises Mano to embrace his ability to answer simple questions from colleagues and to find value in his contributions, rather than aspiring only to \"grand\" problems. Finally, Feynman encourages Mano to recognize his own worth and find happiness in solving problems, regardless of their perceived scale.\n",
    "chinese_title": "要解决哪些问题 (1966)",
    "chinese_summary": "费曼在一封给以前的学生真野浩一的信中，谈及他对目前在相干理论和湍流大气中电磁波传播研究的不满。费曼认为，真野的不快乐源于对什么是有价值的科学问题的误解，这很可能受到了他以前教授的影响。\n\n费曼认为，最有价值的问题是科学家能够切实解决或做出贡献的问题。他建议真野专注于更简单，甚至看似微不足道的问题，因为这些问题更容易取得成功。不应低估取得进展和帮助他人的乐趣，即使是以微小的方式。\n\n费曼后悔过去指派给真野一个问题，而不是让他自己去发现，这导致了他对什么是有趣和重要的问题的误解——即那些可以积极研究并可能解决的问题。\n\n他强调，如果科学家能够做出切实的贡献，那么没有问题太小或微不足道。他用自己的一系列研究项目来说明这一点，从平凡的（摩擦、电镀）到复杂的（中子扩散、冲击波、弹性弯曲体、湍流）。他建议真野接受他回答同事简单问题的能力，并在他的贡献中找到价值，而不是仅仅渴望“宏大”的问题。最后，费曼鼓励真野认识到自身的价值，并在解决问题中找到快乐，无论问题的规模大小。"
  },
  {
    "id": "44386637",
    "title": "RSS Server Side Reader",
    "url": "https://matklad.github.io/2025/06/26/rssssr.html",
    "summary": "This article discusses the author's journey in creating a personalized RSS reader, focusing on a server-side approach. Dissatisfied with existing RSS readers due to their feature-rich nature (like offline article saving and embedded browsers), the author only needed notifications.\n\nThe author's initial client-side attempt, a web page using browser local storage, failed due to CORS restrictions. The successful solution involves building a personalized feed as part of their blog's build process, hosted as a static HTML page (blogroll.html). This page displays the latest three posts from each feed, without maintaining read/unread status. The blogroll.txt file contains a simple list of feed URLs. The article includes code snippets (Deno) for fetching and parsing the blogroll, converting the data to HTML, and a GitHub Actions workflow for rebuilding the blogroll daily.\n\nThe author prefers Atom feeds over the original RSS due to their simplicity (though JSON Feed is preferred but unmaintained). The key benefit of this approach is the ability to access the curated feed from any device. Finally, the author notes an additional resource: their static list of all-time favorite links, hosted separately.\n",
    "chinese_title": "RSS服务器端阅读器",
    "chinese_summary": "本文探讨了作者创建个性化RSS阅读器的过程，重点介绍了一种服务器端方法。 由于现有RSS阅读器功能丰富（如离线文章保存和嵌入式浏览器），作者对其不满意，而他只需要通知。\n\n作者最初的客户端尝试，一个使用浏览器本地存储的网页，因CORS限制而失败。 成功的解决方案包括将其博客构建过程的一部分构建为个性化feed，并将其托管为静态HTML页面 (blogroll.html)。 此页面显示每个feed的最新三篇文章，而不维护已读/未读状态。 blogroll.txt文件包含一个简单的feed URL列表。 本文包含用于获取和解析博客列表、将数据转换为HTML的代码片段（Deno），以及用于每日重建博客列表的GitHub Actions工作流。\n\n由于Atom feeds的简洁性，作者更喜欢Atom feeds而不是原始RSS（尽管更喜欢JSON Feed，但未维护）。 这种方法的关键好处是能够从任何设备访问精选的feed。 最后，作者指出还有一个额外的资源：他们所有时间最喜欢的链接的静态列表，单独托管。"
  },
  {
    "id": "44379673",
    "title": "Build and Host AI-Powered Apps with Claude – No Deployment Needed",
    "url": "https://www.anthropic.com/news/claude-powered-artifacts",
    "summary": "This article announces a new feature in the Claude app that allows developers to build, host, and share AI-powered applications directly within the platform, eliminating the need for traditional deployment processes. This new capability lets Claude generate interactive artifacts that function as apps powered by its API. Key advantages for developers include:\n\n*   **Simplified Sharing:** Users authenticate with their own Claude account, and their API usage is charged to their subscription, not the developer's, meaning the developer pays nothing for user usage.\n*   **Open Code:** Claude writes the actual code that powers the app, allowing developers to view, modify, and share it freely.\n*   **Rapid Iteration:** Developers can quickly build and iterate on their apps without the complexities and costs associated with scaling.\n*   **Focus on Creation:** Claude handles technical details like prompt engineering, error handling, and orchestration, letting developers concentrate on the application's core functionality.\n\nEarly examples include AI-powered games, personalized learning tools, data analysis apps, writing assistants, and agent workflows. To get started, users can enable the interactive capability in the Claude app and describe the desired app. Claude will then write the code, debug it based on feedback, and allow for instant sharing via a link. Current limitations include no external API calls, no persistent storage, and a text-based completion API. This feature is currently in beta and available to Free, Pro, and Max plan users.\n",
    "chinese_title": "用Claude构建和托管AI驱动的应用 - 无需部署",
    "chinese_summary": "此文章宣布Claude应用推出一项新功能，允许开发者直接在平台内构建、托管和分享AI驱动的应用，无需传统的部署流程。这项新功能使Claude能够生成作为其API驱动的应用程序的交互式作品。开发者的主要优势包括：\n\n*   **简化分享：** 用户使用自己的Claude账户进行身份验证，其API使用量将计入他们的订阅，而不是开发者的，这意味着开发者无需为用户的使用付费。\n*   **开放代码：** Claude编写驱动应用的实际代码，允许开发者自由查看、修改和分享。\n*   **快速迭代：** 开发者可以快速构建和迭代他们的应用，而无需与扩展相关的复杂性和成本。\n*   **专注于创作：** Claude处理诸如提示工程、错误处理和编排等技术细节，让开发者专注于应用程序的核心功能。\n\n早期示例包括AI驱动的游戏、个性化学习工具、数据分析应用、写作助手和代理工作流程。要开始使用，用户可以在Claude应用中启用交互功能并描述所需的应用程序。然后，Claude将编写代码，根据反馈进行调试，并允许通过链接进行即时分享。目前的限制包括没有外部API调用，没有持久存储，以及基于文本的完成API。此功能目前处于测试阶段，适用于Free、Pro和Max计划用户。"
  },
  {
    "id": "44379670",
    "title": "America’s incarceration rate is in decline",
    "url": "https://www.theatlantic.com/ideas/archive/2025/06/prisoner-populations-are-plummeting/683310/",
    "summary": "This article argues that the United States' mass incarceration era is coming to an end. After peaking in 2009, the prison population has significantly declined and is projected to continue falling, potentially reaching levels not seen in half a century.\n\nThe author explains that the prison population reflects crime rates from decades prior due to lengthy sentences and high recidivism. The surge in incarceration from the late 20th century was a delayed response to a major crime wave. However, the \"great crime decline\" that began in the 1990s is now impacting prison populations.\n\nCrucially, juvenile arrests have plummeted in the 21st century, meaning fewer young people are entering the criminal justice system and refilling the prisons as older generations age out. Despite a brief crime spike during COVID, this trend continues.\n\nThe author suggests policy changes to accelerate decarceration, including halting prison construction (even private prisons, to counter public sector union influence), establishing prison-closing commissions, and prioritizing compassionate release for elderly and ill inmates.\n\nThe expected decline in incarceration will not only benefit individuals and communities, but also free up resources for other priorities like education. The author concludes that a smaller prison population is a societal win for all.\n",
    "chinese_title": "美国的监禁率正在下降",
    "chinese_summary": "美国大规模监禁时代即将终结"
  },
  {
    "id": "44379792",
    "title": "MCP in LM Studio",
    "url": "https://lmstudio.ai/blog/lmstudio-v0.3.17",
    "summary": "This LM Studio blog post announces the introduction of Model Context Protocol (MCP) support in version 0.3.17, enabling users to connect MCP servers to the application and use them with local models. MCP allows LLMs to access external tools and resources, and LM Studio supports both local and remote MCP servers. Users can add MCP servers by editing the `mcp.json` file or via the \"Add to LM Studio\" button.\n\nThe post provides an example of using a Hugging Face MCP server for model and dataset search and warns users to be cautious about installing MCPs from untrusted sources due to potential security risks. It also describes the tool call confirmation dialog, which allows users to review and edit tool call arguments before execution.\n\nThe post further explains how LM Studio loads MCP servers, highlighting the importance of having necessary tools like `npx` or `uvx` installed for local servers. It also includes a section for developers on creating \"Add to LM Studio\" buttons for their MCP servers.\n\nFinally, the post details other updates in version 0.3.17, including support for 11 new languages, bug fixes, UI improvements like the \"Solarized Dark\" theme, and various enhancements to chat functionality, tool call handling, and MCP reliability.  A call to action encourages developers to sign up for a private beta to create their own tools and custom resources.\n",
    "chinese_title": "LM Studio 中的 MCP",
    "chinese_summary": "LM Studio 博客宣布在 0.3.17 版本中引入模型上下文协议 (MCP) 支持，使用户可以将 MCP 服务器连接到应用程序并与本地模型一起使用。MCP 允许 LLM 访问外部工具和资源，LM Studio 支持本地和远程 MCP 服务器。用户可以通过编辑 `mcp.json` 文件或通过“添加到 LM Studio”按钮添加 MCP 服务器。\n\n该文章提供了一个使用 Hugging Face MCP 服务器进行模型和数据集搜索的示例，并警告用户谨慎安装来自不受信任来源的 MCP，因为存在潜在的安全风险。它还描述了工具调用确认对话框，该对话框允许用户在执行前审查和编辑工具调用参数。\n\n该文章进一步解释了 LM Studio 如何加载 MCP 服务器，强调了安装必要的工具（如 `npx` 或 `uvx`）对于本地服务器的重要性。它还包括一个面向开发者的部分，介绍如何为他们的 MCP 服务器创建“添加到 LM Studio”按钮。\n\n最后，该文章详细介绍了 0.3.17 版本中的其他更新，包括对 11 种新语言的支持、错误修复、UI 改进（如“Solarized Dark”主题），以及对聊天功能、工具调用处理和 MCP 可靠性的各种增强。最后鼓励开发者注册私人测试版，以创建他们自己的工具和自定义资源。"
  },
  {
    "id": "44358667",
    "title": "Howdy – Windows Hello style facial authentication for Linux",
    "url": "https://github.com/boltgolt/howdy",
    "summary": "Howdy enables Windows Hello-style facial authentication on Linux, leveraging IR emitters and cameras for login, lock screen, sudo, and more using the PAM system. It's available for Debian/Ubuntu, Arch Linux, Fedora, and openSUSE with specific installation instructions provided for each distribution.\n\nInstallation typically involves adding repositories, updating packages, and installing the `howdy` package. Some distributions may require additional configuration steps as outlined in their respective wikis. Building from source is also possible, requiring Python 3.6+, pip, setuptools, meson, ninja, and other dependencies.\n\nPost-installation, users must add face models using `sudo howdy add`. `sudo -i` can then be used to test facial authentication. Configuration options are accessible via `sudo howdy config`. The `howdy` command offers functionalities like adding, removing, listing face models, taking snapshots, and testing camera input.\n\nThe article emphasizes that Howdy is a convenience feature, **not a security enhancement**. It is vulnerable to similar-looking individuals or high-quality photographs. Using Howdy as the sole authentication method is strongly discouraged. Python errors are logged to the console, and authentication failures may be recorded in `/var/log/auth.log`.\n",
    "chinese_title": "Linux 下 Windows Hello 风格的面部识别认证",
    "chinese_summary": "Howdy：在Linux上启用Windows Hello风格的面部识别认证\n\nHowdy利用红外发射器和摄像头，通过PAM系统在Linux上实现Windows Hello风格的面部识别认证，可用于登录、锁屏、sudo等操作。它适用于Debian/Ubuntu、Arch Linux、Fedora和openSUSE，并为每个发行版提供特定的安装说明。\n\n安装通常涉及添加软件源、更新软件包和安装`howdy`包。某些发行版可能需要额外的配置步骤，如其各自的Wiki中所述。也可以从源代码构建，这需要Python 3.6+、pip、setuptools、meson、ninja和其他依赖项。\n\n安装后，用户必须使用`sudo howdy add`添加面部模型。然后可以使用`sudo -i`测试面部识别认证。配置选项可通过`sudo howdy config`访问。`howdy`命令提供诸如添加、删除、列出面部模型、拍摄快照和测试摄像头输入等功能。\n\n本文强调，Howdy是一项便利功能，**并非安全增强**。它容易受到相貌相似的人或高质量照片的攻击。强烈建议不要将Howdy作为唯一的身份验证方法。Python错误会被记录到控制台，认证失败可能会记录在`/var/log/auth.log`中。"
  },
  {
    "id": "44382752",
    "title": "Define policy forbidding use of AI code generators",
    "url": "https://github.com/qemu/qemu/commit/3d40db0efc22520fa6c399cf73960dced423b048",
    "summary": "This document outlines the QEMU project's policy prohibiting the use of AI code generators like ChatGPT, Claude, Copilot, and Llama for contributions. The policy stems from concerns regarding the unclear copyright and licensing status of AI-generated code, posing potential legal risks for the project.\n\nQEMU requires contributors to adhere to the Developer's Certificate of Origin (DCO), which necessitates a complete understanding of the copyright and license implications of contributed content. The uncertainty surrounding the licensing of AI-generated outputs makes it difficult to comply with the DCO. The training data used by these AI models often includes material with restrictive licenses, potentially incompatible with QEMU's requirements.\n\nTherefore, QEMU will reject contributions suspected or known to contain AI-generated code. However, the policy does not restrict the use of AI for research, static analysis, or debugging, as long as the output isn't incorporated into submitted code.\n\nThe policy emphasizes the current lack of clarity in the legal landscape surrounding AI-generated content. While the policy may evolve as AI tools mature and legal precedents are established, exceptions will be considered on a case-by-case basis, requiring demonstrable clarity of license and copyright status. The key concern is mitigating the legal risks associated with AI-generated code and ensuring compliance with the DCO.\n",
    "chinese_title": "禁止使用AI代码生成器的政策定义",
    "chinese_summary": "本文概述了QEMU项目禁止使用ChatGPT、Claude、Copilot和Llama等AI代码生成器进行代码贡献的政策。该政策源于对AI生成代码版权和许可状态不明的担忧，这可能给项目带来潜在的法律风险。\n\nQEMU要求贡献者遵守开发者原创声明（DCO），这要求完全理解贡献内容的版权和许可影响。AI生成输出的许可不确定性使得难以遵守DCO。这些AI模型使用的训练数据通常包含具有限制性许可证的材料，可能与QEMU的要求不兼容。\n\n因此，QEMU将拒绝任何疑似或已知包含AI生成代码的贡献。但是，该政策并不限制将AI用于研究、静态分析或调试，只要输出不被纳入提交的代码中。\n\n该政策强调当前AI生成内容周围法律环境的缺乏清晰性。虽然该政策可能会随着AI工具的成熟和法律先例的建立而发展，但例外情况将根据具体情况进行考虑，需要证明许可证和版权状态的清晰性。关键在于降低与AI生成代码相关的法律风险，并确保符合DCO。"
  },
  {
    "id": "44381168",
    "title": "The Offline Club",
    "url": "https://www.theoffline-club.com",
    "summary": "The Offline Club is a global movement promoting real-world connection by offering alternatives to screen time. They host offline events, digital detox retreats, and business events designed to help people unplug, relax, and connect with like-minded individuals.\n\nThe club boasts a 4.7/5 rating based on 251 reviews, highlighting customer satisfaction. They offer various activities, including café hangouts, phone-free dinners, and creative spaces for reading, drawing, and writing. The Offline Club aims to provide an atmosphere where people can have meaningful conversations, focus, and take a break from social media.\n\nThey have chapters in multiple cities across seven countries, including Amsterdam, London, Paris, Barcelona, Milan, Berlin, and Copenhagen, and they are actively looking to expand. Individuals can join city waitlists or apply to start their own local Offline Club chapter.\n\nThe Offline Club also offers Digital Detox Retreats, providing weekends away from digital distractions. For businesses, they curate unique offline experiences and events for teams and organizations. Their work has been featured in various media outlets, highlighting the growing movement toward more genuine connection. The club distributes \"The Offline Times,\" a newsletter with offline inspiration and digital detoxing tips, and offers a 24-hour digital detox challenge.\n",
    "chinese_title": "离线俱乐部",
    "chinese_summary": "线下俱乐部是一个全球性运动，旨在通过提供屏幕时间替代方案来促进现实世界的连接。他们举办线下活动、数字排毒静修和商务活动，旨在帮助人们解除网络连接、放松身心并与志同道合的人建立联系。\n\n该俱乐部拥有基于251条评论的4.7/5评分，突显了客户满意度。他们提供各种活动，包括咖啡馆聚会、无手机晚餐以及用于阅读、绘画和写作的创意空间。线下俱乐部旨在提供一种人们可以进行有意义的对话、集中精力并从社交媒体中休息的环境。\n\n他们在包括阿姆斯特丹、伦敦、巴黎、巴塞罗那、米兰、柏林和哥本哈根在内的七个国家/地区的多个城市设有分会，并且正在积极寻求扩张。个人可以加入城市等候名单或申请启动自己的本地线下俱乐部。\n\n线下俱乐部还提供数字排毒静修，提供远离数字干扰的周末。对于企业，他们为团队和组织策划独特的线下体验和活动。他们的工作已在各种媒体上得到报道，突显了人们对更真实联系的日益增长的追求。该俱乐部发行“线下时报”，这是一份包含线下灵感和数字排毒技巧的通讯，并提供24小时数字排毒挑战。"
  },
  {
    "id": "44385742",
    "title": "Apptainer: Application Containers for Linux",
    "url": "https://apptainer.org/",
    "summary": "Apptainer (formerly Singularity) is a container system designed for portability and reproducibility of software. It simplifies container creation and execution, allowing users to encapsulate application components for easy sharing and archiving.\n\nKey features and benefits of Apptainer include:\n\n*   **Security:** Designed for secure execution, Apptainer prohibits privilege escalation within containers, ensuring users have the same permissions inside and outside.\n*   **Portability:** The single-file SIF format enables easy sharing and movement of workloads across diverse environments, from workstations to HPC clusters and the edge.\n*   **Encryption:** Apptainer supports container encryption and integrates with secret management platforms like Vault to protect applications, models, and data.\n*   **Docker Compatibility:** Apptainer offers maximum compatibility with Docker containers from OCI registries, allowing users to pull, run, and build containers from Docker Hub with minimal or no modifications. This eases the transition for users already familiar with Docker.\n\nApptainer aims to provide a secure, portable, and easy-to-use container solution suitable for use in industry and academia.\n",
    "chinese_title": "Apptainer: Linux 应用程序容器",
    "chinese_summary": "Apptainer (原 Singularity) 是一个容器系统，专为软件的可移植性和可重复性而设计。它简化了容器的创建和执行，允许用户封装应用程序组件，以便轻松共享和归档。\n\nApptainer 的主要特性和优势包括：\n\n*   **安全性：** Apptainer 专为安全执行而设计，禁止容器内的权限提升，确保用户在容器内外拥有相同的权限。\n*   **可移植性：** 单文件 SIF 格式便于在各种环境中轻松共享和移动工作负载，从工作站到 HPC 集群和边缘设备。\n*   **加密：** Apptainer 支持容器加密，并与 Vault 等密钥管理平台集成，以保护应用程序、模型和数据。\n*   **Docker 兼容性：** Apptainer 提供与来自 OCI 注册表的 Docker 容器的最大兼容性，允许用户以最小或无需修改的方式从 Docker Hub 拉取、运行和构建容器。 这简化了已熟悉 Docker 的用户的过渡。\n\nApptainer 旨在提供一种安全、可移植且易于使用的容器解决方案，适用于工业界和学术界。"
  },
  {
    "id": "44350655",
    "title": "The Art of Hanakami, or Flower-Petal Folding",
    "url": "https://origamiusa.org/thefold/article/art-hanakami-or-flower-petal-folding",
    "summary": "Michael Lai's article, \"The Art of Hanakami, or Flower-Petal Folding,\" introduces a unique origami technique where flower petals are used instead of paper. Hanakami, a term coined by the author, emphasizes the substitution of organic flower petals for traditional paper. The article details the process, from selecting and preparing petals to folding them into delicate origami models.\n\nLai emphasizes that finding the right flower petal is important. He suggests considering flowering season, petal shape and size, color when dried, thickness, surface texture and fragrance. Flat, minimally petaled flowers that aren't too thick are the easiest to fold.\n\nThe process involves collecting petals, ideally fallen ones to minimize environmental impact, and then drying and pressing them to remove excess moisture and flatten them. The goal is to achieve a pliable state, not complete dryness. Once dried, petals are cut into squares, maximizing the usable surface area and considering vein patterns. Experimentation is key, and moisture can be carefully reintroduced if a petal is too brittle.\n\nThe article underscores the challenges inherent in hanakami, acknowledging that flower petals are not designed for folding. It encourages patience and emphasizes the value of the process, even if the final model isn't perfect. Ultimately, hanakami offers a novel way to appreciate the beauty of flowers by transforming them into intricate origami art.\n",
    "chinese_title": "花瓣折叠艺术",
    "chinese_summary": "赖迈克的文章《花瓣折纸艺术》介绍了一种独特的折纸技巧，使用花瓣代替纸张。花瓣折纸（Hanakami）是作者创造的一个术语，强调用有机花瓣替代传统纸张。文章详细介绍了整个过程，从选择和准备花瓣到将它们折叠成精致的折纸模型。\n\n赖强调，找到合适的花瓣至关重要。他建议考虑花期、花瓣形状和大小、干燥后的颜色、厚度、表面纹理和香味。平整、花瓣少的、不太厚的花朵最容易折叠。\n\n这个过程包括收集花瓣，最好是落下的花瓣，以尽量减少对环境的影响，然后将它们干燥并压平，以去除多余的水分并使它们平整。目标是达到柔韧的状态，而不是完全干燥。干燥后，将花瓣切割成正方形，最大限度地利用可用表面积并考虑纹路。实验是关键，如果花瓣太脆，可以小心地重新引入水分。\n\n文章强调了花瓣折纸固有的挑战，承认花瓣并非为折叠而设计。它鼓励耐心，并强调过程的价值，即使最终的模型并不完美。最终，花瓣折纸提供了一种欣赏花朵之美的新颖方式，通过将它们转化为精致的折纸艺术。"
  },
  {
    "id": "44376919",
    "title": "Gemini CLI",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/",
    "summary": "The article introduces Gemini CLI, an open-source AI agent that brings the power of the Gemini AI model directly to developers' terminals. It's positioned as a versatile tool for coding, content generation, problem-solving, research, and task management.\n\nKey benefits include:\n\n*   **Free access:** Users can access Gemini 2.5 Pro (1 million token context window) for free by logging in with a personal Google account to get a free Gemini Code Assist license, with generous usage limits (60 requests per minute, 1000 per day). Paid options exist for higher usage or specific models.\n*   **Powerful capabilities:** Gemini CLI offers features like grounding prompts with Google Search for real-time context, extending functionality via the Model Context Protocol (MCP), customizing prompts, and automating tasks.\n*   **Open-source and extensible:** Developers can inspect the code, contribute improvements, and customize the tool to fit their needs.\n*   **Integration with Gemini Code Assist:** Gemini CLI shares technology with Gemini Code Assist, Google's AI coding assistant, allowing seamless AI-powered coding in both the terminal and VS Code. Gemini Code Assist's agent mode is available across all plans, offering advanced features like multi-step planning and error recovery.\n\nThe article emphasizes Gemini CLI's potential to significantly upgrade the command-line experience and streamline developer workflows. It encourages developers to try it out.\n",
    "chinese_title": "Gemini 命令行工具",
    "chinese_summary": "Gemini CLI：将 Gemini 模型带到终端的开源 AI 助手\n\n本文介绍 Gemini CLI，一款开源 AI 助手，它将 Gemini AI 模型的强大功能直接带到开发者的终端。它定位为一个多功能工具，适用于编码、内容生成、问题解决、研究和任务管理。\n\n主要优势包括：\n\n*   **免费访问：** 用户可以通过个人 Google 帐户登录以获得免费的 Gemini Code Assist 许可证，从而免费访问 Gemini 2.5 Pro (100 万 token 上下文窗口)，并享有慷慨的使用限制（每分钟 60 个请求，每天 1000 个）。付费选项可用于更高的使用量或特定模型。\n*   **强大的功能：** Gemini CLI 提供诸如通过 Google 搜索进行实时上下文扎根提示、通过模型上下文协议 (MCP) 扩展功能、自定义提示以及自动化任务等功能。\n*   **开源和可扩展：** 开发者可以检查代码、贡献改进意见并自定义工具以满足他们的需求。\n*   **与 Gemini Code Assist 集成：** Gemini CLI 与 Google 的 AI 编码助手 Gemini Code Assist 共享技术，从而可以在终端和 VS Code 中实现无缝的 AI 驱动编码。Gemini Code Assist 的代理模式在所有计划中均可用，提供诸如多步规划和错误恢复等高级功能。\n\n本文强调了 Gemini CLI 在显著升级命令行体验和简化开发者工作流程方面的潜力。它鼓励开发者尝试使用。"
  },
  {
    "id": "44360651",
    "title": "Getting by on the Generosity of Strangers in Japan",
    "url": "https://theworld.org/stories/2025/06/20/out-of-eden-walk-getting-by-on-the-generosity-of-strangers",
    "summary": "In this interview, National Geographic Explorer Paul Salopek discusses the vital role of hospitality in his 12-year \"Out of Eden Walk,\" a journey tracing human migration across continents. He recounts his experience at the Migita guesthouse in Japan, run by 84-year-old Yoshiko Yamana, highlighting her warmth, resilience, and the unique sense of welcome she offers guests.\n\nSalopek emphasizes that hospitality is a universal human trait, encountered consistently throughout his travels, even in unexpected places like shepherds' huts, palaces, and caves. He notes that those with the least often offer the most generous hospitality, born from an understanding of suffering.\n\nHe reflects on the importance of chance encounters and compassion in his project, stating that people are his ultimate destination. While acknowledging cultural nuances and his own missteps, Salopek appreciates the highly codified traditions of hospitality in Japan, where even the placement of shoes carries significance. He stresses that years of traversing diverse cultures have heightened his awareness of human kindness and goodness, reinforcing his belief in its pervasive presence worldwide.\n",
    "chinese_title": "在日本靠陌生人的慷慨解囊度日",
    "chinese_summary": "在本次访谈中，国家地理探险家保罗·萨洛佩克探讨了款待在他为期 12 年的“走出伊甸园”徒步旅行中的重要作用，这是一次追溯人类跨越大陆迁徙的旅程。他讲述了在日本 Migita 旅馆的经历，这家旅馆由 84 岁的山名芳子经营，并强调了她的热情、韧性以及她为客人提供的独特的欢迎感。\n\n萨洛佩克强调，款待是一种普遍的人类特征，在他的旅程中始终如一地遇到，即使是在意想不到的地方，如牧羊人的小屋、宫殿和洞穴。他指出，那些拥有最少资源的人往往提供最慷慨的款待，这源于对苦难的理解。\n\n他反思了偶然相遇和同情在他的项目中的重要性，并表示人是他的最终目的地。在承认文化差异和他自己的失误的同时，萨洛佩克欣赏日本高度规范化的款待传统，即使是鞋子的摆放也具有重要意义。他强调，多年来穿越各种文化，提高了他对人类善良和美好的认识，加强了他对它在世界范围内普遍存在的信念。"
  },
  {
    "id": "44378127",
    "title": "Bot or human? Creating an invisible Turing test for the internet",
    "url": "https://research.roundtable.ai/proof-of-human/",
    "summary": "This article from Roundtable Technologies argues that current bot detection methods, like Google's reCAPTCHA v3, are insufficient because AI agents can pass them despite exhibiting non-human behavior. The authors propose a new approach based on behavioral and cognitive signatures. They highlight that humans have unique patterns in keystroke dynamics and mouse movements that bots struggle to replicate convincingly due to the cost complexity of doing so.\n\nThe article presents interactive demos showcasing the differences in keystroke patterns, mouse movements, and cognitive performance (using the Stroop task) between humans and bots. These demos illustrate how bots often exhibit unnatural regularity in typing and movement, and lack the cognitive interference that humans experience.\n\nThe authors argue that replicating the full range of human cognition, not just mimicking outputs, presents a significant challenge for AI agents. They describe their early research involving tasks like the \"Boston Temperature Test,\" where human errors were predictable, unlike the random or overly perfect responses of bots.\n\nRoundtable Technologies offers a Proof-of-Human API that uses behavioral and cognitive analysis to verify users invisibly, continuously, and instantaneously. This approach focuses on making it economically challenging for bots to replicate human cognition, rather than relying on privacy-invasive methods. Ultimately, the goal is to create an \"invisible Turing Test\" that can effectively differentiate between humans and AI agents on the internet.\n",
    "chinese_title": "机器人还是人类？为互联网打造隐形图灵测试",
    "chinese_summary": "圆桌科技的文章认为，当前机器人检测方法（如谷歌的reCAPTCHA v3）不足以有效识别AI代理，因为即使表现出非人类行为，AI代理也能通过验证。作者提出了一种基于行为和认知特征的新方法，强调人类在按键动态和鼠标移动方面具有独特的模式，而机器人难以令人信服地复制，因为这样做的成本过于复杂。\n\n文章展示了交互式演示，突出了人类和机器人之间在按键模式、鼠标移动和认知表现（使用Stroop任务）上的差异。这些演示表明，机器人通常在打字和移动方面表现出不自然的规律性，并且缺乏人类所经历的认知干扰。\n\n作者认为，复制人类认知的完整范围，而不仅仅是模仿输出，对AI代理来说是一个巨大的挑战。他们描述了他们的早期研究，其中包括“波士顿温度测试”等任务，在这些任务中，人类的错误是可以预测的，这与机器人随机或过于完美的反应不同。\n\n圆桌科技提供了一个人类身份验证API，该API使用行为和认知分析来隐形、连续和即时地验证用户。这种方法侧重于使机器人复制人类认知在经济上具有挑战性，而不是依赖于侵犯隐私的方法。最终，目标是创建一个“隐形的图灵测试”，可以有效地在互联网上区分人类和AI代理。"
  },
  {
    "id": "44385612",
    "title": "The first non-opoid painkiller",
    "url": "https://www.worksinprogress.news/p/the-first-non-opioid-painkiller",
    "summary": "This article details the development and approval of Journavx (suzetrigine), the first non-opioid pain reliever suitable for post-surgery pain, approved by the FDA in January 2025. Traditional painkillers rely on opioids, which, while effective, carry significant risks of addiction and overdose. Journavx works differently, targeting NaV1.8 sodium ion channels located on peripheral nociceptors (pain-sensing neurons) to prevent pain signals from reaching the brain, unlike opioids which act centrally in the brain.\n\nThe development of Journavx was a lengthy and complex process, spanning decades due to the challenges of targeting pain pathways without disrupting other vital bodily functions. Previous attempts at non-opioid pain relief, such as TRPV1 and nerve growth factor inhibitors, failed due to significant side effects.\n\nVertex Pharmaceuticals utilized its E-VIPR technology to screen millions of compounds to find a selective NaV1.8 blocker, facing numerous setbacks and terminated projects along the way. The successful candidate, VX-548 (suzetrigine), showed efficacy in treating acute pain with minimal adverse effects in clinical trials.\n\nWhile Journavx is not a perfect solution, as it doesn't outperform opioid-acetaminophen combinations and its use in chronic pain is still under investigation, it represents a significant step in minimizing opioid use. Vertex is continuing to research even more potent and selective NaV1.8 blockers and is exploring potential complementarities with NaV1.7 inhibitors.\n",
    "chinese_title": "首个非阿片类止痛药",
    "chinese_summary": "本文详细介绍了Journavx (suzetrigine) 的研发和批准过程。Journavx是首个适用于术后疼痛的非阿片类镇痛药，于2025年1月获得FDA批准。 传统的止痛药依赖于阿片类药物，虽然有效，但存在严重的成瘾和过量风险。 Journavx 的作用机制不同，它靶向位于外周伤害性感受器（疼痛感应神经元）上的NaV1.8钠离子通道，以阻止疼痛信号到达大脑，这与作用于大脑中枢的阿片类药物不同。\n\nJournavx 的研发是一个漫长而复杂的过程，历时数十年，因为在不扰乱其他重要身体功能的情况下靶向疼痛通路面临诸多挑战。 之前尝试的非阿片类镇痛方法，如TRPV1和神经生长因子抑制剂，因显著的副作用而失败。\n\nVertex Pharmaceuticals 公司利用其E-VIPR 技术筛选了数百万种化合物，以寻找一种选择性的NaV1.8阻滞剂，在此过程中面临许多挫折和终止的项目。 成功的候选药物 VX-548 (suzetrigine) 在临床试验中显示出治疗急性疼痛的疗效，且不良反应极小。\n\n虽然 Journavx 并非完美解决方案，因为它在疗效上并未超过阿片类-对乙酰氨基酚的组合，并且其在慢性疼痛中的应用仍在研究中，但它代表着在最大限度地减少阿片类药物使用方面迈出了重要一步。 Vertex 公司正在继续研究更有效和更具选择性的 NaV1.8 阻滞剂，并探索与 NaV1.7 抑制剂的潜在互补性。"
  },
  {
    "id": "44385892",
    "title": "I fought in Ukraine and here's why FPV drones kind of suck",
    "url": "https://warontherocks.com/2025/06/i-fought-in-ukraine-and-heres-why-fpv-drones-kind-of-suck/",
    "summary": "Jakub Jajcay, a volunteer who fought in Ukraine on an FPV attack drone team, argues that while FPV drones are touted as revolutionary, they are often less effective than portrayed. Although the drones can execute impressive strikes in videos, these are exceptions.\n\nJajcay's team experienced a 43% success rate (drone hits target and detonates), but most sorties targeted areas already struck by mortars or other drones. Only a single-digit percentage of missions utilized the drones' unique capabilities (precision strikes not achievable by other means). This is because commanders use them even when cheaper alternatives exist (like mortars, costing far less than the $500 drone sortie) and because the drones are technically unreliable.\n\nThe drones suffer from frequent technical faults, limited night vision, and susceptibility to weather. A quarter malfunction before takeoff, often due to radio receiver or video transmitter issues. Even airborne, batteries die frequently, and warheads sometimes fail to detonate. They're hard to fly, requiring extensive training, and lack navigational aids.\n\nThe biggest problem is the unreliable radio link, easily disrupted by terrain and electronic warfare jamming. Signal interference from other drones (friendly or enemy) and jamming caused a significant percentage of mission failures. Enemy jamming alone downed 31% of sorties.\n\nWhile technology is improving (better components, digital signals, signal boosters), current solutions like fiber-optic cable drones have drawbacks like limited maneuverability, higher cost, and limited production capacity.\n",
    "chinese_title": "我在乌克兰作战，以下是我认为FPV无人机有点糟糕的原因",
    "chinese_summary": "雅库布·亚伊凯（Jakub Jajcay）是一名在乌克兰参与FPV攻击无人机作战的志愿者，他认为虽然FPV无人机被吹捧为革命性的，但它们的效果往往不如所描述的那样。尽管无人机可以在视频中执行令人印象深刻的打击，但这些只是例外。\n\n亚伊凯的团队成功率只有43%（无人机击中目标并引爆），但大多数出击的目标区域已经被迫击炮或其他无人机打击过。只有个位数的任务利用了无人机独特的性能（其他手段无法实现的精确打击）。这是因为指挥官即使在存在更廉价的替代方案（如成本远低于500美元无人机出击的迫击炮）时也使用它们，并且因为无人机在技术上不可靠。\n\n无人机经常出现技术故障、夜视能力有限且易受天气影响。四分之一的无人机在起飞前就发生故障，通常是由于无线电接收器或视频发射器问题。即使在空中，电池也经常耗尽，弹头有时也无法引爆。它们很难飞行，需要大量训练，并且缺乏导航辅助设备。\n\n最大的问题是不可靠的无线电链路，很容易受到地形和电子战干扰。来自其他无人机（友方或敌方）的信号干扰和干扰导致了相当一部分任务失败。仅敌方干扰就击落了31%的出击。\n\n虽然技术正在改进（更好的组件、数字信号、信号增强器），但目前的解决方案，如光纤电缆无人机，也存在机动性有限、成本更高和生产能力有限等缺点。"
  },
  {
    "id": "44365754",
    "title": "A new PNG spec",
    "url": "https://www.programmax.net/articles/png-is-back/",
    "summary": "This article announces a revitalized PNG specification after over two decades of stagnation. Key updates include proper HDR support using only 4 bytes, official recognition of APNG animations, and support for Exif data. The updates were driven by the W3C Timed Text Working Group's need for HDR support and garnered support from major companies like Adobe, Apple, Google, and the BBC.\n\nThe article highlights that many programs, including Chrome, Safari, Firefox, Photoshop, and DaVinci Resolve, already support the new spec, and broadcast companies are updating their hardware and tooling. The author also anticipates that the next update (Fourth Edition) will focus on improving HDR & SDR interoperability. The Fifth Edition will focus on better compression and parallel encoding/decoding. The author thanks the PNG Working Group for their hard work in making the updated specification a reality. The author also notes that the PNG format is used and recommended by the U.S. Library of Congress, Library and Archives Canada, and the National Archives of Australia.\n",
    "chinese_title": "一个新的PNG规范",
    "chinese_summary": "本文宣布在停滞二十余年后，PNG规范迎来重大更新。主要更新包括：仅使用4字节即可实现正确的HDR支持、官方认可APNG动画以及支持Exif数据。此次更新由W3C定时文本工作组对HDR支持的需求驱动，并获得了Adobe、Apple、Google和BBC等主要公司的支持。\n\n文章强调，包括Chrome、Safari、Firefox、Photoshop和DaVinci Resolve在内的许多程序已经支持新规范，广播公司也在更新其硬件和工具。作者还预计，下一个版本（第四版）将侧重于提高HDR和SDR的互操作性。第五版将侧重于更好的压缩和并行编码/解码。作者感谢PNG工作组为使更新后的规范成为现实所付出的辛勤努力。作者还指出，美国国会图书馆、加拿大图书馆和档案馆以及澳大利亚国家档案馆都在使用和推荐PNG格式。"
  },
  {
    "id": "44378486",
    "title": "Web Embeddable Common Lisp",
    "url": "https://turtleware.eu/static/paste/wecl-test-gl/main.html",
    "summary": "The article \"Web Embeddable Common Lisp\" likely discusses the potential for, or actual implementations of, embedding Common Lisp (CL) code within web applications. Given the title alone, we can infer the following likely aspects:\n\n*   **Focus on Web Integration:** The core topic revolves around leveraging CL in a web environment. This distinguishes it from traditional CL applications which often operate outside of web browsers.\n*   **Embedding vs. Server-Side Only:** The term \"embeddable\" suggests that CL code can be integrated into web pages or applications in a way that goes beyond simple server-side processing (e.g., generating HTML).  It might imply executing CL code directly within the browser or having some form of client-side CL functionality.\n*   **Potential Technologies:** The article might cover technologies or techniques that enable this embedding, such as:\n    *   Transpiling CL to JavaScript (or WebAssembly).\n    *   Creating CL-based web frameworks that facilitate embedding components.\n    *   Using CL as a server-side language with tight integration with client-side JavaScript.\n*   **Benefits/Use Cases:**  It could also explore the advantages of using CL in web development (e.g., its expressiveness, powerful macro system, or performance) and potential use cases where embedding CL would be particularly beneficial.\n*   **Limitations/Challenges:** Finally, the article might address the challenges associated with embedding CL in web environments, such as deployment complexities, debugging, or performance considerations.\n\nIn essence, the article probably explores the intersection of Common Lisp and web technologies, specifically focusing on methods and opportunities for embedding CL functionality directly within web applications.\n",
    "chinese_title": "可嵌入网页的通用 Lisp",
    "chinese_summary": "文章“Web Embeddable Common Lisp”可能探讨了在 Web 应用程序中嵌入 Common Lisp (CL) 代码的潜力或实际实现。仅从标题来看，我们可以推断出以下可能方面：\n\n*   **关注 Web 集成：** 核心主题围绕着在 Web 环境中利用 CL。这将其与通常在 Web 浏览器之外运行的传统 CL 应用程序区分开来。\n*   **嵌入 vs. 仅服务器端：** 术语“embeddable”（可嵌入）表明 CL 代码可以集成到网页或应用程序中，其方式超越了简单的服务器端处理（例如，生成 HTML）。 它可能暗示在浏览器中直接执行 CL 代码，或者具有某种形式的客户端 CL 功能。\n*   **潜在技术：** 文章可能涵盖支持这种嵌入的技术或方法，例如：\n    *   将 CL 转译为 JavaScript（或 WebAssembly）。\n    *   创建基于 CL 的 Web 框架，以方便嵌入组件。\n    *   使用 CL 作为服务器端语言，并与客户端 JavaScript 紧密集成。\n*   **优势/用例：** 它还可能探讨在 Web 开发中使用 CL 的优势（例如，其表现力、强大的宏系统或性能）以及嵌入 CL 可能特别有益的潜在用例。\n*   **局限性/挑战：** 最后，文章可能会讨论与在 Web 环境中嵌入 CL 相关的挑战，例如部署复杂性、调试或性能考虑因素。\n\n本质上，该文章可能探讨了 Common Lisp 和 Web 技术的交叉点，特别是侧重于直接在 Web 应用程序中嵌入 CL 功能的方法和机会。"
  },
  {
    "id": "44379173",
    "title": "Iroh: A library to establish direct connection between peers",
    "url": "https://github.com/n0-computer/iroh",
    "summary": "Iroh is a Rust library designed to establish direct peer-to-peer connections, minimizing network reliance. It facilitates connections by public key, finding and maintaining the fastest route, even through NATs using hole-punching techniques, with fallback to public relay servers. Iroh prioritizes speed through continuous connection measurement and is built upon QUIC for authenticated encryption, concurrent streams, and avoidance of head-of-line blocking.\n\nThe library supports composable protocols such as iroh-blobs for content-addressed blob transfer, iroh-gossip for scalable publish-subscribe networks, iroh-docs for a key-value store of blobs, and iroh-willow (under construction).\n\nGetting started involves using the Rust library via `cargo add iroh`. The documentation includes example code demonstrating basic connection and communication. Iroh offers FFI bindings for use in other languages.\n\nThe repository encompasses several crates: `iroh` (core library), `iroh-relay` (relay server), `iroh-base` (common types), `iroh-dns-server` (DNS server for NodeIds), and `iroh-net-report` (network analysis tool). The project is dual-licensed under Apache 2.0 and MIT licenses.\n",
    "chinese_title": "Iroh: 建立对等连接的库",
    "chinese_summary": "Iroh 是一个 Rust 库，旨在建立直接的对等连接，最大限度地减少对网络的依赖。它通过公钥促进连接，寻找并维护最快的路由，即使通过使用打孔技术的 NAT，并回退到公共中继服务器。Iroh 通过持续的连接测量来优先考虑速度，并基于 QUIC 构建，以实现经过身份验证的加密、并发流和避免队头阻塞。\n\n该库支持可组合的协议，例如用于内容寻址的 blob 传输的 iroh-blobs、用于可扩展的发布-订阅网络的 iroh-gossip、用于 blob 的键值存储的 iroh-docs，以及 iroh-willow（正在建设中）。\n\n入门涉及通过 `cargo add iroh` 使用 Rust 库。文档包含示例代码，演示了基本的连接和通信。Iroh 提供了 FFI 绑定，以便在其他语言中使用。\n\n该存储库包含多个 crate：`iroh`（核心库）、`iroh-relay`（中继服务器）、`iroh-base`（通用类型）、`iroh-dns-server`（NodeId 的 DNS 服务器）和 `iroh-net-report`（网络分析工具）。该项目采用 Apache 2.0 和 MIT 双重许可。"
  },
  {
    "id": "44387409",
    "title": "Announcing the Android Workgroup",
    "url": "https://forums.swift.org/t/announcing-the-android-workgroup/80666",
    "summary": "The Swift community is launching the Android Workgroup to officially support Android as a Swift platform. The group aims to establish and maintain Android as an officially supported platform for Swift. To get involved, individuals can review the Android Workgroup charter, participate in discussions on the Android forum, and directly contact the workgroup using the @android-workgroup handle on the forums.\n",
    "chinese_title": "Android工作组成立公告",
    "chinese_summary": "Swift社区启动Android工作组，以正式支持Android作为Swift平台。该工作组旨在建立并维护Android作为Swift的官方支持平台。要参与其中，个人可以查看Android工作组章程，参与Android论坛上的讨论，并使用论坛上的@android-workgroup账号直接联系工作组。"
  },
  {
    "id": "44379191",
    "title": "Interstellar Flight: Perspectives and Patience",
    "url": "https://www.centauri-dreams.org/2025/06/25/interstellar-flight-perspectives-and-patience/",
    "summary": "Paul Gilster's \"Interstellar Flight: Perspectives and Patience\" reflects on the vast distances and time scales involved in interstellar travel, prompted by Coltrane's music and the Parker Solar Probe's achievements. The article juxtaposes human speed records (Apollo 10, Voyager 1, Parker Solar Probe) with the immense gulf separating us from even the nearest star, Proxima Centauri. He notes that at Parker's speed, it would still take 6,600 years to reach Proxima Centauri.\n\nGilster highlights the significance of Voyager 1 reaching one light-day from the Sun in 2027, marking a symbolic milestone. He then places the massive Voyager project (11,000 work-years) in perspective with historical feats like the Great Pyramid construction. The Khufu solar boat further emphasizes humanity's enduring fascination with cosmic journeys.\n\nHe emphasizes the need to recalibrate our perception of time and distance. While acknowledging the challenges, he expresses hope for beamed energy propulsion, like the Breakthrough Starshot concept, potentially enabling flybys to Proxima Centauri within decades. The comments section further delves into the ethical considerations of interstellar exploration, the potential for technological advancements, and the importance of long-term survival.\n",
    "chinese_title": "星际航行：视角与耐心",
    "chinese_summary": "保罗·吉尔斯特的《星际航行：视角与耐心》反思了星际旅行所涉及的巨大距离和时间尺度，这源于科尔特雷恩的音乐和帕克太阳探测器的成就。文章将人类的速度记录（阿波罗10号、旅行者1号、帕克太阳探测器）与我们与最近的恒星比邻星之间存在的巨大鸿沟进行对比。他指出，以帕克探测器的速度，仍然需要6600年才能到达比邻星。\n\n吉尔斯特强调了旅行者1号将于2027年到达距离太阳一个光日的里程碑意义，这是一个象征性的里程碑。然后，他将庞大的旅行者项目（11000个工作年）与历史上诸如大金字塔建造等壮举相提并论。胡夫太阳船进一步强调了人类对宇宙旅程的持久迷恋。\n\n他强调需要重新校准我们对时间和距离的感知。在承认挑战的同时，他表达了对诸如突破摄星等定向能量推进的希望，这可能会在几十年内实现对比邻星的飞掠。评论部分进一步深入探讨了星际探索的伦理考量、技术进步的可能性以及长期生存的重要性。"
  },
  {
    "id": "44381093",
    "title": "Libxml2's \"no security embargoes\" policy",
    "url": "https://lwn.net/SubscriberLink/1025971/73f269ad3695186d/",
    "summary": "This LWN.net article discusses libxml2's new security policy, driven by maintainer Nick Wellnhofer's frustration with the demands of maintaining a widely-used open-source project without adequate support. Wellnhofer announced that libxml2 would no longer honor security embargoes, treating security flaws as regular bugs, made public as soon as they are reported. He cites the unsustainable burden of unpaid work demanded by security researchers and the lack of corporate contribution despite heavy reliance on libxml2 by major companies like Apple, Google, and Microsoft. He also stepped down as maintainer of the related libxslt project.\n\nWellnhofer argues these companies benefit immensely from libxml2's permissive MIT license but fail to adequately support its maintenance, essentially exploiting the goodwill of volunteers. This policy shift aims to encourage contributions and force companies to address their technical debt by either improving libxml2, developing their own solutions, or switching to better alternatives.\n\nThe article also explores the broader issue of corporate behavior in the open-source ecosystem, highlighting a \"regulatory capture of the commons\" where companies exploit open-source resources without contributing back. It introduces the idea of public maintenance terms (MAINTENANCE-TERMS.md) to give maintainers \"psychological safety\" to decline corporate demands. The article suggests Wellnhofer's stance reflects a growing sentiment among open-source maintainers who feel exploited by corporations. Ultimately, the piece argues that the sustainability of open-source depends on addressing the imbalance between corporate benefit and maintainer burden.\n",
    "chinese_title": "Libxml2 的“不设安全封锁”政策",
    "chinese_summary": "LWN.net文章讨论了libxml2新的安全策略，起因是维护者Nick Wellnhofer对维护一个广泛使用的开源项目却缺乏足够支持感到沮丧。Wellnhofer宣布libxml2将不再遵守安全禁运，而是将安全漏洞视为普通bug，一旦报告就会公开。他认为安全研究人员要求的无偿工作负担不可持续，且苹果、谷歌和微软等主要公司严重依赖libxml2，却没有提供相应的企业贡献。他还辞去了相关libxslt项目的维护者职务。\n\nWellnhofer认为这些公司从libxml2宽松的MIT许可证中获益良多，但未能充分支持其维护，实际上是在利用志愿者的善意。这项政策转变旨在鼓励贡献，并迫使公司通过改进libxml2、开发自己的解决方案或切换到更好的替代方案来解决其技术债务。\n\n文章还探讨了开源生态系统中更广泛的企业行为问题，强调了一种“公共领域的监管俘获”，即公司在没有贡献的情况下利用开源资源。它提出了公共维护条款 (MAINTENANCE-TERMS.md) 的概念，以给予维护者“心理安全”，从而拒绝企业的需求。文章表明Wellnhofer的立场反映了开源维护者中日益增长的情绪，他们感到被企业利用。最终，文章认为开源的可持续性取决于解决企业利益和维护者负担之间的不平衡。"
  },
  {
    "id": "44377495",
    "title": "Is Lovable getting monetization wrong?",
    "url": "https://getlago.substack.com/p/lovable-makes-60m-in-6-monthsbut",
    "summary": "Here's a summary of the article \"Is Lovable getting monetization wrong?\" based on the URL provided:\n\nThe article discusses Lovable, a company reportedly generating $60 million in revenue within six months, and questions whether their current monetization strategy is optimal for long-term growth and profitability, particularly in the SaaS space. While the rapid revenue growth is impressive, the author suggests that Lovable might be leaving money on the table by underpricing their product or offering too much value for the price they charge.\n\nThe author argues that Lovable's focus on rapid acquisition and seemingly aggressive pricing might be prioritizing short-term gains over building a sustainable, high-value business. They point out that in SaaS, perceived value and willingness to pay are often linked to features, support, and the overall experience. Undervaluing the product could attract customers who are highly price-sensitive and less likely to be loyal or advocate for the platform.\n\nThe article proposes that Lovable should consider implementing a tiered pricing model with different feature sets to cater to varying customer needs and willingness to pay. This would allow them to capture more value from users who are willing to pay for premium features and dedicated support. The author emphasizes the importance of segmenting customers and aligning pricing with the specific value delivered to each segment. Ultimately, the article suggests that while impressive revenue growth is a positive indicator, Lovable should carefully evaluate its monetization strategy to ensure it aligns with long-term sustainability and profitability.\n",
    "chinese_title": "可爱多是否在盈利模式上出了问题？",
    "chinese_summary": "以下是基于所提供URL的文章《Lovable是否在货币化方面犯了错误？》的摘要：\n\n文章讨论了Lovable公司，据报道该公司在六个月内创造了6000万美元的收入，并质疑他们目前的货币化策略对于长期增长和盈利能力，尤其是在SaaS领域，是否是最优的。尽管收入增长迅速令人印象深刻，但作者认为Lovable可能因为产品定价过低或为他们所收取的费用提供了过多的价值而错失了赚钱的机会。\n\n作者认为，Lovable专注于快速获取客户和看似激进的定价可能更注重短期收益，而不是建立一个可持续的高价值业务。他们指出，在SaaS领域，感知价值和支付意愿通常与功能、支持和整体体验相关。低估产品价值可能会吸引对价格高度敏感的客户，而这些客户不太可能忠诚或支持该平台。\n\n文章建议Lovable考虑实施分层定价模式，提供不同的功能组合，以满足不同的客户需求和支付意愿。这将使他们能够从愿意为高级功能和专门支持付费的用户那里获得更多价值。作者强调了细分客户以及将定价与交付给每个细分市场的特定价值对齐的重要性。最终，文章认为，虽然令人印象深刻的收入增长是一个积极的指标，但Lovable应仔细评估其货币化策略，以确保其与长期可持续性和盈利能力相符。"
  },
  {
    "id": "44381358",
    "title": "Microsoft Dependency Has Risks",
    "url": "https://blog.miloslavhomer.cz/p/microsoft-dependency-has-risks",
    "summary": "Miloslav Homer's article \"Microsoft Dependency Has Risks\" analyzes the potential consequences of over-reliance on Microsoft products, triggered by an incident where Microsoft allegedly blocked an ICC employee's mailbox due to US sanctions. The author explores the likelihood and cost of a Microsoft service cutoff for organizations.\n\nHe argues that the unpredictable nature of US political decisions, particularly regarding sanctions, combined with Microsoft's dependence on US government contracts, makes it probable that MS will comply with sanction requests, potentially disrupting service to affected clients.  He acknowledges that the probability is low but the consequences can be severe.\n\nThe article discusses how companies critically depend on MS for communication, file management, identity management, and backups.  A full outage of these services can be extremely costly, potentially costing millions per day for large enterprises.\n\nHe then attempts to apply a Return on Security Investment (ROSI) model to determine a rational investment level to prevent such a scenario. However, he concludes that the low probability of the event occurring makes it difficult to justify a significant investment, and the lack of reliable data makes accurate modeling impossible.  He states that these ROSI calculations are practically impossible because of the data immaturity in the security field. He highlights the challenge of balancing the benefits of using MS products with the potential risks of dependency, and that without accurate predictions, sound defense is almost impossible to model.\n",
    "chinese_title": "微软依赖有风险",
    "chinese_summary": "米洛斯拉夫·霍默的文章《微软依赖的风险》分析了过度依赖微软产品可能造成的后果。起因是微软据称因美国制裁而封锁了一名国际刑事法院 (ICC) 员工的邮箱。作者探讨了组织机构面临微软服务中断的可能性和成本。\n\n他认为，美国政治决策（尤其是关于制裁的决策）具有不可预测性，加上微软对美国政府合同的依赖，使得微软很可能遵守制裁要求，从而可能中断对受影响客户的服务。他承认这种可能性很低，但后果可能很严重。\n\n文章讨论了公司如何在通信、文件管理、身份管理和备份方面严重依赖微软。这些服务的完全中断可能会造成极其高昂的代价，对于大型企业而言，每天可能损失数百万美元。\n\n然后，他试图应用安全投资回报率 (ROSI) 模型来确定防止这种情况发生的合理投资水平。然而，他得出结论，由于事件发生的可能性较低，因此很难证明进行大量投资是合理的，并且缺乏可靠的数据使得准确建模成为不可能。他表示，由于安全领域的数据不成熟，这些 ROSI 计算实际上是不可能的。他强调了平衡使用微软产品的好处与依赖的潜在风险所面临的挑战，并且如果没有准确的预测，几乎不可能对合理的防御进行建模。"
  },
  {
    "id": "44381144",
    "title": "Games run faster on SteamOS than Windows 11, Ars testing finds",
    "url": "https://arstechnica.com/gaming/2025/06/games-run-faster-on-steamos-than-windows-11-ars-testing-finds/",
    "summary": "Ars Technica tested the gaming performance of SteamOS 3.7 versus Windows 11 on the Lenovo Legion Go S, finding that SteamOS generally delivers higher frame rates in recent games. This marks a significant improvement from the original SteamOS, which performed worse than Windows.\n\nThe testing involved running five high-end 3D games using built-in benchmarks at different graphics settings on both operating systems. While Windows 11 was installed with updated drivers from Lenovo, the article notes the challenges in obtaining truly up-to-date drivers, eventually using unofficial Asus drivers.\n\nThe results showed that SteamOS offered noticeable frame rate improvements in most games tested.  In some cases, the difference between the operating systems could mean the difference between a playable and unplayable frame rate. While Borderlands 3 showed comparable performance, other games demonstrated frame rate drops on Windows of up to 36 percent.\n\nThe improved performance on SteamOS is attributed to Valve's ongoing work on Proton (the translation layer for Windows games) and Linux's Mesa graphics drivers, along with the elimination of unnecessary overhead compared to the general-purpose Windows operating system.\n\nDespite the performance gains, the article acknowledges that some games are incompatible with SteamOS, and its hardware compatibility is still limited. However, the performance advantage, combined with a lower retail price and a more streamlined user interface, strengthens SteamOS as a viable alternative to Windows for gaming handhelds.\n",
    "chinese_title": "Ars测试发现，SteamOS上游戏运行速度比Windows 11快",
    "chinese_summary": "Ars Technica测试联想拯救者Go S上SteamOS 3.7与Windows 11的游戏性能，发现SteamOS通常能在近期游戏中提供更高的帧率。这标志着相对于表现不如Windows的初代SteamOS而言，是一项重大改进。\n\n测试包括在两个操作系统上使用内置基准测试，以不同的图形设置运行五款高端3D游戏。虽然Windows 11安装了联想更新的驱动程序，但文章指出获取真正最新的驱动程序存在挑战，最终使用了非官方的华硕驱动程序。\n\n结果表明，SteamOS在大多数测试游戏中提供了显著的帧率提升。在某些情况下，操作系统之间的差异可能意味着可玩帧率和不可玩帧率之间的差异。虽然《无主之地3》表现出相似的性能，但其他游戏在Windows上的帧率下降高达36%。\n\nSteamOS性能的提升归功于Valve持续致力于Proton（Windows游戏的翻译层）和Linux的Mesa图形驱动程序，以及与通用Windows操作系统相比，消除了不必要的开销。\n\n尽管性能有所提升，但文章承认某些游戏与SteamOS不兼容，其硬件兼容性仍然有限。然而，性能优势、较低的零售价和更精简的用户界面，巩固了SteamOS作为游戏掌机上Windows的可行替代方案的地位。"
  },
  {
    "id": "44353098",
    "title": "RaptorCast: Designing a Messaging Layer",
    "url": "https://www.category.xyz/blogs/raptorcast-designing-a-messaging-layer",
    "summary": "RaptorCast addresses the challenge of efficiently and securely propagating block proposals from a leader to validators in Proof of Stake blockchains. It focuses on performance, security, and robustness, especially in the presence of packet loss and Byzantine actors.\n\nThe design employs UDP for its speed, mitigating inherent reliability issues with an encoding system and packet-level authentication. R10, an implementation of Raptor codes, is chosen for its performance and scalability in forward error correction (FEC), adding redundancy to ensure data recovery despite packet loss. To prevent tampering, each chunk includes a Merkle proof and the leader's signature, verifying the data's integrity and origin.\n\nThe system structures the block proposal into chunks that fit within UDP packets. Each packet contains a Merkle proof, a header (including the leader's signature, version, epoch, timestamp, and block proposal hash), a chunk header, and the data payload. The Merkle tree approach reduces the number of required signatures.\n\nThe broadcast strategy utilizes structured forwarding, where validators re-broadcast specific data portions to predefined peer groups. The redundancy level is determined considering potential packet loss and malicious nodes, ensuring honest validators receive enough encoded packets to reconstruct the original proposal. The R10 encoding system builds on LT codes, enabling the generation of encoded symbols from source chunks. Decoding involves a peeling process, incrementally recovering source chunks from the received encoded symbols.\n",
    "chinese_title": "RaptorCast：消息层设计",
    "chinese_summary": "RaptorCast旨在解决权益证明区块链中区块提议从领导者高效、安全地传播到验证者的问题。它专注于性能、安全性和稳健性，尤其是在存在丢包和拜占庭行为者的情况下。\n\n该设计采用UDP以提高速度，并通过编码系统和数据包级身份验证来缓解固有的可靠性问题。Raptor码的一种实现R10，因其在前向纠错（FEC）中的性能和可扩展性而被选择，增加了冗余以确保在发生丢包时的数据恢复。为了防止篡改，每个数据块都包含一个Merkle证明和领导者的签名，以验证数据的完整性和来源。\n\n该系统将区块提议结构化为适合UDP数据包的数据块。每个数据包包含一个Merkle证明、一个头部（包括领导者的签名、版本、纪元、时间戳和区块提议哈希）、一个数据块头部以及数据有效负载。Merkle树方法减少了所需的签名数量。\n\n广播策略采用结构化转发，其中验证者将特定的数据部分重新广播到预定义的对等组。冗余级别是根据潜在的丢包和恶意节点确定的，以确保诚实的验证者收到足够的编码数据包来重建原始提议。R10编码系统建立在LT码的基础上，能够从源数据块生成编码符号。解码涉及一个剥离过程，从接收到的编码符号中逐步恢复源数据块。"
  },
  {
    "id": "44351912",
    "title": "The symbol of earthly good, and the immediate object of toil",
    "url": "https://crookedtimber.org/2025/06/23/the-symbol-of-earthly-good-and-the-immediate-object-of-toil/",
    "summary": "Hannah Forsyth's article, \"The symbol of earthly good, and the immediate object of toil,\" uses George Eliot's *Silas Marner* as a lens to examine the relationship between work, money, entitlement, and societal values. Inspired by overhearing a child excited about earning stickers, the author explores the idea of money as a symbolic representation of earthly good and the object of toil.\n\nShe draws parallels between Silas Marner's obsession with hoarding gold and the Protestant Ethic, where money becomes a measure of worth and spiritual reward. Forsyth contrasts this with the entitlement of characters like Dunstan, who believes he deserves wealth regardless of effort, highlighting the inherent inequality in societal systems.\n\nThe author connects these themes to contemporary issues, such as the persistence of entitlement based on race, class, and gender. She critiques the idea of a meritocratic system, arguing that it often reinforces existing power structures and rewards those already privileged.\n\nUltimately, Forsyth highlights the transformative power of love, as Silas Marner finds redemption and true value in raising a child instead of pursuing material wealth. She concludes with a note of optimism, suggesting that human connection and purpose can replace the pursuit of money as the ultimate measure of worth.\n",
    "chinese_title": "人间福祉的象征，也是劳作的直接目标",
    "chinese_summary": "Hannah Forsyth的文章《尘世福祉的象征与劳动的直接目标》以乔治·艾略特的《织工马南》为视角，探讨了工作、金钱、权利与社会价值观之间的关系。受到偶然听到一个孩子因获得贴纸而兴奋的启发，作者探索了金钱作为尘世福祉的象征和劳动目标的概念。\n\n她将西拉斯·马南对囤积黄金的痴迷与新教伦理相提并论，在后者中，金钱成为衡量价值和精神回报的标准。Forsyth将此与邓斯坦等认为自己理应获得财富而不论努力的角色形成对比，突显了社会体系中固有的不平等。\n\n作者将这些主题与当代问题联系起来，例如基于种族、阶级和性别的权利持续存在。她批判了精英统治制度的理念，认为它常常强化现有的权力结构，并奖励那些已经享有特权的人。\n\n最终，Forsyth强调了爱的变革力量，西拉斯·马南在抚养孩子而不是追求物质财富中找到了救赎和真正的价值。她以乐观的语调结尾，暗示人与人之间的联系和目标可以取代对金钱的追求，成为衡量价值的最终标准。"
  },
  {
    "id": "44379034",
    "title": "Getting ready to issue IP address certificates",
    "url": "https://community.letsencrypt.org/t/getting-ready-to-issue-ip-address-certificates/238777",
    "summary": "This announcement indicates that Let's Encrypt is nearing the ability to issue SSL/TLS certificates for IP address Subject Alternative Names (SANs) in their production environment. However, the feature is not yet publicly available and will initially be limited to an allowlist-only profile.\n\nKey points:\n\n*   **IP Address SAN Support Coming:** Let's Encrypt is preparing to support issuing certificates where the domain name in the certificate is an IP address.\n*   **Short Validity Period:** Certificates issued with IP address SANs will be under the \"shortlived\" profile, meaning they'll only be valid for 6 days.\n*   **Allowlist Only Initially:** This feature will initially be restricted to an allowlist of approved users. No timeline is given for wider availability, and allowlist requests aren't being accepted yet.\n*   **Testing:** They've provided a sample certificate and a website utilizing it for testing purposes, and are asking for feedback on any issues encountered.\n*   **Bug Discovery:** A bug has already been identified in Firefox's display of IP address SANs.\n",
    "chinese_title": "准备颁发IP地址证书",
    "chinese_summary": "Let's Encrypt即将支持IP地址SAN证书\n\n要点：\n\n*   **即将支持IP地址SAN：** Let's Encrypt正准备支持签发证书，其中证书中的域名为IP地址。\n*   **有效期短：** 带有IP地址SAN的证书将采用“shortlived”配置文件，意味着有效期仅为6天。\n*   **初始仅限白名单：** 此功能最初将限制在批准用户的白名单中。尚未给出更广泛可用性的时间表，且暂不接受白名单申请。\n*   **测试：** 他们提供了一个示例证书和一个使用该证书的网站用于测试，并要求对遇到的任何问题提供反馈。\n*   **发现Bug：** 已经在Firefox的IP地址SAN显示中发现了一个Bug。"
  },
  {
    "id": "44382582",
    "title": "The Hollow Men of Hims",
    "url": "https://www.alexkesin.com/p/the-hollow-men-of-hims",
    "summary": "Alex Kesin's article \"The Hollow Men of Hims\" presents a scathing critique of Hims & Hers Health, accusing the company of being a \"medical grift\" that exploits loopholes and consumer desperation for profit. Kesin argues that Hims & Hers prioritizes profit over patient care by selling overpriced, potentially dangerous products through deceptive marketing and subscription traps.\n\nThe article highlights Hims & Hers' exploitation of FDA compounding exemptions, using them to mass-produce \"personalized\" versions of drugs like semaglutide (for weight loss) sourced from questionable Chinese suppliers. This is exemplified by their short-lived partnership with Novo Nordisk, which ended after Hims continued selling knockoff Wegovy.\n\nKesin also criticizes Hims & Hers' approach to erectile dysfunction, particularly their \"Hard Mints,\" which combine sildenafil and tadalafil, the active ingredients in Viagra and Cialis. This combination, likened to the dangerous \"Rhino\" pills sold at gas stations, is presented as a hazardous shortcut masked by prescription legitimacy.\n\nThe article emphasizes the company's high prices for generic medications, often significantly more expensive than traditional pharmacies, coupled with automated consultations and subscription traps. Customers are often locked into long-term commitments, charged without warning, and struggle to obtain refunds, all while receiving minimal medical oversight. Kesin concludes that Hims & Hers exemplifies regulatory arbitrage, prioritizing profit through convenience at the expense of genuine healthcare and patient well-being.\n",
    "chinese_title": "希姆斯空心人",
    "chinese_summary": "亚历克斯·凯辛的文章《Hims的空心人》严厉批评了Hims & Hers Health公司，指责该公司是一个利用漏洞和消费者绝望心理牟利的“医疗骗局”。凯辛认为，Hims & Hers通过欺骗性营销和订阅陷阱销售价格过高、可能存在危险的产品，将利润置于患者护理之上。\n\n文章强调了Hims & Hers对FDA复配豁免条款的利用，用其大量生产“个性化”药物，例如从可疑的中国供应商处采购的司美格鲁肽（用于减肥）。他们与诺和诺德短暂的合作就证明了这一点，Hims在诺和诺德终止合作后仍继续销售仿冒Wegovy。\n\n凯辛还批评了Hims & Hers治疗勃起功能障碍的方法，特别是他们的“硬糖”，其中混合了西地那非和他达拉非，即伟哥和希爱力的活性成分。这种组合被比作加油站出售的危险“犀牛”药丸，被视为一种隐藏在处方合法性下的危险捷径。\n\n文章强调，该公司仿制药的价格很高，通常比传统药房贵得多，再加上自动化咨询和订阅陷阱。客户经常被锁定在长期承诺中，在没有警告的情况下被收费，并且难以获得退款，同时接受的医疗监督极少。凯辛总结说，Hims & Hers体现了监管套利，以牺牲真正的医疗保健和患者福祉为代价，通过便利性来优先考虑利润。"
  },
  {
    "id": "44382073",
    "title": "CUDA Ray Tracing 2x Faster Than RTX: My CUDA Ray Tracing Journey",
    "url": "https://karimsayedre.github.io/RTIOW.html",
    "summary": "This article chronicles the author's journey of creating a high-performance CUDA-based ray tracer that surprisingly outperforms a Vulkan/RTX implementation (RayTracingInVulkan) on the same hardware, achieving a 2x speedup after correcting a comparison oversight. The key takeaway is that, in certain synthetic scenarios with minimal shading and procedural geometry (spheres), CUDA's compute-centric approach can be faster than relying on dedicated RTX hardware cores for BVH traversal.\n\nThe author emphasizes the importance of understanding low-level GPU architecture and leveraging CUDA's capabilities for optimization. They highlight specific pitfalls like recursion, which causes register pressure and memory spills, and the need to avoid virtual calls and dynamic polymorphism.\n\nKey optimizations included:\n\n*   **Adopting a header-only design:** Enabled aggressive inlining of device functions, significantly reducing register spilling and boosting performance.\n*   **Replacing recursion with an explicit stack:** Improved register control, limited stack depth, and avoided unnecessary memory spills.\n*   **Strategic inlining:** carefully choose to inline smaller functions and leave larger functions that can be called multiple times and save compile time, not inlined.\n\nThe article underscores the importance of managing register pressure in CUDA and thinking like a GPU to achieve optimal performance. The author concludes that CUDA provides the tools for creating extremely fast graphics, but developers need to understand how GPUs work.\n",
    "chinese_title": "CUDA光线追踪速度是RTX的两倍：我的CUDA光线追踪之旅",
    "chinese_summary": "本文记录了作者创建一个高性能CUDA光线追踪器的历程，该追踪器在同一硬件上出人意料地超越了Vulkan/RTX实现 (RayTracingInVulkan)，在纠正了一个对比疏忽后，速度提高了2倍。主要结论是，在某些具有最小着色和程序几何图形（球体）的合成场景中，CUDA以计算为中心的方法可能比依赖专用RTX硬件核心进行BVH遍历更快。\n\n作者强调了理解底层GPU架构和利用CUDA优化能力的重要性。他们重点指出了诸如递归之类的陷阱，这些陷阱会导致寄存器压力和内存溢出，以及避免虚函数调用和动态多态的必要性。\n\n关键优化包括：\n\n*   **采用仅头文件设计：** 实现了设备函数的主动内联，显著减少了寄存器溢出并提高了性能。\n*   **用显式栈替换递归：** 改善了寄存器控制，限制了栈深度，并避免了不必要的内存溢出。\n*   **策略性内联：** 谨慎选择内联较小的函数，并保留可以多次调用并节省编译时间的大型函数，不进行内联。\n\n本文强调了在CUDA中管理寄存器压力和像GPU一样思考以实现最佳性能的重要性。作者总结说，CUDA提供了创建极速图形的工具，但开发者需要了解GPU的工作原理。"
  },
  {
    "id": "44360038",
    "title": "'Sticky thinking' hampers decisions in depression",
    "url": "https://www.bps.org.uk/research-digest/sticky-thinking-hampers-decisions-depression",
    "summary": "A recent study published in the journal *Emotion* (Yang & van Vugt, 2025) explores the link between 'sticky thinking' (difficulty disengaging from thoughts) and impaired decision-making in individuals prone to depression and worry. The researchers found that rumination, particularly 'sticky thinking,' can hinder the ability to weigh options effectively when making decisions.\n\nThe study involved participants completing questionnaires to assess depressive symptoms and the 'stickiness' of their thinking. A subset then wrote about negative experiences to induce rumination, after which their brain activity was monitored using EEG while they performed a cognitive task. Participants who reported more sticky thinking made more errors and took longer to respond. EEG data revealed that sticky thinking correlated with increased alpha wave activity, indicative of an unfocused mental state.\n\nThe researchers concluded that 'sticky thinking' could explain decision-making impairments in individuals vulnerable to depression and worry. However, a limitation of the study is that a disproportionate number of women were in the high \"sticky thinking\" group, suggesting a possible gender effect that warrants further investigation. The findings support the idea that addressing rumination and promoting flexible thinking might improve decision-making abilities in individuals with depressive tendencies.\n",
    "chinese_title": "“僵化思维”阻碍抑郁症患者的决策",
    "chinese_summary": "最近发表在《情绪》(Emotion)期刊上的一项研究（Yang & van Vugt, 2025）探讨了“思维固着”（难以摆脱某种想法）与易患抑郁症和焦虑症的个体决策能力受损之间的联系。研究人员发现，反刍思维，特别是“思维固着”，会妨碍做出决策时有效权衡各种选择的能力。\n\n该研究让参与者填写问卷，以评估抑郁症状和他们思维的“固着性”。随后，一部分参与者撰写了关于负面经历的文章以诱发反刍思维，之后，在使用脑电图监测他们大脑活动的同时，他们完成了一项认知任务。报告思维越固着的参与者犯的错误越多，反应时间也越长。脑电图数据显示，思维固着与阿尔法波活动增加相关，表明一种注意力不集中的精神状态。\n\n研究人员得出结论，“思维固着”可以解释易患抑郁症和焦虑症的个体决策能力受损的原因。然而，该研究的一个局限性是，在高“思维固着”组中，女性人数不成比例，这表明可能存在性别影响，值得进一步调查。研究结果支持这样一种观点，即解决反刍思维并促进灵活思维可能改善有抑郁倾向的个体的决策能力。"
  },
  {
    "id": "44376362",
    "title": "Third places and neighborhood entrepreneurship (2024)",
    "url": "https://www.nber.org/papers/w32604",
    "summary": "This working paper by Choi, Guzman, and Small (NBER, June 2024, revised October 2024) investigates the impact of \"third places,\" specifically Starbucks cafés, on neighborhood entrepreneurship in the United States. The study finds that the introduction of Starbucks into neighborhoods without existing coffee shops leads to a significant increase in startup activity.\n\nComparing census tracts that received a Starbucks to those scheduled but didn't, the researchers observed a 9.1% to 18% (or 2.9 to 5.7 firms) increase in the number of startups per year over a 7-year period. The impact was even more pronounced in underprivileged neighborhoods targeted by a Starbucks-Magic Johnson partnership.\n\nThe authors suggest that this effect is driven by a \"networks mechanism,\" implying that Starbucks cafés facilitate the development and utilization of social and professional connections crucial for entrepreneurial success. The research was supported by the Columbia Tamer Institute for Social Enterprise and data from the Startup Cartography Project (partially funded by the Kauffman Foundation). The authors acknowledge helpful feedback from various academics and institutions.\n",
    "chinese_title": "第三空间与社区创业 (2024)",
    "chinese_summary": "Choi、Guzman和Small撰写的工作论文（NBER，2024年6月，2024年10月修订）调查了“第三空间”，特别是星巴克咖啡馆，对美国社区创业的影响。该研究发现，在没有现有咖啡店的社区引入星巴克会导致创业活动的显著增加。\n\n通过比较开设了星巴克的普查区和计划开设但未开设的普查区，研究人员观察到，在7年期间，每年新创企业数量增加了9.1%至18%（即2.9至5.7家企业）。在星巴克-魔术师约翰逊合作项目所针对的弱势社区，这种影响更为显著。\n\n作者认为，这种效应是由“网络机制”驱动的，这意味着星巴克咖啡馆促进了对创业成功至关重要的社会和专业关系的发展和利用。该研究得到了哥伦比亚Tamer社会企业研究所的支持，并使用了来自创业制图项目（Startup Cartography Project，部分由考夫曼基金会资助）的数据。作者感谢多位学者和机构提供的有益反馈。"
  },
  {
    "id": "44338182",
    "title": "Bill Atkinson: Polaroids Showing the Evolution of the Lisa GUI [video]",
    "url": "https://www.youtube.com/watch?v=Qg0mHFcB510",
    "summary": "The described article is a YouTube video titled \"Bill Atkinson: Polaroids Showing the Evolution of the Lisa GUI\". The content listed beneath is standard YouTube boilerplate text relating to copyright, contact information, advertising, developer information, terms of service, privacy policy, safety, and general information about how YouTube works.\n\nTherefore, the key information is:\n\n*   The article is a video on YouTube.\n*   The video features Bill Atkinson.\n*   The video topic is about the evolution of the Lisa GUI (Graphical User Interface).\n*   The video uses Polaroids as a medium to illustrate this evolution.\n\nThe video likely presents a visual walkthrough, using Polaroids taken during the development process, to show how the Lisa GUI changed and improved over time. It might contain insights from Bill Atkinson, a key figure in the Lisa project, about design decisions and the challenges faced.\n",
    "chinese_title": "比尔·阿特金森：宝丽来照片展示Lisa GUI的演变 [视频]",
    "chinese_summary": "所述文章是一部YouTube视频，标题为“Bill Atkinson：展示Lisa GUI演变的宝丽来照片”。下方列出的内容是标准的YouTube样板文字，涉及版权、联系方式、广告、开发者信息、服务条款、隐私政策、安全以及关于YouTube运作方式的常规信息。\n\n因此，关键信息是：\n\n*   该文章是一部YouTube视频。\n*   该视频以Bill Atkinson为主角。\n*   该视频的主题是关于Lisa GUI（图形用户界面）的演变。\n*   该视频使用宝丽来照片作为媒介来展示这种演变。\n\n该视频很可能通过展示开发过程中拍摄的宝丽来照片，直观地展示Lisa GUI如何随着时间的推移而变化和改进。它可能包含Lisa项目中的关键人物Bill Atkinson关于设计决策和所面临挑战的见解。"
  },
  {
    "id": "44382813",
    "title": "I made a history timeline to learn what events happened around the same time",
    "url": "https://seanhollen.com/1300-2000/",
    "summary": "The article describes an interactive history timeline spanning from 1300 AD to 2000 AD. Its purpose is to visualize historical events and allow users to explore what events happened concurrently during different periods. The timeline functions as a learning tool, enabling users to understand the interconnectedness of historical occurrences and gain a broader perspective on specific eras. By visualizing events side-by-side, the timeline allows users to see relationships and patterns that might be missed when studying events in isolation. Essentially, it offers a dynamic and engaging way to learn history by contextualizing events within their broader historical setting.\n",
    "chinese_title": "我做了一个历史时间轴，用来了解同时期发生的事件。",
    "chinese_summary": "本文描述了一个互动式历史时间轴，其时间跨度从公元1300年至2000年。其目的是可视化历史事件，并允许用户探索不同时期同时发生的事件。该时间轴作为一个学习工具，使用户能够理解历史事件的相互关联性，并获得对特定时代的更广阔视角。通过并排显示事件，该时间轴使用户能够看到在孤立地研究事件时可能错过的关系和模式。本质上，它提供了一种动态且引人入胜的方式来学习历史，方法是将事件置于更广阔的历史背景中。"
  },
  {
    "id": "44353241",
    "title": "LLM Hallucinations in Practical Code Generation",
    "url": "https://dl.acm.org/doi/10.1145/3728894",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "实用代码生成中的LLM幻觉",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44377274",
    "title": "Deep Down the Rabbit Hole: Bash, OverlayFS, and a 30-Year-Old Surprise",
    "url": "https://sigma-star.at/blog/2025/06/deep-down-the-rabbit-hole-bash-overlayfs-and-a-30-year-old-surprise/",
    "summary": "This blog post details a complex debugging journey involving Bash, OverlayFS, and a 30-year-old coding oversight. The initial problem was `scp` failing with \"Inappropriate ioctl for device\" after a customer switched to OverlayFS. The error, it turned out, stemmed from Bash's inability to determine the current working directory.\n\nThe investigation revealed that due to a misconfigured cross-compilation environment, Bash was using its own ancient `getcwd()` implementation instead of the glibc version. This fallback was intended for systems lacking the `getcwd()` system call, but the cross-compilation caused the build process to incorrectly define `GETCWD_BROKEN`, triggering its use.\n\nThe fallback `getcwd()` relied on comparing inode numbers obtained from `stat(\".\")` and `readdir(\"..\")` to reconstruct the path. OverlayFS, particularly on 32-bit systems, doesn't guarantee that these inode numbers match, breaking Bash's assumption. OverlayFS prioritizes fast directory listings, and only stat() provides fully stable inodes.\n\nFurthermore, the investigation exposed a decades-old bug in Bash's `getcwd()` implementation. It failed to properly check `errno` after calling `readdir()`, leading to incorrect error reporting, sometimes resulting in the misleading ENOTTY error.\n\nThe issue was resolved by explicitly setting `bash_cv_getcwd_malloc=yes` during the build process, forcing Bash to use the glibc version of `getcwd()`. The investigation highlighted the complexities of portability, legacy code, and filesystem interactions, especially in the context of OverlayFS and 32-bit systems.\n",
    "chinese_title": "深入兔子洞：Bash、OverlayFS 和一个 30 年的惊喜",
    "chinese_summary": "Bash、OverlayFS 与 30 年前的代码疏忽：一次复杂的调试之旅\n\n该博文详细描述了一次复杂的调试过程，涉及 Bash、OverlayFS 和一个 30 年前的代码疏忽。起初，客户切换到 OverlayFS 后，`scp` 命令失败，并显示“不适合设备的 ioctl”错误。最终发现，该错误源于 Bash 无法确定当前工作目录。\n\n调查显示，由于交叉编译环境配置错误，Bash 使用了自身古老的 `getcwd()` 实现，而非 glibc 版本。这种回退机制原本是为了缺少 `getcwd()` 系统调用的系统而设计的，但交叉编译导致构建过程错误地定义了 `GETCWD_BROKEN`，从而触发了它的使用。\n\n回退的 `getcwd()` 依赖于比较从 `stat(\".\")` 和 `readdir(\"..\")` 获取的 inode 号码来重建路径。OverlayFS，尤其是在 32 位系统上，无法保证这些 inode 号码匹配，从而打破了 Bash 的假设。OverlayFS 优先考虑快速目录列表，只有 stat() 提供完全稳定的 inode。\n\n此外，调查还暴露了 Bash 的 `getcwd()` 实现中一个存在了几十年的 bug。它在调用 `readdir()` 后未能正确检查 `errno`，导致错误的错误报告，有时会导致误导性的 ENOTTY 错误。\n\n通过在构建过程中显式设置 `bash_cv_getcwd_malloc=yes`，强制 Bash 使用 glibc 版本的 `getcwd()`，问题得以解决。本次调查突出了可移植性、遗留代码和文件系统交互的复杂性，尤其是在 OverlayFS 和 32 位系统上下文中。"
  },
  {
    "id": "44386329",
    "title": "Blender 5.0 Introducing HDR Support on Linux with Vulkan and Wayland",
    "url": "https://www.phoronix.com/news/Blender-5.0-HDR-Linux-Wayland",
    "summary": "Blender 5.0 will introduce experimental HDR (High Dynamic Range) display support on Linux, specifically when using Wayland and Vulkan graphics acceleration. This feature is currently limited to Wayland desktops, with no X11 support planned.\n\nThe HDR implementation is considered experimental due to limited testing so far. Enabling it requires an HDR display, a Wayland desktop environment, Vulkan API acceleration, and enabling the experimental feature within Blender 5.0.\n\nInitial tests with the Blender 5.0 alpha build on Ubuntu Linux, using Samsung Odyssey OLED G8 G81SF and ASUS ROG Swift OLED PG27UCDM displays, have shown promising results.\n\nUsers interested in testing this feature are encouraged to provide feedback on the Blender DevTalk thread, helping to determine whether the HDR support will be promoted beyond the experimental stage for the final Blender 5.0 release.\n",
    "chinese_title": "Blender 5.0：引入Vulkan和Wayland对Linux的HDR支持",
    "chinese_summary": "Blender 5.0 将在 Linux 上引入实验性 HDR (高动态范围) 显示支持，特别是在使用 Wayland 和 Vulkan 图形加速时。此功能目前仅限于 Wayland 桌面，暂无计划支持 X11。\n\n由于目前测试有限，HDR 实现被认为是实验性的。启用它需要 HDR 显示器、Wayland 桌面环境、Vulkan API 加速，以及在 Blender 5.0 中启用实验性功能。\n\n在 Ubuntu Linux 上使用 Blender 5.0 alpha 版本，搭配 Samsung Odyssey OLED G8 G81SF 和 ASUS ROG Swift OLED PG27UCDM 显示器的初步测试显示出令人满意的结果。\n\n我们鼓励有兴趣测试此功能的用户在 Blender DevTalk 论坛上提供反馈，以帮助确定 HDR 支持是否会在最终的 Blender 5.0 版本中超出实验阶段。"
  },
  {
    "id": "44386021",
    "title": "A Few Thoughts on Extraterrestrial Intelligence",
    "url": "https://www.rxjourney.net/a-few-thoughts-on-extraterrestrial-intelligence",
    "summary": "This article, titled \"A Few Thoughts on Extraterrestrial Intelligence,\" explores the intriguing possibility of alien life and the potential implications of such a discovery. The author uses the analogy of a 10th-century human encountering modern technology to illustrate how an advanced alien civilization might be perceived as god-like. He highlights the quote, \"Any sufficiently advanced civilization is indistinguishable from magic.\"\n\nThe article challenges common portrayals of aliens in science fiction, arguing that extraterrestrial life forms are unlikely to resemble humans due to vastly different evolutionary pressures on other planets. It cites examples of specialized adaptations in Earth's own diverse ecosystems, like deep-sea organisms and bats, to illustrate how environmental factors shape biology.\n\nThe author also raises a cautionary point about the potential for conflict in human-alien encounters, drawing parallels with historical instances of technologically advanced humans exploiting less advanced populations. This leads to a contemplation of the potential dangers of contact.\n\nThe article concludes with Arthur C. Clarke's quote, \"Two possibilities exist: either we are alone in the Universe or we are not. Both are equally terrifying,\" encapsulating the profound and unsettling nature of the question of extraterrestrial intelligence. The author invites readers to donate to support future content creation.\n",
    "chinese_title": "关于外星智能的一些思考",
    "chinese_summary": "关于地外文明的一些思考\n\n本文题为《关于地外文明的一些思考》，探讨了外星生命这种引人入胜的可能性，以及这种发现可能带来的潜在影响。作者用 10 世纪人类遇到现代科技的类比，来说明一个高度发达的外星文明可能被视为神一般。他强调了这句话：“任何足够先进的文明都与魔法无异。”\n\n文章挑战了科幻作品中对外星人的常见描述，认为由于其他星球上存在着截然不同的进化压力，外星生命形式不太可能与人类相似。文章引用了地球自身多样化生态系统中的专业适应性案例，例如深海生物和蝙蝠，来说明环境因素如何塑造生物学。\n\n作者还提出了关于人类与外星人相遇时潜在冲突的警示，并与技术先进的人类剥削技术落后人群的历史实例进行类比。这引出了对接触潜在危险的思考。\n\n文章以亚瑟·克拉克的名言“存在两种可能性：要么我们是宇宙中唯一的生命，要么不是。两种可能性都同样可怕”作为结尾，概括了地外文明问题深刻而不稳定的本质。作者邀请读者捐款以支持未来的内容创作。"
  },
  {
    "id": "44387007",
    "title": "Reflecting JSON into C++ Objects",
    "url": "https://brevzin.github.io/c++/2025/06/26/json-reflection/",
    "summary": "This article explains how to use C++26 reflection features to convert a JSON file into a C++ object at compile time.  The author walks through the process of building a `json_to_object` function, which, given a JSON file, generates a C++ struct with fields corresponding to the JSON keys and values.\n\nThe explanation starts with a simplified scenario: parsing a JSON object with a single key and an integer value.  The steps include: reflecting data member specifications (`data_member_spec`), using `define_aggregate` to create a struct type, and using `substitute` to specialize template types.\n\nThe article then expands the solution to handle multiple key/value pairs, storing members and initializers in vectors. Finally, it tackles the general JSON object parsing, addressing different value types (numbers, strings, and nested objects) using recursion. Special attention is given to handling string literals by utilizing `std::meta::reflect_constant_string`.\n\nThe article relies on hypothetical `constexpr` support for Boost.JSON to illustrate the JSON parsing logic. The final code leverages C++26 reflection to create a type provider-like functionality, enabling the conversion of JSON data directly into C++ objects at compile time. UDLs are also shown for using the reflection with string literals.\n",
    "chinese_title": "将 JSON 反射到 C++ 对象",
    "chinese_summary": "本文阐述了如何利用 C++26 的反射特性在编译时将 JSON 文件转换为 C++ 对象。作者逐步讲解了构建 `json_to_object` 函数的过程，该函数接收一个 JSON 文件，并生成一个 C++ 结构体，其字段对应于 JSON 的键和值。\n\n解释从一个简化的场景开始：解析一个具有单个键和一个整数值的 JSON 对象。步骤包括：反射数据成员规范 (`data_member_spec`)，使用 `define_aggregate` 创建一个结构体类型，以及使用 `substitute` 来特化模板类型。\n\n然后，本文扩展了解决方案以处理多个键/值对，将成员和初始化器存储在向量中。最后，它解决了通用的 JSON 对象解析问题，使用递归处理不同的值类型（数字、字符串和嵌套对象）。特别关注了使用 `std::meta::reflect_constant_string` 处理字符串字面量。\n\n本文依赖于 Boost.JSON 的假设性 `constexpr` 支持来说明 JSON 解析逻辑。最终代码利用 C++26 反射来创建类似类型提供程序的功能，从而能够在编译时将 JSON 数据直接转换为 C++ 对象。文章还展示了使用 UDLs 将反射与字符串字面量结合使用的方法。"
  },
  {
    "id": "44381639",
    "title": "Anthropic wins fair use victory for AI – but still in trouble for stealing books",
    "url": "https://simonwillison.net/2025/Jun/24/anthropic-training/",
    "summary": "In a significant legal development for the AI industry, Anthropic secured a partial victory in a lawsuit concerning copyright infringement. Judge William Alsup issued a summary judgement finding that Anthropic's practice of purchasing and scanning millions of print books for AI training falls under \"fair use\" because the scanned versions were transformative and not distributed externally.\n\nHowever, the judgement also highlighted Anthropic's earlier practice of downloading millions of unauthorized ebooks from sources like Books3, LibGen, and PiLiMi to build their initial \"research library.\" The judge ruled that this use of pirated material did not constitute fair use, setting the stage for a jury trial to determine the consequences.\n\nThe core debate revolved around whether training Large Language Models (LLMs) on unlicensed data qualifies as \"fair use.\" The judge sided with Anthropic on this point, arguing that the process of reading and learning from texts, even copyrighted ones, is fundamental to creating new works, and imposing restrictions would be \"unthinkable.\" This aspect of the ruling establishes an important precedent for the AI industry's reliance on training data.\n\nThe article also notes that Anthropic transitioned to purchasing and scanning books to avoid legal issues, hiring an ex-Google book-scanning expert to acquire \"all the books in the world.\" The judge, William Alsup, is described as an interesting character with programming experience, known for his active engagement in tech-related legal cases.\n",
    "chinese_title": "Anthropic 在 AI 合理使用方面获胜，但盗窃书籍一事仍陷困境",
    "chinese_summary": "在人工智能行业的一项重要法律进展中，Anthropic在版权侵权诉讼中取得部分胜利。法官威廉·阿尔苏普发布了一项简易判决，认为Anthropic购买和扫描数百万本印刷书籍用于人工智能训练的做法属于“合理使用”，因为扫描版本具有转化性，且未对外分发。\n\n然而，该判决也强调了Anthropic早期从Books3、LibGen和PiLiMi等来源下载数百万未经授权的电子书以构建其最初“研究图书馆”的做法。法官裁定，这种使用盗版材料的行为不构成合理使用，为确定后果的陪审团审判奠定了基础。\n\n核心辩论围绕着在未经许可的数据上训练大型语言模型（LLMs）是否符合“合理使用”。法官在这一点上支持Anthropic，认为阅读和学习文本（即使是有版权的文本）是创作新作品的基础，施加限制将是“不可想象的”。该裁决的这一方面为人工智能行业对训练数据的依赖性树立了重要的先例。\n\n文章还指出，Anthropic已转变为购买和扫描书籍以避免法律问题，并聘请了一位前谷歌图书扫描专家来获取“世界上所有的书籍”。法官威廉·阿尔苏普被描述为一个有趣的人物，具有编程经验，以积极参与与科技相关的法律案件而闻名。"
  },
  {
    "id": "44343293",
    "title": "The probability of a hash collision (2022)",
    "url": "https://kevingal.com/blog/collisions.html",
    "summary": "This article explores the probability of hash collisions, a phenomenon where a hash function assigns the same value to different inputs. The author uses the \"birthday problem\" as an analogy, highlighting that the probability of a collision increases surprisingly quickly as more items are hashed.\n\nThe article presents four methods for calculating this probability: the exact calculation, which is computationally expensive for large datasets, and three approximations. The first approximation, derived using the fact that 1-x ≈ e^-x for small x, offers a significant speedup with good accuracy, especially for large N (number of possible hash values). Further approximations are derived, simplifying the formula to k(k-1)/2N and then to k^2/2N, where k is the number of items being hashed.\n\nA comparison of the approximations reveals that the exponential approximation is the most robust, while the simpler ones are only reliable for smaller values of k. The author provides proofs in the appendix to justify the validity of the approximations. Finally, the article suggests using a hash collision calculator and emphasizes the importance of minimizing collision probability in applications such as databases and data storage.\n",
    "chinese_title": "哈希碰撞的概率 (2022)",
    "chinese_summary": "本文探讨了哈希冲突的概率，即哈希函数将相同的值分配给不同的输入的情况。作者用“生日悖论”作比喻，强调随着哈希项目数量的增加，冲突概率会以惊人的速度增长。\n\n文章提出了四种计算该概率的方法：精确计算，它对于大型数据集而言计算量很大，以及三种近似方法。第一种近似方法，利用1-x ≈ e^-x （当x很小时）推导得出，在保证良好准确性的前提下，显著提高了速度，尤其是在N（可能的哈希值的数量）很大的情况下。文章进一步推导了近似公式，将其简化为k(k-1)/2N，然后简化为k^2/2N，其中k是被哈希项目的数量。\n\n对这些近似方法的比较表明，指数近似法是最稳健的，而更简单的近似方法仅在较小的k值下可靠。作者在附录中提供了证明，以证明这些近似方法的有效性。最后，文章建议使用哈希冲突计算器，并强调了在数据库和数据存储等应用中最小化冲突概率的重要性。"
  },
  {
    "id": "44330585",
    "title": "How Cloudflare blocked a monumental 7.3 Tbps DDoS attack",
    "url": "https://blog.cloudflare.com/defending-the-internet-how-cloudflare-blocked-a-monumental-7-3-tbps-ddos/",
    "summary": "In mid-May 2025, Cloudflare successfully blocked a record-breaking 7.3 Tbps DDoS attack targeting a hosting provider using Magic Transit. This massive attack, delivered 37.4 terabytes of data in just 45 seconds, originating from over 122,000 IP addresses across 161 countries. The attack primarily utilized UDP floods, but also included QOTD, Echo, NTP, Mirai UDP, Portmap, and RIPv1 reflection and amplification attacks.\n\nCloudflare's globally distributed network, leveraging Anycast, routed attack traffic to the closest data centers (477 data centers across 293 locations), mitigating it near the botnet source. The company's autonomous DDoS detection and mitigation systems, powered by the \"dosd\" heuristic engine, analyze packet samples in real-time to identify suspicious patterns and generate fingerprints for mitigation. These fingerprints are then compiled into eBPF programs to drop malicious packets.\n\nCloudflare also shares real-time threat intelligence (fingerprint permutations) across servers within data centers and globally, improving mitigation effectiveness. The company offers a free DDoS Botnet Threat Feed for Service Providers to identify and address abusive accounts launching these attacks. The successful mitigation of this massive attack demonstrates the effectiveness of Cloudflare's DDoS protection systems, aligning with their mission to provide free, unmetered DDoS protection and build a better internet.\n",
    "chinese_title": "How Cloudflare blocked a monumental 7.3 Tbps DDoS attack",
    "chinese_summary": "In mid-May 2025, Cloudflare successfully blocked a record-breaking 7.3 Tbps DDoS attack targeting a hosting provider using Magic Transit. This massive attack, delivered 37.4 terabytes of data in just 45 seconds, originating from over 122,000 IP addresses across 161 countries. The attack primarily utilized UDP floods, but also included QOTD, Echo, NTP, Mirai UDP, Portmap, and RIPv1 reflection and amplification attacks.\n\nCloudflare's globally distributed network, leveraging Anycast, routed attack traffic to the closest data centers (477 data centers across 293 locations), mitigating it near the botnet source. The company's autonomous DDoS detection and mitigation systems, powered by the \"dosd\" heuristic engine, analyze packet samples in real-time to identify suspicious patterns and generate fingerprints for mitigation. These fingerprints are then compiled into eBPF programs to drop malicious packets.\n\nCloudflare also shares real-time threat intelligence (fingerprint permutations) across servers within data centers and globally, improving mitigation effectiveness. The company offers a free DDoS Botnet Threat Feed for Service Providers to identify and address abusive accounts launching these attacks. The successful mitigation of this massive attack demonstrates the effectiveness of Cloudflare's DDoS protection systems, aligning with their mission to provide free, unmetered DDoS protection and build a better internet.\n"
  },
  {
    "id": "44374574",
    "title": "Reading NFC Passport Chips in Linux",
    "url": "https://shkspr.mobi/blog/2025/06/reading-nfc-passport-chips-in-linux/",
    "summary": "生成摘要时出错",
    "chinese_title": "Reading NFC Passport Chips in Linux",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44379688",
    "title": "DeepSpeech Is Discontinued (2020)",
    "url": "https://github.com/mozilla/DeepSpeech",
    "summary": "生成摘要时出错",
    "chinese_title": "DeepSpeech Is Discontinued (2020)",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44372424",
    "title": "Thnickels",
    "url": "https://thick-coins.net/?_bhlid=8a5736885893b7837e681aa73f890b9805a4673e",
    "summary": "生成摘要时出错",
    "chinese_title": "Thnickels",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44354643",
    "title": "Build a Sentence-Level Text-to-Speech Reader in JavaScript",
    "url": "https://jsdev.space/tts-sentence-reader/",
    "summary": "生成摘要时出错",
    "chinese_title": "Build a Sentence-Level Text-to-Speech Reader in JavaScript",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44367084",
    "title": "Writing toy software is a joy",
    "url": "https://blog.jsbarretto.com/post/software-is-joy",
    "summary": "生成摘要时出错",
    "chinese_title": "Writing toy software is a joy",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44377666",
    "title": "How to Write Compelling Release Announcements",
    "url": "https://refactoringenglish.com/chapters/release-announcements/",
    "summary": "生成摘要时出错",
    "chinese_title": "How to Write Compelling Release Announcements",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44385086",
    "title": "The Unbearable Anger of Broken Audio",
    "url": "https://arunraghavan.net/2025/06/the-unbearable-anger-of-broken-audio/",
    "summary": "生成摘要时出错",
    "chinese_title": "The Unbearable Anger of Broken Audio",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44384619",
    "title": "Gemini Users: We're Going to Look at Your Texts Whether You Like It or Not",
    "url": "https://gizmodo.com/google-to-gemini-users-were-going-to-look-at-your-texts-whether-you-like-it-or-not-2000620141",
    "summary": "生成摘要时出错",
    "chinese_title": "Gemini Users: We're Going to Look at Your Texts Whether You Like It or Not",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44372528",
    "title": "Managing time when time doesn't exist",
    "url": "https://multiverseemployeehandbook.com/blog/temporal-resources-managing-time-when-time-doesnt-exist/",
    "summary": "生成摘要时出错",
    "chinese_title": "Managing time when time doesn't exist",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44369388",
    "title": "Fun with uv and PEP 723",
    "url": "https://www.cottongeeks.com/articles/2025-06-24-fun-with-uv-and-pep-723",
    "summary": "生成摘要时出错",
    "chinese_title": "Fun with uv and PEP 723",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44376353",
    "title": "Introducing Qodo Gen CLI: Build and Run Coding Agents Anywhere in the SDLC",
    "url": "https://www.qodo.ai/blog/introducing-qodo-gen-cli-build-run-and-automate-agents-anywhere-in-your-sdlc/",
    "summary": "生成摘要时出错",
    "chinese_title": "Introducing Qodo Gen CLI: Build and Run Coding Agents Anywhere in the SDLC",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44370426",
    "title": "How to Think About Time in Programming",
    "url": "https://shanrauf.com/archive/how-to-think-about-time-in-programming",
    "summary": "生成摘要时出错",
    "chinese_title": "How to Think About Time in Programming",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44364406",
    "title": "Switching Pip to Uv in a Dockerized Flask / Django App",
    "url": "https://nickjanetakis.com/blog/switching-pip-to-uv-in-a-dockerized-flask-or-django-app",
    "summary": "生成摘要时出错",
    "chinese_title": "Switching Pip to Uv in a Dockerized Flask / Django App",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44353383",
    "title": "Thoughts on Asunción, Paraguay",
    "url": "https://cpsi.media/p/thoughts-on-asuncion-paraguay",
    "summary": "生成摘要时出错",
    "chinese_title": "Thoughts on Asunción, Paraguay",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44382105",
    "title": "Restmail – sendmail-compatible CLI for Gmail and outlook",
    "url": "https://github.com/tonymet/restmail",
    "summary": "生成摘要时出错",
    "chinese_title": "Restmail – sendmail-compatible CLI for Gmail and outlook",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44361494",
    "title": "FICO to incorporate buy-now-pay-later loans into credit scores",
    "url": "https://www.axios.com/2025/06/23/fico-credit-scores-bnpl-buy-now-pay-later",
    "summary": "生成摘要时出错",
    "chinese_title": "FICO to incorporate buy-now-pay-later loans into credit scores",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44387074",
    "title": "Can AI speak the language Japan tried to kill?",
    "url": "https://www.bbc.com/future/article/20250625-can-ai-speak-the-language-japan-tried-to-kill",
    "summary": "生成摘要时出错",
    "chinese_title": "Can AI speak the language Japan tried to kill?",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44382367",
    "title": "IBM's Dmitry Krotov wants to crack the 'physics' of memory",
    "url": "https://research.ibm.com/blog/dmitry-krotov-ai-physics",
    "summary": "生成摘要时出错",
    "chinese_title": "IBM's Dmitry Krotov wants to crack the 'physics' of memory",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44375696",
    "title": "Experience Making a 1-minute AI movie with my 7-year old daughter",
    "url": "https://drsandor.net/ai/minecraft/",
    "summary": "生成摘要时出错",
    "chinese_title": "Experience Making a 1-minute AI movie with my 7-year old daughter",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44389088",
    "title": "Europe's Manhattan Project moment, argues a tech boss",
    "url": "https://www.economist.com/by-invitation/2025/06/26/this-is-europes-manhattan-project-moment-argues-a-tech-boss",
    "summary": "生成摘要时出错",
    "chinese_title": "Europe's Manhattan Project moment, argues a tech boss",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44378254",
    "title": "Show HN: Elelem, a tool-calling CLI for Ollama and DeepSeek in C",
    "url": "https://codeberg.org/politebot/elelem",
    "summary": "生成摘要时出错",
    "chinese_title": "Show HN: Elelem, a tool-calling CLI for Ollama and DeepSeek in C",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44381292",
    "title": "Building a Monostable Tetrahedron",
    "url": "https://arxiv.org/abs/2506.19244",
    "summary": "生成摘要时出错",
    "chinese_title": "Building a Monostable Tetrahedron",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44372380",
    "title": "Microsoft Edit",
    "url": "https://github.com/microsoft/edit",
    "summary": "生成摘要时出错",
    "chinese_title": "Microsoft Edit",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44355198",
    "title": "Deep Research as a Swim Coach",
    "url": "https://suthakamal.substack.com/p/swimming-with-an-ai-coach",
    "summary": "生成摘要时出错",
    "chinese_title": "Deep Research as a Swim Coach",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44380500",
    "title": "NLNet: 62 new projects contribute to digital commons",
    "url": "https://nlnet.nl/news/2025/20250624-announcement-grants-CommonsFund.html",
    "summary": "生成摘要时出错",
    "chinese_title": "NLNet: 62 new projects contribute to digital commons",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44366395",
    "title": "Show HN: Oasis – An open-source, 3D-printed smart terrarium",
    "url": "https://github.com/justbuchanan/oasis",
    "summary": "生成摘要时出错",
    "chinese_title": "Show HN: Oasis – An open-source, 3D-printed smart terrarium",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44354141",
    "title": "Yet another insignificant programming notes",
    "url": "https://chua.bitbucket.io",
    "summary": "生成摘要时出错",
    "chinese_title": "Yet another insignificant programming notes",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44351261",
    "title": "A Dictionary of the Language of Myst's D'ni",
    "url": "http://www.eldalamberon.com/dni_dict.htm",
    "summary": "生成摘要时出错",
    "chinese_title": "A Dictionary of the Language of Myst's D'ni",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44347294",
    "title": "Canal Boat Simulator",
    "url": "https://jacobfilipp.com/boat/",
    "summary": "生成摘要时出错",
    "chinese_title": "Canal Boat Simulator",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44386149",
    "title": "Mixed DPI in X11",
    "url": "https://wok.oblomov.eu/tecnologia/mixed-dpi-x11/",
    "summary": "生成摘要时出错",
    "chinese_title": "Mixed DPI in X11",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44366548",
    "title": "PlasticList – Plastic Levels in Foods",
    "url": "https://www.plasticlist.org/",
    "summary": "生成摘要时出错",
    "chinese_title": "PlasticList – Plastic Levels in Foods",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44374748",
    "title": "Web Translator API",
    "url": "https://developer.mozilla.org/en-US/docs/Web/API/Translator",
    "summary": "生成摘要时出错",
    "chinese_title": "Web Translator API",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44367638",
    "title": "ChatGPT's enterprise success against Copilot fuels OpenAI/Microsoft rivalry",
    "url": "https://www.bloomberg.com/news/articles/2025-06-24/chatgpt-vs-copilot-inside-the-openai-and-microsoft-rivalry",
    "summary": "生成摘要时出错",
    "chinese_title": "ChatGPT's enterprise success against Copilot fuels OpenAI/Microsoft rivalry",
    "chinese_summary": "生成摘要时出错"
  },
  {
    "id": "44365806",
    "title": "Finding a 27-year-old easter egg in the Power Mac G3 ROM",
    "url": "https://www.downtowndougbrown.com/2025/06/finding-a-27-year-old-easter-egg-in-the-power-mac-g3-rom/",
    "summary": "Doug Brown details his discovery of a previously undocumented easter egg hidden within the Power Mac G3's ROM (released 1997-1999). While exploring the ROM using Hex Fiend and Eric Harmon's Mac ROM template, he noticed a JPEG image resource of the development team and strings in the SCSI Manager 4.3 code referencing \"secret ROM image\" and \"The Team\".\n\nIntrigued, Brown disassembled the SCSI Manager code using Ghidra and traced the usage of these strings. He found that the code checks for a volume named \"secret ROM image\" associated with the .EDisk driver (RAM disk). If found, it extracts the JPEG image from the ROM and creates a file named \"The Team\" on that volume.\n\nWhile Brown initially struggled to activate the easter egg, a user named ^alex in the #mac68k Libera chat helped him figure out the activation method: formatting the RAM disk and naming it \"secret ROM image\" in the format dialog. This triggers the code to create the \"The Team\" file containing the hidden JPEG image.\n\nBrown confirmed the easter egg works on real hardware and Infinite Mac emulation, from Mac OS 8.1 up to at least 9.0.4. He believes this easter egg, likely created before Steve Jobs banned them in 1997, was previously unknown despite knowledge of the hidden image's existence. He credits ^alex for their key contribution and invites anyone who was part of \"The Team\" to share their recollections.\n",
    "chinese_title": "Finding a 27-year-old easter egg in the Power Mac G3 ROM",
    "chinese_summary": "Doug Brown details his discovery of a previously undocumented easter egg hidden within the Power Mac G3's ROM (released 1997-1999). While exploring the ROM using Hex Fiend and Eric Harmon's Mac ROM template, he noticed a JPEG image resource of the development team and strings in the SCSI Manager 4.3 code referencing \"secret ROM image\" and \"The Team\".\n\nIntrigued, Brown disassembled the SCSI Manager code using Ghidra and traced the usage of these strings. He found that the code checks for a volume named \"secret ROM image\" associated with the .EDisk driver (RAM disk). If found, it extracts the JPEG image from the ROM and creates a file named \"The Team\" on that volume.\n\nWhile Brown initially struggled to activate the easter egg, a user named ^alex in the #mac68k Libera chat helped him figure out the activation method: formatting the RAM disk and naming it \"secret ROM image\" in the format dialog. This triggers the code to create the \"The Team\" file containing the hidden JPEG image.\n\nBrown confirmed the easter egg works on real hardware and Infinite Mac emulation, from Mac OS 8.1 up to at least 9.0.4. He believes this easter egg, likely created before Steve Jobs banned them in 1997, was previously unknown despite knowledge of the hidden image's existence. He credits ^alex for their key contribution and invites anyone who was part of \"The Team\" to share their recollections.\n"
  }
]