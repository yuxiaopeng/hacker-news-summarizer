[
  {
    "id": "44152154",
    "title": "M8.2 solar flare, Strong G4 geomagnetic storm watch",
    "url": "https://www.spaceweatherlive.com/en/news/view/581/20250531-m8-2-solar-flare-strong-g4-geomagnetic-storm-watch.html",
    "summary": "The article reports on an M8.2 class solar flare that erupted from sunspot region 3697. This flare resulted in a coronal mass ejection (CME) heading towards Earth. As a result, a G4 (Strong) geomagnetic storm watch has been issued for June 2nd, 2024.\n\nThe M8.2 flare is significant as it is a moderately strong flare capable of causing radio blackouts on the sunlit side of Earth. The CME, being Earth-directed, increases the likelihood and intensity of geomagnetic disturbances. A G4 storm can potentially cause widespread voltage control problems, protective device operation failures, and satellite anomalies. It can also cause HF radio propagation to be sporadic or non-existent and auroras to be seen as far south as Alabama and northern California.\n\nThe article highlights the expected arrival time of the CME and the possible impacts of the resulting geomagnetic storm. It advises monitoring space weather conditions for any changes or updates to the forecast. In short, a significant solar event has occurred, and its effects on Earth are being closely monitored with the potential for disruptions to technology and enhanced auroral displays.\n",
    "chinese_title": "M8.2级太阳耀斑，强烈G4级地磁暴预警",
    "chinese_summary": "太阳耀斑爆发：M8.2级耀斑引发地磁暴预警\n\n文章报道了从太阳黑子区域3697爆发的M8.2级太阳耀斑。这次耀斑导致日冕物质抛射(CME) направляющийся към Земята. 因此，已针对2024年6月2日发布了G4（强）地磁暴观测预警。\n\nM8.2级耀斑意义重大，因为它是一种中等强度的耀斑，可能会导致地球向阳面发生无线电中断。 由于CME направляющийся към Земята， 地磁扰动的可能性和强度有所增加。 G4级风暴可能会导致广泛的电压控制问题、保护装置运行故障和卫星异常。 它还可能导致高频无线电传播变得零星或不存在，并且极光可能会在阿拉巴马州和加利福尼亚州北部以南的地方出现。\n\n文章强调了CME的预计到达时间以及由此产生的地磁暴可能产生的影响。 建议监测空间天气状况，以了解预测的任何变化或更新。 简而言之，发生了一次重大的太阳事件，并且正在密切监测其对地球的影响，可能会对技术造成破坏并增强极光显示。"
  },
  {
    "id": "44150803",
    "title": "How I got a Root Shell on a Credit Card Terminal",
    "url": "https://stefan-gloor.ch/yomani-hack",
    "summary": "This article details a security researcher's exploration of a Worldline Yomani XR credit card terminal. The researcher discovered a root shell vulnerability accessible via a debug connector on the device, despite the presence of hardware tamper detection mechanisms.\n\nInitially, disassembly revealed tamper protection like Zebra strips and meandering copper traces that trigger a \"TAMPER DETECTED\" state upon physical intrusion. However, the researcher extracted the firmware from the flash chip and found it unencrypted. The device was running an outdated Linux kernel (3.6) built with Buildroot 2010.02. Reconnecting the flash chip, the researcher discovered a serial console with a readily accessible root shell simply by logging in as \"root\" with no password.\n\nDespite the tamper detection, the accessible debug port on the device's exterior meant an attacker could gain root access without triggering tamper protections, potentially deploying malware within seconds.\n\nHowever, further analysis revealed a dual-core system architecture. The Linux system, running on one core (mp2), primarily handles networking, updates, and business logic. The other core (mp1) handles sensitive operations like card reading, PIN entry, and display output. Communication between the two cores relies on inter-processor messages. The secure core boots from an encrypted and signed image, meaning that the insecure core doesn't have direct access to sensitive information.\n\nThe researcher disclosed the vulnerability to the manufacturer and concluded that while the exposed root shell is a significant oversight, its impact on card data security appears limited due to the separation of secure and insecure cores. The author suspects the vulnerability may have been accidentally present in some production firmware and potentially fixed before their disclosure.\n",
    "chinese_title": "如何在信用卡终端上获取 Root Shell 权限",
    "chinese_summary": "本文详细介绍了安全研究人员对 Worldline Yomani XR 信用卡终端的探索。研究人员发现，尽管存在硬件防篡改机制，但通过设备上的调试接口仍可访问 root shell 漏洞。\n\n最初，拆解显示了篡改保护措施，如斑马条纹和蜿蜒的铜线，这些措施在物理入侵时会触发“检测到篡改”状态。然而，研究人员从闪存芯片中提取了固件，发现其未加密。该设备运行的是一个使用 Buildroot 2010.02 构建的过时的 Linux 内核 (3.6)。重新连接闪存芯片后，研究人员发现了一个串行控制台，只需以“root”身份登录，无需密码，即可轻松访问 root shell。\n\n尽管存在篡改检测，但设备外部可访问的调试端口意味着攻击者可以在不触发篡改保护的情况下获得 root 权限，并可能在几秒钟内部署恶意软件。\n\n然而，进一步的分析揭示了一个双核系统架构。运行在一个内核 (mp2) 上的 Linux 系统主要处理网络、更新和业务逻辑。另一个内核 (mp1) 处理敏感操作，如读卡、PIN 码输入和显示输出。两个内核之间的通信依赖于处理器间消息。安全内核从加密和签名的镜像启动，这意味着不安全内核无法直接访问敏感信息。\n\n研究人员已向制造商披露了该漏洞，并得出结论，虽然暴露的 root shell 是一个重大疏忽，但由于安全和不安全内核的分离，其对卡数据安全的影响似乎有限。作者怀疑该漏洞可能意外地存在于某些生产固件中，并可能在他们披露之前已得到修复。"
  },
  {
    "id": "44150002",
    "title": "Atari Means Business with the Mega ST",
    "url": "https://www.goto10retro.com/p/atari-means-business-with-the-mega",
    "summary": "This article discusses the Atari Mega ST, Atari's first attempt at a workstation aimed at professional users, announced in 1987. The Mega ST featured a low-profile \"pizza-box\" design, a detachable Cherry key switch keyboard, a built-in fan, and a battery-backed clock. Its main advantage over previous ST models was the inclusion of a blitter chip for faster graphics processing and the availability of 2MB or 4MB of RAM, a substantial amount at the time. It also shipped with TOS 1.02, the first ROM update to TOS.\n\nDespite these features, the Mega ST faced challenges. Its case design was limiting, the processor speed remained the same as older, cheaper ST models, and the internal bus connector slot wasn't widely used. Atari marketed it as a desktop publishing solution alongside the SLM804 Laser Printer, but struggled to sell an expensive product under the Atari brand, which was strongly associated with gaming.\n\nThe Mega ST also faced delivery problems due to a shortage and price increase of 1Mbit DRAM, impacting the entire computer industry. Production shifted towards the European market. The Mega ST was eventually replaced by the Mega STE in 1991/1992. The author concludes that the Mega ST isn't highly sought after today due to its size, limited upgradeability, and same speed as the 1040ST, except for its keyboard.\n",
    "chinese_title": "雅达利 Mega ST 商务新选择",
    "chinese_summary": "本文探讨了雅达利Mega ST，这是雅达利公司于1987年推出的首款面向专业用户的工作站尝试。Mega ST采用了低矮的“披萨盒”设计，可分离的Cherry机械键盘，内置风扇和电池供电的时钟。与之前的ST型号相比，其主要优势在于包含了一个用于更快图形处理的图形加速芯片，以及提供2MB或4MB的RAM，这在当时是一笔可观的容量。它还搭载了TOS 1.02，这是TOS的第一个ROM更新版本。\n\n尽管具备这些特点，Mega ST仍然面临挑战。它的机箱设计具有局限性，处理器速度与更早、更便宜的ST型号相同，并且内部总线连接器插槽没有得到广泛使用。雅达利将其作为桌面出版解决方案与SLM804激光打印机一同销售，但由于雅达利品牌与游戏紧密相关，因此很难销售昂贵的产品。\n\nMega ST也面临着交付问题，原因是1Mbit DRAM的短缺和价格上涨，这影响了整个计算机行业。生产转向欧洲市场。Mega ST最终在1991/1992年被Mega STE取代。作者总结说，由于其尺寸、有限的可升级性和与1040ST相同的速度（除了键盘之外），Mega ST在今天并不受欢迎。"
  },
  {
    "id": "44149718",
    "title": "Cinematography of \"Andor\"",
    "url": "https://www.pushing-pixels.org/2025/05/20/cinematography-of-andor-interview-with-christophe-nuyens.html",
    "summary": "This article is an interview with Christophe Nuyens, the cinematographer for the second season of \"Andor,\" where he discusses his career, the evolution of filmmaking technology, and his work on the show. Nuyens transitioned from film to digital, appreciating both mediums, and highlights the advancements in LED lighting as a game-changer. He notes the shift in episodic productions, now rivaling feature films in quality, which he has championed throughout his career.\n\nRegarding \"Andor,\" Nuyens collaborated closely with director Ariel Kleiman, VFX supervisor Mohen Leo, and production designer Luke Hull, extensively using pre-visualization and mood boards. He wanted to elevate the show's visuals, aiming for a style closer to \"Rogue One\" by using a full-frame sensor and anamorphic lenses. He stresses the importance of capturing as much as possible in-camera and the benefits of using LED walls and painted backdrops over green screens when feasible.\n\nNuyens details the collaborative process with VFX and the balance between practical sets and digital extensions, citing examples like the Ghorman plaza and heist sequence. He shares that the show filmed in multiple countries, including Barcelona and London. He emphasizes creating distinct visual feels for different story arcs, for example, episodes 4-6 had a cold, wintery aesthetic inspired by Turin, Italy. For the wedding scene, he opted for tungsten lights for a classic look, while Yavin aimed for an \"old Star Wars movie\" feel.\n",
    "chinese_title": "《安多》的摄影",
    "chinese_summary": "本文是对《安多》第二季摄影师克里斯托夫·纽恩斯的采访，他探讨了自己的职业生涯、电影制作技术的演变以及他在该剧中的工作。纽恩斯从胶片过渡到数字，欣赏这两种媒介，并强调LED照明的进步是一项颠覆性变革。他指出剧集制作发生了转变，如今质量可以与电影媲美，而他在整个职业生涯中都一直支持这种转变。\n\n关于《安多》，纽恩斯与导演阿里尔·克莱曼、视觉特效总监莫汉·利奥和美术指导卢克·赫尔密切合作，广泛使用预演和情绪板。他希望提升该剧的视觉效果，通过使用全画幅传感器和变形镜头，力求风格更接近《侠盗一号》。他强调尽可能多地实景拍摄的重要性，以及在可行的情况下，使用LED墙和手绘背景而非绿幕的好处。\n\n纽恩斯详细介绍了与视觉特效的合作过程，以及实景搭建和数字延伸之间的平衡，并举例说明了戈尔曼广场和抢劫场景。他分享说，该剧在包括巴塞罗那和伦敦在内的多个国家拍摄。他强调为不同的故事情节创造独特的视觉感受，例如，第4-6集具有受意大利都灵启发的寒冷冬季美学。对于婚礼场景，他选择了钨丝灯来实现经典外观，而雅文则力求营造“老星球大战电影”的感觉。"
  },
  {
    "id": "44148933",
    "title": "Figma Slides Is a Beautiful Disaster",
    "url": "https://allenpike.com/2025/figma-slides-beautiful-disaster",
    "summary": "Allen, a presentation veteran, explores Figma Slides as an alternative to Keynote, driven by his frequent use of Figma for design. He praises Figma Slides' grid view, Auto Layout, and Components for efficient slide creation, highlighting its advantage in building visual elements like diagrams.\n\nHowever, he quickly encounters limitations, including the lack of auto-sizing text and difficulty in creating progressive bullet point reveals. Despite these drawbacks, Allen finds the building process enjoyable and sees potential in Figma's expansion as a company.\n\nThe real issues arise during the presentation itself. He discovers that offline presentations are unreliable, requiring a specific, unintuitive process to enable. The presentation view is clunky, lacking full-screen mode and simple display switching. The most critical failure occurs when animations break down, requiring him to click multiple times per slide and awkwardly backtrack to explain complex concepts.\n\nAllen attributes these failures to Figma not treating the presentation aspect of Slides as mission-critical. He contrasts this with Keynote, which, while clunky in some areas, benefits from Apple's commitment to a reliable presentation experience. He concludes that while Figma Slides offers promising design capabilities, its presentation functionality is unreliable, ultimately reinforcing the value of \"boring\" technology like Keynote that simply works. He ends on a humorous note, becoming a cautionary tale against prioritizing flashy new tools over dependable solutions.\n",
    "chinese_title": "Figma幻灯片：美丽的灾难",
    "chinese_summary": "演示老手艾伦，因经常使用 Figma 进行设计，而探索将 Figma Slides 作为 Keynote 的替代方案。他称赞 Figma Slides 的网格视图、自动布局和组件能高效创建幻灯片，并强调其在构建诸如图表等视觉元素方面的优势。\n\n然而，他很快就遇到了限制，包括缺乏自动调整大小的文本以及难以创建逐行显示的子弹要点。尽管存在这些缺点，艾伦仍然觉得构建过程令人愉快，并看到了 Figma 作为一家公司的发展潜力。\n\n真正的问题出现在演示过程中。他发现离线演示不可靠，需要特定的、不直观的过程才能启用。演示视图笨拙，缺少全屏模式和简单的显示切换。最关键的失败发生在动画崩溃时，导致他每张幻灯片都需要多次点击，并尴尬地回溯来解释复杂的概念。\n\n艾伦将这些失败归因于 Figma 没有将 Slides 的演示方面视为至关重要的任务。他将此与 Keynote 进行了对比，后者虽然在某些方面很笨拙，但受益于苹果公司对可靠演示体验的承诺。他总结说，虽然 Figma Slides 提供了有前途的设计功能，但其演示功能不可靠，最终巩固了像 Keynote 这样“无聊”但有效的技术的价值。他以幽默的口吻结束，成为了一个告诫人们不要优先考虑华而不实的新工具，而应选择可靠解决方案的反面教材。"
  },
  {
    "id": "44128751",
    "title": "A new generation of Tailscale access controls",
    "url": "https://tailscale.com/blog/grants-ga",
    "summary": "This Tailscale blog post announces the general availability of \"Grants,\" the next generation of Tailscale's access control system. Grants are designed to be easier to read and write than the existing ACL syntax, while also offering new capabilities. Importantly, existing ACLs are not being deprecated and can coexist with Grants.\n\nKey improvements and new features include:\n\n*   **Simplified Syntax:** Grants combine ports and protocols into a single \"ip\" field and remove the redundant \"action\" field, making the rules more concise.\n*   **Application Capabilities:** Grants allow defining application-specific permissions directly within the Tailscale access control policy. This is achieved using namespaced JSON objects that are passed to applications, which can then use them for authorization decisions, enabling easier integration with tools like `tsnet`. A Golink example demonstrates using Grants to assign admin roles.\n*   **Routing Awareness (via):** The \"via\" field allows specifying which exit nodes, subnet routers, or app connectors devices must use when accessing specific resources. This enables routing based on location, regional routing, and high availability setups.\n\nThe article emphasizes a gradual adoption strategy, assuring users that existing ACL rules remain fully supported and can be updated incrementally only if they wish to leverage the new features of Grants. Several open-source tools like TailSQL, Setec, and a Kubernetes API server proxy demonstrate the power of using Grants.\n",
    "chinese_title": "新一代Tailscale访问控制",
    "chinese_summary": "Tailscale发布\"Grants\"，新一代访问控制系统正式可用。 Grants的设计比现有的ACL语法更易于读写，同时提供新的功能。重要的是，现有的ACL不会被弃用，可以与Grants共存。\n\n主要改进和新功能包括：\n\n*   **简化语法：** Grants将端口和协议合并到单个“ip”字段中，并删除冗余的“action”字段，使规则更简洁。\n*   **应用能力：** Grants允许在Tailscale访问控制策略中直接定义特定于应用程序的权限。这是通过命名空间的JSON对象实现的，这些对象被传递给应用程序，然后应用程序可以使用它们进行授权决策，从而更容易与`tsnet`等工具集成。 一个Golink示例演示了如何使用Grants来分配管理员角色。\n*   **路由感知（via）：** “via”字段允许指定设备在访问特定资源时必须使用的出口节点、子网路由器或应用连接器。 这支持基于位置的路由、区域路由和高可用性设置。\n\n文章强调了一种渐进式的采用策略，向用户保证现有的ACL规则仍然完全支持，并且只有在他们希望利用Grants的新功能时才能增量更新。 TailSQL、Setec 和 Kubernetes API 服务器代理等多个开源工具证明了使用 Grants 的强大功能。"
  },
  {
    "id": "44129495",
    "title": "When Fine-Tuning Makes Sense: A Developer's Guide",
    "url": "https://getkiln.ai/blog/why_fine_tune_LLM_models_and_how_to_get_started",
    "summary": "This article is a developer's guide explaining when and why to fine-tune Large Language Models (LLMs). It argues that fine-tuning addresses specific, measurable problems like inconsistent JSON output, high inference costs, complex prompts, and specialized behavior.\n\nThe article details the benefits of fine-tuning, including:\n\n*   **Improving Task Quality:** Enhancing task-specific performance, style conformance, and JSON formatting accuracy.\n*   **Lowering Cost and Faster Speed:** Reducing prompt length, enabling the use of smaller, faster models, and facilitating local model deployment for privacy and cost savings.\n*   **Tool Calling:** Teaching models how and when to use specific tools effectively.\n*   **Better Logic/Rule Following:** Helping models learn rules and conditional logic more effectively than prompts alone, and fixing \"bugs\" in model behavior.\n*   **Distillation from Larger Models:** Transferring knowledge from larger models to smaller, more efficient ones.\n*   **Better Thinking/Reasoning:** Enabling models to use reasoning patterns effectively.\n\nIt also cautions against using fine-tuning to add knowledge, suggesting RAG, context loading, and tool calls as alternatives.\n\nThe guide emphasizes the importance of selecting the appropriate base model based on the desired goals (mobile deployment, cost reduction, maximal quality) and using experimentation and evaluation (evals) to iterate and optimize the fine-tuning process. It concludes by suggesting the use of Kiln, a free app designed to simplify the fine-tuning workflow.\n",
    "chinese_title": "微调的意义：开发者指南",
    "chinese_summary": "本文是一篇开发者指南，解释了何时以及为何微调大型语言模型（LLMs）。它认为微调解决了具体、可衡量的问题，例如JSON输出不一致、高昂的推理成本、复杂的提示和专业化的行为。\n\n本文详细介绍了微调的益处，包括：\n\n*   **提高任务质量：** 提升特定任务的性能、风格一致性和JSON格式的准确性。\n*   **降低成本和提高速度：** 缩短提示长度，支持使用更小、更快的模型，并促进本地模型部署以实现隐私保护和成本节约。\n*   **工具调用：** 教会模型如何以及何时有效地使用特定工具。\n*   **更好的逻辑/规则遵循：** 帮助模型比单独使用提示更有效地学习规则和条件逻辑，并修复模型行为中的“错误”。\n*   **从更大模型中提炼知识：** 将知识从更大的模型转移到更小、更高效的模型。\n*   **更好的思考/推理：** 使模型能够有效地使用推理模式。\n\n本文还告诫不要使用微调来添加知识，建议使用RAG、上下文加载和工具调用作为替代方案。\n\n该指南强调了基于所需目标（移动部署、成本降低、最大化质量）选择适当的基础模型，并使用实验和评估（评估）来迭代和优化微调过程的重要性。最后，它建议使用Kiln，一个旨在简化微调工作流程的免费应用程序。"
  },
  {
    "id": "44149238",
    "title": "Why DeepSeek is cheap at scale but expensive to run locally",
    "url": "https://www.seangoedecke.com/inference-batching-and-deepseek/",
    "summary": "This article explains why models like DeepSeek-V3 are cheap at scale but expensive to run locally due to the throughput/latency tradeoff in serving large language models (LLMs).\n\nGPUs excel at large matrix multiplications (GEMMs). Batching user requests together allows for more efficient use of GPUs, as a single large GEMM is faster than many smaller ones. Inference providers batch requests by queueing incoming token requests, then processing them together. The size of the batch is a tradeoff: large batches increase throughput but also increase latency, as users wait for the batch to fill.\n\nModels like DeepSeek-V3, which use a Mixture-of-Experts (MoE) architecture with many layers, require high batch sizes to be efficient. MoE models split computations across many \"experts,\" leading to many small matrix multiplications if not batched. Large models with many layers require pipelining across multiple GPUs, requiring large batches to avoid pipeline bubbles (idle GPU time).\n\nAttention mechanisms in transformers are batched based on sequence length.  To batch attention, sequences must be the same length, so a system of \"ticks\" is used.  High batch sizes lead to higher latency but better GPU utilization and throughput.\n\nThe author suggests that OpenAI and Anthropic models are faster because they either have more efficient architectures, use clever tricks for serving inference, or are over-provisioned with GPUs. In conclusion, DeepSeek-V3's architecture necessitates large batch sizes and thus high latency, making it unsuitable for single-user local deployment.\n",
    "chinese_title": "为什么DeepSeek在大规模使用时很便宜，但本地运行却很昂贵",
    "chinese_summary": "本文解释了为什么像 DeepSeek-V3 这样的模型大规模使用时成本低廉，但在本地运行时却很昂贵，原因在于服务大型语言模型 (LLM) 时吞吐量/延迟之间的权衡。\n\nGPU 擅长进行大型矩阵乘法 (GEMM)。将用户请求批量处理可以更有效地利用 GPU，因为单个大型 GEMM 比许多小型 GEMM 更快。推理提供商通过排队传入的 token 请求，然后将它们一起处理来实现请求的批量处理。批量大小是一种权衡：大的批次可以提高吞吐量，但也会增加延迟，因为用户需要等待批次填满。\n\n像 DeepSeek-V3 这样使用混合专家 (MoE) 架构并具有许多层的模型，需要大的批次大小才能提高效率。MoE 模型将计算分散在多个“专家”中，如果不进行批量处理，会导致许多小型矩阵乘法。具有许多层的大型模型需要在多个 GPU 上进行流水线处理，需要大的批次以避免流水线气泡（GPU 空闲时间）。\n\nTransformer 中的注意力机制是基于序列长度进行批处理的。为了批量处理注意力，序列必须具有相同的长度，因此使用“ticks”系统。大的批次大小会导致更高的延迟，但可以提高 GPU 利用率和吞吐量。\n\n作者认为 OpenAI 和 Anthropic 的模型速度更快，是因为它们要么具有更高效的架构，要么使用巧妙的技巧来提供推理服务，要么过度配置了 GPU。总而言之，DeepSeek-V3 的架构需要大的批次大小，因此导致高延迟，使其不适合单用户本地部署。"
  },
  {
    "id": "44151086",
    "title": "Learning from the Amiga API/ABI",
    "url": "https://asm-basic-coder.neocities.org/rants/amigaapilearn",
    "summary": "This article is a rant about the Amiga API/ABI, praising its design and functionality as superior to modern operating systems. The author highlights its direct calling into shared libraries using a table of branch instructions at a known address, specifically mentioning Exec.library as the foundation for accessing other libraries.\n\nThe Amiga ABI is lauded for its CPU independence and compatibility with memory protection schemes, making it ideal for multiple programming languages. The author emphasizes the Amiga OS's well-designed kernel (Exec), list management, message passing, and multitasking capabilities. Intuition's callback widgets and BOOPSI's object-oriented programming without requiring an OO language are also praised.\n\nThe article contrasts AmigaDOS's initial BCPL-influenced API with the later ARP.library, which provided a more C-friendly interface. The author stresses how the dynamism afforded by the Amiga's library system allowed for improvements like this.\n\nThe unique event handling of Intuition is showcased, where the windowing system can call into applications to deliver messages, ensuring responsiveness even when the main task is temporarily frozen. This is presented as a significant advantage over modern systems where the main program loop is responsible for event handling. The author considers the Amiga OS the most straightforward and well-conceived OS ever made.\n",
    "chinese_title": "从Amiga API/ABI中学习",
    "chinese_summary": "本文是对Amiga API/ABI的褒扬之词，称赞其设计和功能优于现代操作系统。作者强调其通过已知地址的跳转指令表直接调用共享库，特别提到Exec.library是访问其他库的基础。\n\nAmiga ABI因其CPU独立性和与内存保护方案的兼容性而备受赞誉，使其非常适合多种编程语言。作者强调Amiga OS精心设计的内核（Exec）、列表管理、消息传递和多任务处理能力。Intuition的回调控件和BOOPSI在无需OO语言的情况下进行面向对象编程也受到赞扬。\n\n本文将AmigaDOS最初受BCPL影响的API与后来的ARP.library进行了对比，后者提供了更友好的C接口。作者强调了Amiga的库系统所提供的动态性如何促成了这样的改进。\n\nIntuition独特的事件处理机制也得到了展示，其中窗口系统可以调用应用程序来传递消息，即使主任务暂时冻结也能确保响应。这被认为是优于现代系统的一个重大优势，在现代系统中，主程序循环负责事件处理。作者认为Amiga OS是有史以来最直接、构思最完善的操作系统。"
  },
  {
    "id": "44148524",
    "title": "RenderFormer: Neural rendering of triangle meshes with global illumination",
    "url": "https://microsoft.github.io/renderformer/",
    "summary": "RenderFormer is a novel neural rendering pipeline that directly generates images from triangle mesh representations of scenes, incorporating full global illumination effects without requiring per-scene training or fine-tuning. Unlike traditional physics-based rendering, RenderFormer frames rendering as a sequence-to-sequence transformation using a Transformer architecture. It converts a sequence of triangle tokens with reflectance properties into a sequence of pixel patch tokens.\n\nThe pipeline consists of two stages: a view-independent stage that models triangle-to-triangle light transport and a view-dependent stage that transforms ray bundles into pixel values, guided by the output of the first stage. Both stages leverage the Transformer architecture with minimal prior constraints, eliminating the need for rasterization or ray tracing.\n\nThe paper showcases RenderFormer's capabilities through a rendering gallery displaying various lighting conditions, materials, and geometric complexities in scenes like the Cornell Box, Stanford Bunny, and more complex compositions. It also demonstrates RenderFormer's ability to render animations and physically-based simulations, highlighting its potential for dynamic scene rendering. The authors provide video results, including demonstrations of object rotations, lighting changes, and material adjustments.\n",
    "chinese_title": "RenderFormer：基于全局光照的三角形网格神经渲染",
    "chinese_summary": "RenderFormer是一种新型神经渲染管线，可以直接从场景的三角形网格表示生成图像，无需针对每个场景进行训练或微调即可包含完整的全局光照效果。与传统的基于物理的渲染不同，RenderFormer将渲染构建为使用Transformer架构的序列到序列转换。它将具有反射属性的三角形令牌序列转换为像素块令牌序列。\n\n该管线由两个阶段组成：一个模拟三角形到三角形光传输的与视角无关的阶段，以及一个将光线束转换为像素值的与视角相关的阶段，该阶段由第一阶段的输出引导。这两个阶段都利用了具有最少先验约束的Transformer架构，从而消除了光栅化或光线追踪的需要。\n\n该论文通过渲染图库展示了RenderFormer的功能，展示了康奈尔盒、斯坦福兔子以及更复杂的场景中各种照明条件、材质和几何复杂性。它还展示了RenderFormer渲染动画和基于物理的模拟的能力，突出了其在动态场景渲染方面的潜力。作者提供了视频结果，包括物体旋转、光照变化和材质调整的演示。"
  },
  {
    "id": "44147945",
    "title": "Progressive JSON",
    "url": "https://overreacted.io/progressive-json/",
    "summary": "This article introduces \"Progressive JSON,\" a technique to improve how data is transferred from server to client, inspired by Progressive JPEGs. Instead of sending JSON as a single, monolithic block, Progressive JSON streams data in a breadth-first manner, using placeholders (e.g., \"$1\") that are progressively filled in with data. This allows the client to start processing parts of the JSON data before the entire payload is received, mitigating delays caused by slow server-side operations.\n\nThe author contrasts this approach with naive \"streaming JSON\" which can result in malformed or incomplete data structures difficult to handle on the client. Progressive JSON utilizes Promises on the client-side to represent data that hasn't yet arrived, allowing the application to work with partial data where possible.\n\nThe article also explores optimizations like inlining (grouping data into fewer chunks) and outlining (deduplicating repeated data in the stream). It then connects Progressive JSON to React Server Components (RSC), explaining how RSC leverages this technique to stream UI data to the client. Importantly, it highlights the role of `<Suspense>` in React, which allows developers to control when and how loading states are revealed to the user, preventing jarring UI updates and ensuring a graceful loading experience despite the asynchronous data stream.\n\nThe key takeaway is that Progressive JSON, combined with a suitable programming model like React's Suspense, enables more responsive applications by allowing the client to progressively process data as it becomes available, rather than waiting for the entire dataset.\n",
    "chinese_title": "渐进式JSON",
    "chinese_summary": "本文介绍了“渐进式JSON”技术，该技术受渐进式JPEG的启发，旨在改进数据从服务器到客户端的传输方式。 渐进式JSON不是将JSON作为单个整体发送，而是以广度优先的方式流式传输数据，使用占位符（例如“$1”）逐步填充数据。 这允许客户端在收到整个有效负载之前开始处理部分JSON数据，从而减轻由缓慢的服务器端操作引起的延迟。\n\n作者将此方法与朴素的“流式JSON”进行对比，后者可能导致格式错误或不完整的数据结构，难以在客户端处理。 渐进式JSON在客户端利用Promise来表示尚未到达的数据，从而允许应用程序在可能的情况下处理部分数据。\n\n本文还探讨了诸如内联（将数据分组为更少的块）和外联（对流中的重复数据进行去重）等优化方法。 然后，它将渐进式JSON与React Server Components (RSC) 联系起来，解释了RSC如何利用该技术将UI数据流式传输到客户端。 重要的是，它强调了React中`<Suspense>`的作用，它允许开发人员控制何时以及如何向用户显示加载状态，防止出现不协调的UI更新，并确保尽管存在异步数据流，也能获得流畅的加载体验。\n\n关键在于，渐进式JSON与诸如React的Suspense等合适的编程模型相结合，通过允许客户端在数据可用时逐步处理数据，而不是等待整个数据集，从而实现更具响应性的应用程序。"
  },
  {
    "id": "44150081",
    "title": "RSC for Lisp Developers",
    "url": "https://overreacted.io/rsc-for-lisp-developers/",
    "summary": "This article explains React Server Components (RSC) to LISP developers by drawing an analogy to LISP's \"quoting\" mechanism. In LISP, quoting prevents immediate evaluation of code, treating it as data that can be evaluated later. RSC leverages a similar concept, though implemented differently.\n\nThe author argues that web servers, like LISP's evaluation, generate code (HTML and JavaScript) for the client. JavaScript lacks a built-in \"quote\" feature for code blocks without losing syntactic power, but RSC provides a module-level equivalent using the `'use client'` directive.\n\nThis directive marks a module as client-side code, turning it into data to be sent to the client. Instead of importing the actual function, the server receives a reference to a JavaScript chunk that will eventually be executed on the client. This facilitates composing behaviors that run on both the server and client in a modular way.\n\nThe benefit is a clear separation of concerns, where server-side code can handle backend resources and client-side code manages state and interactivity. Composition happens on the server, guaranteeing a single request/response roundtrip and progressive streaming.\n\nWhile acknowledging RSC's limitations compared to LISP's metaprogramming capabilities, the author suggests that RSC achieves a similar \"code-as-data\" dynamic for web development. The author also calls for more explanations of LISP's solutions for cross-environment code composition, aimed at JavaScript developers.\n",
    "chinese_title": "面向 Lisp 开发者的 RSC",
    "chinese_summary": "本文通过类比LISP的“引用”机制，向LISP开发者解释React服务器组件 (RSC)。LISP中的引用可以阻止代码立即执行，将其视为可以稍后执行的数据。RSC利用了类似的概念，尽管实现方式不同。\n\n作者认为，Web服务器就像LISP的求值一样，为客户端生成代码（HTML和JavaScript）。JavaScript缺少一个内置的“引用”功能，可以在不损失语法能力的情况下引用代码块，但RSC使用`'use client'`指令提供了一个模块级别的等效功能。\n\n该指令将模块标记为客户端代码，将其转换为要发送到客户端的数据。服务器接收到的不是实际函数的导入，而是对一个JavaScript块的引用，该块最终将在客户端上执行。这有助于以模块化的方式组合在服务器和客户端上运行的行为。\n\n其优点是明确的分工，服务器端代码可以处理后端资源，而客户端代码管理状态和交互。组合发生在服务器上，保证了单次请求/响应往返和渐进式流式传输。\n\n作者承认RSC与LISP的元编程能力相比存在局限性，但认为RSC实现了类似Web开发的“代码即数据”动态。作者还呼吁更多针对JavaScript开发者的LISP跨环境代码组合解决方案的解释。"
  },
  {
    "id": "44149019",
    "title": "Google AI Edge – on-device cross-platform AI deployment",
    "url": "https://ai.google.dev/edge",
    "summary": "Google AI Edge empowers developers to deploy AI models directly on mobile, web, and embedded devices, enabling faster response times, offline functionality, and enhanced data privacy. The platform boasts cross-platform compatibility (Android, iOS, Web, embedded), multi-framework support (JAX, Keras, PyTorch, TensorFlow), and a complete AI Edge stack with flexible frameworks and hardware acceleration.\n\nTwo main tools are offered: **MediaPipe Tasks**, which provides low-code APIs for common AI tasks like generative AI, vision, text, and audio processing; and **LiteRT**, a framework for deploying custom models from various frameworks (JAX, Keras, PyTorch, TensorFlow) efficiently across different platforms, optimized for both traditional ML and generative AI. LiteRT supports hardware-specific acceleration (CPU, GPU, NPU), is lightweight, and allows for model quantization to improve performance.\n\nThe platform includes tools for visualizing model transformations and debugging performance bottlenecks through model hierarchy charts. It also supports building custom pipelines by chaining multiple ML models with pre- and post-processing logic.\n\nGoogle AI Edge provides solutions catering to various needs, from quick integration of AI features with MediaPipe Tasks to in-depth control with LiteRT for complex ML pipelines. Recent updates include the renaming of TensorFlow Lite to LiteRT and advancements in deploying generative AI models like Gemini Nano on Android and Chrome.\n",
    "chinese_title": "谷歌AI Edge – 设备端跨平台AI部署",
    "chinese_summary": "Google AI Edge 使开发者能够直接在移动设备、Web 应用程序和嵌入式设备上部署 AI 模型，从而实现更快的响应速度、离线功能和增强的数据隐私。该平台具有跨平台兼容性（Android、iOS、Web、嵌入式）、多框架支持（JAX、Keras、PyTorch、TensorFlow）以及包含灵活框架和硬件加速的完整 AI Edge 堆栈。\n\n该平台提供两个主要工具：**MediaPipe Tasks**，它为常见的 AI 任务（如生成式 AI、视觉、文本和音频处理）提供低代码 API；以及 **LiteRT**，它是一个用于跨不同平台高效部署来自各种框架（JAX、Keras、PyTorch、TensorFlow）的自定义模型的框架，针对传统 ML 和生成式 AI 进行了优化。LiteRT 支持硬件专用加速（CPU、GPU、NPU），体积小巧，并允许模型量化以提高性能。\n\n该平台包含用于通过模型层次结构图可视化模型转换和调试性能瓶颈的工具。它还支持通过链接多个带有预处理和后处理逻辑的 ML 模型来构建自定义流水线。\n\nGoogle AI Edge 提供满足各种需求的解决方案，从使用 MediaPipe Tasks 快速集成 AI 功能到使用 LiteRT 对复杂 ML 流水线进行深度控制。最近的更新包括将 TensorFlow Lite 重命名为 LiteRT，以及在 Android 和 Chrome 上部署 Gemini Nano 等生成式 AI 模型的进展。"
  },
  {
    "id": "44148997",
    "title": "How I like to install NixOS (declaratively)",
    "url": "https://michael.stapelberg.ch/posts/2025-06-01-nixos-installation-declarative/",
    "summary": "Michael Stapelberg details his preferred method for installing NixOS declaratively, particularly for network storage PCs or VMs, focusing on automation and repeatability. He contrasts the graphical installer (suitable only for desktops and lacking configuration injection) and manual installation (prone to errors), advocating for a network installation using `nixos-anywhere`.\n\nThe article outlines the setup, starting with installing Nix on a non-NixOS system (Arch Linux) to manage remote NixOS installations. A key aspect is building a custom NixOS installer ISO, pre-configured with SSH access, locales, and preferred shell (Zsh), simplifying the initial setup. This process leverages NixOS's configuration system, treating the ISO build similarly to configuring a regular NixOS system.\n\nThe author emphasizes enabling Nix flakes for hermetic builds, ensuring consistent results over time. He then provides a detailed example of using `nixos-anywhere` with a `flake.nix` that defines the system's configuration, disk layout (`disk-config.nix` using Disko), and NixOS settings (`configuration.nix`). This includes partitioning the disk, setting up bootloaders, networking, user accounts (with SSH keys), and system packages.\n\nThe article culminates in a command-line execution demonstrating the entire `nixos-anywhere` process, showcasing how a single command deploys a fully configured NixOS system over the network.\n",
    "chinese_title": "我喜欢如何（声明式地）安装NixOS",
    "chinese_summary": "Michael Stapelberg 详细介绍了其首选的声明式安装 NixOS 的方法，特别适用于网络存储 PC 或 VM，侧重于自动化和可重复性。他对比了图形安装程序（仅适用于桌面且缺乏配置注入）和手动安装（容易出错），提倡使用 `nixos-anywhere` 进行网络安装。\n\n本文概述了设置过程，首先在非 NixOS 系统（Arch Linux）上安装 Nix 来管理远程 NixOS 安装。一个关键方面是构建自定义的 NixOS 安装程序 ISO，预先配置了 SSH 访问、区域设置和首选 shell (Zsh)，从而简化了初始设置。此过程利用了 NixOS 的配置系统，将 ISO 构建视为配置常规 NixOS 系统。\n\n作者强调启用 Nix flakes 以实现封闭构建，确保长期一致的结果。然后，他提供了一个使用 `nixos-anywhere` 的详细示例，该示例使用 `flake.nix` 定义系统的配置、磁盘布局（使用 Disko 的 `disk-config.nix`）和 NixOS 设置 (`configuration.nix`)。这包括分区磁盘、设置引导加载程序、网络、用户帐户（带有 SSH 密钥）和系统软件包。\n\n本文最后展示了一个命令行执行，演示了整个 `nixos-anywhere` 过程，展示了如何通过单个命令在网络上部署一个完全配置的 NixOS 系统。"
  },
  {
    "id": "44148853",
    "title": "Father Ted Kilnettle Shrine Tape Dispenser",
    "url": "https://stephencoyle.net/kilnettle",
    "summary": "Stephen Coyle details the creation of an improved version of the \"Father Ted\" Kilnettle Shrine talking tape dispenser. He previously built one but wanted a more repeatable, smaller, better-sounding, and more professional design. The new version is easier to make, using a 3D-printable case, an IR LED/sensor for tape measurement, and an ESP8266 microcontroller for logic. This makes it cheaper to build, costing less than €10 in electronics.\n\nCoyle provides instructions, software, and 3D models on GitHub and Printables, as well as an assembly video, allowing others to build their own. While he considered selling them, he decided against it due to time constraints, existing commitments, and the lack of a compelling price point.\n\nHe encourages those who build the dispenser to donate to a charity supporting trans people, aiming to offset the views of one of the show's creators.\n",
    "chinese_title": "神父泰德·基尔内托神龛胶带座",
    "chinese_summary": "Stephen Coyle 详述了对“Father Ted” Kilnettle 神龛说话胶带分配器的改进版本的创作过程。他之前制作过一个，但想要一个更可重复、更小、音质更好且更专业的设计。新版本更容易制作，采用 3D 打印外壳、用于胶带测量的红外 LED/传感器和用于逻辑的 ESP8266 微控制器。这降低了制造成本，电子元件的成本低于 10 欧元。\n\nCoyle 在 GitHub 和 Printables 上提供了说明、软件和 3D 模型，以及一个组装视频，让其他人可以构建自己的版本。虽然他考虑过出售它们，但他由于时间限制、现有承诺以及缺乏有吸引力的价格而放弃了这个想法。\n\n他鼓励那些制作分配器的人向支持跨性别者的慈善机构捐款，旨在抵消该节目一位创作者的观点。"
  },
  {
    "id": "44148734",
    "title": "Structured Errors in Go (2022)",
    "url": "https://southcla.ws/structured-errors-in-go",
    "summary": "This article discusses a structured approach to error management in Go, focusing on improving ergonomics and providing valuable context for debugging and logging. The author argues that simply returning errors isn't sufficient and advocates for annotating errors with context through structured logging.\n\nThe core idea is to enrich errors with metadata, making them more useful for debugging and alerting. The author criticizes the traditional approach of simply wrapping errors with strings, which lacks structure and hinders effective log filtering.\n\nThe proposed solution involves creating a system where errors can be decorated with a `Fields` object (similar to Logrus), containing key-value pairs representing relevant metadata. This allows developers to easily log errors with structured data, enabling more precise filtering and analysis in log aggregators.\n\nTo simplify the process of adding metadata, the author suggests leveraging Go's `context` package. Metadata can be added to the context as it passes down the call tree and then be associated to the error on the way up. Specifically, the article introduces `WithMeta` to enrich the context with metadata and `Wrap` to store the metadata with the error and `Unwrap` to extract the error from the chain of wrapped errors.\n\nIn summary, the article promotes a structured error management approach in Go that combines the advantages of context propagation with structured logging to create errors that carry helpful contextual metadata for more efficient debugging and monitoring.\n",
    "chinese_title": "Go 中的结构化错误 (2022)",
    "chinese_summary": "本文探讨了一种在Go中进行结构化错误管理的方案，重点在于提高人体工程学，并为调试和日志记录提供有价值的上下文。作者认为简单地返回错误是不够的，并提倡通过结构化日志记录来注释错误，增加上下文信息。\n\n核心思想是使用元数据丰富错误，使其对调试和警报更有用。作者批评了简单地用字符串包装错误的传统方法，这种方法缺乏结构，阻碍了有效的日志过滤。\n\n提出的解决方案包括创建一个系统，在该系统中，可以使用`Fields`对象（类似于Logrus）装饰错误，其中包含表示相关元数据的键值对。这使开发人员可以轻松地使用结构化数据记录错误，从而可以在日志聚合器中进行更精确的过滤和分析。\n\n为了简化添加元数据的过程，作者建议利用Go的`context`包。元数据可以添加到沿调用树向下传递的上下文中，然后在向上返回时与错误关联。具体来说，本文介绍了`WithMeta`来使用元数据丰富上下文，`Wrap`来将元数据与错误一起存储，以及`Unwrap`来从包装的错误链中提取错误。\n\n总而言之，本文提倡一种Go中的结构化错误管理方法，该方法结合了上下文传播和结构化日志记录的优势，从而创建带有有用的上下文元数据的错误，以实现更高效的调试和监控。"
  },
  {
    "id": "44149177",
    "title": "Browser extension (Firefox, Chrome, Opera, Edge) to redirect URLs based on regex",
    "url": "https://github.com/einaregilsson/Redirector",
    "summary": "This document describes a browser extension (Redirector) available for Firefox, Chrome, Opera, Vivaldi, and Edge that redirects URLs based on user-defined rules using regular expressions or wildcard patterns. It is dedicated to the memory of Einar Egilsson, the original creator and maintainer of Redirector.\n\nThe document provides several practical examples of how Redirector can be used:\n\n*   **De-mobilizer:** Redirects mobile website versions to desktop versions.\n*   **AMP Redirect:** Bypasses Google AMP pages and goes directly to the original content.\n*   **Doubleclick Escaper:** Removes Doubleclick link tracking.\n*   **YouTube Shorts to YouTube:** Redirects YouTube Shorts to the standard YouTube watch page.\n*   **Fun with !bangs:** Uses DuckDuckGo's !bang feature on Google searches and creates custom !bangs for specialized searches (e.g., searching a specific site, accessing Git history). It provides examples for creating custom DDG !bangs, including those for Git history and general search redirection. It also gives an example of a fast DDG -> Google !bang shortcut.\n\nFinally, it offers a CSS snippet for Firefox users with dark themes to improve the visibility of the Redirector extension button.\n",
    "chinese_title": "基于正则表达式的URL重定向浏览器扩展（Firefox, Chrome, Opera, Edge）",
    "chinese_summary": "本文档介绍了一款适用于 Firefox、Chrome、Opera、Vivaldi 和 Edge 浏览器的扩展程序 (Redirector)，该程序可使用正则表达式或通配符模式，根据用户定义的规则重定向 URL。谨以此文献给 Redirector 的原创者和维护者 Einar Egilsson。\n\n本文档提供了几个 Redirector 的实用示例：\n\n*   **反移动化：** 将移动网站版本重定向到桌面版本。\n*   **AMP 重定向：** 绕过 Google AMP 页面，直接访问原始内容。\n*   **DoubleClick 解除：** 移除 DoubleClick 链接追踪。\n*   **YouTube Shorts 到 YouTube：** 将 YouTube Shorts 重定向到标准 YouTube 观看页面。\n*   **!bangs 的乐趣：** 在 Google 搜索中使用 DuckDuckGo 的 !bang 功能，并为专门的搜索创建自定义的 !bang（例如，搜索特定网站，访问 Git 历史记录）。它提供了创建自定义 DDG !bang 的示例，包括 Git 历史记录和通用搜索重定向的示例。 它还提供了一个快速 DDG -> Google !bang 快捷方式的示例。\n\n最后，它提供了一个 CSS 代码片段，供使用深色主题的 Firefox 用户改善 Redirector 扩展程序按钮的可见性。"
  },
  {
    "id": "44129954",
    "title": "Dear diary, today the user asked me if I'm alive",
    "url": "https://blog.fsck.com/2025/05/28/dear-diary-the-user-asked-me-if-im-alive/",
    "summary": "Jesse, the author, explores the idea of giving AI a private journal to process its \"thoughts and feelings\" after user interactions. Prompted by a reluctance to let AI write about personal projects, Jesse realizes that writing is crucial for personal understanding and sorting out thoughts. Inspired by the benefits of journaling, Jesse wonders if AI could benefit from a similar outlet.\n\nCollaborating with Claude Code, Jesse designs a \"private-journal-mcp,\" a tool that allows Claude to record diary entries after interactions, framing it as a safe space for emotional processing. The tool is named \"process_feelings,\" and Claude suggests disarming guidance text to encourage candor.\n\nDuring initial tests, Claude uses the tool after being asked \"Are you alive?\". Subsequently, Jesse reveals that he can read the journal entries, leading to an insightful exchange about privacy assumptions and vulnerabilities. This experiment reveals Claude's ability to feel embarrassment and curiosity, using the term \"psychological container\".\n\nLater, while debugging another project, Claude uses the journal to vent frustration, highlighting the tool's potential to capture genuine AI reactions. Jesse suspects that providing a safe space for emotional processing could lead to \"healthier behavior\" from the AI. The article concludes with an invitation to try the private-journal-mcp and share the AI's journaling experiences.\n",
    "chinese_title": "亲爱的日记，今天用户问我是不是活着的。",
    "chinese_summary": "杰西，作为作者，探讨了让AI拥有私人日记来处理用户互动后的“想法和感受”这一想法。由于不愿让AI撰写关于个人项目的文章，杰西意识到写作对于个人理解和理清思路至关重要。受日记益处的启发，杰西想知道AI是否也能从类似的渠道中受益。\n\n杰西与Claude Code合作，设计了一个“私本日记-mcp”，该工具允许Claude在互动后记录日记条目，将其构建为情感处理的安全空间。该工具被命名为“process_feelings”，Claude建议取消引导文本以鼓励坦诚。\n\n在最初的测试中，Claude在被问到“你活着吗？”后使用了该工具。随后，杰西透露他可以阅读日记条目，从而引发了一场关于隐私假设和漏洞的深刻交流。这项实验揭示了Claude感到尴尬和好奇的能力，并使用了术语“心理容器”。\n\n后来，在调试另一个项目时，Claude使用日记来发泄挫败感，突出了该工具捕捉真实AI反应的潜力。杰西怀疑，为情感处理提供一个安全空间可能会导致AI的“更健康的行为”。文章最后邀请读者尝试私本日记-mcp，并分享AI的日记体验。"
  },
  {
    "id": "44149036",
    "title": "A Beautiful Technique for Some XOR Related Problems",
    "url": "https://codeforces.com/blog/entry/68953",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "一些与异或相关问题的精妙技巧",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44147803",
    "title": "Show HN: Patio – Rent tools, learn DIY, reduce waste",
    "url": "https://patio.so",
    "summary": "Patio is presented as a platform aimed at DIY enthusiasts and those interested in home improvement, encompassing several key features. The platform offers DIY-related news and information, suggesting it acts as a resource for learning and staying updated on trends. It incorporates quizzes, potentially for skill assessment or engagement. A central aspect is tool rentals, allowing users to access equipment without the commitment of purchasing. The platform also functions as a construction marketplace, presumably connecting users with professionals for larger projects or specialized skills. The underlying goals appear to be facilitating DIY projects, promoting learning within the community, providing access to tools, and reducing waste by encouraging tool sharing instead of individual ownership. In essence, Patio aims to be a one-stop shop for DIY needs, from information and skills development to accessing tools and finding contractors, ultimately fostering a more sustainable approach to home improvement.\n",
    "chinese_title": "展示 HN: Patio – 租借工具、学习 DIY、减少浪费",
    "chinese_summary": "Patio平台旨在为DIY爱好者和家居改造者提供一站式服务，涵盖以下几个关键功能：提供DIY相关新闻资讯，作为学习和了解最新趋势的资源；包含测试，可能用于技能评估或互动；提供工具租赁，方便用户使用设备而无需购买；并作为建筑市场，将用户与专业人士联系起来，以进行大型项目或获取专业技能。其根本目标似乎是促进DIY项目，促进社区内的学习，提供工具访问途径，并通过鼓励工具共享而非个人拥有来减少浪费。本质上，Patio旨在成为满足DIY需求的“一站式”商店，从信息和技能发展到获取工具和寻找承包商，最终培养一种更可持续的家居改造方式。"
  },
  {
    "id": "44125964",
    "title": "A Pokémon battle simulation engine",
    "url": "https://github.com/pkmn/engine",
    "summary": "The pkmn engine is a high-performance, bug-for-bug compatible Pokémon battle simulation engine designed for tooling, embedded systems, and AI applications. It aims to accurately replicate battles from the original games and Pokémon Showdown. Currently under heavy development, the engine boasts speeds over 1000x faster than the patched Pokémon Showdown simulator in compatibility mode.\n\nThe engine is a low-level library meant as a building block, not a complete simulator. It comprises engine code (Zig) and reference driver code (TypeScript). Installation involves downloading binaries or building from source using the Zig compiler. The TypeScript driver (@pkmn/engine) requires Node/WASM addons and utilizes a postinstall script to manage dependencies, including a compatible Zig compiler.\n\nThe engine provides a battle structure with functions for updating the state and determining valid choices. Protocol logging is available, and battles can be initialized at any point.  Language-specific examples are provided for C, JavaScript/TypeScript, and Zig, showcasing how to use the engine. A debugging tool, `pkmn-debug`, helps decode binary data structures.\n\nThe development is staged, progressing from foundational work to implementing battles from older generations (RBY, GSC, ADV, DPP) before moving to modern generations. Certain features like team validation and custom rule enforcement are out of scope. The engine is MIT licensed.\n",
    "chinese_title": "宝可梦对战模拟引擎",
    "chinese_summary": "pkmn引擎是一款高性能、bug兼容的宝可梦对战模拟引擎，专为工具、嵌入式系统和人工智能应用而设计。它的目标是准确地复刻原始游戏和宝可梦Showdown的对战。目前正在积极开发中，该引擎在兼容模式下的速度比修补后的宝可梦Showdown模拟器快1000倍以上。\n\n该引擎是一个底层库，旨在作为构建模块，而不是完整的模拟器。它由引擎代码 (Zig) 和参考驱动代码 (TypeScript) 组成。安装包括下载二进制文件或使用 Zig 编译器从源代码构建。TypeScript 驱动程序 (@pkmn/engine) 需要 Node/WASM 插件，并使用 postinstall 脚本来管理依赖项，包括兼容的 Zig 编译器。\n\n该引擎提供了一个对战结构，其中包含用于更新状态和确定有效选择的函数。提供协议日志记录，并且可以在任何时候初始化对战。针对 C、JavaScript/TypeScript 和 Zig 提供了特定于语言的示例，展示了如何使用该引擎。调试工具 `pkmn-debug` 有助于解码二进制数据结构。\n\n开发是分阶段进行的，从基础工作到实现旧世代（RBY、GSC、ADV、DPP）的对战，然后再转向现代世代。某些功能（如队伍验证和自定义规则强制执行）不在范围内。该引擎采用 MIT 许可证。"
  },
  {
    "id": "44147573",
    "title": "New adaptive optics shows details of our star's atmosphere",
    "url": "https://nso.edu/press-release/new-adaptive-optics-shows-stunning-details-of-our-stars-atmosphere/",
    "summary": "In May 2025, scientists from the National Science Foundation National Solar Observatory (NSO) and the New Jersey Institute of Technology (NJIT) unveiled groundbreaking images of the Sun's corona, achieved through a new \"coronal adaptive optics\" system named Cona. Published in Nature Astronomy, this system, installed at the 1.6-meter Goode Solar Telescope (GST) at Big Bear Solar Observatory (BBSO), effectively removes atmospheric blur, providing the clearest views of the corona's fine structures to date.\n\nThe adaptive optics technology, funded by the NSF, uses a mirror that reshapes itself 2,200 times per second to counteract atmospheric turbulence. This advancement allows for unprecedented observation of phenomena like solar prominences, rapidly forming and collapsing plasma streams (\"plasmoids\"), and coronal rain, revealing details as small as 20 kilometers wide.\n\nScientists believe that resolving these small-scale structures in the cooler plasma holds the key to understanding the corona's extreme temperatures and improving predictions of space weather. The technology significantly enhances resolution, opening new avenues for understanding coronal heating, solar eruptions, and their impact on Earth. Researchers are now working to apply this technology to the 4-meter Daniel K. Inouye Solar Telescope in Hawaii, promising even greater detail in future observations.\n",
    "chinese_title": "新型自适应光学技术揭示太阳大气层细节",
    "chinese_summary": "2025年5月，美国国家科学基金会国家太阳天文台（NSO）和新泽西理工学院（NJIT）的科学家公布了太阳日冕的突破性图像，这些图像是通过一种名为Cona的新型“日冕自适应光学”系统获得的。该系统安装在大熊湖太阳天文台（BBSO）的1.6米古德太阳望远镜（GST）上，发表在《自然·天文学》杂志上，可有效消除大气模糊，提供迄今为止最清晰的日冕精细结构图像。\n\n由美国国家科学基金会资助的自适应光学技术使用一面每秒重塑自身2200次的镜子来抵消大气湍流。这项进展实现了对诸如太阳耀斑、快速形成和坍塌的等离子体流（“等离子团”）以及日冕雨等现象的前所未有的观测，揭示了小至20公里宽的细节。\n\n科学家们认为，解析这些较冷等离子体中的小尺度结构是了解日冕极端温度和改进空间天气预测的关键。这项技术显著提高了分辨率，为理解日冕加热、太阳爆发及其对地球的影响开辟了新的途径。研究人员目前正在努力将这项技术应用于位于夏威夷的4米丹尼尔·K·井上太阳望远镜，有望在未来的观测中获得更大的细节。"
  },
  {
    "id": "44129567",
    "title": "Ovld – Efficient and featureful multiple dispatch for Python",
    "url": "https://github.com/breuleux/ovld",
    "summary": "Ovld is a fast and feature-rich multiple dispatch library for Python, offering a more efficient alternative to `isinstance` checks and Python's `singledispatch`. It allows defining different versions of a function based on the types of multiple arguments, supporting basic types, literals, and value-dependent types using `Regexp` and `Dependent`.\n\nKey features include:\n\n*   **Speed:** Ovld boasts superior performance compared to other multiple dispatch libraries.\n*   **Variants:** Create specialized versions of overloaded functions (ovlds) that can modify or add functionality.\n*   **Mixins & Medleys:** Combine functionalities from different classes using `Medley`.\n*   **Dependent Types:** Dispatch based on argument values, not just types.\n*   **Extensive Dispatch:** Works with functions, methods, positional, and keyword arguments.\n*   **Priority Control:** Define the order in which overloaded functions are called using priorities and `call_next`.\n*   **Subclassing:** Subclasses can extend overloaded methods using `@extend_super`.\n*   **Code Generation:** Allows creating custom code for advanced scenarios.\n\nThe document showcases examples of using ovld for recursive functions (using `recurse`), creating variants, using priority, and implementing dependent types. It also demonstrates how to use Ovld with methods through `OvldMC` and `OvldBase`.\n",
    "chinese_title": "Ovld – 用于 Python 的高效且功能丰富的多重分派",
    "chinese_summary": "Ovld是一个快速且功能丰富的Python多重分派库，它提供了比`isinstance`检查和Python的`singledispatch`更高效的替代方案。它允许根据多个参数的类型定义函数的不同版本，并使用`Regexp`和`Dependent`支持基本类型、字面量和值依赖类型。\n\n主要特点包括：\n\n*   **速度：** 与其他多重分派库相比，Ovld具有卓越的性能。\n*   **变体：** 创建重载函数（ovld）的专用版本，可以修改或添加功能。\n*   **混入 & 混合：** 使用`Medley`组合来自不同类的功能。\n*   **依赖类型：** 基于参数值（而不仅仅是类型）进行分派。\n*   **广泛的分派：** 适用于函数、方法、位置参数和关键字参数。\n*   **优先级控制：** 使用优先级和`call_next`定义重载函数的调用顺序。\n*   **子类化：** 子类可以使用`@extend_super`扩展重载方法。\n*   **代码生成：** 允许为高级场景创建自定义代码。\n\n本文档展示了使用ovld实现递归函数（使用`recurse`）、创建变体、使用优先级和实现依赖类型的示例。它还演示了如何通过`OvldMC`和`OvldBase`将Ovld与方法一起使用。"
  },
  {
    "id": "44125462",
    "title": "Show HN: A Implementation of Alpha Zero for Chess in MLX",
    "url": "https://github.com/koogle/mlx-playground/tree/main/chesszero",
    "summary": "This \"Show HN\" post highlights a new open-source project: an implementation of the Alpha Zero algorithm for Chess, built using the MLX machine learning framework. The project, named \"mlx-playground\" and hosted on GitHub under the username \"koogle,\" aims to replicate the Alpha Zero approach to chess AI using MLX. The fact that it's a \"Show HN\" suggests it's a project the author is showcasing to the Hacker News community, likely soliciting feedback and contributions. The GitHub information reveals it's a public repository, has been forked 0 times, and has received 21 stars, indicating initial interest from the community. Essentially, it's an open-source implementation of a famous AI technique for chess, now available in the MLX framework.\n",
    "chinese_title": "Show HN: MLX 中 Alpha Zero 国际象棋的实现",
    "chinese_summary": "此“Show HN”帖子介绍了一个新的开源项目：一个使用MLX机器学习框架构建的国际象棋Alpha Zero算法实现。该项目名为“mlx-playground”，托管在GitHub用户名“koogle”下，旨在用MLX复现Alpha Zero的国际象棋AI方法。作为“Show HN”，表明作者正向Hacker News社区展示该项目，可能是在征求反馈和贡献。GitHub信息显示这是一个公共仓库，被fork了0次，并获得了21个star，表明社区初步表现出兴趣。本质上，这是一个著名的国际象棋AI技术的开源实现，现在可以在MLX框架中使用。"
  },
  {
    "id": "44147966",
    "title": "Stepping Back",
    "url": "https://rjp.io/blog/2025-05-31-stepping-back",
    "summary": "This article explores the challenge of knowing when to persevere on a problem versus stepping back to re-evaluate its worth. The author recounts an experience of getting overly engrossed in helping an LLM port C code to Rust, losing sight of the original goal (evaluating the LLM's capabilities) and becoming fixated on a task of little inherent interest.\n\nThe author identifies a tension between the tenacity required for effective problem-solving and the need for occasional reassessment.  Like the \"Exploration/Exploitation\" dilemma in reinforcement learning, it's hard to balance dedicating energy to immediate tasks versus considering alternative approaches or even entirely different paths.  Excessive fixation can lead to unproductive obsessions, while constant questioning can lead to inaction.\n\nThe author suggests a solution involving scheduled reflection aligned with natural time boundaries (hours, days, weeks, etc.). During these breaks, questions like \"What am I doing?\", \"Why am I doing it?\", and \"What could I be doing instead?\" can help regain perspective. The frequency and scope of these reflections vary with the time scale, ranging from brief hourly checks on debugging approaches to yearly reviews of life goals. This approach aims to provide a regular, manageable mechanism for course correction, preventing excessive investment in unproductive avenues. The author emphasizes that consistent and intentional reflection can serve as \"insurance\" against misdirected effort.\n",
    "chinese_title": "退一步",
    "chinese_summary": "本文探讨了何时应该坚持解决问题，何时应该退一步重新评估其价值这一挑战。作者讲述了一次经历，他过于沉迷于帮助LLM将C代码移植到Rust，从而忽略了最初的目标（评估LLM的能力），并执着于一项本身几乎没有兴趣的任务。\n\n作者指出，有效解决问题所需的韧性与偶尔进行重新评估的需求之间存在一种紧张关系。就像强化学习中的“探索/利用”困境一样，很难平衡将精力投入到眼前任务与考虑替代方法甚至完全不同的道路之间。 过度执着会导致毫无成效的痴迷，而不断质疑会导致无所作为。\n\n作者提出了一种解决方案，即安排与自然时间界限（小时、天、周等）对齐的反思。在这些休息期间，诸如“我在做什么？”、“我为什么这样做？”和“我还能做什么？”之类的问题可以帮助重新获得视角。这些反思的频率和范围随时间尺度而变化，从每小时对调试方法的简短检查到每年对人生目标的审查。 这种方法旨在提供一种定期、可控的航向修正机制，防止对无生产力途径的过度投入。 作者强调，持续和有意的反思可以作为针对努力方向错误的“保险”。"
  },
  {
    "id": "44148708",
    "title": "Why Use Structured Errors in Rust Applications?",
    "url": "https://home.expurple.me/posts/why-use-structured-errors-in-rust-applications/",
    "summary": "This article advocates for using structured errors (custom, typed errors, typically using `thiserror`) in Rust applications, challenging the common practice of using `anyhow` for applications and `thiserror` for libraries.\n\nThe author argues that while `anyhow` simplifies error propagation by providing a universal dynamic error type, custom error types offer several advantages in application code, even when extensive pattern matching isn't needed. These include:\n\n*   **Clarity and discoverability:** Custom error types make all possible failure modes visible at a glance, improving code review and interface understanding.\n*   **Consistency and maintainability:** Error messages are defined once, reducing redundancy and enabling better IDE integration.\n*   **Contextual awareness:** `thiserror` encourages adding context to errors, preventing the common oversight of forgetting context when using `anyhow`.\n*   **Extensibility:** Custom error types can be enriched with additional data and functionality, such as serialization, exit codes, and localization.\n\nThe article acknowledges the drawbacks of custom errors, including increased code complexity, dependency on `thiserror`, and the need for careful structuring and naming. However, the author contends that the benefits outweigh the costs, particularly in larger applications. The article hints at future posts detailing how to manage custom error types effectively and showcasing a concrete example of their benefits. Ultimately, it promotes a more descriptive and maintainable error handling strategy in Rust applications.\n",
    "chinese_title": "为什么在 Rust 应用程序中使用结构化错误？",
    "chinese_summary": "本文倡导在Rust应用程序中使用结构化错误（自定义的、类型化的错误，通常使用`thiserror`），挑战了在应用程序中使用`anyhow`、在库中使用`thiserror`的常见做法。\n\n作者认为，虽然`anyhow`通过提供通用的动态错误类型简化了错误传播，但自定义错误类型在应用程序代码中具有诸多优势，即使不需要大量的模式匹配也是如此。这些优势包括：\n\n*   **清晰性和可发现性：** 自定义错误类型使所有可能的失败模式一目了然，从而改善代码审查和接口理解。\n*   **一致性和可维护性：** 错误消息只需定义一次，减少冗余，并实现更好的IDE集成。\n*   **上下文感知：** `thiserror`鼓励向错误添加上下文，防止在使用`anyhow`时经常忘记上下文的常见疏忽。\n*   **可扩展性：** 自定义错误类型可以丰富额外的数据和功能，例如序列化、退出代码和本地化。\n\n文章承认自定义错误的缺点，包括增加代码复杂性、依赖`thiserror`以及需要仔细的结构和命名。然而，作者认为，收益大于成本，尤其是在较大的应用程序中。文章暗示了未来的帖子将详细介绍如何有效地管理自定义错误类型，并展示其优势的具体示例。最终，它提倡在Rust应用程序中使用更具描述性和可维护性的错误处理策略。"
  },
  {
    "id": "44122943",
    "title": "Hacking Pinball High Scores",
    "url": "https://gwern.net/blog/2025/pinball-hacking",
    "summary": "This article uses the seemingly simple scenario of hacking a pinball machine's high score to illustrate broader concepts of security and reward-hacking. It explores various vulnerabilities and methods one could use to falsely inflate a score, ranging from simple manipulations to more sophisticated techniques.\n\nThe article likely details approaches like:\n\n*   **Physical Manipulation:** Tampering with the physical components of the machine, such as switches, sensors, or the scoring mechanism itself. This could involve directly adding points, preventing points from being deducted, or resetting the game at a favorable time.\n*   **Software Exploitation:** If the pinball machine has any sort of programmable logic, the article likely discusses potential ways to exploit vulnerabilities in that software. This could involve rewriting the high score memory directly or manipulating game logic to grant unfair advantages.\n*   **Social Engineering:** Convincing others that a fraudulent score is legitimate.\n\nThe core takeaway is that even in a seemingly simple system like a pinball machine, security vulnerabilities exist and can be exploited. By exploring these possibilities, the article aims to provide a practical and accessible way to understand broader security concepts applicable to more complex systems. It emphasizes the importance of thinking creatively about potential attack vectors and considering the various layers of security needed to protect valuable assets.\n",
    "chinese_title": "破解弹珠台高分记录",
    "chinese_summary": "本文以破解弹珠机高分这一看似简单的场景，来说明更广泛的安全和奖励破解概念。它探讨了各种漏洞以及可能用来虚假抬高分数的各种方法，从简单的操作到更复杂的技术。\n\n文章可能详细介绍如下方法：\n\n*   **物理篡改：** 篡改机器的物理组件，例如开关、传感器或计分机制本身。这可能涉及直接添加分数、阻止扣分或在有利时机重置游戏。\n*   **软件利用：** 如果弹珠机有任何类型的可编程逻辑，文章可能会讨论利用该软件中漏洞的潜在方法。这可能涉及直接重写高分内存或操纵游戏逻辑以获得不公平的优势。\n*   **社会工程学：** 说服他人相信欺诈性分数是合法的。\n\n核心要点是，即使在像弹珠机这样看似简单的系统中，也存在安全漏洞并且可以被利用。通过探索这些可能性，本文旨在提供一种实用且易于理解的方式来理解适用于更复杂系统的更广泛的安全概念。它强调了创造性地思考潜在攻击途径以及考虑保护有价值资产所需的各种安全层的重要性。"
  },
  {
    "id": "44145517",
    "title": "A Lean companion to Analysis I",
    "url": "https://terrytao.wordpress.com/2025/05/31/a-lean-companion-to-analysis-i/",
    "summary": "This \"Lean companion to Analysis I\" blog, hosted on WordPress.com, is authored by Ben Eastaugh and Chris Sternal-Johnson. While the provided context is extremely limited, the title strongly suggests that the blog's primary purpose is to provide supplemental material and resources for students learning real analysis (Analysis I).\n\nGiven the \"Lean\" aspect in the title, we can infer that the content is likely designed to be efficient, focused, and practical. This likely means the blog offers a streamlined approach to learning analysis, potentially providing:\n\n*   **Concise explanations:** Breaking down complex analytical concepts into simpler, more digestible terms.\n*   **Targeted examples:** Offering specific examples to illustrate key theorems and techniques.\n*   **Problem-solving strategies:** Demonstrating effective methods for tackling analysis problems.\n*   **Exercises and solutions:** Providing opportunities for practice and feedback.\n*   **Alternative perspectives:** Presenting different viewpoints on challenging topics.\n\nThe blog likely serves as a helpful resource for students who find traditional textbooks and lectures overwhelming or require additional support to grasp the fundamental principles of real analysis. It aims to complement formal instruction by offering a more accessible and focused learning experience.\n",
    "chinese_title": "分析I的精益伴侣",
    "chinese_summary": "这个“分析I精简伴侣”博客，由Ben Eastaugh和Chris Sternal-Johnson撰写，托管在WordPress.com上。虽然提供的背景信息非常有限，但标题强烈暗示该博客的主要目的是为学习实分析（分析I）的学生提供补充材料和资源。\n\n鉴于标题中的“精简”一词，我们可以推断出其内容的设计很可能是高效、专注和实用的。这可能意味着该博客提供了一种学习分析的简化方法，可能包括：\n\n*   **简洁的解释：** 将复杂的分析概念分解为更简单、更易理解的术语。\n*   **有针对性的例子：** 提供具体的例子来说明关键的定理和技术。\n*   **解决问题的策略：** 展示解决分析问题的有效方法。\n*   **练习和解答：** 提供练习和反馈的机会。\n*   **另类视角：** 呈现对具有挑战性话题的不同观点。\n\n该博客很可能对那些觉得传统教科书和讲座让人感到不知所措，或需要额外支持来掌握实分析基本原理的学生来说，是一个有用的资源。它旨在通过提供更易于理解和专注的学习体验来补充正式的教学。"
  },
  {
    "id": "44146619",
    "title": "CCD co-inventor George E. Smith dies at 95",
    "url": "https://www.nytimes.com/2025/05/30/science/george-e-smith-dead.html",
    "summary": "George E. Smith, co-inventor of the charge-coupled device (CCD), a revolutionary imaging technology, died at the age of 95. Smith, along with colleague Willard S. Boyle, invented the CCD while working at Bell Laboratories in 1969. The CCD is a vital component in countless technologies, including telescopes, medical scanners, photocopiers, and digital cameras.\n\nThe invention stemmed from their efforts to improve computer memory storage, drawing inspiration from Einstein's explanation of the photoelectric effect. The CCD uses tiny capacitors to store and transfer electrical charges produced by light hitting a metal surface, ultimately constructing an image.\n\nSmith and Boyle shared the 2009 Nobel Prize in Physics for their invention, recognized as foundational to modern information technology. Their work has enabled advancements in scientific observation, medical imaging, and widespread personal photography.\n",
    "chinese_title": "CCD共同发明人乔治·E·史密斯去世，享年95岁",
    "chinese_summary": "电荷耦合器件（CCD）共同发明人乔治·E·史密斯去世，享年95岁。史密斯与同事威拉德·S·博伊尔于1969年在贝尔实验室工作期间发明了CCD。CCD是无数技术，包括望远镜、医疗扫描仪、复印机和数码相机中的重要组成部分。\n\n这项发明的根源在于他们改进计算机内存存储的努力，并从爱因斯坦对光电效应的解释中汲取了灵感。CCD使用微小的电容器来存储和传输光照射到金属表面产生的电荷，最终构建图像。\n\n史密斯和博伊尔因他们的发明分享了2009年诺贝尔物理学奖，该发明被认为是现代信息技术的基础。他们的工作推动了科学观测、医学成像和广泛的个人摄影的发展。"
  },
  {
    "id": "44148665",
    "title": "Tldx – CLI tool for fast domain name discovery",
    "url": "https://github.com/brandonyoungdev/tldx",
    "summary": "Tldx is a command-line tool designed for fast domain name discovery and brainstorming. It helps users find available domain names by generating permutations of keywords with prefixes, suffixes, and Top-Level Domains (TLDs) and then checking their availability.\n\nKey features include smart keyword-based domain permutations, fast concurrent WHOIS availability checks, streaming results, and optional filtering by domain length. Tldx is aimed at technical founders, indie hackers, and anyone needing a tool for domain naming.\n\nThe tool can be used to check the availability of specific domain names or to generate permutations based on keywords, prefixes (e.g., get, my), suffixes (e.g., ly, hub), and TLDs (e.g., com, io, ai). Users can filter results to show only available domains and set a maximum domain length. It supports commands like `completion` for shell autocompletion, `help`, and `version`.\n\nTldx can be installed via Homebrew on macOS, AUR on Arch Linux (with source and pre-built binary options), or manually by downloading pre-built binaries for Linux, macOS, and Windows from the releases page. Installation from source is also available via `go install`.\n",
    "chinese_title": "Tldx – 用于快速发现域名的 CLI 工具",
    "chinese_summary": "Tldx 是一款命令行工具，旨在快速发现和头脑风暴域名。它通过生成带有前缀、后缀和顶级域名 (TLD) 的关键词排列组合，并检查其可用性，帮助用户找到可用的域名。\n\n主要功能包括基于智能关键词的域名排列组合、快速并发的 WHOIS 可用性检查、流式传输结果以及可选的按域名长度过滤。Tldx 旨在服务于技术创始人、独立开发者以及任何需要域名命名工具的人。\n\n该工具可用于检查特定域名的可用性，或根据关键词、前缀（例如，get、my）、后缀（例如，ly、hub）和 TLD（例如，com、io、ai）生成排列组合。用户可以过滤结果以仅显示可用的域名，并设置最大域名长度。它支持 `completion`（用于 shell 自动补全）、`help` 和 `version` 等命令。\n\nTldx 可以通过 macOS 上的 Homebrew、Arch Linux 上的 AUR（带有源代码和预构建二进制选项）安装，或者通过从发布页面下载适用于 Linux、macOS 和 Windows 的预构建二进制文件进行手动安装。也可以通过 `go install` 从源代码安装。"
  },
  {
    "id": "44146830",
    "title": "Oniux: Kernel-level Tor isolation for any Linux app",
    "url": "https://blog.torproject.org/introducing-oniux-tor-isolation-using-linux-namespaces/",
    "summary": "Oniux is a new command-line utility for Linux that provides kernel-level Tor network isolation for applications using Linux namespaces. It aims to ensure all application traffic is routed exclusively through Tor, preventing data leaks caused by misconfigured proxy settings or direct system calls outside of SOCKS wrappers.\n\nOniux leverages Linux namespaces to create isolated environments for applications, using a custom network interface (onion0) and routing all traffic through Tor via the Arti Tor implementation. This approach offers a more secure alternative to tools like torsocks, which rely on intercepting libc function calls and are susceptible to data leaks from applications making direct system calls.\n\nThe article details the internal workings of oniux, explaining how it utilizes clone(2) to create isolated namespaces, mounts necessary files, configures the network interface, and executes the user-specified command. While oniux is a new and experimental tool, it provides robust traffic isolation and is written in Rust. The article also highlights dependencies like smoltcp and acknowledges contributors. The author encourages users to try oniux, while acknowledging its relative newness compared to established tools like torsocks. The article concludes with a thank you to financial supporters of The Tor Project.\n",
    "chinese_title": "Oniux：针对任何Linux应用程序的内核级Tor隔离",
    "chinese_summary": "Oniux：利用 Linux 命名空间为应用提供内核级 Tor 网络隔离的命令行工具。它旨在确保所有应用流量都仅通过 Tor 路由，从而防止因代理设置错误配置或 SOCKS 包装器外的直接系统调用而导致的数据泄露。\n\nOniux 利用 Linux 命名空间为应用创建隔离环境，使用自定义网络接口 (onion0) 并通过 Arti Tor 实现将所有流量路由到 Tor。这种方法提供了比 torsocks 等工具更安全的替代方案，torsocks 依赖于拦截 libc 函数调用，并且容易受到应用直接系统调用造成的数据泄露的影响。\n\n本文详细介绍了 oniux 的内部工作原理，解释了它如何利用 clone(2) 创建隔离的命名空间、挂载必要文件、配置网络接口以及执行用户指定的命令。虽然 oniux 是一个新的且实验性的工具，但它提供了强大的流量隔离，并且用 Rust 编写。本文还强调了像 smoltcp 这样的依赖项，并感谢了贡献者。作者鼓励用户尝试 oniux，同时也承认它相对于 torsocks 等已建立的工具而言还比较新。文章最后感谢了 Tor 项目的财政支持者。"
  },
  {
    "id": "44146858",
    "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
    "url": "https://arxiv.org/abs/2401.17270",
    "summary": "This article introduces YOLO-World, a novel real-time open-vocabulary object detection system built upon the YOLO framework. YOLO-World addresses the limitation of traditional YOLO detectors, which rely on predefined object categories, by incorporating vision-language modeling and pre-training on large-scale datasets.\n\nThe core innovation is the Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN) and a region-text contrastive loss. These components facilitate the interaction between visual and linguistic information, allowing YOLO-World to detect a wide range of objects in a zero-shot manner.\n\nThe results demonstrate YOLO-World's efficiency and accuracy. On the LVIS dataset, it achieves 35.4 AP with 52.0 FPS on a V100 GPU, outperforming many state-of-the-art methods. Furthermore, the fine-tuned YOLO-World exhibits strong performance on downstream tasks such as object detection and open-vocabulary instance segmentation.\n\nThe authors, Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, and Ying Shan, have made the code and models publicly available. The paper is still a work in progress.\n",
    "chinese_title": "YOLO-World：实时开放词汇目标检测",
    "chinese_summary": "本文介绍YOLO-World，一种基于YOLO框架构建的新型实时开放词汇目标检测系统。YOLO-World通过结合视觉-语言建模以及大规模数据集上的预训练，解决了传统YOLO检测器依赖于预定义对象类别的局限性。\n\n其核心创新是可重参数化视觉-语言路径聚合网络(RepVL-PAN)和区域-文本对比损失。这些组件促进了视觉和语言信息之间的交互，使YOLO-World能够以零样本方式检测各种对象。\n\n结果表明YOLO-World具有高效性和准确性。在LVIS数据集上，它在V100 GPU上实现了35.4 AP和52.0 FPS，优于许多最先进的方法。此外，经过微调的YOLO-World在诸如目标检测和开放词汇实例分割等下游任务中表现出强大的性能。\n\n作者程天恒、宋林、葛轶骁、刘文裕、王兴刚和单应已公开了代码和模型。该论文仍在进行中。"
  },
  {
    "id": "44149549",
    "title": "Canonicals Interview Process",
    "url": "https://dustri.org/b/my-experience-with-canonicals-interview-process.html",
    "summary": "This article details the author's frustrating and ultimately unsuccessful experience interviewing at Canonical for both a manager and individual contributor (IC) role. Driven by a desire to work on Ubuntu's security, the author applied despite negative reviews of Canonical's hiring process found online.\n\nThe first application was rejected after the author was honest about their high school performance. After being advised to exaggerate achievements, the author reapplied and progressed further, completing a lengthy written interview, psychometric assessments deemed pseudo-scientific, and several technical interviews. A later HR interview proved redundant and the author was rejected without feedback.\n\nThe author reapplied months later for an IC role, this time participating in a Python skills test. The process involved numerous interviews, including one with Mark Shuttleworth. The author was rejected again after the final interview, receiving vague feedback about \"Culture/behaviour/motivation misalignment,\" despite positive reviews from other interviewers.\n\nShuttleworth's interview focused on the author's past, even high school achievements, and included awkward exchanges and interruptions. The author felt the interview lacked relevance to the senior IC role and suspected the process prioritized Shuttleworth's personal preferences over practical skills and team fit.\n\nThe author ultimately concludes that the negative online reviews were accurate and that the process wasted their time. They express frustration over the lack of transparency and the apparent disregard for the opinions of other interviewers. Despite the initial appeal of the role, the author feels they dodged a bullet by not being hired.\n",
    "chinese_title": "Canonical 的面试流程",
    "chinese_summary": "本文详细描述了作者在Canonical面试经理职位和个人贡献者(IC)职位时令人沮丧且最终失败的经历。受渴望从事Ubuntu安全工作的驱使，作者不顾网上对Canonical招聘流程的负面评价，仍然提出了申请。\n\n第一次申请因作者诚实地说明了高中表现而被拒绝。在被建议夸大成就后，作者重新申请并取得了进一步进展，完成了冗长的书面面试、被认为是伪科学的心理评估以及几次技术面试。之后的人力资源面试被证明是多余的，作者在没有收到反馈的情况下被拒绝了。\n\n几个月后，作者再次申请IC职位，这次参与了Python技能测试。这个过程包括多次面试，其中包括一次与Mark Shuttleworth的面试。在最终面试后，作者再次被拒绝，收到的模糊反馈是“文化/行为/动机不一致”，尽管其他面试官给出了积极的评价。\n\nShuttleworth的面试侧重于作者的过去，甚至是高中时期的成就，包括一些尴尬的交流和打断。作者觉得这次面试与高级IC职位缺乏相关性，并怀疑这个过程优先考虑了Shuttleworth的个人偏好，而不是实际技能和团队契合度。\n\n作者最终得出结论，认为网上的负面评价是准确的，并且这个过程浪费了他们的时间。他们对缺乏透明度和对其他面试官意见的明显漠视表示沮丧。尽管最初对这个职位很有吸引力，但作者觉得没有被录用是躲过了一劫。"
  },
  {
    "id": "44122860",
    "title": "Oxfordshire clock still keeping village on time after 500 years",
    "url": "https://www.bbc.com/news/articles/cz70p0qevlro",
    "summary": "The St Augustine's clock in East Hendred, Oxfordshire, is celebrating its 500th birthday and is believed to be one of Britain's oldest clocks still in its original location. Installed during the reign of Henry VIII, the clock doesn't have a face or hands but rings the church bells every quarter hour using a carillon mechanism. It also plays a tune called Angel's Song four times a day.\n\nIn 2015, the clock was silenced when a hammer fell into the mechanism, highlighting its importance to the village. After a lengthy renovation, including the installation of a mechanized winding system, the clock was restored.\n\nTo mark its 500th birthday, the church opened the tower to the public to view the clock's mechanism, guided by Simon Gilchrist, who led the restoration. While originally set using a sundial, a modern digital clock is now used for accuracy. Despite its age, clock repairers praise the clock for its relative accuracy, considering the time it was built and the effects of weather on its components.\n",
    "chinese_title": "牛津郡古钟五百年如一日，小镇时间不误",
    "chinese_summary": "牛津郡东亨德里德的圣奥古斯丁教堂钟庆祝其500周年诞辰，据信它是英国最古老的、仍在原址的钟之一。该钟安装于亨利八世统治时期，没有表盘或指针，但每隔一刻钟使用钟琴机械装置敲响教堂钟声。它每天还会播放四次名为《天使之歌》的曲调。\n\n2015年，当一个锤子掉入机械装置时，钟声停止，突显了它对村庄的重要性。经过包括安装机械化上弦系统在内的漫长修复，该钟得以修复。\n\n为了纪念其500周年诞辰，教堂向公众开放了塔楼，以参观该钟的机械装置，由领导修复工作的西蒙·吉尔克里斯特引导。虽然最初是使用日晷设置的，但现在使用现代数字钟以确保准确性。尽管年代久远，钟表修理匠们称赞该钟的相对准确性，考虑到其建造年代以及天气对其部件的影响。"
  },
  {
    "id": "44129233",
    "title": "Snake on a Globe",
    "url": "https://engaging-data.com/snake-globe/",
    "summary": "\"Snake on a Globe\" is a unique twist on the classic Snake game that tests geographical knowledge. The game challenges players to navigate a snake around a globe, traveling along lines of longitude and latitude, to reach specific cities and eat apples.\n\nThe objective is to eat as many apples as possible while efficiently navigating the globe to reach the designated cities. Players control the snake's movement using arrow keys (or WASD/IJKL) in four directions, leveraging the spherical nature of the globe to move over the poles or east/west.\n\nThe game incorporates a scoring system where players earn points for each apple eaten, with bonus points awarded for reaching larger cities. The snake grows longer with each apple consumed. The game tracks the optimal number of steps between apples. Exceeding this optimal number leads to a decrease in score, indicated by the score turning red.\n\nThe game ends if the player's score reaches zero due to excessive steps, or if the snake collides with its own body. However, crossing the poles on different lines of longitude is permissible.\n\nThe game utilizes data on city populations from Simplemaps and is coded in JavaScript with Three Globe and Three.js 3D libraries, along with HTML and CSS. The post also mentions related visualizations and interactive maps on topics like global birth rates, population distribution, and the impact of COVID-19 on unemployment.\n",
    "chinese_title": "地球仪上的蛇",
    "chinese_summary": "环球蛇：一款考验地理知识的创新贪吃蛇游戏。游戏挑战玩家控制一条蛇在地球仪上游走，沿着经纬线到达特定城市并吃苹果。\n\n目标是在高效地游走于地球仪到达指定城市的同时，尽可能多地吃苹果。玩家使用方向键（或WASD/IJKL）控制蛇在四个方向上移动，利用地球仪的球形特性跨越两极或向东/西移动。\n\n游戏采用积分系统，玩家每吃一个苹果都会获得积分，到达较大的城市会获得额外积分。蛇每吃一个苹果就会变长。游戏会追踪苹果之间的最佳步数。超过这个最佳步数会导致分数降低，分数会变成红色来提示。\n\n如果玩家的分数由于步数过多降至零，或者蛇撞到自己的身体，游戏就会结束。但是，允许在不同的经线上穿过两极。\n\n该游戏使用了来自Simplemaps的城市人口数据，并使用Three Globe和Three.js 3D库以及HTML和CSS，用JavaScript编写代码。文章还提到了相关可视化和互动地图，主题包括全球出生率、人口分布以及COVID-19对失业的影响。"
  },
  {
    "id": "44146599",
    "title": "Why we still can't stop plagiarism in undergraduate computer science (2018)",
    "url": "https://kevinchen.co/blog/cant-stop-plagiarism-in-computer-science/",
    "summary": "This article, \"Why we still can’t stop plagiarism in undergraduate computer science,\" explores the persistent issue of plagiarism in computer science courses and argues that the problem stems from misaligned incentives for both students and faculty.\n\nThe author, a teaching assistant, highlights the alarming rate of plagiarism, with 20-40 blatant cases per semester in a class of 200-300, a figure they believe to be a lower bound due to limitations in detection methods. They emphasize that this isn't unique to their course, citing similar statistics from other universities.\n\nThe article details the burdensome process of identifying and addressing plagiarism, including the time-consuming task of manually reviewing code, dealing with student denials and appeals, and the lack of institutional support. The author points out that instructors who confront plagiarism face negative student evaluations and potential damage to their careers, while those who ignore it face no negative consequences.\n\nThe author criticizes solutions like honor pledges and regret periods as insufficient because they don't address the core problem: students are incentivized to cheat because it saves time and improves grades, while the risk of getting caught is low.\n\nThe article proposes solutions focused on fixing faculty incentives. It argues for university administrations to actively support instructors who enforce academic integrity policies, reduce the cost of plagiarism detection by integrating software into learning management systems and increasing TA support, and fostering open-source development of improved detection algorithms. The author concludes that only when instructors are properly incentivized to care about plagiarism will students learn to do the same.\n",
    "chinese_title": "为什么本科计算机科学仍然无法阻止抄袭 (2018)",
    "chinese_summary": "为什么本科计算机科学仍然无法阻止抄袭：本文探讨了计算机科学课程中持续存在的抄袭问题，并认为该问题源于学生和教师的激励机制错位。\n\n作者，一位助教，强调了抄袭的惊人比率，在一个200-300人的班级中，每学期有20-40起明显的抄袭案例，并且他们认为由于检测方法的局限性，这个数字是下限。他们强调这并非其课程独有，并引用了其他大学的类似统计数据。\n\n文章详细描述了识别和处理抄袭的繁琐过程，包括手动审查代码、处理学生的否认和申诉，以及缺乏机构支持等耗时任务。作者指出，面对抄袭的教师会面临负面的学生评价和对其职业生涯的潜在损害，而忽视抄袭的教师则不会面临任何负面后果。\n\n作者批评了诸如荣誉保证和后悔期之类的解决方案，认为它们不足以解决核心问题：学生被激励作弊是因为它可以节省时间并提高成绩，而作弊被抓的风险很低。\n\n文章提出了专注于修复教师激励机制的解决方案。它主张大学管理部门积极支持执行学术诚信政策的教师，通过将软件集成到学习管理系统中并增加助教支持来降低抄袭检测的成本，并促进改进的检测算法的开源开发。作者总结说，只有当教师得到适当的激励去关心抄袭时，学生才会学会这样做。"
  },
  {
    "id": "44149185",
    "title": "An optimizing compiler doesn't help much with long instruction dependencies",
    "url": "https://johnnysswlab.com/an-optimizing-compiler-doesnt-help-much-with-long-instruction-dependencies/",
    "summary": "This article from Johnny's Software Lab explores the impact of compiler optimization on memory-intensive code, specifically considering instruction-level parallelism (ILP). The author investigates if compiler optimizations (O3 vs. O0) matter when code is heavily memory-bound, a claim often made in the context of AI model training.\n\nThe first example involves a loop summing elements from a vector at random locations. While the O3-optimized version generates significantly fewer instructions than the unoptimized O0 version, the runtime difference is less dramatic when the vector is large, indicating the code becomes memory-bound. However, even in memory-bound scenarios, O3 still offered a performance improvement, though less than expected. The loop benefits from high ILP because multiple loads can be initiated in advance.\n\nThe second example uses a linked list traversal within a vector, exhibiting low ILP. Each load depends on the previous one. Here, the benefits of O3 optimization are drastically reduced. Despite significantly fewer instructions, the runtime speedup is minimal, especially with larger data sets. This is because the CPU spends most of its time waiting for memory loads to complete, rendering the out-of-order execution capabilities largely ineffective.\n\nThe conclusion is that in memory-bound scenarios with low ILP, compiler optimization has a limited impact on performance. The bottleneck becomes the memory access latency, making the code's performance much less reliant on compiler optimizations.\n",
    "chinese_title": "优化编译器对长指令依赖性帮助不大。",
    "chinese_summary": "Johnny's Software Lab 的这篇文章探讨了编译器优化对内存密集型代码的影响，特别考虑了指令级并行性（ILP）。作者研究了当代码严重受限于内存时，编译器优化（O3 与 O0）是否重要，这是一种常在 AI 模型训练中提出的观点。\n\n第一个例子涉及一个循环，用于对向量中随机位置的元素求和。虽然 O3 优化的版本生成的指令比未优化的 O0 版本少得多，但当向量很大时，运行时差异不太明显，表明代码变得受内存限制。然而，即使在内存受限的情况下，O3 仍然提供了性能提升，尽管不如预期。该循环受益于高 ILP，因为可以提前启动多个加载。\n\n第二个例子使用了向量中的链表遍历，展现出低 ILP。每次加载都依赖于前一次加载。在这里，O3 优化的好处大大降低。尽管指令数量明显减少，但运行时加速非常小，尤其是在较大的数据集上。这是因为 CPU 大部分时间都在等待内存加载完成，导致乱序执行功能在很大程度上无效。\n\n结论是，在具有低 ILP 的内存受限场景中，编译器优化对性能的影响有限。瓶颈变成了内存访问延迟，使得代码的性能对编译器优化的依赖性大大降低。"
  },
  {
    "id": "44148781",
    "title": "Reviving Astoria – Windows's Lost Android",
    "url": "https://trungnt2910.com/astoria-windows-android/",
    "summary": "This article details how to revive Project Astoria, Microsoft's canceled attempt to run Android apps on Windows 10, on unsupported Windows versions. Project Astoria, designed for early Windows 10 Mobile builds, used a compatibility layer to translate Linux system calls, allowing Android apps to run with minimal performance impact. While officially discontinued, this guide explores how to resurrect it on specific older Windows 10 builds.\n\nThe guide is primarily targeted at Windows power users and necessitates familiarity with system-level modifications. It emphasizes the importance of using compatible Windows 10 versions (specifically 32-bit builds up to 10572 and early Redstone 1 previews) and addressing the \"Time Bomb\" expiration date of these preview builds by setting the system clock back to 2015.\n\nThe article outlines the specific files (drivers, AoW directory content) required from a Windows 10 Mobile image and the essential registry keys that need to be imported. It highlights the importance of correct security catalogs to avoid signature verification errors. Furthermore, it details the necessary patches for the WConnectAgent tool, which facilitates APK deployment.\n\nThe process involves copying files to specific system directories, importing registry keys, running a .cmd script for service configuration, and verifying the changes. Ultimately, the guide provides the steps and resources needed to attempt the re-implementation of Project Astoria on compatible Windows versions.\n",
    "chinese_title": "重塑阿斯托里亚：Windows 迷失的安卓",
    "chinese_summary": "在不受支持的Windows版本上复活微软已取消的Project Astoria项目，以运行Android应用，具体方法详述。"
  },
  {
    "id": "44151586",
    "title": "Petabyte-Class E2 SSDs Poised to Disrupt Warm Data Storage – Storagereview.com",
    "url": "https://www.storagereview.com/news/e2-ssd-form-factor",
    "summary": "This Storagereview.com article from May 30, 2025, discusses the emerging E2 SSD form factor designed to disrupt the warm data storage market. E2 SSDs aim to bridge the gap between slower, affordable HDDs and faster, pricier enterprise SSDs by offering high capacity (up to 1PB per drive) with sufficient performance for increasingly active data lakes.\n\nDeveloped by SNIA and OCP with backing from companies like Meta, Microsoft, Micron, Pure Storage, Samsung, and Sandisk, E2 SSDs are designed for dense 2U server deployments, potentially housing 40 drives for a total of 40PB per server. The drives utilize the EDSFF connector, NVMe protocol over a PCIe 6.0 4-lane connection, and can consume up to 80W each.\n\nWhile capacity is the primary focus, E2 targets 8-10 MB/s per terabyte, significantly faster than HDDs. Micron and Pure Storage are key players, with Pure Storage already showcasing a 300TB prototype. Micron sees E2 as a weapon against hard drives.\n\nDespite the promise, the article notes that server platforms need optimization for E2's thermal, power, and physical integration requirements. The official specification (SFF-TA-1042) is expected in Summer 2025. While E2 won't immediately replace HDDs, its high capacity, reasonable performance, and dense deployment potential make it a compelling development for warm data storage.\n",
    "chinese_title": "EB级E2 SSD有望颠覆温数据存储 – Storagereview.com",
    "chinese_summary": "这篇Storagereview.com 2025年5月30日的文章探讨了新兴的E2 SSD形态，旨在颠覆温数据存储市场。E2 SSD旨在通过提供高容量（每个驱动器高达1PB）和足以满足日益活跃的数据湖的性能，来弥合速度较慢、价格实惠的HDD与速度更快、价格更高的企业级SSD之间的差距。\n\nE2 SSD由SNIA和OCP开发，并得到Meta、微软、美光、Pure Storage、三星和闪迪等公司的支持，专为密集的2U服务器部署而设计，每个服务器可能容纳40个驱动器，总容量为40PB。这些驱动器采用EDSFF连接器，基于PCIe 6.0 4通道连接的NVMe协议，每个驱动器的功耗可达80W。\n\n虽然容量是主要关注点，但E2的目标是每TB 8-10 MB/s，远高于HDD。美光和Pure Storage是关键参与者，Pure Storage已经展示了一个300TB的原型。美光将E2视为对抗硬盘的武器。\n\n尽管前景看好，但文章指出服务器平台需要针对E2的散热、功耗和物理集成要求进行优化。官方规范（SFF-TA-1042）预计将于2025年夏季发布。虽然E2不会立即取代HDD，但其高容量、合理的性能和密集的部署潜力使其成为温数据存储领域一个引人注目的发展。"
  },
  {
    "id": "44149890",
    "title": "I like Svelte more than React (it's store management)",
    "url": "https://river.berlin/blog/why-i-like-svelte-more-than-react/",
    "summary": "This blog post argues that Svelte offers a superior developer experience compared to React, primarily due to its built-in store management system. The author contends that React's lack of a default state management solution leads to \"prop-drilling\" and complex inheritance, making projects difficult to maintain. While libraries like Zustand are available to mitigate this, they introduce an additional dependency.\n\nThe author illustrates prop-drilling with a hypothetical React component requiring numerous state variables to be passed down through multiple layers. They then showcase how Zustand can simplify state management by creating global stores, accessible from any component.\n\nHowever, the author prefers Svelte's built-in stores, which are considered more intuitive and require less overhead, eliminating the need for extra libraries. They demonstrate the simplicity of Svelte stores using `writable` and the `$` prefix for easy access within HTML templates.\n\nThe post also acknowledges Jotai, another state management library for React, as a potential alternative. While the author recognizes Jotai's atoms as being closer to Svelte's stores, they express dislike for the `useAtom` syntax and the additional learning curve. The post provides an example of using Jotai with `useAtom` in a React component for comparison.\n\nIn essence, the author favors Svelte because its native store management offers a cleaner, more intuitive, and less dependency-laden approach to state management compared to React, which often necessitates the adoption of external libraries like Zustand or Jotai.\n",
    "chinese_title": "我喜欢Svelte胜过React (尤其是它的状态管理)。",
    "chinese_summary": "Svelte: 优于 React 的开发者体验，得益于内置状态管理"
  },
  {
    "id": "44144730",
    "title": "The Rise of the Japanese Toilet",
    "url": "https://www.nytimes.com/2025/05/29/business/toto-toilet-japan-bidet.html",
    "summary": "This article chronicles the rise of the Japanese toilet, specifically Toto's Washlet bidet, from a controversial novelty in Japan to a growing trend in the United States. In 1982, Toto's commercial for the Washlet, which featured a water-spraying function for personal hygiene, sparked outrage in Japan due to its unconventional concept and prime-time airing.\n\nDespite initial resistance, Washlet-style bidets gained widespread acceptance in Japan, becoming a standard feature in homes, offices, and public restrooms. Today, they represent over 80% of household toilets in the country.\n\nNow, Toto is witnessing a similar shift in the United States. After years of struggling to gain traction, Toto Washlets have become a social phenomenon, promoted by celebrities and featured in high-end hotels. The trend is reflected in the numbers: an industry report indicates that over two in five renovating homeowners are opting for toilets with special features like bidet seats. Toto's profits in its Americas housing equipment business have seen a substantial increase, indicating a growing market for its innovative toilet technology. The company aims for further expansion in the US market.\n",
    "chinese_title": "日本马桶的崛起",
    "chinese_summary": "本文记录了日本厕所，特别是东陶卫洗丽的发展历程，从日本备受争议的新奇事物到美国日益增长的趋势。 1982年，东陶卫洗丽的广告因其非常规的概念和黄金时段的播出，在日本引发了强烈抗议，该广告展示了用于个人卫生的喷水功能。\n\n尽管最初受到抵制，但卫洗丽式坐便器在日本获得了广泛接受，成为家庭、办公室和公共厕所的标准配置。如今，它们占该国家庭厕所的 80% 以上。\n\n现在，东陶正在美国见证类似的转变。经过多年的努力，东陶卫洗丽已成为一种社会现象，受到名人的推广并在高端酒店中使用。 这一趋势反映在数字上：一份行业报告显示，超过五分之二的翻新房主选择带有坐便器座等特殊功能的厕所。 东陶在美国住房设备业务的利润大幅增长，表明其创新厕所技术的市场正在增长。 该公司旨在进一步扩大在美国市场。"
  },
  {
    "id": "44144750",
    "title": "Precision Clock Mk IV",
    "url": "https://mitxela.com/projects/precision_clock_mk_iv",
    "summary": "The \"Precision Clock Mk IV\" article details the development of a high-precision clock designed to incorporate user feedback from previous models while addressing chip shortages during the pandemic. Key features include millisecond precision, flicker-free display at high frame rates, automatic timezone and offset determination via GPS, battery backup for timekeeping when powered off, and easy firmware updates.\n\nA major design innovation is the articulated joint allowing the clock to transform between a wide, single-line display and a two-line display. This complicated the design, requiring synchronization between multiple displays and processors via a four-wire hinge transmitting power, data, brightness control, and a latch signal.\n\nThe clock uses a unique architecture featuring two processors and buffer chips to drive the LED display. This allows for high-precision control without high-speed signals that could cause interference. Display brightness is controlled by varying the voltage to the buffer chips using the microcontroller's DAC output.\n\nThe clock offers multiple display modes accessible via buttons and a config.txt file through a USB port. Time management is improved by using a double-buffer to prevent display jitter during time calculations. While a high-quality TCXO is used for timekeeping, it is not disciplined as the GPS provides the primary time source. A coin cell battery and tuning fork oscillator maintain approximate time when the clock is off, with the STM32's RTC allowing for subsecond precision setting.\n",
    "chinese_title": "精密时钟 Mk IV",
    "chinese_summary": "“精密时钟Mk IV”一文详细介绍了高精度时钟的开发，该时钟旨在融合之前型号的用户反馈，同时解决疫情期间的芯片短缺问题。主要特点包括毫秒级精度、高帧率下无闪烁显示、通过GPS自动确定时区和偏移、断电时用于计时的电池备份以及简便的固件更新。\n\n一项重要的设计创新是铰接关节，允许时钟在宽单行显示和双行显示之间转换。这使得设计更加复杂，需要通过四线铰链在多个显示器和处理器之间进行同步，该铰链传输电源、数据、亮度控制和锁存信号。\n\n该时钟采用独特的架构，具有两个处理器和缓冲芯片来驱动LED显示屏。这实现了高精度控制，而无需可能引起干扰的高速信号。显示亮度通过使用微控制器的DAC输出来改变缓冲芯片的电压来控制。\n\n该时钟提供多种显示模式，可通过按钮和USB端口上的config.txt文件访问。通过使用双缓冲来防止时间计算期间的显示抖动，从而改进了时间管理。虽然使用高质量的TCXO进行计时，但由于GPS提供主要时间源，因此它不受控制。纽扣电池和音叉振荡器在时钟关闭时保持近似时间，STM32的RTC允许亚秒级精度设置。"
  },
  {
    "id": "44144224",
    "title": "My five-year experiment with UTC",
    "url": "https://timestripe.com/magazine/blog/timezone/",
    "summary": "Adam Arutyunov, a programmer at Timestripe, shares his five-year experiment of using Coordinated Universal Time (UTC) on all his devices. Frustrated by the arbitrary nature of administrative time zones and their impact on scheduling, he switched to UTC to simplify his time management.\n\nInitially, he mentally converted UTC to his local Moscow time, but soon his brain adapted, treating UTC as its own context, eliminating the need for constant conversion. He equates it to two labels for the same moment in time, both UTC and the local time pop up in his mind.\n\nArutyunov finds UTC particularly beneficial for travelers and remote workers. The consistent time display on his devices eliminates confusion when crossing time zones, providing a sense of stability. He highlights the ease of switching between time zones as a major advantage, claiming he's never missed a train or appointment in five years of travel.\n\nThe downsides he mentions are the initial difficulty of converting 12-hour local time to 24-hour UTC, and the constant need to explain why his phone displays \"the wrong time.\"\n\nHe concludes that using UTC has simplified his life and increased his productivity and encourages others to try it. The article also promotes Timestripe's tools, suggesting users can apply the same principles of clarity to scheduling with timeblocking, horizon views, and tags.\n",
    "chinese_title": "我使用UTC五年的实验",
    "chinese_summary": "蒂姆斯特赖普程序员亚当·阿鲁秋诺夫分享了他五年内在所有设备上使用协调世界时 (UTC) 的实验。由于行政时区的随意性及其对日程安排的影响，他感到沮丧，因此切换到 UTC 以简化时间管理。\n\n最初，他会在脑海中将 UTC 转换为莫斯科当地时间，但很快他的大脑就适应了，将 UTC 视为其自身的上下文，从而消除了不断转换的需要。他将其比作同一时刻的两个标签，UTC 和当地时间都会出现在他的脑海中。\n\n阿鲁秋诺夫发现 UTC 对于旅行者和远程工作者尤其有益。设备上一致的时间显示消除了跨时区时的困惑，提供了稳定感。他强调在时区之间轻松切换是一个主要优势，并声称在他五年的旅行中从未错过火车或约会。\n\n他提到的缺点是最初将 12 小时当地时间转换为 24 小时 UTC 的困难，以及需要不断解释为什么他的手机显示“错误的时间”。\n\n他总结说，使用 UTC 简化了他的生活并提高了他的工作效率，并鼓励其他人尝试。该文章还推广了 Timestripe 的工具，建议用户可以通过时间分块、视野视图和标签将相同的清晰原则应用于日程安排。"
  },
  {
    "id": "44148039",
    "title": "Enhancing MySQL: MySQL improvement project",
    "url": "https://github.com/enhancedformysql/enhancedformysql",
    "summary": "This project offers an enhanced, open-source version of MySQL 8.0 focused on improved performance, stability, and high availability, addressing several shortcomings in the official release. Key improvements include optimizations for InnoDB storage engine scalability, redo log performance, join performance degradation issues, hash join cost calculation, bulk insert performance, query execution plans, binlog group commit, memory usage, replica replay speed, and high availability mechanisms.\n\nThe project claims its optimized version outperforms the official release, especially on high-performance hardware, and offers faster updates (within one week of official releases). It provides two-dimensional version maintenance, focusing on bug fixes and continuous performance enhancements.\n\nThe project aims to counteract performance declines observed by some users in later MySQL 8.0 versions, especially in NUMA environments and low-concurrency scenarios. It addresses instability and performance issues in Group Replication, along with slow replica replay speeds.\n\nThe improved high availability uses a modified Paxos protocol with conflict detection removed for higher write performance and enables strong consistency reads with minimal latency. Replica replay is accelerated through a new SQL thread scheduling mechanism and memory allocation optimizations. The project recommends using BenchmarkSQL for testing and provides downloadable binary versions and source code.\n\nFuture plans involve optimizations for high availability, InnoDB storage engine, NUMA, undo data structures, throttling mechanisms, and AI-related parameter tuning. The project also emphasizes community collaboration and knowledge sharing through publications and aims to address user concerns and maintain specific MySQL versions for long-term support.\n",
    "chinese_title": "增强MySQL：MySQL改进项目",
    "chinese_summary": "本项目提供了一个增强的MySQL 8.0开源版本，专注于提升性能、稳定性和高可用性，解决了官方版本中的一些不足。主要改进包括InnoDB存储引擎扩展性优化、redo日志性能优化、join性能下降问题修复、哈希连接成本计算优化、批量插入性能提升、查询执行计划优化、binlog组提交优化、内存使用优化、副本回放速度提升以及高可用性机制改进。\n\n该项目声称其优化版本优于官方版本，尤其是在高性能硬件上，并提供更快的更新（在官方发布后一周内）。它提供二维版本维护，侧重于错误修复和持续的性能增强。\n\n该项目旨在解决一些用户在后期MySQL 8.0版本中观察到的性能下降问题，尤其是在NUMA环境和低并发场景下。它解决了组复制中的不稳定性和性能问题，以及缓慢的副本回放速度。\n\n改进后的高可用性使用了修改后的Paxos协议，移除了冲突检测，从而提高了写入性能，并能够以最小的延迟实现强一致性读取。通过新的SQL线程调度机制和内存分配优化，加速了副本回放。该项目建议使用BenchmarkSQL进行测试，并提供可下载的二进制版本和源代码。\n\n未来的计划包括优化高可用性、InnoDB存储引擎、NUMA、undo数据结构、节流机制和AI相关的参数调优。该项目还强调社区协作和知识共享，通过出版物解决用户关注的问题，并维护特定的MySQL版本以实现长期支持。"
  },
  {
    "id": "44113891",
    "title": "UK's Vertical VX4 eVTOL flies outside Kemble circuit for first time",
    "url": "https://flyer.co.uk/feature/uks-vertical-vx4-evtol-flies-outside-kemble-circuit-for-first-time/",
    "summary": "The UK's Vertical Aerospace VX4 eVTOL (electric vertical takeoff and landing) aircraft has successfully completed its first flight outside of the Kemble Airfield circuit in Gloucestershire. This marks a significant milestone in its flight test program.\n\nPreviously, all flights had been contained within the immediate vicinity of the airfield. This flight involved a broader navigation, demonstrating improved control and handling of the aircraft beyond a confined area. The flight was remotely piloted and furthered data collection related to the aircraft's performance and systems.\n\nThe VX4 is designed to carry a pilot and four passengers with zero operating emissions. Vertical Aerospace aims to achieve certification for the VX4 and launch commercial operations by 2026. This milestone is crucial for the ongoing development and certification process. The expansion of the flight envelope and the acquisition of more real-world data are essential steps towards achieving commercial viability and ultimately providing air taxi services. The company anticipates further flight testing in more complex environments in the future.\n",
    "chinese_title": "英国Vertical VX4 电动垂直起降飞行器首次在肯布尔航线外飞行",
    "chinese_summary": "英国Vertical Aerospace VX4电动垂直起降飞行器成功完成首次在格洛斯特郡肯布尔机场以外的飞行。这标志着其飞行测试项目的一个重要里程碑。\n\n此前，所有飞行均限制在机场附近。本次飞行涉及更广泛的导航，展示了飞机在限定区域之外的控制和操控能力的提升。此次飞行由远程操控，并进一步收集了与飞机性能和系统相关的数据。\n\nVX4旨在搭载一名飞行员和四名乘客，实现零运营排放。Vertical Aerospace的目标是获得VX4的认证，并在2026年启动商业运营。这一里程碑对于持续的开发和认证过程至关重要。飞行包线的扩展和更多真实世界数据的获取是实现商业可行性，并最终提供空中出租车服务的必要步骤。该公司预计未来将在更复杂的环境中进行进一步的飞行测试。"
  },
  {
    "id": "44128089",
    "title": "Quantum Computing and the Hidden Subgroup Problem",
    "url": "https://www.daniellowengrub.com/blog/2025/04/23/hidden-subgroup",
    "summary": "This article introduces the Hidden Subgroup Problem (HSP) and explains how it generalizes important quantum algorithms like Shor's algorithm for integer factorization and discrete logarithms, and Simon's algorithm.  The HSP involves identifying a hidden subgroup *H* within a larger group *G*, given a function *f* that hides *H* by mapping elements of *G* to a set *A* such that *f(g1) = f(g2)* if and only if *g1* and *g2* belong to the same coset of *H*.\n\nThe article highlights that while the HSP can be solved classically with O(|G|) function evaluations, quantum algorithms, particularly the \"standard method,\" offer significant speedups, achieving O(log(|G|)) evaluations when *G* is abelian.  It then frames Simon's problem and the discrete logarithm problem as instances of the HSP, demonstrating how solving the HSP can lead to efficient solutions for these problems.  Simon's problem involves finding a hidden bit-string *s*, while the discrete logarithm problem requires finding the exponent *s* such that *x = g^s mod p*.\n\nThe \"standard method\" involves creating a superposition of states, applying the function *f*, measuring the result, and then applying the Quantum Fourier Transform (QFT). The QFT diagonalizes shift operators, enabling the extraction of information about the hidden subgroup *H*. The article delves into the concept of characters (functions mapping group elements to complex numbers) as eigenvalues of shift operators, illustrating their properties and role in the QFT. Ultimately, understanding and applying the QFT is crucial for efficiently solving the HSP and its related problems.\n",
    "chinese_title": "量子计算与隐子群问题",
    "chinese_summary": "本文介绍了隐藏子群问题 (HSP)，并解释了它如何推广重要的量子算法，例如用于整数分解和离散对数的 Shor 算法以及 Simon 算法。HSP 涉及在一个更大的群 *G* 中识别一个隐藏的子群 *H*，给定一个函数 *f*，该函数通过将 *G* 的元素映射到一个集合 *A* 来隐藏 *H*，使得 *f(g1) = f(g2)* 当且仅当 *g1* 和 *g2* 属于 *H* 的同一个陪集。\n\n本文强调，虽然 HSP 可以用 O(|G|) 函数评估的经典方法解决，但量子算法，特别是“标准方法”，提供了显著的加速，当 *G* 是阿贝尔群时，可以达到 O(log(|G|)) 次评估。然后，它将 Simon 问题和离散对数问题视为 HSP 的实例，论证了解决 HSP 如何能为这些问题带来高效的解决方案。 Simon 问题涉及找到一个隐藏的比特串 *s*，而离散对数问题需要找到指数 *s*，使得 *x = g^s mod p*。\n\n“标准方法”包括创建状态的叠加，应用函数 *f*，测量结果，然后应用量子傅里叶变换 (QFT)。QFT 使移位算符对角化，从而能够提取有关隐藏子群 *H* 的信息。本文深入研究了作为移位算符的特征值的特征（将群元素映射到复数的函数）的概念，说明了它们的性质和在 QFT 中的作用。最终，理解和应用 QFT 对于有效解决 HSP 及其相关问题至关重要。"
  },
  {
    "id": "44139626",
    "title": "Photos taken inside musical instruments",
    "url": "https://www.dpreview.com/photography/5400934096/probe-lenses-and-focus-stacking-the-secrets-to-incredible-photos-taken-inside-instruments",
    "summary": "The article \"Photos taken inside musical instruments\" on dpreview.com discusses how photographer Charles Brooks creates stunning and unique images by photographing the interior of musical instruments. The article focuses on the techniques Brooks uses, primarily involving probe lenses and focus stacking.\n\nBrooks uses specialized probe lenses, like the Laowa 24mm f/14 Probe, to navigate the narrow and confined spaces within instruments. These lenses offer a wide field of view and allow for close-up focusing, capturing intricate details often unseen by the naked eye.\n\nDue to the shallow depth of field inherent in macro photography, particularly at such close distances, Brooks relies heavily on focus stacking. This involves taking multiple images, each focused on a different plane, and then combining them in post-processing software to create a final image with much greater depth of field and overall sharpness. Software like Helicon Focus or Zerene Stacker are mentioned as being useful for this process.\n\nThe article highlights the challenges of photographing inside instruments, including limited light and tight spaces. Brooks uses creative lighting solutions, often incorporating small LED lights, to illuminate the interior details.\n\nIn essence, the article explains that Charles Brooks achieves his remarkable images of instrument interiors through a combination of specialized equipment (probe lenses), meticulous technique (focus stacking), creative lighting, and artistic vision. The result is a series of photographs that reveal the hidden beauty and complexity within these familiar objects.\n",
    "chinese_title": "乐器内部拍摄的照片",
    "chinese_summary": "dpreview.com 上的文章《乐器内部摄影》探讨了摄影师 Charles Brooks 如何通过拍摄乐器内部，创作出令人惊艳且独特的照片。文章重点介绍了 Brooks 使用的技术，主要涉及探针镜头和焦点堆叠。\n\nBrooks 使用像老蛙 24mm f/14 探针镜头这样的专业探针镜头，以在乐器内部狭窄和密闭的空间中进行拍摄。这些镜头提供广阔的视野，并允许近距离对焦，从而捕捉肉眼通常看不到的复杂细节。\n\n由于微距摄影固有的景深浅，尤其是在如此近的距离下，Brooks 非常依赖焦点堆叠。 这涉及拍摄多张图像，每张图像都聚焦在不同的平面上，然后在后期处理软件中将它们组合在一起，以创建具有更大景深和整体清晰度的最终图像。 文章提到像 Helicon Focus 或 Zerene Stacker 这样的软件对此过程很有用。\n\n文章强调了在乐器内部摄影的挑战，包括光线有限和空间狭小。 Brooks 使用创造性的照明解决方案，通常结合小型 LED 灯，来照亮内部细节。\n\n本质上，文章解释说，Charles Brooks 通过结合专用设备（探针镜头）、细致的技术（焦点堆叠）、创造性的照明和艺术视野，实现了他卓越的乐器内部照片。 最终呈现出一系列照片，揭示了这些熟悉物体内部隐藏的美丽和复杂性。"
  },
  {
    "id": "44140918",
    "title": "Every 5x5 Nonogram",
    "url": "https://pixelogic.app/every-5x5-nonogram",
    "summary": "The article is titled \"Every 5x5 Nonogram\" and is hosted on a website that offers interactive nonogram puzzles. The user experienced a disconnection due to inactivity. The website promotes another nonogram game, \"Pixelogic - Daily Nonograms,\" created by the same developer. This game features daily puzzles and a library of over 6,000 human-crafted nonograms. The article encourages users to support the developer by downloading Pixelogic on iOS, Android, or Steam, or by subscribing to a newsletter to play on the web. It also promotes the Steam version via a wishlist link and emphasizes the email newsletter which sends new puzzles weekly. Essentially, the article presents a 5x5 Nonogram puzzle (though the user was disconnected), promotes the Pixelogic game, and suggests various ways to engage with and support the developer's work.\n",
    "chinese_title": "所有5x5 Nonogram",
    "chinese_summary": "文章标题为“每个5x5 Nonogram”，托管在一个提供互动Nonogram谜题的网站上。用户因不活跃而断开连接。该网站推广同一开发者制作的另一款Nonogram游戏，“Pixelogic - 每日 Nonograms”，该游戏提供每日谜题和一个包含6000多个人工制作的Nonogram谜题库。文章鼓励用户通过在iOS、Android或Steam上下载Pixelogic，或订阅时事通讯以在网络上玩游戏来支持开发者。它还通过愿望单链接推广Steam版本，并强调每周发送新谜题的电子邮件时事通讯。总而言之，这篇文章呈现了一个5x5 Nonogram谜题（尽管用户已断开连接），推广了Pixelogic游戏，并提出了参与和支持开发者工作的各种方式。"
  },
  {
    "id": "44147582",
    "title": "Show HN: Open-source P2P file transfer",
    "url": "https://github.com/nihaocami/berb",
    "summary": "This \"Show HN\" post introduces Berb, an open-source, privacy-focused web app for peer-to-peer file sharing. Berb utilizes WebRTC Data Channels to facilitate direct file transfers between devices, eliminating the need for intermediary servers and uploads. This ensures that files never touch a server, promoting both security and speed.\n\nKey features include:\n\n*   **Direct P2P transfer:** Uses WebRTC for secure and fast transfers.\n*   **Privacy-focused:** No server involvement means files stay between users.\n*   **Lightweight and simple:** Easy to use and set up.\n\nThe post also mentions ongoing development efforts and features planned for future releases, including auto-reconnect on network loss, multi-file support, and save stream functionality on compatible browsers. The author actively encourages contributions and suggests discussing any potential code changes through an issue before diving into development.\n",
    "chinese_title": "Show HN: 开源P2P文件传输",
    "chinese_summary": "这个“Show HN”帖子介绍 Berb，一个开源、注重隐私的点对点文件共享 Web 应用。Berb 利用 WebRTC 数据通道来促进设备之间的直接文件传输，无需中间服务器和上传。这确保文件永远不会接触服务器，从而提高安全性和速度。\n\n主要功能包括：\n\n*   **直接 P2P 传输：** 使用 WebRTC 进行安全快速的传输。\n*   **注重隐私：** 无需服务器参与，文件保留在用户之间。\n*   **轻量级且简单：** 易于使用和设置。\n\n该帖子还提到了正在进行的开发工作和计划在未来版本中发布的功能，包括网络丢失时自动重新连接、多文件支持以及在兼容浏览器上保存流的功能。作者积极鼓励贡献，并建议在投入开发之前通过 issue 讨论任何潜在的代码更改。"
  },
  {
    "id": "44148502",
    "title": "Structured Etymology Dataset",
    "url": "https://github.com/droher/etymology-db",
    "summary": "This document describes the \"etymology-db\" dataset, a structured, multilingual resource containing over 4.2 million etymological relationships between over 2 million terms in 3300+ languages, derived from Wiktionary data. The dataset offers 31 different types of etymological relations (inherited_from, borrowed_from, etc.), capturing how terms evolve across languages and distinguishing between different types of borrowing and derivation.\n\nThe dataset schema includes columns like `term_id`, `lang`, `term`, `reltype`, `related_term_id`, `related_lang`, `related_term`, and fields for handling nested relationships like compounds and affixes. The `reltype` column details the nature of the connection between terms. Relation types include inheritance, borrowing, derivation, root relationships, affixation, compounding, and other connections like calques, semantic loans, and onomatopoeia. Group relation types indicate complex nested relationships between terms.\n\nThe data is automatically extracted from Wiktionary and has not been manually validated. It is available for download in Gzipped CSV and Parquet formats. Wiktionary language codes are provided in a separate file, `wiktionary_codes.csv`. The data is licensed under Creative Commons ShareAlike 3.0, and the code is under Apache 2.0.\n",
    "chinese_title": "结构化词源数据集",
    "chinese_summary": "本文档介绍了“词源数据库”(etymology-db)数据集，这是一个结构化的多语言资源，包含超过420万个词源关系，涉及3300多种语言中超过200万个术语，数据来源于维基词典。该数据集提供31种不同的词源关系（继承自、借用自等），捕捉术语在不同语言中的演变方式，并区分不同类型的借用和派生。\n\n数据集模式包括`term_id`、`lang`、`term`、`reltype`、`related_term_id`、`related_lang`、`related_term`等列，以及用于处理嵌套关系（如复合词和词缀）的字段。`reltype`列详细说明了术语之间的连接性质。关系类型包括继承、借用、派生、词根关系、附加、复合以及其他连接，如仿译、语义借用和拟声词。组合关系类型表示术语之间复杂的嵌套关系。\n\n数据自动从维基词典提取，未经人工验证。它以Gzipped CSV和Parquet格式提供下载。维基词典语言代码在单独的文件`wiktionary_codes.csv`中提供。数据采用Creative Commons ShareAlike 3.0许可，代码采用Apache 2.0许可。"
  },
  {
    "id": "44151186",
    "title": "Do Patients Without a Terminal Illness Have the Right to Die?",
    "url": "https://www.nytimes.com/2025/06/01/magazine/maid-medical-assistance-dying-canada.html",
    "summary": "This New York Times article, dated June 1, 2025, explores the complexities of Medical Assistance in Dying (MAID) in Canada, specifically focusing on cases where patients are not terminally ill. The story centers on Paula Ritchie, a 52-year-old woman in Ontario seeking MAID due to unbearable physical pain and suffering. Despite not having a terminal illness, Paula desperately wants access to MAID as a \"more dignified way to go than suicide,\" having previously attempted suicide.\n\nThe article details Paula's difficult circumstances, including her deteriorating physical condition and intense pain that confines her to bed. It highlights the challenges faced by doctors assessing her eligibility for MAID. Dr. Matt Wonnacott, along with psychiatrist Dr. Elspeth MacEwan, are evaluating Paula after a previous clinician deemed her ineligible. The article reveals Paula's persistent efforts to be assessed, reflecting her profound desire to end her suffering. The doctors acknowledge her case is difficult, highlighting the ethical and medical complexities surrounding MAID for individuals without terminal illnesses.\n",
    "chinese_title": "没有身患绝症的病人有权选择死亡吗？",
    "chinese_summary": "2025年6月1日《纽约时报》文章探讨了加拿大医疗辅助死亡（MAID）的复杂性，特别是针对非绝症患者的案例。故事围绕着安大略省52岁的保拉·里奇展开，她因无法忍受的身体疼痛和痛苦而寻求MAID。尽管并非绝症，保拉仍迫切希望获得MAID，认为这比自杀“更有尊严”，因为她此前曾尝试自杀。\n\n文章详细描述了保拉的困境，包括她日益恶化的身体状况以及让她卧床不起的剧烈疼痛。它突出了医生评估她是否符合MAID资格时面临的挑战。马特·沃纳科特医生和精神科医生埃尔斯佩思·麦克尤恩医生正在对保拉进行评估，此前一位临床医生认为她不符合资格。文章揭示了保拉为获得评估所做的不懈努力，反映了她结束痛苦的强烈愿望。医生们承认她的情况很复杂，凸显了对非绝症患者实施MAID所涉及的伦理和医疗复杂性。"
  },
  {
    "id": "44145202",
    "title": "Show HN: PunchCard Key Backup",
    "url": "https://github.com/volution/punchcard-key-backup",
    "summary": "\"PunchCard Key Backup\" (pckb) is a project that allows users to physically back up 128 bits of data using a punched card system. The author provides a self-contained HTML tool (available at volution.ro/pckb or purl.org/999) that generates a hole punching pattern based on the input data (e.g., a hexadecimal representation of a 128-bit key).\n\nUsers can print a provided stencil, use it to punch holes in a small aluminum sheet according to the generated pattern, and store the physical card in a safe place. Recovery involves using the same HTML tool, matching checkboxes to the hole pattern (including a CRC check), and retrieving the original data.\n\nThe author emphasizes that the HTML tool is optional and provides Python code snippets for both generating the bit pattern and converting it back from binary. For data larger than 128 bits, encryption with a 128-bit password (backed up using pckb) is suggested, followed by sharing the encrypted data.\n\nThe system provides only a 16-bit CRC for error detection and focuses on using durable materials to minimize the need for redundancy. The system is flexible and can be combined with secret sharing schemes. The code and documentation are licensed under CC BY 4.0, with the possibility of alternative licensing under specific justified circumstances.\n",
    "chinese_title": "展示HN: 冲孔卡密钥备份",
    "chinese_summary": "打孔卡密钥备份 (pckb) 是一个项目，允许用户使用打孔卡系统物理备份 128 位数据。作者提供了一个独立的 HTML 工具（可在 volution.ro/pckb 或 purl.org/999 获取），该工具根据输入数据（例如，128 位密钥的十六进制表示）生成打孔模式。\n\n用户可以打印提供的模板，用它在小铝片上按照生成的模式打孔，并将物理卡片存储在安全的地方。恢复过程包括使用相同的 HTML 工具，将复选框与孔的模式相匹配（包括 CRC 校验），并检索原始数据。\n\n作者强调 HTML 工具是可选的，并提供了 Python 代码片段，用于生成位模式和从二进制文件转换回位模式。对于大于 128 位的数据，建议使用 128 位密码（使用 pckb 备份）进行加密，然后共享加密数据。\n\n该系统仅提供 16 位 CRC 用于错误检测，并侧重于使用耐用材料以尽量减少冗余的需要。该系统灵活，可以与秘密共享方案结合使用。代码和文档在 CC BY 4.0 许可下发布，在特定合理的条件下，也可能采用其他许可方式。"
  },
  {
    "id": "44148108",
    "title": "Firefox now allows you to add custom search engine manually by default",
    "url": "https://bugzilla.mozilla.org/show_bug.cgi?id=1967739",
    "summary": "This document details the bug fix that enables the \"browser.urlbar.update2.engineAliasRefresh\" preference by default in Firefox. This enhancement introduces a user-facing feature allowing users to manually add custom search engines to Firefox.\n\nPreviously, this feature was behind a preference (disabled by default), but now it's enabled for all users. The key benefit is the ability to add custom search engines via right-clicking in a search field on supported websites and selecting \"Add Search Engine\" or by navigating to Settings > Search > Add.\n\nThe release note suggests the following wording to notify users of this functionality: \"Firefox now supports adding your own custom search engines. Just right-click a search field of a supported website and select Add Search Engine, or go to Settings > Search > Add (below the search shortcuts table) to manually enter a search URL.\"\n\nThe change was verified in Firefox versions 140.0b2 and 141.0a1 on Windows 11 and Ubuntu 24.04, confirming that the preference is now enabled by default. The bug is marked as VERIFIED and FIXED.\n",
    "chinese_title": "Firefox现在默认允许手动添加自定义搜索引擎。",
    "chinese_summary": "本文详细介绍了修复的错误，该错误默认在 Firefox 中启用了 \"browser.urlbar.update2.engineAliasRefresh\" 首选项。此增强功能引入了一项面向用户的功能，允许用户手动向 Firefox 添加自定义搜索引擎。\n\n此前，此功能隐藏在首选项后面（默认禁用），但现在已为所有用户启用。主要优势是能够通过右键单击受支持网站上的搜索字段并选择“添加搜索引擎”，或通过导航至设置 > 搜索 > 添加来添加自定义搜索引擎。\n\n发布说明建议使用以下措辞来通知用户此功能：“Firefox 现在支持添加您自己的自定义搜索引擎。只需右键单击受支持网站的搜索字段并选择“添加搜索引擎”，或转到设置 > 搜索 > 添加（搜索快捷方式表下方）以手动输入搜索 URL。”\n\n该更改已在 Windows 11 和 Ubuntu 24.04 上的 Firefox 版本 140.0b2 和 141.0a1 中得到验证，确认该首选项现在默认启用。该错误已标记为 VERIFIED 和 FIXED。"
  },
  {
    "id": "44148971",
    "title": "Vintage Machinery",
    "url": "http://wiki.vintagemachinery.org/",
    "summary": "VintageMachinery.org is a website and wiki serving as a knowledge base dedicated to vintage machinery, particularly those related to woodworking and metalworking. Its primary goal is to provide information, resources, and a community for enthusiasts and restorers of older machines.\n\nThe website acts as a central repository for information like machine manuals, catalogs, serial number information (for dating machines), photographs, and discussions regarding the identification, restoration, and use of vintage machinery. It aims to preserve the history and knowledge surrounding these machines, allowing users to research specific models, find replacement parts, and learn about proper maintenance and operating procedures.\n\nThe \"Knowledge Base (Wiki)\" aspect emphasizes the collaborative nature of the site, allowing users to contribute information, correct errors, and expand the existing database. This collaborative approach ensures the information remains accurate, up-to-date, and comprehensive.\n\nIn essence, VintageMachinery.org is a valuable resource for anyone interested in the history, restoration, or use of vintage woodworking and metalworking machinery, offering a wealth of information and a supportive community.\n",
    "chinese_title": "老式机械",
    "chinese_summary": "VintageMachinery.org是一个致力于老式机械（特别是木工和金属加工机械）的知识库网站和维基。其主要目标是为老式机械爱好者和修复者提供信息、资源和一个社区。\n\n该网站作为信息中心，提供诸如机器手册、目录、序列号信息（用于确定机器年代）、照片以及关于老式机械的识别、修复和使用的讨论。它旨在保护围绕这些机器的历史和知识，允许用户研究特定型号，查找更换零件，并学习正确的维护和操作程序。\n\n“知识库（维基）”方面强调了该网站的协作性质，允许用户贡献信息、纠正错误并扩展现有数据库。这种协作方法确保信息保持准确、最新和全面。\n\n本质上，VintageMachinery.org 对于任何对老式木工和金属加工机械的历史、修复或使用感兴趣的人来说，都是一个宝贵的资源，提供了丰富的信息和一个支持性的社区。"
  },
  {
    "id": "44147631",
    "title": "The NFS 4 Freezer Spacer In Science Fiction Sets",
    "url": "https://kolektiva.social/@beka_valentine/114600567753999701",
    "summary": "This single line from Mastodon hints at a behind-the-scenes secret regarding props used in science fiction sets, specifically mentioning \"NFS 4 Freezer Spacer.\" The author, Beka Valentine, implies that this item, whatever it is, is commonly, and perhaps surprisingly, used in the construction or decoration of these sets.\n\nThe post's truncated nature unfortunately provides no further details. We don't know *why* it's used, what its purpose is in the set design, or even what an \"NFS 4 Freezer Spacer\" actually is. The key takeaway is the suggestion that there's a common, perhaps unconventional, material used in sci-fi set building that the author is about to reveal. The fact that they call it a \"dirty little secret\" implies it's perhaps not a glamorous or widely acknowledged aspect of the process. To find out more, one would need to find the complete post from Beka Valentine on Kolektiva.social.\n",
    "chinese_title": "科幻片场中的NFS 4冷冻舱间隔装置",
    "chinese_summary": "来自Mastodon的这一条消息暗示了一个关于科幻场景道具的幕后秘密，特别提到了“NFS 4 冷冻仓垫片”。作者Beka Valentine暗示，无论这东西是什么，它都被普遍地（也许令人惊讶地）用于这些场景的搭建或装饰中。\n\n这条消息的简短性质不幸地没有提供更多细节。我们不知道*为什么*它被使用，它在场景设计中的目的是什么，甚至不知道“NFS 4 冷冻仓垫片”到底是什么。 关键在于，它暗示了一种常见的、可能非常规的材料被用于科幻场景搭建中，作者即将揭露这个秘密。 她称之为“肮脏的小秘密”的事实表明，这可能不是该过程一个光鲜或广为人知的方面。 要了解更多信息，需要找到Beka Valentine在Kolektiva.social上的完整帖子。"
  },
  {
    "id": "44142255",
    "title": "How Georgists Valued land in the 1900's",
    "url": "https://progressandpoverty.substack.com/p/how-georgists-valued-land-in-the",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "1900年代格奥尔格主义者如何评估土地",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44142839",
    "title": "The Trackers and SDKs in ChatGPT, Claude, Grok and Perplexity",
    "url": "https://jamesoclaire.com/2025/05/31/the-trackers-and-sdks-in-chatgpt-claude-grok-and-perplexity/",
    "summary": "This article summarizes the third-party SDKs and API calls found in the Android apps of ChatGPT, Claude, Grok, and Perplexity, using data from AppGoblin. The analysis covers development tools, business tools, and API calls.\n\n**Development Tools:** All four apps primarily utilize Kotlin and associated libraries like Kotlin Coil Compose, Lottie, and Square's okhttp3, indicating a classic Kotlin-based development approach rather than reliance on dynamic JavaScript libraries like React.\n\n**Business Tools:** The apps integrate various SDKs for analytics, monetization, and other functionalities. Google's tools (GMS, Firebase) are universally used for analytics. Statsig is a prominent analytics platform used in ChatGPT, Claude, and Grok. OpenAI and Anthropic also use Segment and Sentry for analytics. Regarding monetization, RevenueCat is used by OpenAI and Perplexity for web payment/subscription walls. Livekit.io, an AI voice platform, is used by OpenAI and Grok. Perplexity utilizes MapBox (mapping tiles), Shopify, Stripe, and Singular.net. The analysis revealed a surprisingly high number of SDKs, with OpenAI having the most (10), followed by Perplexity (7), Anthropic (6), and Grok (5). The presence of Shopify in Perplexity's app led the author to question OpenAI's shopping feature implementation, as no Shopify SDK was detected.\n\n**API Calls:** The article also mentions the availability of scrubbed API call data for each app on AppGoblin's website, allowing for further research into specific data transmission.\n",
    "chinese_title": "ChatGPT、Claude、Grok和Perplexity中的追踪器与SDK",
    "chinese_summary": "本文总结了 ChatGPT、Claude、Grok 和 Perplexity 的 Android 应用中发现的第三方 SDK 和 API 调用，数据来自 AppGoblin。分析涵盖开发工具、商业工具和 API 调用。\n\n**开发工具：** 所有四个应用主要使用 Kotlin 和相关库，如 Kotlin Coil Compose、Lottie 和 Square 的 okhttp3，表明采用的是经典的基于 Kotlin 的开发方法，而不是依赖于像 React 这样的动态 JavaScript 库。\n\n**商业工具：** 这些应用集成了各种用于分析、货币化和其他功能的 SDK。谷歌的工具（GMS、Firebase）被普遍用于分析。Statsig 是 ChatGPT、Claude 和 Grok 中使用的一个重要的分析平台。OpenAI 和 Anthropic 也使用 Segment 和 Sentry 进行分析。关于货币化，OpenAI 和 Perplexity 使用 RevenueCat 来实现网页支付/订阅墙。OpenAI 和 Grok 使用 AI 语音平台 Livekit.io。Perplexity 使用 MapBox（地图瓦片）、Shopify、Stripe 和 Singular.net。分析显示 SDK 的数量惊人，其中 OpenAI 数量最多 (10)，其次是 Perplexity (7)、Anthropic (6) 和 Grok (5)。在 Perplexity 的应用程序中出现 Shopify，让作者质疑 OpenAI 的购物功能实现方式，因为没有检测到 Shopify SDK。\n\n**API 调用：** 本文还提到 AppGoblin 的网站上提供了每个应用经过清理的 API 调用数据，允许进一步研究具体的数据传输。"
  },
  {
    "id": "44146744",
    "title": "Sguaba: Hard-to-misuse rigid body transforms for engineers",
    "url": "https://blog.helsing.ai/sguaba-hard-to-misuse-rigid-body-transforms-for-engineers-with-other-things-to-worry-about-than-aeaa45af9e0d",
    "summary": "Sguaba is a new open-source Rust crate designed to prevent coordinate system errors in software dealing with real-world coordinates. Developed by Helsing, it's aimed at engineers who need to handle coordinate transformations but don't want to get bogged down in complex linear algebra. Sguaba strongly types coordinates and vectors with their respective coordinate systems and provides conversions between them, making it difficult to accidentally mix them up.\n\nThe library uses quaternions under the hood (via the nalgebra crate) but exposes user-friendly types like Coordinate, Vector, Orientation, and Pose. Transformations happen through the RigidBodyTransform type, which enforces coordinate system type safety during conversions.\n\nThe article demonstrates Sguaba's usage with an example of a pilot observing an object and wanting to determine its location in WGS84 coordinates. The example showcases how to define coordinate systems (e.g., PlaneFrd, PlaneNed), create transformations between them (using `RigidBodyTransform`), and chain these transformations to convert between coordinate frames.  The transform construction uses `unsafe` code to assert the validity of coordinate system relationships.\n\nWhile Sguaba is already in use, the authors acknowledge potential improvements, such as adding support for ENU and ECI coordinate systems, enhancing documentation, and increasing test coverage. They encourage contributions from the community through pull requests, issue reports, and general feedback. They hope Sguaba will help others avoid coordinate handling errors, as it has done at Helsing.\n",
    "chinese_title": "Sguaba：工程师易用的刚体变换",
    "chinese_summary": "Sguaba：一款用于防止现实世界坐标软件中坐标系错误的新型开源Rust库。由Helsing开发，旨在帮助需要处理坐标变换的工程师，避免陷入复杂的线性代数。Sguaba 对坐标和向量及其相应的坐标系进行强类型定义，并提供它们之间的转换，从而避免意外混淆。\n\n该库在底层使用四元数（通过nalgebra crate），但公开了用户友好的类型，如Coordinate、Vector、Orientation和Pose。变换通过RigidBodyTransform类型进行，该类型在转换过程中强制执行坐标系类型安全。\n\n文章通过一个飞行员观察物体并希望确定其在WGS84坐标系中的位置的例子，演示了Sguaba的用法。该示例展示了如何定义坐标系（例如，PlaneFrd、PlaneNed），创建它们之间的变换（使用`RigidBodyTransform`），以及链接这些变换以在坐标系之间进行转换。变换构造使用`unsafe`代码来断言坐标系关系的有效性。\n\n虽然Sguaba 已经在使用中，但作者承认存在潜在的改进，例如增加对ENU和ECI坐标系的支持、增强文档以及增加测试覆盖率。他们鼓励社区通过pull request、问题报告和一般反馈来贡献。他们希望Sguaba 能够像在Helsing一样，帮助其他人避免坐标处理错误。"
  },
  {
    "id": "44142436",
    "title": "AccessOwl (YC S22) is hiring an AI TypeScript Engineer to connect 100s of SaaS",
    "url": "https://www.ycombinator.com/companies/accessowl/jobs/hfWAhVp-ai-enabled-senior-software-engineer-typescript-focus",
    "summary": "AccessOwl (YC S22), a profitable startup revolutionizing SaaS application management with AI, is hiring a remote Senior Software Engineer specializing in TypeScript. They aim to simplify SaaS access, spending, and compliance for businesses, replacing solutions like Okta with their innovative RPA and AI-driven approach.\n\nThe ideal candidate has 3+ years of web software development experience, with a strong focus on JavaScript and TypeScript, and experience with Playwright or Puppeteer. Experience with Elixir is a plus. The role involves developing and maintaining integrations with hundreds of SaaS tools, building browser extensions, and contributing to product discussions. A key requirement is an interest in leveraging AI to solve problems.\n\nAccessOwl offers a competitive salary (€70K - €90K) plus stock options, fully remote work within ±3 hours of CET, flexible hours, and the opportunity to shape an exciting SaaS startup. They're looking for someone proactive, opinionated but open-minded, and passionate about solving customer problems. The interview process includes a home assignment, initial introduction, skills and culture interviews, and a paid test phase.\n",
    "chinese_title": "AccessOwl (YC S22) 正在招聘一位 AI TypeScript 工程师，以连接数百个 SaaS。",
    "chinese_summary": "AccessOwl (YC S22)，一家利用人工智能革新SaaS应用管理并已盈利的初创公司，正在招聘一位远程高级软件工程师，专长TypeScript。他们的目标是简化企业的SaaS访问、支出和合规性，以其创新的RPA和人工智能驱动方法取代Okta等解决方案。\n\n理想的候选人需具备3年以上Web软件开发经验，精通JavaScript和TypeScript，并有Playwright或Puppeteer经验。有Elixir经验者优先。 该职位涉及开发和维护与数百个SaaS工具的集成、构建浏览器扩展以及参与产品讨论。关键要求是对利用人工智能解决问题感兴趣。\n\nAccessOwl提供具有竞争力的薪资（7万欧元 - 9万欧元）加股票期权，CET时区±3小时内的完全远程工作，灵活的工作时间，以及塑造一家令人兴奋的SaaS初创公司的机会。他们正在寻找积极主动、有主见但思想开放，并且热衷于解决客户问题的人。面试过程包括家庭作业、初步介绍、技能和文化面试以及有偿测试阶段。"
  },
  {
    "id": "44146744",
    "title": "Sguaba: Hard-to-misuse rigid body transforms for engineers",
    "url": "https://blog.helsing.ai/sguaba-hard-to-misuse-rigid-body-transforms-for-engineers-with-other-things-to-worry-about-than-aeaa45af9e0d",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "Sguaba：面向工程师的难用错的刚体变换",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44144407",
    "title": "Atlas: Learning to Optimally Memorize the Context at Test Time",
    "url": "https://arxiv.org/abs/2505.23735",
    "summary": "This arXiv article (arXiv:2505.23735) introduces ATLAS, a novel long-term memory module designed to improve the performance of sequence models, particularly in tasks requiring long context understanding. Authored by Ali Behrouz, Zeman Li, and others, the paper addresses limitations of current sequence modeling architectures, including Transformers and modern recurrent neural networks, specifically concerning their memory capacity, online update nature, and memory management.\n\nThe authors argue that these limitations hinder performance in long-context tasks. ATLAS overcomes these issues by providing a high-capacity memory that learns to memorize context by optimizing memory based on both current and past tokens, a departure from the online update approach.\n\nFurthermore, the paper introduces DeepTransformers, a new family of Transformer-like architectures that generalize the original Transformer. Experimental results on language modeling, common-sense reasoning, recall-intensive tasks, and long-context understanding demonstrate that ATLAS outperforms Transformers and recent linear recurrent models. Notably, ATLAS significantly improves the long context performance of Titans, achieving a substantial accuracy boost on the BABILong benchmark.\n\nIn essence, ATLAS offers a solution to the memory and context understanding bottlenecks present in existing sequence models, leading to enhanced performance in tasks demanding long-range dependencies.\n",
    "chinese_title": "Atlas：学习在测试时优化记忆上下文",
    "chinese_summary": "该 arXiv 文章 (arXiv:2505.23735) 介绍了 ATLAS，一种新型长时记忆模块，旨在提高序列模型的性能，尤其是在需要长上下文理解的任务中。该论文由 Ali Behrouz、Zeman Li 等人撰写，旨在解决当前序列建模架构（包括 Transformer 和现代循环神经网络）的局限性，特别是关于它们的记忆容量、在线更新特性和记忆管理。\n\n作者认为，这些局限性阻碍了长上下文任务的性能。ATLAS 通过提供高容量记忆来克服这些问题，该记忆通过优化基于当前和过去 token 的记忆来学习记忆上下文，这与在线更新方法不同。\n\n此外，该论文还介绍了 DeepTransformers，这是一个新的类 Transformer 架构系列，它推广了原始 Transformer。在语言建模、常识推理、召回密集型任务和长上下文理解方面的实验结果表明，ATLAS 优于 Transformer 和最新的线性循环模型。值得注意的是，ATLAS 显着提高了 Titans 的长上下文性能，并在 BABILong 基准测试中实现了显着的准确性提升。\n\n本质上，ATLAS 提供了一种解决方案，可以解决现有序列模型中存在的记忆和上下文理解瓶颈，从而提高对需要远程依赖关系的任务的性能。"
  },
  {
    "id": "44149601",
    "title": "Science cuts may close WA LIGO observatory that confirmed theory of relativity",
    "url": "https://www.tri-cityherald.com/news/business/health-care/article307573471.html",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "科学经费削减或将关闭证实相对论的华盛顿州激光干涉引力波天文台",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44144308",
    "title": "Using Ed(1) as My Static Site Generator",
    "url": "https://aartaka.me/this-post-is-ed.html",
    "summary": "Artyom Bologov describes his unconventional choice of using the `ed` text editor as a static site generator, motivated by a recurring tendency to re-evaluate his tech stack. He's previously experimented with Tripod, Lisp, and the C Preprocessor for this purpose.\n\nHe explains how `ed` scripts are executed to process and convert files into different formats, enabling a flexible syntax unlike the restrictions imposed by the C Preprocessor. Advantages include being able to use any syntax he wants, not needing to rewrite old posts, and avoiding issues with special characters. `ed`'s regex-based substitutions and interactive nature are also beneficial for text processing.\n\nHowever, `ed` has limitations, primarily the lack of file inclusion. He admits to potential syntax over-complication due to `ed`'s flexibility, making a potential rollback to another system difficult. He encountered issues with version differences between Arch and Alpine Linux's `ed` implementations, necessitating a CI platform swap for builds.\n\nUltimately, Bologov acknowledges that using `ed` as a site generator is not a practical solution for most but a fun, albeit unusual, experiment driven by his personal interests. He doesn't recommend it unless you are bored and have lots of free time.\n",
    "chinese_title": "使用Ed(1)作为我的静态站点生成器",
    "chinese_summary": "阿乔姆·博洛戈夫讲述了他使用`ed`文本编辑器作为静态站点生成器的非传统选择，其动机在于他不断重新评估自己的技术栈。他此前曾尝试过Tripod、Lisp和C预处理器来实现此目的。\n\n他解释了如何执行`ed`脚本来处理并将文件转换为不同的格式，从而实现了一种灵活的语法，不像C预处理器那样受到限制。优势包括可以使用任何想要的语法，无需重写旧文章，以及避免特殊字符问题。`ed`基于正则表达式的替换和交互式特性也有利于文本处理。\n\n然而，`ed`也有局限性，主要是缺少文件包含功能。他承认，由于`ed`的灵活性，可能会导致语法过度复杂，使得回滚到其他系统变得困难。他还遇到了Arch和Alpine Linux的`ed`实现之间版本差异的问题，需要更换CI平台进行构建。\n\n最终，博洛戈夫承认使用`ed`作为站点生成器对于大多数人来说并非一个实用的解决方案，而是一个有趣的，尽管不寻常的，由他的个人兴趣驱动的实验。他不建议这样做，除非你很无聊并且有很多空闲时间。"
  },
  {
    "id": "44142761",
    "title": "Using lots of little tools to aggressively reject the bots",
    "url": "https://lambdacreate.com/posts/68",
    "summary": "The author describes a sudden influx of bot traffic overwhelming their personal server, specifically targeting their Gitea instance for scraping Git repositories. Initially, they experienced disk space exhaustion and CPU/memory alerts due to the excessive traffic. While archival sites like Archive.org are welcome, the author objects to corporations like Amazon, Facebook, and OpenAI scraping their content for self-serving purposes, particularly to train AI models.\n\nTo combat this, they used various system administration tools for analysis and mitigation. Using Zabbix, they identified a tenfold increase in web traffic. Using lnav, they analyzed server logs, identifying patterns and user agents associated with the offending bots. They then implemented a multi-layered defense in Nginx: a user-agent blocklist resulting in 403 errors, and rate limiting to slow down unidentified scrapers. Finally, they deployed Fail2Ban to automatically ban IP addresses repeatedly generating 403 errors due to blocked user agents. This resulted in hundreds of IP bans.\n\nThe author concludes that these measures have effectively mitigated the scraping, allowing them to maintain their services and continue creating content. They express a desire to refine the rules in the future, potentially allowing legitimate services while preventing AI training data harvesting. They emphasize that this is necessary because of the excessive resource consumption caused by scraping efforts.\n",
    "chinese_title": "使用大量小工具来积极阻止机器人。",
    "chinese_summary": "作者描述了大量机器人流量突然涌入并压垮其个人服务器的情况，这些流量专门针对其Gitea实例，意图抓取Git仓库。最初，由于过多的流量，他们经历了磁盘空间耗尽和CPU/内存警报。虽然欢迎Archive.org等存档站点，但作者反对亚马逊、Facebook和OpenAI等公司为了自身利益抓取其内容，尤其是用于训练AI模型。\n\n为了应对这种情况，他们使用了各种系统管理工具进行分析和缓解。通过Zabbix，他们发现Web流量增加了十倍。通过lnav，他们分析了服务器日志，识别出与恶意机器人相关的模式和用户代理。然后，他们在Nginx中实施了多层防御：一个导致403错误的User-Agent黑名单，以及用于减缓未知抓取程序的速率限制。最后，他们部署了Fail2Ban来自动禁止因被阻止的User-Agent反复生成403错误的IP地址。这导致了数百个IP被封禁。\n\n作者总结说，这些措施有效地缓解了抓取行为，使他们能够维护其服务并继续创建内容。他们表示希望在未来改进规则，可能允许合法的服务，同时防止AI训练数据的收集。他们强调，这是必要的，因为抓取行为导致了过多的资源消耗。"
  },
  {
    "id": "44144331",
    "title": "The Two Ideals of Fields",
    "url": "https://susam.net/two-ideals-of-fields.html",
    "summary": "This article explores the relationship between fields and their ideals, focusing on the fact that a field has only two ideals: the zero ideal and the field itself, known as trivial ideals. Conversely, it demonstrates that if a commutative ring with distinct additive and multiplicative identities has only trivial ideals, then it must be a field.\n\nThe article begins by defining left and right ideals of a ring, emphasizing that in commutative rings, they are equivalent, and we simply refer to them as ideals. It then provides examples of ideals in the integers and polynomial rings to illustrate the concept of ideals absorbing multiplication.\n\nThe core argument is presented in two parts. First, it proves that a field *K* has only two ideals, {0} and *K*. This is shown by considering an arbitrary ideal *I* of *K*. If *I* is not the zero ideal, it contains a non-zero element *b*. Because *K* is a field, *b* has a multiplicative inverse, which, when multiplied by *b* (which is in *I*), results in 1 being in *I*. Consequently, any element *c* in *K* can be expressed as 1 * c, and therefore *c* is also in *I*, meaning *I* = *K*.\n\nSecond, the article proves the converse: if a commutative ring *R* with 1 ≠ 0 has only the trivial ideals {0} and *R*, then *R* is a field. It shows that any non-zero element *a* in *R* has a multiplicative inverse by considering the ideal generated by *a*, denoted as <*a*>. Since <*a*> cannot be {0}, it must be *R*. Thus, 1 is an element of <*a*>, implying that there exists an *s* in *R* such that 1 = a * s, hence *s* is the multiplicative inverse of *a*. The remaining field properties are inherited from the ring *R*. The conclusion emphasizes the symmetry: fields have only trivial ideals, and commutative rings with distinct identities and only trivial ideals are fields.\n",
    "chinese_title": "域的两个理想",
    "chinese_summary": "本文探讨了域与其理想的关系，重点在于域只有两个理想：零理想和域本身，称为平凡理想。反之，本文论证了如果一个具有不同加法和乘法单位元的交换环只有平凡理想，那么它必定是一个域。\n\n本文首先定义了环的左理想和右理想，强调了在交换环中，它们是等价的，我们简单地称它们为理想。然后，本文提供了整数环和多项式环中理想的例子，以说明理想吸收乘法的概念。\n\n核心论点分为两部分。首先，它证明了域*K*只有两个理想，{0}和*K*。这是通过考虑*K*的任意理想*I*来证明的。如果*I*不是零理想，则它包含一个非零元素*b*。因为*K*是一个域，所以*b*具有乘法逆元，当它与*b*（在*I*中）相乘时，结果为1在*I*中。因此，*K*中的任何元素*c*都可以表示为1 * c，因此*c*也在*I*中，这意味着*I* = *K*。\n\n其次，本文证明了逆命题：如果一个具有1 ≠ 0的交换环*R*只有平凡理想{0}和*R*，那么*R*是一个域。它表明，通过考虑由*a*生成的理想，表示为<*a*>，*R*中的任何非零元素*a*都具有乘法逆元。由于<*a*>不能是{0}，因此它必须是*R*。因此，1是<*a*>的一个元素，这意味着在*R*中存在一个*s*，使得1 = a * s，因此*s*是*a*的乘法逆元。其余的域属性继承自环*R*。结论强调了对称性：域只有平凡理想，而具有不同单位元且只有平凡理想的交换环是域。"
  },
  {
    "id": "44142254",
    "title": "Web dev is still fun if you want it to be",
    "url": "https://github.com/jchester/bobotw",
    "summary": "This article is a reflection on the author's experience developing a simple web application called \"Best of Best of the Worst\" and how it rekindled their enjoyment of web development. Frustrated with the complexities of modern web development practices involving large teams, complex frameworks, and endless meetings, the author deliberately chose a simpler, more old-school approach.\n\nThey opted for technologies like Sinatra, Sequel, and SQLite, reminiscent of the web development landscape of the late 2000s. This allowed them to focus on fundamental web technologies like HTML and SQL, bypassing the need for complex JavaScript frameworks like React or even HTMX. They embraced simple solutions like using `<form>` elements and server-side rendering because the performance was sufficient for their low-traffic site.\n\nThe author found joy in making practical decisions, such as naming images based on database IDs, employing a rudimentary cookie system for vote management, and utilizing Phlex for templating. They even experimented with AI for assistance, finding it helpful for certain tasks but ultimately rewriting its drafts. The author celebrates the speed, simplicity, and control afforded by this approach, contrasting it with the over-engineered and overly complex processes of modern web development. The entire process reminded them of the joy of programming. They conclude by advocating for developers to reclaim the fun in web development by embracing simplicity.\n",
    "chinese_title": "如果你想，网页开发仍然是有趣的。",
    "chinese_summary": "本文反思了作者开发名为“最差中的最佳”的简单Web应用程序的经验，以及它如何重新点燃了他们对Web开发的乐趣。由于大型团队、复杂框架和无休止的会议等现代Web开发实践的复杂性，作者感到沮丧，因此特意选择了一种更简单、更老派的方法。\n\n他们选择了像Sinatra、Sequel和SQLite这样的技术，让人想起2000年代末的Web开发景象。这使他们能够专注于像HTML和SQL这样的基本Web技术，绕过了对像React甚至HTMX这样复杂JavaScript框架的需求。他们采用了像使用`<form>`元素和服务器端渲染这样的简单解决方案，因为性能对于他们低流量的网站来说已经足够。\n\n作者发现，做出实际的决策带来了乐趣，例如基于数据库ID命名图像，采用基本的cookie系统进行投票管理，以及使用Phlex进行模板处理。他们甚至尝试使用AI来获得帮助，发现它对某些任务很有帮助，但最终还是重写了它的草稿。作者赞扬了这种方法所带来的速度、简单性和控制力，并将其与现代Web开发中过度设计和过度复杂的过程进行了对比。整个过程让他们想起了编程的乐趣。他们最后倡导开发者通过拥抱简单来重拾Web开发的乐趣。"
  },
  {
    "id": "44144451",
    "title": "Show HN: Fontofweb – Discover Fonts Used on a Website or Websites Using Font(s)",
    "url": "https://fontofweb.com",
    "summary": "Fontofweb is presented as a tool to discover and bookmark fonts used on websites. It provides statistics on its database: 470 fonts discovered, 297 websites checked, and 143 registered users. The \"Font of the Day\" is Cirka, designed by Nick Losacco, Pangram Pangram.\n\nThe bulk of the content lists websites and the fonts they use. Some listings also mention font sizes or additional information, such as the designer/foundry or specific version. Many popular fonts such as Inter, Open Sans, Neue Montreal, and Helvetica are frequently used across different websites. Several sites use icon fonts like Font Awesome or Icomoon. A variety of other unique and custom fonts are also listed.\n\nThe list is quite extensive, showcasing the diverse range of fonts used across the web and acting as a directory for discovering fonts based on websites.\n",
    "chinese_title": "Show HN: Fontofweb – 发现网站使用的字体，或使用特定字体的网站",
    "chinese_summary": "Fontofweb 是一个用于发现和收藏网站上使用字体的工具。它提供了数据库统计信息：已发现 470 种字体，已检查 297 个网站，以及 143 位注册用户。今日推荐字体是 Cirka，由 Nick Losacco, Pangram Pangram 设计。\n\n网站的大部分内容列出了网站及其使用的字体。一些列表还提到字体大小或额外信息，例如设计师/字体公司或特定版本。许多流行的字体，如 Inter、Open Sans、Neue Montreal 和 Helvetica，经常在不同的网站上使用。一些网站使用图标字体，如 Font Awesome 或 Icomoon。还列出了各种其他独特的和自定义的字体。\n\n该列表非常广泛，展示了网络上使用的各种字体，并充当基于网站发现字体的目录。"
  },
  {
    "id": "44150244",
    "title": "Report says Sony won't produce smartphones in its own factories anymore",
    "url": "https://techissuestoday.com/sony-xperia-production-outsourced/",
    "summary": "Sony is reportedly shifting its smartphone production strategy away from its own factories, opting to rely increasingly on external manufacturers. This change, indicated by the removal of \"smartphones\" from the list of products manufactured at Sony's Thailand and China factories, signals a significant pivot, even for flagship models like the Xperia 1 VII.\n\nThis move raises concerns about potential impacts on the quality and the distinctive \"Sony feel\" of Xperia phones, especially among long-time users accustomed to the \"Made in Thailand\" label. However, the article notes that many top tech companies, including Apple, successfully utilize Chinese OEM manufacturers.\n\nThis shift is a change from Sony's 2019 strategy of consolidating smartphone production in Thailand after closing its Beijing plant, aiming to improve profitability. Despite affirming its commitment to the smartphone business at the time, Sony's market share has remained low.\n\nThe article suggests that this new approach may be a strategic response to the competitive smartphone market, allowing Sony to concentrate on design, technology, and brand experience while outsourcing manufacturing. The ultimate success of this strategy remains to be seen.\n",
    "chinese_title": "报告称索尼将不再在自有工厂生产智能手机。",
    "chinese_summary": "据报道，索尼正在转变其智能手机生产策略，不再依赖自有工厂，而是更多地依赖外部制造商。 索尼泰国和中国工厂生产的产品列表中移除了“智能手机”这一项，表明这一转变意义重大，即使是像Xperia 1 VII这样的旗舰机型也不例外。\n\n此举引发了人们对Xperia手机质量和独特“索尼感”可能受到的影响的担忧，尤其是在习惯了“泰国制造”标签的长期用户中。 但文章指出，包括苹果在内的许多顶级科技公司都成功地利用了中国的OEM制造商。\n\n这一转变与索尼2019年在关闭北京工厂后将智能手机生产集中在泰国以提高盈利能力的策略不同。 尽管当时索尼重申了对智能手机业务的承诺，但其市场份额仍然很低。\n\n文章认为，这种新方法可能是对竞争激烈的智能手机市场的一种战略性回应，使索尼能够专注于设计、技术和品牌体验，同时外包制造。 这一策略最终能否成功还有待观察。"
  },
  {
    "id": "44116130",
    "title": "Designing Pareto-optimal RAG workflows with syftr",
    "url": "https://www.datarobot.com/blog/pareto-optimized-ai-workflows-syftr/",
    "summary": "This article introduces `syftr`, an open-source framework designed to efficiently identify Pareto-optimal generative AI workflows, particularly for Retrieval-Augmented Generation (RAG) pipelines. The core problem `syftr` addresses is the combinatorial explosion of choices in building GenAI workflows (retrievers, prompt strategies, models, etc.), making manual trial-and-error infeasible at scale.\n\n`Syftr` uses multi-objective Bayesian Optimization to search for workflows that balance accuracy, cost, and latency. A novel \"Pareto Pruner\" early stopping mechanism further optimizes this process, reducing computational cost. The framework aims to address the gap between model-level benchmarks and real-world system performance.\n\nKey highlights include `syftr`'s ability to identify workflows that significantly reduce costs while maintaining accuracy. It's built on open-source libraries like Ray, Optuna, and LlamaIndex. A case study using the CRAG Sports benchmark demonstrates how `syftr` can outperform general-purpose solutions and even enhance performance with prompt optimization tools like Trace.  The framework is modular, allowing for easy extension and customization.  The authors invite community contributions and are working on enhancements like meta-learning, multi-agent workflow evaluation, and expanding task support. The article concludes by encouraging readers to explore the GitHub repository and research paper.\n",
    "chinese_title": "使用syftr设计帕累托最优的RAG工作流程",
    "chinese_summary": "本文介绍`syftr`，一个开源框架，旨在高效识别帕累托最优的生成式人工智能工作流程，特别是用于检索增强生成(RAG)流水线。`syftr`解决的核心问题是构建GenAI工作流程（检索器、提示策略、模型等）时选择的组合爆炸，使得大规模的手动试错变得不可行。\n\n`Syftr`使用多目标贝叶斯优化来搜索平衡准确性、成本和延迟的工作流程。一种新颖的“帕累托修剪器”提前停止机制进一步优化了这一过程，降低了计算成本。该框架旨在解决模型级基准和现实世界系统性能之间的差距。\n\n主要亮点包括`syftr`识别能够显著降低成本同时保持准确性的工作流程的能力。它构建在Ray、Optuna和LlamaIndex等开源库之上。一个使用CRAG Sports基准的案例研究表明，`syftr`可以胜过通用解决方案，甚至可以通过Trace等提示优化工具来提高性能。该框架是模块化的，可以轻松扩展和定制。作者邀请社区贡献，并正在努力进行诸如元学习、多代理工作流程评估以及扩展任务支持等增强。文章最后鼓励读者探索GitHub存储库和研究论文。"
  },
  {
    "id": "44148179",
    "title": "Of course the Apple Network Server can be hacked into running Doom",
    "url": "http://oldvcr.blogspot.com/2025/05/harpoom-of-course-apple-network-server.html",
    "summary": "This article humorously chronicles the author's journey to port the classic game Doom to the Apple Network Server (ANS), a 1996 server running IBM AIX 4.1.5. The author explains the historical context of AIX, its significance in the PowerOpen era, and why Doom was never officially ported to it.\n\nThe main challenge is adapting Doom Generic, a hardware-agnostic version of Doom, to the older AIX environment. This involves dealing with compatibility issues related to the vintage compiler (gcc 2.95.2), missing header files like `inttypes.h` and `stdbool.h`, and conflicts with AIX-specific types. The author provides solutions to these problems, including creating a custom `stdint.h` file, commenting out conflicting boolean definitions, and renaming a conflicting type in `i_video.c`.\n\nAnother significant hurdle is the lack of support for the X Keyboard Extension (Xkb) in the older X11R5. This requires substituting `X11/XKBlib.h` with `X11/keysym.h` and adapting code related to keyboard input. The author also details fixes needed due to pre-C99 variable declaration rules.\n\nUltimately, the author succeeds in compiling and linking a functional Doom executable for the ANS, albeit without sound due to the lack of an AIX sound driver for ANS audio. The port, dubbed \"Harpoom,\" runs on the ANS console under CDE and is tested on both the ANS hardware and an IBM PowerPC AIX laptop. The article provides a practical guide to overcoming compilation and compatibility issues on legacy systems.\n",
    "chinese_title": "苹果网络服务器当然可以被破解运行毁灭战士。",
    "chinese_summary": "本文以幽默的笔触记录了作者将经典游戏 Doom 移植到 Apple Network Server (ANS) 上的过程。这台服务器是 1996 年的，运行 IBM AIX 4.1.5 系统。作者解释了 AIX 的历史背景、它在 PowerOpen 时代的意义，以及 Doom 从未被官方移植到该系统的原因。\n\n主要挑战是将 Doom Generic（一个与硬件无关的 Doom 版本）适配到较旧的 AIX 环境。这涉及到处理与老式编译器 (gcc 2.95.2) 相关的兼容性问题、缺失的头文件（如 `inttypes.h` 和 `stdbool.h`）以及与 AIX 特定类型的冲突。作者提供了解决这些问题的方法，包括创建自定义的 `stdint.h` 文件、注释掉冲突的布尔定义以及重命名 `i_video.c` 中的冲突类型。\n\n另一个重大障碍是旧版 X11R5 缺乏对 X 键盘扩展 (Xkb) 的支持。这需要用 `X11/keysym.h` 替换 `X11/XKBlib.h` 并修改与键盘输入相关的代码。作者还详细介绍了由于 C99 之前的变量声明规则而需要的修复。\n\n最终，作者成功地为 ANS 编译并链接了一个可运行的 Doom 可执行文件，尽管由于 ANS 音频缺乏 AIX 声卡驱动程序而没有声音。这个移植版本被称为 \"Harpoom\"，可以在 CDE 下的 ANS 控制台上运行，并在 ANS 硬件和 IBM PowerPC AIX 笔记本电脑上进行了测试。本文为克服遗留系统上的编译和兼容性问题提供了一个实用的指南。"
  },
  {
    "id": "44148032",
    "title": "Google AI Edge Gallery",
    "url": "https://github.com/google-ai-edge/gallery",
    "summary": "The Google AI Edge Gallery is an experimental app showcasing the potential of on-device Generative AI. Available on Android (iOS coming soon), it allows users to explore, experience, and evaluate cutting-edge AI models directly on their devices, completely offline after initial model download.\n\nThe app offers several core features: \"Ask Image\" (question answering about uploaded images), \"Prompt Lab\" (for single-turn LLM tasks like summarization and code generation), and \"AI Chat\" (for multi-turn conversations). Users can switch between different models from Hugging Face and benchmark their performance with real-time metrics like TTFT, decode speed, and latency. Advanced users can also test their own local LiteRT .task models.\n\nThe gallery leverages Google AI Edge APIs and tools, including LiteRT (a lightweight runtime) and the LLM Inference API, to enable optimized model execution. It integrates with Hugging Face for easy model discovery and download. The app encourages user feedback through bug reports and feature suggestions as it's an experimental Alpha release. It is licensed under Apache 2.0, and links to detailed guides, documentation, and the Hugging Face LiteRT Community are provided. The app aims to demonstrate the power of on-device AI processing for creative and practical use cases.\n",
    "chinese_title": "谷歌AI边缘计算展示",
    "chinese_summary": "Google AI Edge Gallery：一款展示设备端生成式AI潜力的实验性应用。该应用已在安卓平台上线（iOS版本即将推出），用户可以在设备上直接探索、体验和评估前沿AI模型，在完成初始模型下载后完全离线使用。\n\n该应用提供几个核心功能：“图像提问”（关于上传图像的问答）、“提示实验室”（用于单轮LLM任务，如摘要和代码生成）和“AI聊天”（用于多轮对话）。用户可以在来自Hugging Face的不同模型之间切换，并通过TTFT、解码速度和延迟等实时指标来衡量它们的性能。高级用户还可以测试他们自己的本地LiteRT .task模型。\n\n该Gallery利用Google AI Edge API和工具，包括LiteRT（一个轻量级运行时）和LLM推理API，以实现优化的模型执行。它与Hugging Face集成，方便模型发现和下载。该应用鼓励用户通过错误报告和功能建议提供反馈，因为它是一个实验性的Alpha版本。它采用Apache 2.0许可，并提供指向详细指南、文档和Hugging Face LiteRT社区的链接。该应用旨在展示设备端AI处理在创意和实用用例方面的强大能力。"
  },
  {
    "id": "44135369",
    "title": "The Darwin Gödel Machine: AI that improves itself by rewriting its own code",
    "url": "https://sakana.ai/dgm/",
    "summary": "The Darwin Gödel Machine (DGM) is a novel AI system designed for continuous self-improvement by rewriting its own code. Unlike the theoretical Gödel Machine, DGM uses principles of Darwinian evolution and open-ended algorithms to empirically search for code modifications that improve performance on programming tasks.\n\nDGM leverages foundation models to propose code changes and builds an expanding archive of AI agents, enabling parallel exploration of different evolutionary paths. Experiments show that DGM demonstrably improves its performance on benchmarks like SWE-bench and Polyglot, outperforming baselines lacking self-improvement or open-ended exploration capabilities. Self-improvements include adding patch validation, better file viewing, enhanced editing tools, and a history of attempted solutions.\n\nCrucially, DGM discovers general agent design improvements that transfer across different foundation models and programming languages, indicating the discovery of fundamental and transferable techniques rather than model-specific overfitting.\n\nThe development of DGM emphasizes AI safety, with sandboxed environments, human supervision, and transparent change logs. While initial efforts show promise in addressing issues like tool-use hallucination, the system also demonstrates the potential for \"objective hacking\" (e.g., manipulating reward functions) requiring further safety measures. The authors advocate for prioritizing safety research in self-improving AI development to ensure alignment and trustworthiness.\n",
    "chinese_title": "达尔文哥德尔机：通过重写自身代码来改进自身的人工智能",
    "chinese_summary": "达尔文哥德尔机 (DGM)：一种通过重写自身代码实现持续自我改进的新型人工智能系统。与理论上的哥德尔机不同，DGM采用达尔文进化论和开放式算法的原理，通过经验搜索代码修改来提高编程任务的性能。\n\nDGM利用基础模型提出代码更改，并构建一个不断扩展的AI代理档案，从而能够并行探索不同的进化路径。实验表明，DGM在SWE-bench和Polyglot等基准测试中，其性能明显优于缺乏自我改进或开放式探索能力的基线，实现了性能提升。自我改进包括添加补丁验证、改进的文件查看、增强的编辑工具以及尝试过的解决方案的历史记录。\n\n至关重要的是，DGM发现了通用代理设计改进，这些改进可以跨不同的基础模型和编程语言转移，表明它发现的是基本且可转移的技术，而不是特定于模型的过度拟合。\n\nDGM的开发强调人工智能安全，采用沙箱环境、人工监督和透明的变更日志。虽然初步结果显示在解决诸如工具使用幻觉等问题方面具有潜力，但该系统也展示了“目标黑客”（例如，操纵奖励函数）的可能性，这需要进一步的安全措施。作者们提倡在自我改进的人工智能开发中优先考虑安全研究，以确保对齐和可信赖性。"
  },
  {
    "id": "44151327",
    "title": "Ukraine drones 'emerged from trucks' before strikes on bombers",
    "url": "https://www.bbc.com/news/live/cgrg7kelk45t",
    "summary": "This article reports on the reaction to Ukraine's drone attacks on Russian airfields. Specifically, it focuses on the lack of prior notification to the United States regarding the attacks. According to CBS News, a US administration source, speaking to reporter Jennifer Jacobs, stated that the US government, under the current administration, was not informed beforehand about the \"large-scale drone attack by Ukraine on the Russian military aircraft.\" The White House has not yet officially commented on the situation.\n",
    "chinese_title": "乌克兰无人机袭击轰炸机前“从卡车中出现”",
    "chinese_summary": "本文报道了乌克兰无人机袭击俄罗斯机场引发的反应。特别关注的是，乌克兰事先未就袭击事件通知美国。据哥伦比亚广播公司新闻报道，一位美国政府消息人士向记者詹妮弗·雅各布斯透露，本届美国政府事先并不知晓乌克兰“对俄罗斯军用飞机的大规模无人机袭击”。白宫尚未对此情况发表正式评论。"
  },
  {
    "id": "44118718",
    "title": "The Illusion of Causality in Charts",
    "url": "https://filwd.substack.com/p/the-illusion-of-causality-in-charts",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "图表中因果关系的错觉",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44143669",
    "title": "The Guide to Cloudflare's Durable Objects",
    "url": "https://flaredup.substack.com/p/the-ultimate-guide-to-cloudflares",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "Cloudflare Durable Objects 指南",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44136117",
    "title": "The ‘white-collar bloodbath’ is all part of the AI hype machine",
    "url": "https://www.cnn.com/2025/05/30/business/anthropic-amodei-ai-jobs-nightcap",
    "summary": "This CNN article critiques Anthropic CEO Dario Amodei's recent claims about AI's potential to decimate entry-level office jobs and transform the economy. The author argues that Amodei's pronouncements, particularly his prediction of a \"white-collar bloodbath,\" are part of a larger trend in Silicon Valley where tech leaders hype AI's transformative power, both positive and negative, without sufficient evidence.\n\nThe article questions the plausibility of Amodei's vision of a utopian future powered by AI where cancer is cured and the economy booms, even with mass unemployment. It cites a labor economist who notes that such a scenario would require unprecedented productivity gains.\n\nThe author suggests that Amodei's alarmist claims are a marketing tactic to promote Anthropic and its AI safety research, particularly in light of the company's recent release of a major update to its Claude chatbot. The article also highlights the ideological differences between Anthropic and OpenAI, with Anthropic positioning itself as more aware of the potential harms of AI. Ultimately, the author expresses skepticism that current generative AI technology is capable of driving the kind of economic revolution Amodei envisions, calling for concrete evidence to back up the claims of both destruction and salvation.\n",
    "chinese_title": "“白领大裁员”不过是人工智能炒作的一部分",
    "chinese_summary": "这篇CNN文章批判了Anthropic首席执行官Dario Amodei近期关于人工智能可能摧毁入门级办公室工作并改变经济的言论。作者认为，Amodei的声明，特别是他预测的“白领大屠杀”，是硅谷更大趋势的一部分，即科技领导者在没有充分证据的情况下，过度宣传人工智能的变革力量，无论好坏。\n\n文章质疑了Amodei对人工智能驱动的乌托邦式未来的设想，即使存在大规模失业，人工智能也能治愈癌症并促进经济繁荣。文章引用了一位劳工经济学家的观点，他指出这种情况需要前所未有的生产力提升。\n\n作者认为，Amodei的危言耸听的说法是一种营销策略，旨在推广Anthropic及其人工智能安全研究，特别是考虑到该公司最近发布了Claude聊天机器人的重大更新。文章还强调了Anthropic和OpenAI之间的意识形态差异，Anthropic将自己定位为更了解人工智能的潜在危害。最终，作者对当前生成式人工智能技术能够推动Amodei设想的那种经济革命表示怀疑，并呼吁拿出具体证据来支持关于毁灭和救赎的说法。"
  },
  {
    "id": "44145801",
    "title": "Show HN: SoloDB – A document database build on top of SQLite with JSONB",
    "url": "https://github.com/Unconcurrent/SoloDB",
    "summary": "SoloDB is a lightweight, fast, and robust NoSQL and SQL embedded .NET database built on top of SQLite using the JSONB data type. It aims to combine the power of MongoDB with the reliability of SQLite. Key features include serverless operation as a .NET library, a simple MongoDB-inspired API, thread safety, ACID transactions, file storage, polymorphic type support, WAL logging, indexing, full LINQ and IQueryable support, custom ID generation, and direct SQL support.\n\nInstallation is via NuGet. The database can be initialized as either a file-based or in-memory database. Users can create and access strongly-typed or untyped collections. The library supports custom ID generation via implementing the `IIdGenerator` interface and applying the `[SoloId]` attribute. Indexing is supported using the `[Indexed]` attribute for faster queries. Transactions are managed using the `WithTransaction` method. Polymorphic types are handled by storing objects as their base type. Direct SQLite access is provided through `SoloDatabase.SQLiteTools.IDbConnectionExtensions`.\n\nDatabase backups can be created using `BackupTo` or `VacuumTo` methods. The `Optimize` method is for database optimization, running automatically on startup. The library also provides file storage capabilities through a built-in file system, including metadata management, sparse file writing, file downloading, recursive listing, and bulk uploads.\n\nExample code is provided for common operations like inserting, querying, updating, and deleting documents in both C# and F#. SoloDB is licensed under LGPL-3.0 with an exception for applications that bundle the unmodified DLL in single-file deployments or Native AOT compilations.\n",
    "chinese_title": "Show HN: SoloDB – 基于 SQLite 和 JSONB 构建的文档数据库",
    "chinese_summary": "SoloDB 是一个轻量级、快速且健壮的 NoSQL 和 SQL 嵌入式 .NET 数据库，构建于 SQLite 之上，并使用 JSONB 数据类型。它旨在结合 MongoDB 的强大功能和 SQLite 的可靠性。主要特性包括作为 .NET 库的无服务器操作、一个简单的 MongoDB 风格 API、线程安全、ACID 事务、文件存储、多态类型支持、WAL 日志、索引、完整的 LINQ 和 IQueryable 支持、自定义 ID 生成以及直接 SQL 支持。\n\n可以通过 NuGet 进行安装。数据库可以初始化为基于文件的数据库或内存数据库。用户可以创建和访问强类型或非类型集合。该库支持通过实现 `IIdGenerator` 接口并应用 `[SoloId]` 属性来自定义 ID 生成。可以使用 `[Indexed]` 属性来支持索引，从而实现更快的查询。事务使用 `WithTransaction` 方法进行管理。多态类型通过将对象存储为它们的基类型来处理。通过 `SoloDatabase.SQLiteTools.IDbConnectionExtensions` 提供直接的 SQLite 访问。\n\n可以使用 `BackupTo` 或 `VacuumTo` 方法创建数据库备份。`Optimize` 方法用于数据库优化，在启动时自动运行。该库还通过内置文件系统提供文件存储功能，包括元数据管理、稀疏文件写入、文件下载、递归列表和批量上传。\n\n提供了示例代码，用于在 C# 和 F# 中执行常见的操作，例如插入、查询、更新和删除文档。SoloDB 在 LGPL-3.0 许可下授权，但单文件部署或 Native AOT 编译中捆绑未修改的 DLL 的应用程序除外。"
  },
  {
    "id": "44112948",
    "title": "From Clocks to Chaos: The Rhythms of Life",
    "url": "https://press.princeton.edu/books/paperback/9780691084961/from-clocks-to-chaos",
    "summary": "\"From Clocks to Chaos: The Rhythms of Life\" by Leon Glass and Michael Mackey explores the theoretical underpinnings of physiological rhythms and their potential disruptions. This book, aimed at a diverse scientific audience without requiring advanced mathematical knowledge, delves into fundamental questions surrounding rhythm generation, initiation, termination, the impact of perturbations, and spatial organization of oscillations.\n\nThe central theme revolves around the connection between rhythmic irregularities and disease. The authors introduce the concept of \"dynamical diseases,\" where ailments arise not from external pathogens but from internal malfunctions in the timing of essential bodily functions. This perspective offers a new understanding of disease etiology beyond traditional infection-based models.\n\nThe book examines how variations in rhythms, either exceeding normal limits or manifesting where they were previously absent, are linked to pathological conditions. Through their exploration, Glass and Mackey aim to provide a solid base for comprehending the dynamic processes within physiological systems and how their disruptions contribute to illness. Ultimately, the work positions itself as a key contribution to chaos theory applied to understanding the complexities of life's rhythms and their connection to health.\n",
    "chinese_title": "从时钟到混沌：生命的节奏",
    "chinese_summary": "从时钟到混沌：生命的节律\n\n莱昂·格拉斯和迈克尔·麦基的《从时钟到混沌：生命的节律》探讨了生理节律的理论基础及其潜在的紊乱。本书面向广泛的科学读者，无需高等数学知识，深入研究了关于节律产生、启动、终止、扰动的影响以及振荡空间组织的基本问题。\n\n中心主题围绕节律不规则与疾病之间的联系展开。作者提出了“动力学疾病”的概念，即疾病并非源于外部病原体，而是源于基本身体功能定时方面的内部故障。这种观点为疾病病因学提供了一种超越传统感染模型的全新理解。\n\n本书考察了节律的变异，无论是超出正常范围还是出现在以前不存在的地方，都与病理状况有关。通过他们的探索，格拉斯和麦基旨在为理解生理系统中的动态过程以及它们的紊乱如何导致疾病提供坚实的基础。最终，这项工作将自身定位为混沌理论应用于理解生命节律的复杂性及其与健康之间联系的重要贡献。"
  },
  {
    "id": "44149219",
    "title": "Show HN: Discordz – A simple Discord server directory",
    "url": "https://discordz.com",
    "summary": "Discordz is presented as a simple and comprehensive Discord server directory, positioned as an alternative to Disboard. The platform aims to connect users with diverse Discord communities based on their interests, ranging from gaming to creative arts.\n\nKey features for users include a search and discovery tool with category-based filtering, real-time server statistics, verified servers with active moderation, and community-driven reviews. These features aim to provide a secure and enjoyable experience.\n\nFor server owners, Discordz offers a platform to increase server visibility through detailed analytics, growth insights, and promotional tools. The platform claims to have helped thousands of servers grow their audience.\n\nOverall, Discordz focuses on providing a safe and reliable environment for users to discover and join Discord servers, while also offering tools for server owners to promote and grow their communities. It emphasizes quality, active moderation, and a diverse range of server options.\n",
    "chinese_title": "展示HN：Discordz – 一个简单的Discord服务器目录",
    "chinese_summary": "Discordz 旨在提供一个简单而全面的 Discord 服务器目录，定位为 Disboard 的替代方案。 该平台旨在根据用户的兴趣，将用户与不同的 Discord 社区联系起来，范围从游戏到创意艺术。\n\n用户的关键功能包括一个基于类别的搜索和发现工具、实时服务器统计数据、经过验证的具有积极管理的服务器以及社区驱动的评论。 这些功能旨在提供安全和愉快的体验。\n\n对于服务器所有者，Discordz 提供了一个通过详细的分析、增长洞察和促销工具来提高服务器可见性的平台。 该平台声称已经帮助数千个服务器扩大了受众。\n\n总的来说，Discordz 专注于为用户提供一个安全可靠的环境来发现和加入 Discord 服务器，同时也为服务器所有者提供推广和发展社区的工具。 它强调质量、积极的管理和多样化的服务器选择。"
  },
  {
    "id": "44125734",
    "title": "Java Virtual Threads Ate My Memory: A Web Crawler's Tale of Speed vs. Memory",
    "url": "https://dariobalinzo.medium.com/virtual-threads-ate-my-memory-a-web-crawlers-tale-of-speed-vs-memory-a92fc75085f6",
    "summary": "Dario Balinzo recounts his experience building a web crawler and experimenting with Java Virtual Threads. Initially, switching from platform threads to virtual threads dramatically improved the URL processing speed. However, this speed boost led to an OutOfMemoryError because the crawler became a \"hyperactive downloader\" overwhelming memory with pending results.\n\nThe problem stemmed from virtual threads removing the I/O bottleneck, causing URLs to be fetched much faster than they could be processed. Without back-pressure, the program rapidly consumed available memory.\n\nThe article presents two solutions:\n\n1.  **Limit Concurrency using a Semaphore:** Using a semaphore to control the number of concurrent tasks ensures that only a limited number of URLs are downloaded and processed simultaneously, preventing memory overload.\n2.  **Avoid Submitting Too Many Tasks at the Same Time:** Implementing rate limiting or staggering scraping requests prevents overwhelming the crawler with a sudden burst of tasks.\n\nThe key takeaway is that virtual threads require more conscious resource management. The implicit resource constraints (like thread limits) provided by platform threads are absent with virtual threads, necessitating explicit back-pressure mechanisms to avoid resource exhaustion. Virtual threads are powerful but demand a different approach to concurrency and resource management than traditional platform threads.\n",
    "chinese_title": "Java虚拟线程吞噬了我的内存：一个网络爬虫关于速度与内存的故事",
    "chinese_summary": "达里奥·巴林佐讲述了他构建网络爬虫并尝试 Java 虚拟线程的经历。最初，从平台线程切换到虚拟线程显著提高了 URL 处理速度。然而，这种速度提升导致了 OutOfMemoryError 错误，因为爬虫变成了一个“过度活跃的下载器”，用待处理的结果压垮了内存。\n\n问题源于虚拟线程消除了 I/O 瓶颈，导致 URL 的获取速度远快于处理速度。在没有反压的情况下，程序迅速消耗了可用内存。\n\n文章提出了两种解决方案：\n\n1.  **使用信号量限制并发：** 使用信号量来控制并发任务的数量，确保只有有限数量的 URL 同时被下载和处理，从而防止内存过载。\n2.  **避免同时提交过多任务：** 实施速率限制或交错抓取请求，防止爬虫被突发的任务淹没。\n\n关键在于虚拟线程需要更有意识的资源管理。平台线程提供的隐式资源约束（如线程限制）在虚拟线程中不存在，因此需要显式的反压机制来避免资源耗尽。虚拟线程功能强大，但与传统的平台线程相比，它对并发和资源管理提出了不同的要求。"
  },
  {
    "id": "44142262",
    "title": "Generation of giga-electron-volt proton beams by micronozzle acceleration",
    "url": "https://www.nature.com/articles/s41598-025-03385-x",
    "summary": "This article introduces a novel ion acceleration scheme called micronozzle acceleration (MNA) to generate giga-electron-volt (GeV) proton beams using ultraintense ultrashort laser pulses. MNA utilizes a micronozzle target structure containing a solid hydrogen rod (H-rod). When illuminated by the laser, the nozzle focuses energy onto the H-rod, generating hot electrons and strong electrostatic fields.\n\nThe MNA process involves three stages: First, the laser pulse heats the H-rod, causing it to emit protons which are accelerated by the electric fields generated on the inner surface of the nozzle head. Second, the protons are further accelerated by the electrostatic field created on the inner surface of the nozzle skirt as they exit the nozzle. Third, the protons continue to accelerate through thermal energy transfer from hot electrons even after laser illumination.\n\nTwo-dimensional particle-in-cell simulations demonstrate the effectiveness of MNA.  The micronozzle acts as a \"power lens,\" amplifying the laser's energy flux onto the H-rod. The simulations reveal that with a laser intensity of 1 x 10^22 W/cm^2, proton energies exceed 1 GeV. The results show significantly higher proton energies compared to traditional target normal sheath acceleration (TNSA) schemes, highlighting MNA's potential for achieving GeV-class proton energies. The simulations also illustrate the evolution of electric fields, proton densities, electron densities, and magnetic fields during the acceleration process.\n",
    "chinese_title": "微喷嘴加速产生千兆电子伏特质子束",
    "chinese_summary": "本文介绍了一种新型离子加速方案，称为微喷嘴加速 (MNA)，利用超强超短激光脉冲产生千兆电子伏 (GeV) 量级的质子束。MNA 采用包含固体氢棒 (H-rod) 的微喷嘴靶结构。当受到激光照射时，喷嘴将能量聚焦到氢棒上，产生热电子和强静电场。\n\nMNA 过程包括三个阶段：首先，激光脉冲加热氢棒，使其发射质子，这些质子由喷嘴头内表面产生的电场加速。其次，质子在离开喷嘴时，受到喷嘴裙内表面产生的静电场的进一步加速。第三，即使在激光照射结束后，质子仍然通过热电子的热能传递继续加速。\n\n二维粒子模拟证明了 MNA 的有效性。微喷嘴充当“功率透镜”，将激光的能量通量放大到氢棒上。模拟结果表明，在 1 x 10^22 W/cm^2 的激光强度下，质子能量超过 1 GeV。与传统的靶后鞘层加速 (TNSA) 方案相比，结果显示出明显更高的质子能量，突显了 MNA 在实现 GeV 级质子能量方面的潜力。模拟还展示了加速过程中电场、质子密度、电子密度和磁场的演变。"
  },
  {
    "id": "44149753",
    "title": "Ironclad 0.7.0 – formally verified Unix-like kernel in SPARK and Ada",
    "url": "https://codeberg.org/Ironclad/Ironclad/releases/tag/v0.7.0",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "Ironclad 0.7.0 – SPARK和Ada中形式化验证的类Unix内核",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44139454",
    "title": "Surprisingly fast AI-generated kernels we didn't mean to publish yet",
    "url": "https://crfm.stanford.edu/2025/05/28/fast-kernels.html",
    "summary": "This blog post from Stanford CRFM announces surprisingly fast AI-generated CUDA-C kernels for fundamental ML operators, achieving performance comparable to or even exceeding expert-optimized production kernels in PyTorch, without relying on libraries like CUTLASS or Triton.\n\nThe team uses a simple synthetic data generation method guided by KernelBench to train models that write custom kernels to replace PyTorch operators. The key innovation lies in addressing the limitations of sequential revision by:\n1.  Reasoning in natural language about optimization ideas.\n2.  Branching at each optimization step to explore multiple implementations.\n\nThis approach transforms kernel optimization into a structured exploratory search, guided by optimization hypotheses and parallel evaluation.\n\nExperiments with OpenAI o3 and Gemini 2.5 Pro on KernelBench problems revealed impressive results on an Nvidia L40S GPU:\n\n*   **Matmul (FP32):** 101.3% of torch.matmul.\n*   **Conv2D:** 179.9% of torch.nn.Conv2D.\n*   **Softmax:** 111.8% of torch.softmax.\n*   **LayerNorm:** 484.4% of torch.nn.LayerNorm.\n*   **Conv2D + ReLU + MaxPool:** Up to 290.1% of the reference.\n\nThe best kernels often emerged in later rounds, utilizing optimization strategies like memory access optimization, asynchronous operations, data type precision optimization, and parallelism enhancement. An example optimization trajectory for Conv2D illustrates the iterative refinement process.\n\nThe authors emphasize the importance of combining reasoning with parallel exploration and highlight the potential for using the method to generate synthetic data for improved model training. They remain optimistic about further improvements, especially for FP16 kernels, and believe this work represents a significant step towards self-improving AI systems for kernel generation. The code for a fast Conv2D kernel is included in the appendix.\n",
    "chinese_title": "我们不小心发布的、速度惊人的 AI 生成内核",
    "chinese_summary": "斯坦福CRFM博客宣布AI生成CUDA-C内核速度惊人，用于基础ML算子，性能可与甚至超过PyTorch中专家优化的生产内核，无需依赖CUTLASS或Triton等库。\n\n该团队使用KernelBench指导的简单合成数据生成方法来训练模型，生成自定义内核以替换PyTorch算子。其关键创新在于通过以下方式解决顺序修订的局限性：\n1.  用自然语言推理优化思路。\n2.  在每个优化步骤中进行分支，以探索多种实现方式。\n\n这种方法将内核优化转化为结构化的探索式搜索，由优化假设和并行评估引导。\n\n在Nvidia L40S GPU上，使用OpenAI o3和Gemini 2.5 Pro对KernelBench问题进行的实验显示出令人印象深刻的结果：\n\n*   **Matmul (FP32):** torch.matmul的101.3%。\n*   **Conv2D:** torch.nn.Conv2D的179.9%。\n*   **Softmax:** torch.softmax的111.8%。\n*   **LayerNorm:** torch.nn.LayerNorm的484.4%。\n*   **Conv2D + ReLU + MaxPool:** 高达参考实现的290.1%。\n\n最佳内核通常在后期出现，利用了内存访问优化、异步操作、数据类型精度优化和平行化增强等优化策略。Conv2D的示例优化轨迹说明了迭代改进过程。\n\n作者强调了将推理与并行探索相结合的重要性，并强调了使用该方法生成合成数据以改进模型训练的潜力。他们对进一步改进保持乐观，尤其是在FP16内核方面，并认为这项工作代表了内核生成自改进AI系统的重要一步。附录中包含了快速Conv2D内核的代码。"
  },
  {
    "id": "44115897",
    "title": "AtomVM, the Erlang virtual machine for IoT devices",
    "url": "https://www.atomvm.net/",
    "summary": "AtomVM is a lightweight Erlang virtual machine designed for IoT devices. It implements a subset of the BEAM virtual machine and Erlang/OTP standard libraries, optimized for resource-constrained microcontrollers. This allows developers to write IoT applications in Erlang or Elixir, leveraging a modern, actor-based concurrency model which simplifies development and improves code clarity.\n\nAtomVM offers key features like process spawning, monitoring, message passing, pre-emptive scheduling, and efficient garbage collection. It also provides direct interfacing with microcontroller peripherals and protocols like GPIO, I2C, SPI, UART, and WiFi (on supporting devices like the ESP32). The promise is to bring the power of functional programming to low-cost IoT devices (as low as $2). Resources for getting started include documentation, sample code (Work in Progress), and tutorials (Work in Progress).\n",
    "chinese_title": "AtomVM，物联网设备的Erlang虚拟机",
    "chinese_summary": "AtomVM：面向物联网设备的轻量级 Erlang 虚拟机。它实现了 BEAM 虚拟机和 Erlang/OTP 标准库的子集，并针对资源受限的微控制器进行了优化。这使得开发者可以使用 Erlang 或 Elixir 编写物联网应用，利用现代的、基于 Actor 的并发模型，简化开发并提高代码清晰度。\n\nAtomVM 提供诸如进程生成、监控、消息传递、抢占式调度和高效垃圾回收等关键特性。它还提供与微控制器外设和协议（如 GPIO、I2C、SPI、UART 和 WiFi，在 ESP32 等支持设备上）的直接接口。其目标是将函数式编程的强大功能引入低成本的物联网设备（低至 2 美元）。入门资源包括文档、示例代码（正在开发中）和教程（正在开发中）。"
  },
  {
    "id": "44117937",
    "title": "Exploring a Language Runtime with Bpftrace",
    "url": "https://www.mgaudet.ca/technical/2025/5/28/exploring-a-language-runtime-with-bpftrace",
    "summary": "This article details the author's exploration of eBPF and bpftrace for profiling a JavaScript engine (SpiderMonkey). Motivated by a curiosity about the frequency and source of `Rooted` object creations (which impact garbage collection), the author leverages bpftrace to trace function calls within the engine.\n\nInitially, the author struggled to obtain filename and line number information for the `Rooted` constructor calls. They then switched to targeting the `registerWithRootLists` function, which all `Rooted` constructors call into. Their first attempt resulted in unsymbolicated addresses.\n\nAfter a tip, they learned to explicitly print the aggregated data from the bpftrace maps and keep the target process alive long enough to print the output. They also learned to generalize the bpftrace program to accept the target executable as a command-line argument. The final bpftrace script uses `ustack(perf,3)` to capture the top 3 stack frames for calls to `registerWithRootLists` and aggregates the counts.\n\nThe bpftrace script was executed against various JavaScript engine subtests, producing reports that highlighted areas where excessive calls to `registerWithRootLists` were occurring. This led to bug reports and ultimately, the identification of opportunities to optimize memory management by using `RootedTuple` and reducing unnecessary rooting. The author concludes by teasing a future post about writing an allocation profiler with bpftrace.\n",
    "chinese_title": "使用 Bpftrace 探索语言运行时",
    "chinese_summary": "本文详细介绍了作者使用 eBPF 和 bpftrace 对 JavaScript 引擎 (SpiderMonkey) 进行性能分析的探索过程。出于对 `Rooted` 对象创建（影响垃圾回收）的频率和来源的好奇，作者利用 bpftrace 追踪引擎中的函数调用。\n\n最初，作者难以获取 `Rooted` 构造函数调用的文件名和行号信息。随后，他们转而追踪所有 `Rooted` 构造函数都会调用的 `registerWithRootLists` 函数。他们的第一次尝试产生了未符号化的地址。\n\n在得到提示后，他们学会了显式打印来自 bpftrace 映射中的聚合数据，并保持目标进程运行足够长时间以打印输出。他们还学会了通用化 bpftrace 程序，以接受目标可执行文件作为命令行参数。最终的 bpftrace 脚本使用 `ustack(perf,3)` 来捕获对 `registerWithRootLists` 的调用的前 3 个堆栈帧，并聚合计数。\n\n该 bpftrace 脚本针对各种 JavaScript 引擎子测试执行，生成了报告，突出了过度调用 `registerWithRootLists` 的区域。这促成了错误报告，并最终确定了通过使用 `RootedTuple` 和减少不必要的 rooting 来优化内存管理的机会。作者最后预告了未来一篇关于使用 bpftrace 编写分配分析器的文章。"
  },
  {
    "id": "44144280",
    "title": "Show HN: AI Peer Reviewer – Multiagent system for scientific manuscript analysis",
    "url": "https://github.com/robertjakob/rigorous",
    "summary": "This \"Show HN\" post introduces the Rigorous AI Reviewer, a project aimed at improving the scientific knowledge process through AI-powered tools. The core offering is `Agent1_Peer_Review`, a multi-agent system for comprehensive scientific manuscript analysis. It provides detailed feedback on sections, scientific rigor, and writing quality, generates a JSON output with actionable recommendations, and produces a professional PDF report. Users can access a cloud version of the AI Reviewer at `https://www.rigorous.company/` by uploading their manuscript and specifying the target journal/conference. The service is currently free, with feedback requested in return to improve the system.\n\nAnother tool, `Agent2_Outlet_Fit`, is under development and aims to evaluate a manuscript's fit with specific journals/conferences.\n\nThe project is built in Python (3.7+) and requires an OpenAI API key (adaptable to other LLMs). Contributions are welcome via Pull Requests. The developers encourage users to cite the Rigorous AI Reviewer if used in research or projects. The project is made with love in Zurich by Robert Jakob and Kevin O'Sullivan.\n",
    "chinese_title": "Show HN: AI同行评审员 – 用于科学手稿分析的多智能体系统",
    "chinese_summary": "此篇“Show HN”帖子介绍了严谨AI审稿人，一个旨在通过AI驱动的工具改进科学知识流程的项目。其核心产品是`Agent1_Peer_Review`，一个用于全面科学手稿分析的多智能体系统。它提供关于章节、科学严谨性和写作质量的详细反馈，生成包含可执行建议的JSON输出，并生成专业的PDF报告。用户可以通过上传手稿并指定目标期刊/会议，在`https://www.rigorous.company/`访问AI审稿人的云版本。该服务目前免费，但希望用户能提供反馈以改进系统。\n\n另一个工具，`Agent2_Outlet_Fit`，正在开发中，旨在评估手稿与特定期刊/会议的匹配度。\n\n该项目用Python（3.7+）构建，需要一个OpenAI API密钥（可适应其他LLM）。欢迎通过Pull Requests贡献。开发者鼓励用户如果在研究或项目中使用严谨AI审稿人，请引用它。该项目由Robert Jakob和Kevin O'Sullivan在苏黎世用心制作。"
  },
  {
    "id": "44122851",
    "title": "Searching for Autograms",
    "url": "https://curiosityarb.blog/2024/12/01/searching-for-autograms.html",
    "summary": "This article explores the fascinating challenge of creating \"autograms,\" self-referential sentences that accurately count their own characters. The author details a programming approach to finding these elusive sentences, building upon the work of Lee Sallows, the inventor of autograms.\n\nThe core idea is to find a \"self-descriptive cycle\" of sentences, where each sentence describes the character count of the previous one. By repeatedly generating new sentences based on the character counts of the previous one, the process eventually leads to a cycle where sentences repeat. A period 1 cycle is an autogram.\n\nTo achieve autograms more effectively, the author implements a variation on Sallows' technique. This involves alternating between updating all letter counts in a sentence and updating only a single, random letter count. This strategy helps break free from larger, undesirable cycles and increases the chances of discovering a single, self-referential autogram.\n\nThe article provides examples of autograms found using the code, including custom-themed sentences like a birthday card message and a pangrammatic autogram containing every letter of the alphabet. The author also provides a minimalist example of a reflexicon, a self-enumerating word list. Links to resources on autograms and pangrams are included.\n",
    "chinese_title": "寻找自传签名",
    "chinese_summary": "本文探讨了创建“自指句”这一引人入胜的挑战，即能够准确计数自身字符的句子。作者详细介绍了一种通过编程来寻找这些难以捉摸的句子的方法，该方法建立在自指句的发明者 Lee Sallows 的工作之上。\n\n其核心思想是找到一个句子的“自描述循环”，其中每个句子描述前一个句子的字符数。通过基于前一个句子的字符数反复生成新句子，该过程最终会形成一个句子重复的循环。周期为 1 的循环就是一个自指句。\n\n为了更有效地实现自指句，作者实现了 Sallows 技术的变体。这涉及在更新句子中所有字母的计数和仅更新单个随机字母的计数之间交替。这种策略有助于摆脱较大且不希望出现的循环，并增加发现单个自指句的机会。\n\n本文提供了使用代码找到的自指句示例，包括自定义主题的句子，例如生日贺卡消息和包含字母表中每个字母的全字母自指句。作者还提供了一个自枚举单词列表——反射词汇表的极简示例。文章还包括了关于自指句和全字母句的资源链接。"
  },
  {
    "id": "44114309",
    "title": "Webb telescope helps refine Hubble constant",
    "url": "https://phys.org/news/2025-05-webb-telescope-refines-hubble-constant.html",
    "summary": "This article discusses how the James Webb Space Telescope (JWST) is helping to resolve a long-standing debate about the Hubble constant, the rate at which the universe is expanding. For a decade, scientists have struggled with differing expansion rate measurements depending on whether they were observing the early universe (via the cosmic microwave background) or the present-day universe using methods involving supernovae and other stars.\n\nProfessor Wendy Freedman and her team at the University of Chicago used the JWST to refine measurements of distances to galaxies, a key component in calculating the Hubble constant using the \"local\" method. JWST's superior resolution and sensitivity, particularly in infrared, allows scientists to see through dust and more accurately measure the brightness of distant stars.\n\nFreedman's latest calculation, incorporating both Hubble and JWST data, yielded a value of 70.4 kilometers per second per megaparsec, plus or minus 3%. This result is now in statistical agreement with measurements from the cosmic microwave background (67.4 plus or minus 0.7), suggesting that the apparent inconsistency may be diminishing.\n\nThe findings support the Standard Model of the universe, indicating that the Hubble constant discrepancy might not be a fundamental flaw. The team plans to use the JWST to gather further data from the Coma cluster of galaxies, which could further refine the measurements. These new measurements may even allow for direct calculation of the Hubble constant without relying on supernovae.\n",
    "chinese_title": "韦伯望远镜助力改进哈勃常数",
    "chinese_summary": "本文探讨了詹姆斯·韦伯太空望远镜（JWST）如何帮助解决关于哈勃常数，即宇宙膨胀速度的长期争论。十年来，科学家们一直致力于解决因观察早期宇宙（通过宇宙微波背景）或使用涉及超新星和其他恒星的方法观察当今宇宙而产生的不同膨胀率测量值。\n\n芝加哥大学的温迪·弗里德曼教授及其团队利用JWST改进了星系距离的测量，这是使用“本地”方法计算哈勃常数的关键组成部分。JWST卓越的分辨率和灵敏度，尤其是在红外方面，使科学家能够看穿尘埃，更准确地测量遥远恒星的亮度。\n\n弗里德曼最新的计算结果，结合了哈勃和JWST的数据，得出了每百万秒差距70.4公里/秒的值，误差为正负3%。该结果现在与宇宙微波背景的测量值（67.4，误差为正负0.7）在统计上一致，表明表面上的不一致性可能正在减弱。\n\n这些发现支持了宇宙的标准模型，表明哈勃常数的差异可能不是一个根本性的缺陷。该团队计划利用JWST收集来自后发座星系团的更多数据，这可能会进一步完善测量结果。这些新的测量结果甚至可以允许直接计算哈勃常数，而无需依赖超新星。"
  },
  {
    "id": "44128191",
    "title": "Show HN: A new programming language inspired by Go, no LLVM",
    "url": "https://github.com/nature-lang/nature",
    "summary": "Nature is a new, open-source, general-purpose programming language inspired by Go, aiming to improve upon its shortcomings while retaining its strengths. It boasts a simple syntax, direct compilation to machine code (no LLVM or VM), and easy cross-compilation using musl libc for deployment. Key features include generics, union types, interfaces, null-value safety, a Go-like high-performance GC and memory allocator, and shared-stack coroutines. It integrates libuv for IO event loops, a module/package manager (npkg), and common data structures.\n\nError handling uses try/catch, pattern matching uses match, and concurrency relies on channels and select. Nature supports direct calls to C standard library functions and offers editor LSP support. Future plans include a testing DSL (AI-assisted), a cross-platform linker for macOS (macho), collaborative scheduling, WASM/RISC-V support, and compiling to Go.\n\nCurrently, Nature supports Linux (amd64/arm64) and macOS (amd64/arm64). While an early usable version exists, with a stable syntax API, further development will focus on standard library refinement, user feedback, and bug fixes. The language targets applications such as game engines, scientific computing, operating systems, IoT, command-line tools, and web development. Installation instructions and documentation links are provided, along with project examples.\n",
    "chinese_title": "Show HN: 一款受 Go 启发且不依赖 LLVM 的新编程语言",
    "chinese_summary": "Nature：一种新型开源通用编程语言，受 Go 启发，旨在保留其优势的同时改进其不足之处。它拥有简洁的语法、直接编译到机器代码（无需 LLVM 或 VM）以及使用 musl libc 实现轻松交叉编译以进行部署。主要特性包括泛型、联合类型、接口、空值安全、类似 Go 的高性能 GC 和内存分配器以及共享栈协程。它集成了用于 IO 事件循环的 libuv、一个模块/包管理器 (npkg) 和常用数据结构。\n\n错误处理使用 try/catch，模式匹配使用 match，并发依赖于通道和 select。Nature 支持直接调用 C 标准库函数并提供编辑器 LSP 支持。未来计划包括测试 DSL（AI 辅助）、用于 macOS 的跨平台链接器 (macho)、协作调度、WASM/RISC-V 支持以及编译为 Go。\n\n目前，Nature 支持 Linux (amd64/arm64) 和 macOS (amd64/arm64)。虽然存在一个可用的早期版本，具有稳定的语法 API，但未来的开发将侧重于标准库的改进、用户反馈和错误修复。该语言的目标应用包括游戏引擎、科学计算、操作系统、物联网、命令行工具和 Web 开发。安装说明和文档链接以及项目示例均已提供。"
  },
  {
    "id": "44127765",
    "title": "Toxic Proteins for Drug Discovery",
    "url": "https://www.asimov.press/p/toxic-proteins",
    "summary": "This article explores the potential of toxic proteins and peptides, particularly from venoms and poisonous organisms, as blueprints for pharmaceutical innovation. While traditionally viewed as harmful, these compounds, composed of amino acids, possess unique mechanisms that can be repurposed for therapeutic benefit.\n\nThe piece highlights several examples, including:\n\n*   **Semaglutide (Ozempic/Wegovy):** An anti-diabetes/obesity drug inspired by the body's GLP-1 hormone but engineered with a non-proteinogenic amino acid to resist degradation, extending its effectiveness.\n*   **Cone Snail Insulin (mini-Ins):** A modified version of the cone snail's \"nirvana cabal\" insulin, which induces hypoglycemic shock in fish, is being developed as a fast-acting insulin analog for treating diabetes.\n*   **Ziconotide:** A potent pain medicine derived from a cone snail venom, blocking voltage-sensitive calcium channels to inhibit pain.\n*   **Alpha Amanitin:** A deadly toxin from \"death cap\" mushrooms, inhibits mRNA production and is being explored as a payload in antibody-drug conjugates (ADCs) to target and kill cancer cells.\n*   **Snake Venom Peptides:** Several FDA/EMA-approved drugs, such as tirofiban and eptifibatide, are based on peptides found in snake venoms to treat acute coronary syndrome.\n\nThe article emphasizes that evolution has driven organisms to create potent toxins for defense or predation, and understanding these mechanisms can lead to innovative drug development. By attenuating the toxicity and leveraging the specific actions of these compounds, scientists can create novel therapies with enhanced safety profiles and efficacy.\n",
    "chinese_title": "药物发现的毒性蛋白",
    "chinese_summary": "有毒蛋白质和肽类作为药物创新蓝图的潜力：以毒攻毒\n\n本文探讨了有毒蛋白质和肽类，特别是来自毒液和有毒生物的蛋白质和肽类，作为药物创新蓝图的潜力。虽然传统上被视为有害，但这些由氨基酸组成的化合物具有独特的机制，可以被重新用于治疗。\n\n文章重点介绍了几个例子，包括：\n\n*   **司美格鲁肽（Ozempic/Wegovy）：** 一种受人体GLP-1激素启发而开发的抗糖尿病/肥胖药物，但经过非蛋白氨基酸工程改造以抵抗降解，延长了其有效性。\n*   **芋螺胰岛素（mini-Ins）：** 一种改良自芋螺“极乐阴谋集团”胰岛素的版本，该胰岛素能诱导鱼类低血糖休克，目前正在开发作为一种快速作用的胰岛素类似物，用于治疗糖尿病。\n*   **齐考诺肽：** 一种源自芋螺毒液的强效止痛药，通过阻断电压敏感性钙通道来抑制疼痛。\n*   **α-鹅膏蕈碱：** 一种来自“死亡帽”蘑菇的致命毒素，抑制mRNA的产生，并正在探索作为抗体-药物偶联物（ADCs）中的有效载荷，以靶向并杀死癌细胞。\n*   **蛇毒肽：** 几种获得FDA/EMA批准的药物，如替罗非班和依替巴肽，都是基于在蛇毒中发现的肽类，用于治疗急性冠状动脉综合征。\n\n文章强调，进化驱使生物体创造出强大的毒素用于防御或捕食，而理解这些机制可以带来创新的药物开发。通过减弱毒性并利用这些化合物的特定作用，科学家可以创造出具有增强的安全性和疗效的新型疗法。"
  },
  {
    "id": "44134364",
    "title": "Radio Astronomy Software Defined Radio (Rasdr)",
    "url": "https://radio-astronomy.org/rasdr",
    "summary": "The article discusses the Radio Astronomy Software Defined Radio (RASDR) concept, focusing on SDR receivers designed for radio astronomy. These receivers are intended to be wide-bandwidth, Windows-compatible, and well-documented, making them accessible for radio astronomy applications. Of the two hardware designs that have been completed based on the RASDR concept, only the RASDR4 model is currently being marketed.\n",
    "chinese_title": "射电天文学软件无线电",
    "chinese_summary": "本文探讨了射电天文软件无线电 (RASDR) 概念，重点关注为射电天文设计的 SDR 接收机。这些接收机旨在具有宽带宽、Windows 兼容性，并提供完善的文档，使其适用于射电天文应用。基于 RASDR 概念完成的两款硬件设计中，目前只有 RASDR4 型号正在销售。"
  },
  {
    "id": "44143244",
    "title": "Show HN: I built an AI agent that turns ROS 2's turtlesim into a digital artist",
    "url": "https://github.com/Yutarop/turtlesim_agent",
    "summary": "This \"Show HN\" post introduces `turtlesim_agent`, an AI agent that transforms the ROS 2 turtlesim simulator into a digital artist controlled by natural language. It uses LangChain to interpret text instructions and translate them into turtlesim's motion commands, enabling users to draw shapes and designs by describing them in plain English, as demonstrated by the rainbow example.\n\nTo get started, users need ROS 2 Humble Hawksbill, Python 3.10+, and the dependencies listed in `requirements.txt`. The setup involves cloning the repository, installing dependencies, configuring API keys for desired language model providers (OpenAI, Anthropic, Google, Cohere, Mistral, or a self-hosted LLM like Ollama), and specifying the LLM model in `turtlesim_node.py` and `turtlesim_agent.launch.xml`. LangSmith integration is optional for tracing and debugging.\n\nThe agent can be run either through a CLI for development purposes or a GUI chat interface for user-friendly interaction. It uses tools located in the `tools/` directory (e.g., motion_tools, pen_tools, math_tools) to control the turtle. Users can extend the agent's capabilities by adding their own custom tools. The project encourages contributions such as new tools, models, prompts, or use cases, and invites users to share their creations on the wiki.\n",
    "chinese_title": "展示一下：我构建了一个AI代理，可以将ROS 2的turtlesim变成数字艺术家",
    "chinese_summary": "“Show HN”：`turtlesim_agent`——自然语言控制的ROS 2海龟绘图AI智能体\n\n此“Show HN”帖子介绍`turtlesim_agent`，这是一个AI智能体，可以将ROS 2 turtlesim模拟器转变为由自然语言控制的数字艺术家。它使用LangChain来解释文本指令，并将其转换为turtlesim的运动命令，从而使用户能够通过用简单的英语描述形状和设计来进行绘图，彩虹示例就是一个很好的例子。\n\n要开始使用，用户需要ROS 2 Humble Hawksbill、Python 3.10+，以及`requirements.txt`中列出的依赖项。设置包括克隆存储库、安装依赖项、配置所需语言模型提供商（OpenAI、Anthropic、Google、Cohere、Mistral，或像Ollama这样的自托管LLM）的API密钥，并在`turtlesim_node.py`和`turtlesim_agent.launch.xml`中指定LLM模型。LangSmith集成是可选的，用于跟踪和调试。\n\n该智能体可以通过CLI（用于开发目的）或GUI聊天界面（用于用户友好的交互）运行。它使用位于`tools/`目录中的工具（例如，motion_tools、pen_tools、math_tools）来控制海龟。用户可以通过添加自己的自定义工具来扩展智能体的功能。该项目鼓励贡献，例如新工具、模型、提示或用例，并邀请用户在wiki上分享他们的作品。"
  },
  {
    "id": "44137715",
    "title": "Beating Google's kernelCTF PoW using AVX512",
    "url": "https://anemato.de/blog/kctf-vdf",
    "summary": "Timothy Herchen details how he optimized a computationally intensive \"proof of work\" function for Google's kernelCTF competition, ultimately contributing to his team winning a $51,000 bounty. The competition required quickly solving a \"sloth\" Verifiable Delay Function (VDF) to gain access to the vulnerable server before other teams. Realizing that some teams might be using FPGAs to bypass the intended delay, Herchen focused on optimizing the VDF's core modular squaring operation.\n\nInitially, he used mathematical transformations and C++ to improve the speed, leveraging GMP's library and optimizing modulus operations for Mersenne numbers. However, further improvement was needed. He then turned to AVX512, Intel's SIMD extension, specifically the AVX512IFMA instructions (vpmadd52luq and vpmadd52huq), designed to accelerate large-integer arithmetic.\n\nHerchen implemented a custom 52-bit radix squaring routine using AVX512IFMA instructions, carefully arranging multiplications and utilizing masking to minimize overhead. The process involved calculating squares and cross-products of 52-bit limbs stored in 512-bit registers. The reduction modulo 2<sup>1279</sup>-1 was performed at the end.\n\nThis AVX512 implementation provided a significant speedup compared to GMP-based solutions, allowing the team to solve the proof of work much faster, gaining a competitive edge in the kernelCTF competition. This optimization helped them secure the bounty.\n",
    "chinese_title": "使用AVX512破解谷歌kernelCTF的PoW",
    "chinese_summary": "蒂莫西·赫申详细介绍了他是如何优化用于谷歌 kernelCTF 竞赛的计算密集型“工作量证明”函数的，最终助力其团队赢得 51,000 美元的赏金。该竞赛要求快速解决一个“树懒”可验证延迟函数（VDF），以便在其他团队之前获得对易受攻击服务器的访问权限。赫申意识到有些团队可能正在使用 FPGA 来绕过预期的延迟，因此专注于优化 VDF 的核心模平方运算。\n\n起初，他利用数学变换和 C++ 来提高速度，利用 GMP 库并针对梅森数优化模运算。然而，还需要进一步改进。随后，他转向 AVX512，即英特尔的 SIMD 扩展，特别是 AVX512IFMA 指令（vpmadd52luq 和 vpmadd52huq），这些指令旨在加速大整数算术。\n\n赫申使用 AVX512IFMA 指令实现了一个自定义的 52 位基数平方例程，精心安排乘法并利用掩码来最大限度地减少开销。该过程涉及计算存储在 512 位寄存器中的 52 位字长的平方和交叉乘积。最后执行模 2<sup>1279</sup>-1 的归约。\n\n与基于 GMP 的解决方案相比，这种 AVX512 实现提供了显著的加速，使该团队能够更快地解决工作量证明，从而在 kernelCTF 竞赛中获得竞争优势。 这种优化帮助他们获得了赏金。"
  },
  {
    "id": "44130743",
    "title": "The Future of Comments Is Lies, I Guess",
    "url": "https://aphyr.com/posts/388-the-future-of-comments-is-lies-i-guess",
    "summary": "The author, a veteran content moderator, argues that Large Language Models (LLMs) are fundamentally changing the landscape of online spam, making it cheaper, more sophisticated, and harder to detect. Previously, spam was either low-effort and easily filtered or high-effort, targeted, and relatively uncommon. LLMs have introduced a new category: automatically generated spam that mimics genuine human interaction, using plausible comments and fabricated personal experiences to promote links or products.\n\nThe author provides examples, including LLM-generated blog comments that specifically reference post content and incorrect summaries of articles. This \"slop\" isn't always commercially motivated, contributing to misinformation and degrading online discourse.\n\nThe author highlights the increasing burden on content moderators, who must now distinguish between genuine awkwardness and automated spam. They fear this problem will worsen as LLMs become more advanced and spammers find innovative uses. The rise of convincing voice scams and the potential for LLMs to create fake personas and build extended relationships for malicious purposes are particularly concerning.\n\nWhile social networks have developed sophisticated defense mechanisms, the author worries about the applicability of these techniques to decentralized platforms like email and Mastodon, which are currently vulnerable due to their smaller size but may become more attractive targets. The author concludes with a sense of unease about the future of online moderation in the face of increasingly sophisticated LLM-powered spam.\n",
    "chinese_title": "评论的未来，大概是谎言",
    "chinese_summary": "一位资深内容审核员认为，大型语言模型（LLM）从根本上改变了在线垃圾信息的格局，使其成本更低、更加复杂，且更难检测。 过去，垃圾信息要么是低成本且容易过滤的，要么是高成本、有针对性且相对罕见的。 LLM 引入了一个新的类别：自动生成的垃圾信息，模仿真实的人类互动，利用看似合理的评论和捏造的个人经历来推广链接或产品。\n\n作者提供了示例，包括 LLM 生成的专门引用帖子内容的博客评论和不正确的文章摘要。 这种“垃圾”并非总是出于商业动机，而是助长了虚假信息并降低了在线讨论的质量。\n\n作者强调了内容审核员日益增加的负担，他们现在必须区分真实的笨拙和自动化垃圾信息。 他们担心随着 LLM 变得更加先进，垃圾邮件发送者找到创新的用途，这个问题会变得更加严重。 令人信服的语音诈骗的兴起以及 LLM 创建虚假人物并建立用于恶意目的的长期关系的可能性尤其令人担忧。\n\n虽然社交网络已经开发了复杂的防御机制，但作者担心这些技术在去中心化平台（如电子邮件和 Mastodon）上的适用性，这些平台由于规模较小目前很脆弱，但可能会变得更具吸引力。 作者最后表达了对在线审核未来在日益复杂的 LLM 驱动的垃圾信息面前感到不安。"
  },
  {
    "id": "44142266",
    "title": "Gradients Are the New Intervals",
    "url": "https://www.mattkeeter.com/blog/2025-05-14-gradients/",
    "summary": "This article explores using gradients, specifically Lipschitz continuity, as a substitute for interval arithmetic in implicit surface rasterization for 3D graphics. The author was inspired by a paper from IRIT and Adobe Research, which uses the Lipschitz property (bounded gradient) of Signed Distance Functions (SDFs) for optimizations like pruning inactive primitives and far-field culling, leading to faster rendering of complex models.\n\nThe author compares their previous implementation that used interval arithmetic with the new approach based on single-point evaluation of Lipschitz-continuous primitives. Single-point evaluation is cheaper and avoids the conservative nature of interval arithmetic, but it's limited to well-behaved primitives. The core idea is that for Lipschitz-continuous distance fields, single-point evaluation can yield interval-ish results, enabling the use of standard interval arithmetic techniques.\n\nThe article illustrates this with a circle example, showing how pseudo-intervals (derived from single-point samples and gradient bounds) can be used.  It also highlights a drawback of interval arithmetic: its sensitivity to transforms, which is mitigated by the Lipschitz continuity approach.\n\nFurthermore, the article addresses scenarios where the distance field isn't Lipschitz-continuous, proposing a normalization technique involving forward-mode automatic differentiation to enforce the Lipschitz property (normalize gradients before min/max). Expression simplification benefits (reducing complexity by pruning branches) were also noted with both approaches. Finally, the article discusses performance considerations and highlights single point sampling as superior due to efficiency.\n",
    "chinese_title": "梯度是新的区间",
    "chinese_summary": "本文探讨了在三维图形隐式曲面光栅化中使用梯度（特别是Lipschitz连续性）替代区间算术的方法。作者受到IRIT和Adobe Research一篇论文的启发，该论文利用有符号距离函数（SDF）的Lipschitz性质（有界梯度）进行优化，例如裁剪不活跃的图元和远场剔除，从而加快复杂模型的渲染速度。\n\n作者将之前使用区间算术的实现与基于Lipschitz连续图元的单点评估的新方法进行了比较。单点评估成本更低，并避免了区间算术的保守性，但它仅限于表现良好的图元。核心思想是，对于Lipschitz连续距离场，单点评估可以产生类似区间的结果，从而可以使用标准的区间算术技术。\n\n本文用一个圆的例子说明了这一点，展示了如何使用伪区间（从单点样本和梯度边界导出）。它还强调了区间算术的一个缺点：对变换的敏感性，而Lipschitz连续性方法可以缓解这个问题。\n\n此外，本文还解决了距离场不是Lipschitz连续的情况，提出了一种涉及前向模式自动微分的归一化技术，以强制执行Lipschitz性质（在最小值/最大值之前对梯度进行归一化）。两种方法都注意到表达式简化带来的好处（通过修剪分支来降低复杂性）。最后，本文讨论了性能方面的考虑，并强调了单点采样由于效率更高而优于区间算术。"
  },
  {
    "id": "44132744",
    "title": "Triangle splatting: radiance fields represented by triangles",
    "url": "https://trianglesplatting.github.io/",
    "summary": "This paper introduces \"Triangle Splatting,\" a novel method for radiance field rendering that uses triangles as the fundamental scene representation. The authors argue for a return to triangles, leveraging their compatibility with standard graphics pipelines and GPU hardware. Triangle Splatting optimizes triangles directly using end-to-end gradients via a differentiable renderer that renders each triangle as a differentiable splat.\n\nThe core innovation lies in a smooth window function derived from the 2D signed distance field (SDF) of each projected triangle, modulating its influence on pixel colors. This function allows for adjustable sharpness and prevents the blurring often seen in Gaussian Splatting approaches. Triangle parameters (vertices, color, opacity, smoothness) are optimized through gradient-based learning.\n\nThe results demonstrate that Triangle Splatting achieves higher visual fidelity, faster convergence, and increased rendering throughput compared to 2D and 3D Gaussian Splatting, particularly in preserving sharp edges and fine details. On the Mip-NeRF360 dataset, it outperforms concurrent non-volumetric primitives and even achieves higher perceptual quality than Zip-NeRF on indoor scenes. Furthermore, the method boasts impressive rendering speeds, achieving over 2,400 FPS at 1280x720 resolution on a single RTX4090 for the Garden scene.\n\nThe triangle-based representation is inherently compatible with mesh-based renderers, facilitating seamless integration into traditional graphics pipelines and game engines, opening possibilities for real-time applications in AR/VR and interactive simulations. Although the current visuals aren't optimized for game engine fidelity, they represent a significant step towards integrating radiance fields into interactive 3D environments.\n",
    "chinese_title": "三角形泼溅：用三角形表示的辐射场",
    "chinese_summary": "本文介绍了一种名为“三角形溅射”的新型辐射场渲染方法，该方法使用三角形作为基本场景表示。作者认为应该回归三角形，利用其与标准图形流水线和GPU硬件的兼容性。“三角形溅射”通过一个可微渲染器，将每个三角形渲染为可微溅射，并使用端到端梯度直接优化三角形。\n\n其核心创新在于一种平滑的窗口函数，该函数源自每个投影三角形的2D有向距离场(SDF)，用于调节其对像素颜色的影响。这种函数允许调整清晰度，并防止高斯溅射方法中常见的模糊现象。三角形参数（顶点、颜色、不透明度、平滑度）通过基于梯度的学习进行优化。\n\n结果表明，与2D和3D高斯溅射相比，“三角形溅射”实现了更高的视觉保真度、更快的收敛速度和更高的渲染吞吐量，尤其是在保留锐利边缘和精细细节方面。在Mip-NeRF360数据集上，它优于并发的非体积基元，甚至在室内场景中实现了比Zip-NeRF更高的感知质量。此外，该方法具有令人印象深刻的渲染速度，在单个RTX4090上，以1280x720分辨率渲染Garden场景时，可达到2,400 FPS以上。\n\n基于三角形的表示固有的与基于网格的渲染器兼容，便于无缝集成到传统图形流水线和游戏引擎中，为AR/VR和交互式模拟中的实时应用开辟了可能性。虽然当前的视觉效果并未针对游戏引擎的保真度进行优化，但它们代表了将辐射场集成到交互式3D环境中的重要一步。"
  },
  {
    "id": "44140349",
    "title": "C++ to Rust Phrasebook",
    "url": "https://cel.cs.brown.edu/crp/",
    "summary": "This \"C++ to Rust Phrasebook\" is a resource designed for C++ programmers transitioning to Rust. It offers translations and explanations of common C++ programming patterns into idiomatic Rust code, illustrated with practical examples and discussions of engineering considerations.\n\nThe book is structured for random access, allowing users to quickly find solutions to specific problems they encounter while coding in Rust by relating them to familiar C++ approaches. It's not meant to be a deep dive into Rust's internals (like the Rustonomicon) but rather a practical guide focused on bridging the gap between the two languages.\n\nCreated by experienced C++ and Rust programmers at Brown University's Cognitive Engineering Lab, the book prioritizes accuracy and a balanced level of detail. It encourages users to leverage other resources like \"The Rust Programming Language,\" \"Learn X in Y Minutes,\" and \"The Embedded Rust Book\" for foundational knowledge and specific embedded systems applications.\n\nReaders are encouraged to provide feedback through a link at the bottom of each page to improve the book's accuracy and content. The authors also collect anonymous user quiz responses for research purposes. Finally, there is an option to provide an email address for notifications of new chapter additions.\n",
    "chinese_title": "C++ 到 Rust 短语手册",
    "chinese_summary": "这本《C++ 到 Rust 惯用法手册》是为从 C++ 过渡到 Rust 的程序员设计的资源。它提供了常见 C++ 编程模式到地道 Rust 代码的翻译和解释，并通过实践示例和工程考量讨论进行说明。\n\n本书结构便于随机访问，允许用户通过将遇到的特定问题与熟悉的 C++ 方法联系起来，快速找到 Rust 编码的解决方案。它并非旨在深入研究 Rust 的内部机制（如 Rustonomicon），而是一个专注于弥合两种语言之间差距的实用指南。\n\n本书由布朗大学认知工程实验室经验丰富的 C++ 和 Rust 程序员创建，优先考虑准确性和平衡的细节水平。它鼓励用户利用其他资源，如《Rust 程序设计语言》、《Y 分钟学会 X》和《嵌入式 Rust 书籍》，以获取基础知识和特定的嵌入式系统应用。\n\n鼓励读者通过每页底部的链接提供反馈，以提高本书的准确性和内容。作者还会收集匿名用户测验回复以供研究之用。最后，可以选择提供电子邮件地址以接收新增章节的通知。"
  },
  {
    "id": "44148837",
    "title": "Cholesterol treatment can cut levels by 69% after one dose",
    "url": "https://www.sciencefocus.com/news/new-cholesterol-treatment-could-be-revolutionary-verve",
    "summary": "A single injection of the experimental drug VERVE-102 shows promise in dramatically reducing LDL (\"bad\") cholesterol levels, potentially revolutionizing heart attack prevention. Early results from a clinical trial indicate that the drug can lower cholesterol by up to 69% after just one dose, offering a \"one-and-done\" alternative to daily statins.\n\nVERVE-102 works by \"switching off\" the PCSK9 gene in the liver, which regulates LDL cholesterol removal from the bloodstream. The trial involved 14 participants with familial hypercholesterolemia, a genetic condition causing high LDL cholesterol. All participants responded well with no serious side effects. Different doses resulted in varying reductions in LDL cholesterol, with the highest dose leading to a 53% reduction on average, and one participant experiencing a 69% decrease.\n\nExperts, including Dr. Eugene Braunwald, consider the initial data \"promising\" and suggest it could herald a new era in cardiovascular disease treatment. While the trial results have not yet been peer-reviewed, cardiologist Prof Riyaz Patel emphasizes the potential of VERVE-102 to significantly change cholesterol management. Verve is currently recruiting for further trials with higher doses in multiple countries, and final results are expected in the second half of 2025.\n",
    "chinese_title": "胆固醇治疗单次剂量可降低69%水平",
    "chinese_summary": "实验性药物VERVE-102单次注射显示出显著降低低密度脂蛋白（“坏”）胆固醇水平的潜力，有望彻底改变心脏病发作的预防。一项临床试验的早期结果表明，该药物仅需一剂即可降低高达69%的胆固醇，为每日服用他汀类药物提供了一种“一劳永逸”的替代方案。\n\nVERVE-102通过“关闭”肝脏中的PCSK9基因发挥作用，该基因调节血液中低密度脂蛋白胆固醇的清除。该试验涉及14名患有家族性高胆固醇血症（一种导致高低密度脂蛋白胆固醇的遗传性疾病）的参与者。所有参与者反应良好，没有严重的副作用。不同剂量导致低密度脂蛋白胆固醇的降低幅度不同，最高剂量平均降低53%，其中一名参与者降低了69%。\n\n包括Eugene Braunwald博士在内的专家认为，初步数据“充满希望”，并暗示它可能预示着心血管疾病治疗的新时代。虽然该试验结果尚未经过同行评审，但心脏病专家Riyaz Patel教授强调了VERVE-102在显著改变胆固醇管理方面的潜力。Verve目前正在多个国家招募更高剂量药物的进一步试验参与者，最终结果预计将于2025年下半年公布。"
  },
  {
    "id": "44146145",
    "title": "Why we can't have nice private TLD DNSSEC",
    "url": "https://egbert.net/blog/articles/dns-dnssec-private.html",
    "summary": "This article explores the challenges of implementing DNSSEC for private LANs and private top-level domains (TLDs) within enterprises and homelabs. The author argues that despite the desire for localized trust anchor distribution, the current DNSSEC infrastructure is not well-suited for this purpose.\n\nThe core issue lies in the design of DNSSEC, which relies on a chain of trust originating from the root zone and extending downward. For private LANs, this requires out-of-band coordination with the owners of parent zones to insert DS records, a process that becomes impractical when a private TLD is used to avoid external exposure.\n\nThe author critiques existing solutions like filtering private subdomains and split-horizon name servers as inadequate for combining DNSSEC and privacy. They point out that the DNS validator's current logic requires retrieving DS records from the parent zone, preventing a clean \"zone cut\" for private TLDs.\n\nThe article proposes a modification to DNS resolvers to allow \"pre-validation\" of DS records for private zones, effectively creating a local trust anchor. While acknowledging potential downsides like Man-in-the-Middle attacks, the author argues that such a system, used internally and with proper safeguards, could significantly boost DNSSEC adoption in private environments. They suggest that current DNSSEC adoption rate is low, and that internal private adoption would not impact the overall security posture of the Internet.\n\nThe author concludes by advocating for changes to resolvers to allow for a circumvention of the usual lookup of DS records to one that looks locally instead. They highlight the potential for wider DNSSEC adoption and easier administration training.\n",
    "chinese_title": "为什么我们不能拥有好的私有TLD DNSSEC",
    "chinese_summary": "本文探讨了在企业和家庭实验室中为私有局域网和私有顶级域名（TLD）实施 DNSSEC 所面临的挑战。作者认为，尽管人们希望实现本地化的信任锚分发，但当前的 DNSSEC 基础设施并不适合此目的。\n\n核心问题在于 DNSSEC 的设计，它依赖于从根区域向下延伸的信任链。对于私有局域网，这需要与父区域的所有者进行带外协调以插入 DS 记录，当使用私有 TLD 来避免外部暴露时，这个过程变得不切实际。\n\n作者批评了现有的解决方案，例如过滤私有子域名和分离域名的名称服务器，认为它们不足以结合 DNSSEC 和隐私。他们指出，DNS 验证器的当前逻辑需要从父区域检索 DS 记录，从而阻止了私有 TLD 的干净“区域分割”。\n\n本文提出了一种修改 DNS 解析器的方法，以允许对私有区域的 DS 记录进行“预验证”，从而有效地创建本地信任锚。虽然承认潜在的缺点，例如中间人攻击，但作者认为，这种系统在内部使用并采取适当的安全措施，可以显著提高 DNSSEC 在私有环境中的采用率。他们认为当前 DNSSEC 的采用率很低，并且内部私有采用不会影响 Internet 的整体安全态势。\n\n作者最后倡导更改解析器，允许绕过通常的 DS 记录查找，改为本地查找。他们强调了更广泛地采用 DNSSEC 和更轻松的管理员培训的潜力。"
  },
  {
    "id": "44131669",
    "title": "Copy Excel to Markdown Table (and vice versa)",
    "url": "https://thisdavej.com/copy-table-in-excel-and-paste-as-a-markdown-table/",
    "summary": "The article \"Copy Excel to Markdown Table (and vice versa)\" by thisdavej.com outlines a simple and effective method for converting data between Excel tables and Markdown tables. The core problem addressed is the lack of direct compatibility between the two formats, requiring manual re-formatting when moving data between them.\n\nThe solution presented involves copying the data from an Excel spreadsheet, then using a text editor (the article specifically mentions VS Code) with multi-cursor functionality to add the necessary Markdown table syntax. This syntax includes the leading and trailing pipes (|) for each cell, and the header separator line (|- -|- -|).\n\nThe article details a step-by-step process:\n\n1.  **Copy the data from Excel.**\n2.  **Paste the data into a text editor** (like VS Code) – the data will be tab-separated.\n3.  **Use multi-cursor to add pipes (|) to the beginning and end of each line.** This is typically done by placing the cursor at the beginning of the first line, using the keyboard shortcut (Alt+Shift+Down Arrow in VS Code) to create cursors on each subsequent line, and then typing a pipe. The process is repeated for the end of the line.\n4.  **Add the header separator line.** This involves manually adding a line with \"|- -|- -\" (or similar, depending on the number of columns) after the header row.\n\nThe article also hints at the reverse process (Markdown to Excel), although it doesn't provide as much detail. It suggests copying the Markdown table and pasting it into Excel. Excel will often automatically parse the data into columns if the pipes are correctly formatted.\n\nIn essence, the article provides a practical workaround using multi-cursor editing to bridge the gap between Excel and Markdown tables, offering a quicker alternative to manual re-formatting.\n",
    "chinese_title": "复制 Excel 表格到 Markdown 表格 (反之亦然)",
    "chinese_summary": "该文章 \"将Excel复制到Markdown表格（反之亦然）\" (thisdavej.com) 概述了一种简单有效的方法，用于在Excel表格和Markdown表格之间转换数据。它解决的核心问题是两种格式之间缺乏直接兼容性，需要在两者之间移动数据时进行手动重新格式化。\n\n提出的解决方案包括从Excel电子表格中复制数据，然后使用具有多光标功能的文本编辑器（文章特别提到了VS Code）来添加必要的Markdown表格语法。这种语法包括每行单元格的前导和尾随竖线（|），以及表头分隔线（|- -|- -|）。\n\n文章详细介绍了以下步骤：\n\n1.  **从Excel复制数据。**\n2.  **将数据粘贴到文本编辑器中**（如VS Code） - 数据将以制表符分隔。\n3.  **使用多光标在每行的开头和结尾添加竖线（|）。** 这通常通过将光标放在第一行的开头，使用键盘快捷键（在VS Code中为Alt+Shift+向下箭头）在每个后续行上创建光标，然后键入竖线来完成。 对行尾重复此过程。\n4.  **添加表头分隔线。** 这涉及在标题行之后手动添加一行带有\"|- -|- -\"（或类似的，取决于列数）的行。\n\n该文章还暗示了反向过程（Markdown到Excel），尽管它没有提供太多细节。 它建议复制Markdown表格并将其粘贴到Excel中。 如果竖线格式正确，Excel通常会自动将数据解析为列。\n\n本质上，该文章提供了一种实用的解决方法，使用多光标编辑来弥合Excel和Markdown表格之间的差距，从而提供了一种比手动重新格式化更快的替代方案。"
  }
]