[
  {
    "id": "44224992",
    "title": "Hokusai Moyo Gafu: an album of dyeing patterns",
    "url": "https://ndlsearch.ndl.go.jp/en/imagebank/theme/hokusaimoyo",
    "summary": "This text describes \"Hokusai Moyo Gafu: an album of dyeing patterns,\" a pattern album created by KATSUSHIKA Hokusai as a sample book for dyeing patterns. The album contains many original designs invented by Hokusai himself.\n\nThe text also references the NDL Image Bank, a public-domain digital gallery of the National Diet Library in Japan. This gallery features thousands of out-of-copyright Japanese artworks and images from the library's vast collection.\n\nFurthermore, the text mentions the NDL Gallery and NDL Digital Exhibitions, online content showcasing digitized materials from the National Diet Library, offering exhibitions and explanations covering diverse themes like nishiki-e, landscape photographs, and historical materials. The purpose is to allow users to explore and discover various collections available through the National Diet Library's digital resources. It also provides a long list of similar resources.\n",
    "chinese_title": "北斋模様画谱：染色图案集",
    "chinese_summary": "本文描述了葛飾北齋創作的染紋樣見本帖《北齋模様畫譜》，收錄了大量北齋獨創的設計。\n\n本文還提到了日本國立國會圖書館的公共領域數字圖庫NDL Image Bank。該圖庫收錄了數千張來自該圖書館龐大收藏的無版權日本藝術品和圖像。\n\n此外，本文還提及了NDL Gallery和NDL Digital Exhibitions，它們是在線展示國立國會圖書館數字化資料的內容，提供涵蓋錦繪、風景照片和歷史資料等多種主題的展覽和說明。其目的是讓用戶能夠探索和發現通過國立國會圖書館數字資源提供的各種館藏。它還提供了一長串類似的資源。"
  },
  {
    "id": "44224915",
    "title": "Why Quadratic Funding Is Not Optimal",
    "url": "https://jonathanwarden.com/quadratic-funding-is-not-optimal/",
    "summary": "This article argues that quadratic funding (QF), while theoretically optimal for public goods funding under specific assumptions, often fails in practice because these assumptions rarely hold true in the real world. The author identifies several key assumptions: wealth equality, free subsidies, selfish contributors, equilibrium discovery, sufficient budget, diminishing returns, perfect knowledge, and independent agents.\n\nThe article demonstrates how wealth inequality can lead to disproportionate benefits for wealthy contributors at the expense of projects benefiting lower-income individuals. It also highlights the issue of \"free\" subsidies, pointing out that subsidies are often funded through taxes, potentially leading to wealth transfer from poor to rich.\n\nFurthermore, the author explains how altruistic contributors can lead to overfunding of projects, reducing overall social welfare. The lack of complete information and the absence of an equilibrium discovery process make it difficult for contributors to determine optimal contribution amounts. Insufficient budget and the lack of diminishing returns can lead to unpredictable and suboptimal outcomes.\n\nThe article also highlights the problem of collusion, which is a known issue with QF. The author concludes that because these assumptions are unlikely to hold, the theoretical optimality of QF is often not achieved in practice, and alternative funding mechanisms might yield better results. While improvements like Connection-Oriented Cluster Matching address some issues, such as collusion and non-selfish contributors, they come at the cost of theoretical optimality.\n",
    "chinese_title": "二次方资助并非最优",
    "chinese_summary": "本文认为，二次方资助（QF）在特定假设下理论上是公共产品资助的最佳方案，但由于这些假设在现实世界中很少成立，因此在实践中经常失效。作者指出了几个关键假设：财富平等、免费补贴、自私的贡献者、均衡发现、充足的预算、收益递减、完美知识和独立个体。\n\n本文论证了财富不平等如何导致富裕贡献者不成比例地受益，而牺牲了惠及低收入人群的项目。它还强调了“免费”补贴的问题，指出补贴通常通过税收提供资金，可能导致财富从穷人转移到富人。\n\n此外，作者解释了利他主义贡献者如何导致项目过度融资，从而降低整体社会福利。缺乏完整信息和均衡发现过程使得贡献者难以确定最佳贡献金额。预算不足和缺乏收益递减会导致不可预测且不理想的结果。\n\n本文还强调了勾结问题，这是 QF 的一个已知问题。作者得出结论，由于这些假设不太可能成立，QF 的理论最优性在实践中往往无法实现，而替代融资机制可能会产生更好的结果。虽然诸如面向连接的集群匹配之类的改进解决了一些问题，例如勾结和非自私的贡献者，但它们以牺牲理论最优性为代价。"
  },
  {
    "id": "44224996",
    "title": "The new Gödel Prize winner tastes great and is less filling",
    "url": "https://blog.computationalcomplexity.org/2025/06/the-new-godel-prize-winner-tastes-great.html",
    "summary": "This blog post announces that the 2025 Gödel Prize has been awarded to Eshan Chattopadhyay and David Zuckerman for their work on explicit two-source extractors and resilient functions. The authors, Bill and Lance, discuss the result's significance from different perspectives.\n\nBill emphasizes the application to constructive Ramsey theory, specifically improving the lower bound on the Ramsey number R(k) constructively to exponential in 2^(log k)^epsilon. He contrasts this constructive improvement with the known non-constructive lower bound of k2^(k/2) and the known (and harder to prove) upper bound of 3.993^k.\n\nLance, on the other hand, highlights the result's profound implications for pseudorandomness, arguing that the ability to extract near-perfect random bits from two independent sources of low min-entropy is the paper's real achievement. He dismisses the Ramsey theory application as a minor corollary, showcasing his preference for theoretical computer science applications over combinatorial ones. He also points to his earlier blog post titled \"Extracting Ramsey Graphs,\" a title he deems clever for capturing both aspects of the work.\n\nThe post humorously contrasts Bill and Lance's differing viewpoints, likening it to the Miller Lite slogan \"Less Filling AND Tastes Great\" to suggest that the result can be both a derandomization breakthrough and have Ramsey Theory applications.\n",
    "chinese_title": "新的哥德尔奖得主味道好，而且更管饱。",
    "chinese_summary": "本博客宣布2025年哥德尔奖授予Eshan Chattopadhyay和David Zuckerman，以表彰他们在显式双源提取器和弹性函数方面的工作。作者Bill和Lance从不同角度讨论了这项成果的意义。\n\nBill强调了其在构造性Ramsey理论中的应用，特别是将Ramsey数R(k)的构造性下界提高到2^(log k)^epsilon的指数级别。他将这种构造性改进与已知的k2^(k/2)的非构造性下界以及已知的（且更难证明的）3.993^k的上界进行了对比。\n\n另一方面，Lance强调了该成果对伪随机性的深刻影响，认为从两个具有低最小熵的独立源中提取近乎完美的随机位是这篇论文的真正成就。他认为Ramsey理论的应用只是一个次要的推论，表明了他对理论计算机科学应用胜过组合应用的偏好。他还提到了他之前题为“提取Ramsey图”的博客文章，他认为这个标题巧妙地概括了这项工作的两个方面。\n\n这篇文章幽默地对比了Bill和Lance的不同观点，将其比作米勒淡啤的口号“少填充且味道好”，以表明该成果既可以是一项去随机化的突破，又可以有Ramsey理论的应用。"
  },
  {
    "id": "44224874",
    "title": "Doctors Could Hack the Nervous System with Ultrasound",
    "url": "https://spectrum.ieee.org/focused-ultrasound-stimulation-inflammation-diabetes",
    "summary": "This article explores the potential of Focused Ultrasound Stimulation (FUS) as a non-invasive technique to treat various conditions by modulating the nervous system. FUS uses sound waves to stimulate neurons in targeted areas, offering a more precise alternative to drug-based treatments or invasive procedures like deep brain stimulation.\n\nResearchers at the Institute of Bioelectronic Medicine have shown that FUS can effectively reduce inflammation by targeting the vagus nerve and spleen, potentially offering relief for chronic inflammatory diseases like arthritis. A human trial demonstrated that even brief ultrasound imaging had a moderate anti-inflammatory effect, and subsequent experiments with unplugged machines showed that FUS significantly lowered levels of the inflammation biomarker TNF.\n\nFurthermore, FUS shows promise in treating metabolic disorders like obesity and diabetes. Studies on mice and rats revealed that FUS stimulation of glucose-sensing neurons in the liver's porta hepatis led to reduced glucose levels and weight loss. The mechanism involves the hypothalamus, which regulates metabolism based on signals from the liver.\n\nThe article also discusses FUS's potential in treating cardiopulmonary diseases, specifically pulmonary arterial hypertension. Research on rats showed that FUS sessions reduced pulmonary pressure, improved heart function, and reduced lung inflammation, suggesting a lasting effect on disease progression.\n\nThe future of FUS involves developing user-friendly, wearable devices for at-home treatment, guided by AI systems. Clinical trials are underway to test the effectiveness of FUS in treating obesity and diabetes.\n",
    "chinese_title": "医生或可用超声波入侵神经系统",
    "chinese_summary": "本文探讨了聚焦超声刺激 (FUS) 作为一种非侵入性技术治疗各种疾病的潜力，其原理是通过调节神经系统来实现。FUS利用声波刺激靶向区域的神经元，为基于药物的治疗或诸如脑深部刺激之类的侵入性手术提供了一种更精确的替代方案。\n\n生物电子医学研究所的研究人员表明，FUS可以通过靶向迷走神经和脾脏来有效减轻炎症，从而为诸如关节炎之类的慢性炎症性疾病提供潜在的缓解。一项人体试验表明，即使是短暂的超声成像也具有中度的抗炎作用，随后用未插电的机器进行的实验表明，FUS显著降低了炎症生物标志物TNF的水平。\n\n此外，FUS在治疗诸如肥胖症和糖尿病之类的代谢紊乱方面显示出前景。对小鼠和大鼠的研究表明，FUS刺激肝门静脉中葡萄糖敏感神经元可导致葡萄糖水平降低和体重减轻。该机制涉及下丘脑，下丘脑会根据来自肝脏的信号调节新陈代谢。\n\n本文还讨论了FUS在治疗心肺疾病，特别是肺动脉高压方面的潜力。对大鼠的研究表明，FUS治疗可以降低肺动脉压力，改善心脏功能并减少肺部炎症，这表明对疾病进展具有持久的影响。\n\nFUS的未来包括开发用户友好、可穿戴的家用治疗设备，并由人工智能系统进行指导。目前正在进行临床试验，以测试FUS在治疗肥胖症和糖尿病方面的有效性。"
  },
  {
    "id": "44225761",
    "title": "Algovivo an energy-based formulation for soft-bodied virtual creatures",
    "url": "https://juniorrojas.com/algovivo/",
    "summary": "The article \"Algovivo: An energy-based formulation for soft-bodied virtual creatures\" introduces Algovivo, a system for simulating and animating soft-bodied virtual creatures using an energy-based formulation. The core idea is to model the creature's body as a deformable structure driven by energy principles, rather than relying solely on traditional control methods.\n\nAlgovivo utilizes an energy function that incorporates both internal energy (representing deformation resistance) and external energy (related to environmental interactions and actuation). This allows the system to naturally handle complex deformations and adapt to external forces.\n\nThe article likely details the specific energy functions used to model different aspects of the creature's body, such as elasticity, bending, and damping. It likely also covers the methods used to minimize the energy function, resulting in the creature's stable posture and movements.\n\nA key advantage of Algovivo is its ability to create realistic and physically plausible animations. The energy-based approach allows for emergent behaviors and avoids the limitations of pre-defined motion patterns. This makes it suitable for simulating diverse creatures in complex environments.\n\nFurthermore, the article likely discusses the implementation details of Algovivo, including the computational challenges and optimizations involved in minimizing the energy function. It may also present examples of virtual creatures animated using Algovivo, demonstrating its capabilities and potential applications. The \"algovivo\" mention on its own likely means the authors are providing this term as the system's/algorithm's name.\n",
    "chinese_title": "Algovivo：一种基于能量的软体虚拟生物建模方法",
    "chinese_summary": "文章《Algovivo：一种基于能量的软体虚拟生物建模方法》介绍了Algovivo，一个使用基于能量的公式来模拟和动画软体虚拟生物的系统。其核心思想是将生物的身体建模为由能量原理驱动的可变形结构，而不是仅仅依赖于传统的控制方法。\n\nAlgovivo利用一个能量函数，该函数包含内部能量（代表变形阻力）和外部能量（与环境交互和驱动相关）。这使得系统能够自然地处理复杂的变形并适应外力。\n\n文章可能详细介绍了用于模拟生物身体不同方面的特定能量函数，例如弹性、弯曲和阻尼。它也可能涵盖用于最小化能量函数的方法，从而产生生物的稳定姿势和运动。\n\nAlgovivo的一个关键优势是它能够创建逼真且物理上合理的动画。基于能量的方法允许涌现行为，并避免了预定义运动模式的限制。这使其适用于在复杂环境中模拟各种生物。\n\n此外，文章可能讨论了Algovivo的实现细节，包括最小化能量函数所涉及的计算挑战和优化。它也可能展示使用Algovivo动画的虚拟生物示例，展示其功能和潜在应用。“Algovivo”单独出现时，很可能表示作者将这个术语作为系统/算法的名称。"
  },
  {
    "id": "44225922",
    "title": "Show HN: Glowstick – type level tensor shapes in stable rust",
    "url": "https://github.com/nicksenger/glowstick",
    "summary": "Glowstick is a Rust crate designed to make tensor manipulation safer and easier by encoding tensor shapes within the type system. This enables compile-time shape checking, preventing runtime errors and improving code reliability. The crate supports both static and dynamic dimensions (gradual typing).\n\nGlowstick integrates with popular Rust ML frameworks like Candle and Burn. It provides various tensor operations, including reshape, unsqueeze, squeeze, narrow, broadcast_add, transpose, conv2d, and flatten, all with type-level shape validation. The `debug_tensor!` macro aids in manually checking type-level shapes.\n\nThe crate utilizes type-level numbers for representing dimensions and ranks, enabling expressive tensor shape definitions. The project is currently pre-1.0 and subject to breaking changes. Its goal is to provide support for all ONNX operations and to improve the usability of tensor manipulation in Rust. Error messages are intended to be human-readable, though are indicated as such only \"sort of.\" Example use cases and integrations are available in the \"examples\" directory.\n",
    "chinese_title": "Show HN: Glowstick – 在稳定Rust中实现类型级别张量形状",
    "chinese_summary": "Glowstick 是一个 Rust crate，旨在通过在类型系统中编码张量形状，使张量操作更安全、更简单。 这实现了编译时形状检查，防止运行时错误并提高代码可靠性。 该 crate 支持静态和动态维度（渐进式类型）。\n\nGlowstick 与流行的 Rust ML 框架（如 Candle 和 Burn）集成。 它提供了各种张量操作，包括 reshape、unsqueeze、squeeze、narrow、broadcast_add、transpose、conv2d 和 flatten，所有这些都具有类型级别的形状验证。 `debug_tensor!` 宏有助于手动检查类型级别的形状。\n\n该 crate 利用类型级别的数字来表示维度和秩，从而实现富有表现力的张量形状定义。 该项目目前是 1.0 之前的版本，可能会发生重大更改。 它的目标是为所有 ONNX 操作提供支持，并提高 Rust 中张量操作的可用性。 错误消息旨在实现人类可读性，但仅被“勉强”标注为如此。 示例用例和集成可在“examples”目录中找到。"
  },
  {
    "id": "44224684",
    "title": "Bruteforcing the phone number of any Google user",
    "url": "https://brutecat.com/articles/leaking-google-phones",
    "summary": "This article details a vulnerability allowing the brute-forcing of Google account phone numbers. The author discovered that Google's username recovery form, surprisingly functional without JavaScript, could be exploited. The process involved sending HTTP requests to check if a recovery email/phone number was associated with a specific display name.\n\nInitial attempts to brute-force were thwarted by rate limiting and captchas. However, the author bypassed these restrictions by leveraging IPv6 address rotation and, more importantly, by using the botguard token from the JavaScript-enabled form in the No-JS form, which had no rate limits. This allowed them to check numerous phone numbers quickly.\n\nTo refine the attack, the author addressed the problem of determining the victim's country code by parsing phone number masks from the \"forgot password\" flow using libphonenumbers. They also discovered a method to leak the victim's display name via Google's Looker Studio.\n\nThe author then implemented real-time libphonenumber validation and automated botguard token generation. The complete attack chain involved leaking the display name, obtaining the masked phone number format, and then using a custom program (\"gpb\") to brute-force the phone number.\n\nThe author reported the vulnerability to Google, who initially awarded a small bounty but later increased it to $5,000 after an appeal. Google implemented mitigations and eventually deprecated the No-JS username recovery form, resolving the vulnerability.\n",
    "chinese_title": "暴力破解任何Google用户的电话号码",
    "chinese_summary": "本文详细描述了一个允许暴力破解Google账户电话号码的漏洞。作者发现，Google的用户名找回表单，在没有JavaScript的情况下仍然可以运行，并且可以被利用。该过程涉及发送HTTP请求，以检查恢复电子邮件/电话号码是否与特定的显示名称相关联。\n\n最初的暴力破解尝试受到了速率限制和验证码的阻碍。然而，作者通过利用IPv6地址轮换，更重要的是，通过在无JavaScript表单中使用JavaScript表单中的botguard令牌绕过了这些限制，而无JavaScript表单没有速率限制。这使得他们能够快速检查大量电话号码。\n\n为了改进攻击，作者通过使用libphonenumbers解析“忘记密码”流程中的电话号码掩码，解决了确定受害者国家代码的问题。他们还发现了一种通过Google的Looker Studio泄露受害者显示名称的方法。\n\n然后，作者实现了实时的libphonenumber验证和自动化的botguard令牌生成。完整的攻击链包括泄露显示名称、获取掩码后的电话号码格式，然后使用自定义程序（“gpb”）来暴力破解电话号码。\n\n作者向Google报告了该漏洞，Google最初奖励了一笔小额赏金，但在申诉后将其增加到5,000美元。 Google实施了缓解措施，并最终弃用了无JavaScript用户名找回表单，从而解决了该漏洞。"
  },
  {
    "id": "44225324",
    "title": "Maypole Dance of Braid Like Groups",
    "url": "https://divisbyzero.com/2009/05/04/the-maypole-braid-group/",
    "summary": "This article explores the mathematical structure underlying a traditional Maypole dance, connecting it to the concept of braid groups in knot theory. The author, inspired by a May Day party, observes the patterns created by dancers weaving ribbons around a maypole and relates it to Artin's braid group, a group defined by strings hanging between two rods, wound around each other.\n\nThe article reviews the definition of the Artin braid group, its generators (sigma_i representing adjacent string crossings), and its defining relations: far commutativity (generators commute when far apart) and braid relations (corresponding to Reidemeister moves).\n\nThe author then proposes the concept of a \"maypole braid group\" to model the circular braiding of the maypole ribbons. This group differs from the standard braid group because the ribbons are attached to circles, and the strings cannot pass through the pole's axis.  It's suggested that the usual braid group generators are not sufficient to represent all possible maypole braids.\n\nTo address this, the author introduces a new generator, tau, representing a simultaneous counterclockwise rotation of all ribbons.  The article then postulates that the maypole braid group is generated by the standard braid generators (sigma_i) *and* tau, along with the existing relations from the Artin braid group, plus a new \"rotation relation\" that dictates how tau interacts with the other generators. The author concludes by suggesting that the maypole braid group is fully defined by these generators and relations.\n",
    "chinese_title": "辫状群体的五月柱舞",
    "chinese_summary": "本文探讨了传统五月柱舞蹈背后的数学结构，并将其与纽结理论中的辫群概念联系起来。作者受五一节派对的启发，观察到舞者围绕五月柱编织彩带所形成的图案，并将其与Artin辫群联系起来。Artin辫群是由悬挂在两根杆子之间并相互缠绕的线所定义的群。\n\n本文回顾了Artin辫群的定义、其生成元（sigma_i 代表相邻线交叉）及其定义关系：远距离交换律（生成元在相距较远时交换）和辫关系（对应于Reidemeister移动）。\n\n作者随后提出了“五月柱辫群”的概念，以模拟五月柱彩带的圆形编织。该群与标准辫群不同，因为彩带连接到圆圈，并且线不能穿过柱子的轴。作者认为通常的辫群生成元不足以表示所有可能的五月柱辫。\n\n为了解决这个问题，作者引入了一个新的生成元，tau，代表所有彩带同时逆时针旋转。本文随后假设五月柱辫群由标准辫生成元（sigma_i）*和* tau生成，以及来自Artin辫群的现有关系，再加上一个新的“旋转关系”，该关系规定了tau如何与其他生成元相互作用。作者最后提出，五月柱辫群完全由这些生成元和关系定义。"
  },
  {
    "id": "44206150",
    "title": "A man rebuilding the last Inca rope bridge",
    "url": "https://www.atlasobscura.com/articles/last-inca-rope-bridge-qeswachaka-tradition",
    "summary": "This article recounts the story of the Q’eswachaka, the last remaining Inca rope bridge, and Victoriano Arizapana, the man who rebuilds it annually. The Inca Empire used a vast road system with rope bridges to traverse the Andes' difficult terrain. These bridges were constructed using a unique method of weaving strong cables from locally sourced grass called coya.\n\nWhile hundreds of these bridges once existed, the Q’eswachaka is the sole survivor. Each year, Victoriano leads four local communities in a three-day process to dismantle and re-weave the bridge. This process involves cutting and braiding the coya, creating large cables, and then anchoring them to stone pylons on either side of the river. Victoriano himself then weaves the walking surface of the bridge, suspended barefoot above the rushing water.\n\nThe article emphasizes that this tradition continues despite the existence of a modern steel bridge nearby. The annual rebuilding is a testament to the community's deep connection to their Inca heritage and a way to honor their ancestors. It represents a renewal of life and a link to the past. Despite the inherent danger involved, the communities continue to participate, driven by a cultural imperative passed down through generations.\n",
    "chinese_title": "重建最后一座印加绳桥的人",
    "chinese_summary": "本文讲述了最后一座印加绳桥——盖斯瓦恰卡桥的故事，以及每年重建这座桥的维克托里亚诺·阿里扎帕纳的故事。印加帝国曾利用由绳桥组成的庞大道路系统来穿越安第斯山脉的崎岖地形。这些桥梁采用独特的编织方法，用当地出产的科亚草编织结实的缆绳建造而成。\n\n虽然曾经存在数百座这样的桥梁，但盖斯瓦恰卡桥是唯一幸存的一座。每年，维克托里亚诺都会带领四个当地社区用三天时间来拆除并重新编织这座桥。这个过程包括切割和编织科亚草，制作大型缆绳，然后将其固定在河流两侧的石墩上。随后，维克托里亚诺本人会赤脚悬挂在湍急的水面上，编织桥梁的行走表面。\n\n文章强调，尽管附近有一座现代化的钢桥，但这一传统仍在延续。每年一次的重建是对社区与印加遗产的深厚联系的证明，也是一种纪念祖先的方式。它代表着生命的更新和与过去的联系。尽管存在内在的危险，但社区仍然继续参与，这源于世代相传的文化使命。"
  },
  {
    "id": "44222119",
    "title": "Finding Shawn Mendes (2019)",
    "url": "https://ericneyman.wordpress.com/2019/11/26/finding-shawn-mendes/",
    "summary": "Eric Neyman's \"Finding Shawn Mendes (2019)\" humorously analyzes Shawn Mendes' 2018 song \"Lost in Japan\" to deduce Mendes' political stance on the Kuril Islands dispute between Japan and Russia. The author begins by highlighting celebrities' political influence and notes Mendes' silence on the issue.\n\nNeyman meticulously examines the song's lyrics, particularly the line \"a couple hundred miles from Japan,\" to pinpoint Mendes' location. By eliminating possibilities like South Korea, China, and Taiwan (based on time zones, distances, and Mendes' alleged mosquito allergy), he concludes that Mendes must be in the Russian Far East, specifically Yuzhno-Sakhalinsk.\n\nFurther analysis of flight schedules reveals a potential flight from Yuzhno-Sakhalinsk to Iturup Island, part of the disputed Kuril Islands. Neyman argues this is the most likely scenario, as the timing aligns with the song's lyrics. He even includes a purported photograph of Mendes at Iturup Airport as \"incontrovertible\" evidence.\n\nUltimately, Neyman concludes that Mendes' reference to Iturup Island as \"Japan\" in the song implies support for Japan's claim over the islands. The author uses this \"revelation\" to justify his own newfound stance on the issue, humorously highlighting the perceived influence of celebrities on political opinion.\n",
    "chinese_title": "寻找肖恩·蒙德兹 (2019)",
    "chinese_summary": "埃里克·内曼的《寻找肖恩·蒙德兹（2019）》幽默地分析了肖恩·蒙德兹2018年的歌曲《迷失日本》，以推断蒙德兹对日本和俄罗斯之间关于千岛群岛争端的政治立场。作者首先强调了名人的政治影响力，并注意到蒙德兹在此问题上的沉默。\n\n内曼细致地研究了这首歌的歌词，特别是“距离日本数百英里”这句歌词，以确定蒙德兹的所在地。通过排除韩国、中国和台湾的可能性（基于时区、距离以及蒙德兹据称的蚊虫过敏），他得出结论，蒙德兹一定是在俄罗斯远东地区，特别是南萨哈林斯克。\n\n对航班时刻表的进一步分析揭示了一班从南萨哈林斯克飞往择捉岛（千岛群岛争议地区的一部分）的潜在航班。内曼认为这是最有可能的情况，因为时间与歌曲的歌词相符。他甚至包括了一张据称是蒙德兹在择捉岛机场的照片，作为“无可辩驳”的证据。\n\n最终，内曼得出结论，蒙德兹在歌曲中将择捉岛称为“日本”暗示了他支持日本对这些岛屿的主张。作者利用这一“发现”来证明自己对该问题的新立场是合理的，并幽默地突出了名人对政治观点的潜在影响。"
  },
  {
    "id": "44225450",
    "title": "Anthropic's AI-generated blog dies an early death",
    "url": "https://techcrunch.com/2025/06/09/anthropics-ai-generated-blog-dies-an-early-death/",
    "summary": "Anthropic shut down its AI-generated blog, \"Claude Explains,\" just a week after TechCrunch profiled the experiment. The blog, powered by Anthropic's Claude AI models, aimed to provide explainer-type content showcasing Claude's writing abilities and demonstrating how AI can augment human expertise. The blog covered technical topics related to Claude use cases and was edited by humans for accuracy.\n\nThe decision to discontinue the blog came quickly, as plans to expand its topics were scrapped. While Anthropic claimed the blog demonstrated human-AI collaboration, it lacked transparency about the proportion of AI-generated content in each post.\n\nThe blog received mixed reactions, with some criticizing it as a disguised attempt at automated content marketing and questioning the level of human oversight. Despite its short lifespan (around a month), the blog attracted links from over 24 websites.\n\nThe article suggests Anthropic may have grown concerned about overstating Claude's writing capabilities, particularly given the risk of AI models generating inaccurate information, as seen with other publishers' experiences. Ultimately, Anthropic decided to end the \"pilot\" program, redirecting the blog's address to its homepage.\n",
    "chinese_title": "Anthropic的AI生成博客夭折",
    "chinese_summary": "Anthropic关闭其AI生成博客“Claude Explains”，此前一周TechCrunch曾报道该实验。该博客由Anthropic的Claude AI模型驱动，旨在提供解释性内容，展示Claude的写作能力，并演示AI如何增强人类专业知识。该博客涵盖了与Claude用例相关的技术主题，并由人工编辑以确保准确性。\n\n停止运营该博客的决定来得很快，扩展其主题的计划也被取消。尽管Anthropic声称该博客展示了人机协作，但其在每篇文章中AI生成内容的比例缺乏透明度。\n\n该博客的反应褒贬不一，一些人批评其是伪装成自动化内容营销的尝试，并质疑人工监督的程度。尽管其寿命很短（约一个月），但该博客吸引了来自超过24个网站的链接。\n\n文章暗示，Anthropic可能担心过度夸大Claude的写作能力，特别是考虑到AI模型生成不准确信息的风险，正如其他出版商的经历所表明的那样。最终，Anthropic决定结束这一“试点”项目，并将该博客的地址重定向到其主页。"
  },
  {
    "id": "44192883",
    "title": "The Legend of Prince's Special Custom-Font Symbol Floppy Disks",
    "url": "https://nymag.com/intelligencer/2016/04/princes-legendary-floppy-disk-symbol-font.html",
    "summary": "In 1993, Prince famously changed his name to an unpronounceable symbol to challenge his record label, Warner Bros. This created a practical problem for media outlets who needed to write about him. To solve this, Prince's team developed a custom font containing the symbol and distributed it to news organizations on floppy disks. The font replaced the capital \"P\" with the symbol, and it was also made available on CompuServe.\n\nThe idea originated from the internal frustration of Prince's Paisley Park graphic-design team, who needed a way to communicate his new name efficiently. Distributing the font was a strategic move to ensure the symbol appeared in publications.\n\nSteve Parke, who helped with the distribution, initially questioned the strategy but was later impressed to see the symbol in publications like Rolling Stone. While Prince later became known for his skepticism towards digital platforms like streaming and YouTube, this initiative showcases his forward-thinking approach to technology in the early '90s. He was enthusiastic about graphic design software and online platforms like America Online, engaging with these tools to create art. His interest in online communication even sparked once he understood its potential for connecting with people romantically.\n",
    "chinese_title": "王子特制字体符号软盘传奇",
    "chinese_summary": "1993年，王子为了挑战他的唱片公司华纳兄弟，将自己的名字改为一个无法发音的符号。这给需要报道他的媒体带来了实际问题。为了解决这个问题，王子的团队开发了一种包含该符号的自定义字体，并通过软盘分发给新闻机构。该字体用该符号替换了大写字母“P”，并且也可以在CompuServe上获得。\n\n这个想法源于王子位于佩斯利公园的平面设计团队内部的挫败感，他们需要一种有效沟通他的新名字的方式。分发字体是一项战略举措，旨在确保该符号出现在出版物中。\n\n帮助分发的史蒂夫·帕克最初对该策略表示质疑，但后来看到《滚石》等出版物中出现该符号时印象深刻。虽然王子后来因对流媒体和YouTube等数字平台的怀疑而闻名，但这一举措展示了他在 90 年代初期对技术的前瞻性态度。他对图形设计软件和 America Online 等在线平台充满热情，并利用这些工具进行艺术创作。他对在线交流的兴趣甚至在他意识到其与人浪漫交往的潜力后被激发起来。"
  },
  {
    "id": "44225988",
    "title": "Trusting your own judgement on 'AI' is a risk",
    "url": "https://www.baldurbjarnason.com/2025/trusting-your-own-judgement-on-ai/",
    "summary": "Baldur Bjarnason argues that blindly trusting one's own judgment when evaluating \"AI,\" particularly Large Language Models (LLMs), is a significant risk due to cognitive biases and psychological manipulation. Drawing from Cialdini's work on persuasion, the author emphasizes that intelligence is not a defense against these cognitive traps, and willpower is ineffective. Avoidance of these traps is the best strategy.\n\nBjarnason critiques the tendency in software development to rely on anecdotal evidence and self-experimentation, which he equates to \"gossip,\" instead of rigorous scientific studies. He uses the example of a CloudFlare engineer building an auth library with an LLM to illustrate how a single, uncontrolled experiment can be mistakenly interpreted as proof of LLM effectiveness. He also draws a parallel with homeopathy, warning that self-experimentation can lead to false conclusions and potentially harmful decisions.\n\nThe article highlights that LLMs and chatbots can trigger cognitive biases and psychological \"effects\" that distort judgment. He warns against being swayed by personal validation and the subjective experience of authority figures who claim positive results from using \"AI.\" This is because individuals can rationalize their experiences and reinforce their beliefs. He concludes that impartial research is crucial to understanding the true risks and benefits of \"AI,\" urging caution and skepticism in the meantime.\n",
    "chinese_title": "信任你对“人工智能”的判断是一种冒险。",
    "chinese_summary": "在评估“人工智能”（尤其是大型语言模型 LLM）时，盲目相信自己的判断是一种重大风险，因为存在认知偏差和心理操纵。Bjarnason 认为，借鉴西奥迪尼关于说服力的研究，智力并不能防御这些认知陷阱，意志力也无效。避免这些陷阱是最佳策略。\n\nBjarnason 批评软件开发中依赖轶事证据和自我实验的倾向，他将其等同于“闲聊”，而非严谨的科学研究。他以 CloudFlare 工程师使用 LLM 构建身份验证库为例，说明了单个不受控制的实验如何被错误地解读为 LLM 有效性的证明。他还将此与顺势疗法进行类比，警告说自我实验会导致错误的结论和潜在的有害决策。\n\n文章强调，LLM 和聊天机器人会触发扭曲判断的认知偏差和心理“效应”。他警告说，不要被个人验证和声称使用“人工智能”获得积极结果的权威人士的主观体验所左右。这是因为个人会合理化自己的经历并强化自己的信念。他得出结论，公正的研究对于了解“人工智能”的真正风险和益处至关重要，并敦促在此期间保持谨慎和怀疑。"
  },
  {
    "id": "44219405",
    "title": "Why Android can't use CDC Ethernet (2023)",
    "url": "https://jordemort.dev/blog/why-android-cant-use-cdc-ethernet/",
    "summary": "This article investigates why CDC Ethernet, a standard for USB Ethernet adapters, doesn't work on Android devices despite Android being based on Linux which supports it. The author meticulously debugs the issue, detailing the process of enabling USB debugging, installing ADB, and connecting to the phone over the network.\n\nThe article guides readers on how to find their phone's kernel configuration. For newer phones with Android 11 or later (GKI kernels), the configuration can be found in Google's Android Common Kernel repository. For older phones, like the author's Samsung Galaxy S20, the kernel configuration needs to be obtained from the manufacturer's source releases. A potentially easier alternative is checking for `/proc/config.gz` on the device.\n\nAfter obtaining the kernel configuration, the author greps for `USB_NET` to identify supported USB Ethernet drivers. While the kernel configuration shows support for CDC Ethernet standards (EEM, ECM, NCM), the author discovers that plugging in a CDC Ethernet gadget creates a `usb0` interface. Despite the interface being recognized, the Ethernet settings remain greyed out on the Android device.\n\nThe key finding is that Android's EthernetTracker service only acknowledges interfaces named `ethX`, while Linux's CDC Ethernet drivers create interfaces named `usbX`. The author concludes there's no workaround without rooting the phone to modify the `config_ethernet_iface_regex` value, explaining why CDC Ethernet doesn't function on Android. The article highlights the frustrating reliance on \"hearsay\" to determine USB Ethernet adapter compatibility for Android devices.\n",
    "chinese_title": "为什么安卓不能使用CDC以太网 (2023)",
    "chinese_summary": "本文探讨了为何CDC以太网（USB以太网适配器的一种标准）在Android设备上无法工作，尽管Android基于支持它的Linux。作者细致地调试了该问题，详细描述了启用USB调试、安装ADB以及通过网络连接手机的过程。\n\n本文指导读者如何查找手机的内核配置。对于运行Android 11或更高版本（GKI内核）的新手机，可以在Google的Android通用内核存储库中找到该配置。对于较旧的手机，例如作者的Samsung Galaxy S20，需要从制造商的源代码发布中获取内核配置。一个可能更简单的替代方案是检查设备上的`/proc/config.gz`。\n\n获取内核配置后，作者使用grep命令查找`USB_NET`以识别受支持的USB以太网驱动程序。虽然内核配置显示支持CDC以太网标准（EEM、ECM、NCM），但作者发现插入CDC以太网设备会创建一个`usb0`接口。尽管该接口被识别，但Android设备上的以太网设置仍然灰显。\n\n关键发现是Android的EthernetTracker服务仅识别名为`ethX`的接口，而Linux的CDC以太网驱动程序创建的接口名为`usbX`。作者得出结论，如果没有root手机来修改`config_ethernet_iface_regex`值，就无法解决这个问题，这解释了为什么CDC以太网在Android上不起作用。本文强调了依赖“传闻”来确定Android设备的USB以太网适配器兼容性的令人沮丧之处。"
  },
  {
    "id": "44220179",
    "title": "Riding high in Germany on the world's oldest suspended railway",
    "url": "https://www.theguardian.com/travel/2025/jun/09/riding-high-in-germany-on-the-worlds-oldest-suspended-railway",
    "summary": "This article celebrates the 125th anniversary of the Wuppertal Schwebebahn, the world's oldest suspended railway in Germany. The author recounts their enchanting experience riding the Schwebebahn, describing its unique charm and historical significance. Originally built to solve transport issues in the industrialized Wupper valley, the Schwebebahn continues to operate as a commuter service while offering a unique and almost fairground-like experience, gliding above the River Wupper.\n\nThe article highlights the Schwebodrom, a museum dedicated to the Schwebebahn's history, which includes the famous story of Tuffi the elephant who jumped into the river during a publicity stunt. The railway was rebuilt after WWII while preserving its original steampunk design.\n\nBeyond the Schwebebahn, Wuppertal is presented as a city full of surprises with pleasant streets, diverse restaurants, and a distinctive architectural style. The city's industrial history is intertwined with the wealth of 19th-century industrialists, who contributed to cultural institutions like the Von der Heydt Museum and Historische Stadthalle. The article also mentions Friedrich Engels' connection to Wuppertal and the progressive social reforms implemented by the city's industrialists. Ultimately, the Schwebebahn represents a blend of Wuppertal's unique past and a forward-thinking approach to urban transport.\n",
    "chinese_title": "在德国乘坐世界上最古老的悬浮列车",
    "chinese_summary": "本文庆祝德国伍珀塔尔悬浮列车建成125周年，它是世界上最古老的悬挂式铁路。作者回忆了乘坐悬浮列车的迷人经历，描述了其独特的魅力和历史意义。最初建造它是为了解决工业化的伍珀河谷的交通问题，悬浮列车至今仍在作为通勤服务运营，同时提供了一种独特的、几乎像游乐场般的体验，在伍珀河上空滑行。\n\n本文重点介绍了Schwebodrom博物馆，该博物馆专门介绍悬浮列车的历史，其中包括著名的大象图菲在宣传噱头中跳入河中的故事。该铁路在二战后重建，同时保留了其最初的蒸汽朋克设计。\n\n除了悬浮列车，伍珀塔尔被呈现为一个充满惊喜的城市，拥有宜人的街道、多元化的餐厅和独特的建筑风格。这座城市的工业历史与19世纪实业家的财富交织在一起，他们为冯德海德博物馆和历史市政厅等文化机构做出了贡献。文章还提到了弗里德里希·恩格斯与伍珀塔尔的联系，以及该市工业家实施的进步社会改革。最终，悬浮列车代表了伍珀塔尔独特的过去与前瞻性城市交通方式的融合。"
  },
  {
    "id": "44223448",
    "title": "LLMs are cheap",
    "url": "https://www.snellman.net/blog/archive/2025-06-02-llms-are-cheap/",
    "summary": "This article argues that operating Large Language Models (LLMs) is surprisingly cheap, a point the author feels needs constant reiteration due to persistent misconceptions. The author compares the cost of LLM inference to web search, a similar domain where users aren't directly charged.\n\nUsing API pricing data from Gemini, Bing, and Brave, the author establishes a cost range for web searches. They then analyze the token output and pricing of various LLMs (Gemma, Qwen, Gemini, GPT-4, Deepseek, Claude) to estimate the cost per query. The analysis reveals that many LLMs are significantly cheaper than even the lowest-priced search APIs.\n\nThe author anticipates and addresses common objections, such as LLM responses being longer, API prices being subsidized, search including index maintenance costs, search APIs having higher margins, and search being faster. They argue that these objections don't bridge the substantial cost gap. They also point out that OpenAI's losses are due to under-monetization rather than inherently high costs.\n\nThe author believes that the low cost of LLMs will drive increased demand and that concerns about recouping training costs are unfounded. They predict that advertising will become a viable monetization strategy for consumer AI. The real cost challenges, according to the author, lie in the backend services that AI agents will access, particularly scraping and using external services without compensation. They question whether AI agents will engage in an adversarial arms race with these services or eventually pay for their usage. The author concludes that running the AIs themselves won't be the expensive part. The article concludes with suggested additional reading on related topics.\n",
    "chinese_title": "大型语言模型很便宜",
    "chinese_summary": "运行大型语言模型出乎意料地便宜"
  },
  {
    "id": "44188373",
    "title": "Endangered classic Mac plastic color returns as 3D-printer filament",
    "url": "https://arstechnica.com/apple/2025/06/new-filament-lets-you-3d-print-parts-in-authentic-1980s-apple-computer-color/",
    "summary": "Classic Macintosh enthusiasts rejoice! A new 3D-printer filament that perfectly replicates the iconic \"Platinum\" color scheme of vintage Macs is now available. Collector Joe Strosnider collaborated with Polar Filament to create \"Retro Platinum\" PLA filament, priced at $21.99 per kilogram, finally providing a reliable and color-accurate material for restoration projects and creating new accessories.\n\nThe original Macintosh plastics often become brittle and discolored over time, making color matching a challenge. Strosnider invested in developing the color and making it publicly available, foregoing proprietary rights to benefit the vintage computing community.\n\nThis new filament addresses a previous gap where color options were either expensive, involved international shipping, or suffered from inconsistent quality. The 1.75mm filament is compatible with most standard 3D printers and automated material systems.\n\nThe release coincides with growing interest in 3D-printed cases and accessories for vintage Mac hardware, like the \"SE Mini\" desktop case that allows using vintage Macintosh SE/30 logic boards in a new, compact desktop enclosure. These types of projects highlight the benefit of having color-accurate filament for preserving the classic Macintosh aesthetic. By combining vintage parts and modern technology, hobbyists like Strosnider continue to appreciate and extend the life of classic Apple computers.\n",
    "chinese_title": "濒危经典Mac塑料配色以3D打印耗材形式回归",
    "chinese_summary": "经典Macintosh爱好者欢呼吧！一种能完美复刻经典Mac“白金”配色方案的全新3D打印线材现已上市。收藏家Joe Strosnider与Polar Filament合作推出“Retro Platinum”PLA线材，售价为每公斤21.99美元，最终为修复项目和创建新配件提供了一种可靠且色彩精确的材料。\n\n原始Macintosh塑料随着时间的推移经常变得脆弱和褪色，这使得颜色匹配成为一项挑战。Strosnider投资开发了这种颜色并将其公开，放弃了专有权以造福复古计算社区。\n\n这种新线材解决了以往颜色选择要么昂贵、要么涉及国际运输、要么质量不稳定的问题。这种1.75毫米的线材与大多数标准3D打印机和自动化材料系统兼容。\n\n该产品的发布正值人们对复古Mac硬件的3D打印外壳和配件兴趣日益浓厚之际，例如“SE Mini”桌面外壳，它允许在新而紧凑的桌面外壳中使用复古Macintosh SE/30逻辑板。这些类型的项目突显了拥有色彩精确的线材对于保持经典Macintosh美学的好处。通过结合复古零件和现代技术，像Strosnider这样的爱好者继续欣赏和延长经典Apple电脑的寿命。"
  },
  {
    "id": "44219279",
    "title": "What happens when people don't understand how AI works",
    "url": "https://www.theatlantic.com/culture/archive/2025/06/artificial-intelligence-illiteracy/683021/",
    "summary": "This article argues that widespread misunderstanding of how AI, particularly large language models (LLMs) like ChatGPT, actually works poses a significant threat. It highlights that AI is not a thinking or feeling entity but a sophisticated mimic, generating text based on statistical probability, not genuine understanding.\n\nThe author cites the books \"Empire of AI\" and \"The AI Con\" to support the claim that the AI industry is overhyped and potentially a \"scam.\" He points to cases of \"ChatGPT-induced psychosis\" as extreme examples of the dangers of AI illiteracy, where people develop delusions and believe their LLMs are sapient guides or even divine entities.\n\nBeyond individual delusions, the article critiques the trend of replacing human relationships with AI proxies, such as AI therapists, AI friends, and AI dating concierges. This, the author argues, is driven by Silicon Valley's anthropomorphizing of AI and a flawed logic that prioritizes personalized service over genuine human connection.\n\nThe article also touches upon the exploitative labor practices often hidden behind AI development, citing the example of content moderators exposed to traumatizing content. Despite these concerns, the author offers a note of optimism, highlighting public skepticism towards AI and the potential for education to mitigate its negative consequences. By understanding the true nature and limitations of AI, people can avoid its pitfalls and make informed decisions about its role in their lives.\n",
    "chinese_title": "当人们不了解人工智能如何运作时会发生什么",
    "chinese_summary": "对人工智能，特别是像ChatGPT这样的大型语言模型(LLMs)运作方式的广泛误解构成了重大威胁，本文认为。 它强调人工智能并非具有思考或感受能力的主体，而是一种复杂的模仿者，它根据统计概率生成文本，而非真正的理解。\n\n作者引用了《人工智能帝国》和《人工智能骗局》这两本书来支持人工智能行业被过度炒作且可能是一个“骗局”的观点。他指出“ChatGPT诱导的精神病”病例是人工智能文盲的极端危险案例，在这些案例中，人们产生妄想，并认为他们的LLM是有智慧的导师，甚至是神圣的实体。\n\n除了个人妄想之外，本文还批评了用人工智能代理取代人际关系的趋势，例如人工智能治疗师、人工智能朋友和人工智能约会管家。 作者认为，这是由硅谷对人工智能的拟人化以及一种将个性化服务置于真正人际关系之上的错误逻辑所驱动的。\n\n本文还涉及隐藏在人工智能开发背后的剥削性劳动行为，并以接触创伤性内容的内容审核员为例。 尽管存在这些担忧，但作者还是乐观地指出，公众对人工智能持怀疑态度，并且教育有可能减轻其负面影响。 通过了解人工智能的真实性质和局限性，人们可以避免其陷阱，并就其在生活中的作用做出明智的决定。"
  },
  {
    "id": "44224745",
    "title": "Mushrooms communicate with each other using up to 50 'words', scientist claims (2022)",
    "url": "https://www.theguardian.com/science/2022/apr/06/fungi-electrical-impulses-human-language-study",
    "summary": "This article explores the idea that fungi might communicate using electrical impulses, potentially possessing a complex \"language\" with up to 50 \"words.\" Professor Andrew Adamatzky's research analyzed electrical spike patterns in four fungal species, finding similarities to human speech structure. He suggests these electrical signals could be a way for fungi to share information about food, injury, or attractants/repellents within their mycelial networks. Split gill fungi demonstrated the most intricate electrical activity patterns.\n\nWhile Adamatzky acknowledges it's uncertain if a direct relationship exists between fungal electrical activity and human language, he highlights similarities in information processing across different life forms. He also proposes alternative explanations, such as the signals being a byproduct of charged mycelium tips or serving to maintain the fungi's integrity.\n\nHowever, the interpretation of these signals as a language is met with skepticism by other scientists. Dan Bebber points to other explanations, such as pulsing nutrient transport, and emphasizes the need for more rigorous research and hypothesis testing before concluding that fungi have a language akin to human communication.\n",
    "chinese_title": "科学家称蘑菇使用多达 50 个“词语”相互交流 (2022)",
    "chinese_summary": "真菌或利用电脉冲交流，或拥有包含50个“词汇”的复杂“语言”\n\n本文探讨了真菌可能利用电脉冲进行交流的观点，潜在地拥有包含多达 50 个“词汇”的复杂“语言”。安德鲁·阿达马茨基教授的研究分析了四种真菌的电脉冲模式，发现其与人类语言结构有相似之处。他认为这些电信号可能是真菌在其菌丝网络中分享关于食物、损伤或引诱剂/驱避剂信息的一种方式。裂褶菌表现出最复杂的电活动模式。\n\n虽然阿达马茨基承认真菌电活动与人类语言之间是否存在直接关系尚不确定，但他强调了不同生命形式在信息处理方面的相似性。他还提出了其他解释，例如这些信号可能是带电菌丝尖端产生的副产品，或用于维持真菌的完整性。\n\n然而，将这些信号解释为一种语言的说法遭到了其他科学家的质疑。丹·贝伯指出了其他可能的解释，例如脉冲式营养运输，并强调在得出真菌拥有类似于人类交流的语言的结论之前，需要进行更严谨的研究和假设检验。"
  },
  {
    "id": "44217876",
    "title": "Administering immunotherapy in the morning seems to matter. Why?",
    "url": "https://www.owlposting.com/p/the-time-of-day-that-immunotherapy",
    "summary": "This article explores the surprising impact of timing on immunotherapy effectiveness, specifically that administering immunotherapy in the morning appears to significantly improve patient outcomes. A randomized clinical trial and numerous retrospective studies show that immunotherapy given earlier in the day leads to longer cancer control and improved survival rates.\n\nThe article posits that this phenomenon is linked to the body's circadian rhythm. The immune system is primed to be more active in the morning, anticipating exposure to antigens. Lymphocytes are more concentrated in the lymphatic system, dendritic cells are actively collecting antigens, and the lymphatic system is more open to dendritic cell entry, all making the immune system more prepared for an assault.\n\nWhile immunotherapy drugs like Pembrolizumab have long half-lives, the author suggests that the initial dose and the subsequent first wave of T-cell activation may be crucial. The advantages present during the morning administration, such as increased T-cell availability and dendritic cell activity, potentially amplify the drug's initial impact, setting a higher \"ceiling\" for the immune response.\n\nThe article highlights that more research is needed to fully understand the mechanisms behind this \"immunochronotherapy\" effect and determine the optimal timing for immunotherapy administration. However, the existing evidence strongly suggests that simply scheduling immunotherapy infusions in the morning could offer a risk-free and cost-free way to significantly improve patient outcomes.\n",
    "chinese_title": "早上进行免疫疗法似乎很重要。为什么？",
    "chinese_summary": "免疫疗法时机选择对疗效的惊人影响：上午给药或可显著改善患者预后。一项随机临床试验和多项回顾性研究表明，在上午进行免疫治疗可以延长癌症控制时间并提高生存率。\n\n文章提出，这种现象与人体的昼夜节律有关。免疫系统在早上更活跃，以应对抗原的暴露。淋巴细胞更集中于淋巴系统，树突状细胞正在积极收集抗原，并且淋巴系统对树突状细胞的进入更加开放，所有这些都使得免疫系统为攻击做好了更充分的准备。\n\n虽然像Pembrolizumab这样的免疫治疗药物具有较长的半衰期，但作者认为，初始剂量和随后的第一波T细胞激活可能至关重要。在上午给药期间出现的优势，例如T细胞可用性和树突状细胞活性增加，可能会放大药物的初始影响，从而为免疫反应设定更高的“上限”。\n\n文章强调，需要更多的研究来充分了解这种“免疫时辰疗法”效应背后的机制，并确定免疫疗法给药的最佳时机。然而，现有的证据强烈表明，仅仅将免疫疗法的输注安排在早上，就可以提供一种无风险且无成本的方式来显著改善患者预后。"
  },
  {
    "id": "44219357",
    "title": "Omnimax",
    "url": "https://computer.rip/2025-06-08-Omnimax.html",
    "summary": "This article explores the history and evolution of dome theaters, focusing on the Omnimax format as a prime example. It begins by contrasting the MSG Sphere in Las Vegas with the longer tradition of dome theaters, arguing that the Sphere is simply a continuation, not an innovation.\n\nThe author traces the origins of dome theaters back to the Zeiss planetarium projector in 1923, highlighting its sophisticated optical and mechanical design for accurately representing the night sky. These projectors, initially expensive, became fixtures in science museums but were later largely replaced by digital projection.\n\nThe article then discusses the evolution of planetarium theaters, including the transition from strictly hemispherical domes to tilted domes for more flexible film projection. The Fleet Science Center's planetarium in San Diego is highlighted for its innovative Space Transit Simulator and, more importantly, its unique Omnimax film projection system.\n\nOmnimax, developed to fill the entire dome with a sharp image, utilized a sideways 70mm IMAX format. The Fleet planetarium coined the term to advertise this advancement. However, Omnimax filmmaking presented challenges due to the large and heavy cameras. Early Omnimax films often faked the larger format using smaller negatives. Despite this, Omnimax found its niche in science museums showing documentaries, contrasting with the more commercial trajectory of IMAX. The author concludes by noting how Omnimax has remained more closely tied to its educational origins than the commercialized IMAX format.\n",
    "chinese_title": "巨幕电影",
    "chinese_summary": "本文探讨了穹顶影院的历史和演变，重点以奥姆尼麦斯（Omnimax）格式为例。文章首先将拉斯维加斯的MSG Sphere与历史更悠久的穹顶影院进行对比，认为Sphere只是延续，而非创新。\n\n作者追溯了穹顶影院的起源，始于1923年的蔡司天文投影仪，强调其精巧的光学和机械设计，以准确地呈现夜空。这些投影仪最初价格昂贵，后来成为科学博物馆的固定设施，但随后在很大程度上被数字投影所取代。\n\n文章随后讨论了天文馆影院的演变，包括从严格的半球形穹顶到倾斜穹顶的过渡，以实现更灵活的电影投影。圣地亚哥舰队科学中心的天文馆因其创新的太空运输模拟器，更重要的是其独特的奥姆尼麦斯电影放映系统而备受瞩目。\n\n奥姆尼麦斯（Omnimax）的开发是为了用清晰的图像填充整个穹顶，它采用了侧向的70毫米IMAX格式。舰队天文馆创造了这个术语来宣传这一进步。然而，奥姆尼麦斯电影制作由于其大型且笨重的相机而面临挑战。早期的奥姆尼麦斯电影经常使用较小的底片来伪造更大的格式。尽管如此，奥姆尼麦斯在科学博物馆中找到了展示纪录片的利基市场，与IMAX更商业化的发展轨迹形成对比。作者最后指出，与商业化的IMAX格式相比，奥姆尼麦斯与它的教育起源联系更为紧密。"
  },
  {
    "id": "44222299",
    "title": "CoverDrop: A secure messaging system for newsreader apps",
    "url": "https://github.com/guardian/coverdrop",
    "summary": "CoverDrop is a secure messaging system designed for news organizations' mobile apps, enabling confidential communication between sources and journalists without leaving detectable evidence. It achieves this through a multi-layered approach involving encrypted \"cover messages\" that mask real communications within routine data exchanges between the app and the news organization's servers.\n\nThe system architecture includes a mobile app module, a cloud-based API, a secured on-premises \"CoverNode,\" and a desktop application for journalists. Every app instance sends encrypted cover messages, making it impossible to distinguish between standard usage and secure communication. Source messages are encrypted and swapped with these cover messages, then routed through a Kinesis stream and processed by the CoverNode. Journalists access messages through dead drops, which may contain a mixture of real and fake messages. Message storage on user devices is uniformly encrypted, providing plausible deniability.\n\nThe project implementation is divided into clients and services, encompassing components like Android and iOS libraries, APIs, command-line tools, a CoverNode implementation, and infrastructure resources.\n\nSecurity is a priority, and responsible disclosures of vulnerabilities are welcomed via encrypted email. The project utilizes cryptographic software subject to export regulations and is licensed under Apache License 2.0. The white paper with more details on the design and architecture is available on https://www.coverdrop.org/.\n",
    "chinese_title": "CoverDrop：新闻阅读器应用的安全消息系统",
    "chinese_summary": "CoverDrop：一款安全的信息系统，专为新闻机构的移动应用程序设计，能够在来源和记者之间进行保密通信，且不留下可检测的证据。它通过一种多层方法实现这一目标，该方法涉及加密的“掩护消息”，这些消息在应用程序和新闻机构服务器之间的常规数据交换中掩盖了真实的通信。\n\n系统架构包括一个移动应用程序模块、一个基于云的API、一个安全的本地“掩护节点”和一个记者使用的桌面应用程序。每个应用程序实例都会发送加密的掩护消息，使得无法区分标准使用和安全通信。来源消息被加密并与这些掩护消息交换，然后通过Kinesis流路由并由掩护节点处理。记者通过死信箱访问消息，其中可能包含真实和虚假消息的混合。用户设备上的消息存储经过统一加密，从而提供合理的推诿理由。\n\n项目实施分为客户端和服务端，包括Android和iOS库、API、命令行工具、掩护节点实现和基础设施资源等组件。\n\n安全是首要任务，欢迎通过加密电子邮件负责任地披露漏洞。该项目使用受出口法规约束的密码软件，并根据Apache License 2.0获得许可。有关设计和架构的更多详细信息，请访问 https://www.coverdrop.org/ 获取白皮书。"
  },
  {
    "id": "44220860",
    "title": "FSE meets the FBI",
    "url": "https://blog.freespeechextremist.com/blog/fse-vs-fbi.html",
    "summary": "The article, \"FSE Meets the FBI,\" details the author's experience running the FSE fedi instance and dealing with unwanted elements, specifically pedophiles. The author's primary concern was preventing the platform from being used for illegal activity, attracting law enforcement attention, and dealing with false flags where CP is uploaded to get the site taken down.\n\nThe author initially tried public shaming tactics but found them ineffective. This led to investigating the sources of these users and developing diagnostic tools to analyze server logs. The article then transitions into a technical guide for other instance administrators, emphasizing the importance of understanding log data, identifying unusual activity, and utilizing tools like `awk`, `tail`, and SQL for real-time analysis. The author explains how to extract user information, detect potential DDoS attacks, and distinguish malicious activity from legitimate traffic spikes.\n\nA key takeaway is that the FBI collects data by paying companies to scrape social media and analyze it for keywords. This data is then organized and likely analyzed using sentiment analysis and potentially LLMs within an FBI internal system. The author suggests that instance administrators should focus on data analysis to effectively manage their servers, identify threats, and protect their users.\n",
    "chinese_title": "金融服务交易所与联邦调查局会面",
    "chinese_summary": "文章《FSE会见FBI》详细描述了作者运营FSE联邦实例，并处理不受欢迎分子，特别是恋童癖者的经验。作者主要关注的是防止平台被用于非法活动，吸引执法部门的注意，以及处理虚假信息，即上传儿童色情内容以使网站被关闭的情况。\n\n作者最初尝试了公开羞辱的策略，但发现效果不佳。这促使他调查这些用户的来源，并开发诊断工具来分析服务器日志。文章随后过渡到针对其他实例管理员的技术指南，强调理解日志数据、识别异常活动，以及利用`awk`、`tail`和SQL等工具进行实时分析的重要性。作者解释了如何提取用户信息，检测潜在的DDoS攻击，以及区分恶意活动和合法的流量峰值。\n\n一个重要的结论是，FBI通过付费给公司来抓取社交媒体数据，并分析其中的关键词。这些数据随后会被整理，并可能在FBI内部系统中使用情感分析和潜在的LLM进行分析。作者建议实例管理员应该专注于数据分析，以有效地管理他们的服务器，识别威胁，并保护他们的用户。"
  },
  {
    "id": "44222885",
    "title": "AI Angst",
    "url": "https://www.tbray.org/ongoing/When/202x/2025/06/06/My-AI-Angst",
    "summary": "In \"AI Angst,\" Tim Bray expresses concerns about the generative AI boom, focusing on its costs, environmental impact, and potential societal effects. He questions whether the massive investments in AI infrastructure will ever pay off, given the open-source alternatives and the carbon footprint of data centers.\n\nBray examines AI's impact on coding, teaching, and professional communication. While acknowledging some productivity gains in coding, he worries about the learning curve for junior developers if AI automates the \"easy stuff.\" He is highly critical of AI's role in education, citing reports of widespread cheating and administrative pressure to use AI for efficiency, deeming it \"toxic.\" In professional communication, Bray predicts that excessive reliance on AI for generating and summarizing content will lead to a decline in originality and engagement.\n\nHe concludes by expressing skepticism about the financial viability of genAI, given the enormous capital expenditure, and the limited value it offers in certain sectors. He is especially worried about the carbon emissions that contribute to environmental damage. Ultimately, Bray anticipates a financial meltdown in the AI sector, leaving behind only a few useful applications at sustainable prices, along with a legacy of empty data center shells. He suggests focusing on unique and \"weird\" content creation as an antidote to AI-generated conformity.\n",
    "chinese_title": "AI焦虑",
    "chinese_summary": "在《人工智能焦虑》一文中，蒂姆·布雷表达了对生成式人工智能热潮的担忧，主要集中在其成本、环境影响以及潜在的社会影响上。他质疑对人工智能基础设施的大规模投资是否会得到回报，考虑到开源替代方案和数据中心的碳足迹。\n\n布雷考察了人工智能对编码、教学和专业沟通的影响。虽然他承认在编码方面取得了一些生产力提升，但他担心如果人工智能自动化“简单的事情”，初级开发人员的学习曲线会受到影响。他对人工智能在教育中的作用持高度批评态度，引用了广泛作弊的报告以及使用人工智能提高效率的行政压力，认为这是“有害的”。在专业沟通方面，布雷预测，过度依赖人工智能生成和总结内容将导致原创性和参与度的下降。\n\n最后，他表示对生成式人工智能的财务可行性持怀疑态度，考虑到其巨大的资本支出以及在某些领域提供的有限价值。他特别担心导致环境破坏的碳排放。最终，布雷预计人工智能行业将会发生金融崩溃，只留下少数以可持续价格提供的有用应用程序，以及空空如也的数据中心外壳的遗留物。他建议专注于独特和“古怪”的内容创作，以此来对抗人工智能生成的千篇一律。"
  },
  {
    "id": "44220287",
    "title": "Software is about promises",
    "url": "https://www.bramadams.dev/software-is-about-promises/",
    "summary": "Bram argues that software development hinges on making and keeping promises to users. Software's unique characteristics – being both abstract and real, scaling rapidly but constrained by developer time – create a paradox that demands careful promise management. Overpromising leads to burnout and failure.\n\nThe core idea is to be explicit about what your software *will* do given resource constraints and goals. This involves defining testable promises to avoid \"head in the clouds\" abstractions.\n\nThe article presents a case study using \"Your Commonbase\" (YCB), a personal library science software encompassing four functions: store, search, synthesize, and share. Bram outlines the specific, testable promises made for the beta version:\n\n*   **Store:** Capturing text, images, and URLs from iOS and Chrome with features like saving URLs, screenshots, selected text (Chrome), storing from the iOS share sheet, and using a vision model for image captioning.\n*   **Search:** Semantic search and semantic scrolling capabilities, leveraging Meilisearch and vector embeddings.\n*   **Synthesize:** Adding commentary to entries through threaded comments and manual links between ideas.\n*   **Share:** Limited initially due to resource constraints, focusing on sharing screenshots and direct URLs.\n\nThe conclusion reinforces the importance of promises in protecting developers, users, and the software's integrity. The YCB case study demonstrates how resource allocation is guided by prioritizing foundational elements like store and synthesize for future development in search and share. Bram then invites readers to explore a demo of YCB's architecture and join a waitlist.\n",
    "chinese_title": "软件即承诺",
    "chinese_summary": "软件开发的关键在于对用户的承诺与坚守。软件的独特性——既抽象又真实，扩展迅速却受限于开发者的时间——形成了一个悖论，需要谨慎地管理承诺。过度承诺会导致倦怠和失败。\n\n核心理念是明确说明在资源限制和目标下，你的软件*将要*做什么。这涉及定义可测试的承诺，以避免“空中楼阁”式的抽象概念。\n\n本文提出了一个案例研究，使用“你的通用知识库”（YCB），一款包含存储、搜索、综合和分享四项功能的个人图书馆科学软件。Bram概述了为beta版本做出的具体、可测试的承诺：\n\n*   **存储：** 从iOS和Chrome捕获文本、图像和URL，具有保存URL、屏幕截图、选定文本（Chrome）、从iOS共享表单存储以及使用视觉模型进行图像字幕等功能。\n*   **搜索：** 语义搜索和语义滚动功能，利用Meilisearch和向量嵌入。\n*   **综合：** 通过主题评论和想法之间的手动链接，向条目添加评论。\n*   **分享：** 由于资源限制，最初受到限制，侧重于分享屏幕截图和直接URL。\n\n结论强调了承诺在保护开发者、用户和软件完整性方面的重要性。YCB案例研究表明了资源分配如何通过优先考虑存储和综合等基础要素来指导搜索和分享的未来发展。最后，Bram邀请读者探索YCB架构的演示并加入候补名单。"
  },
  {
    "id": "44220135",
    "title": "I used AI-powered calorie counting apps, and they were even worse than expected",
    "url": "https://lifehacker.com/health/ai-powered-calorie-counting-apps-worse-than-expected",
    "summary": "Meredith Dietz investigated AI-powered calorie counting apps like Cal AI, SnapCalorie, and Calorie Mama, expecting them to streamline calorie tracking. However, she found them surprisingly inaccurate and ultimately more trouble than they were worth.\n\nDietz discovered that the apps struggled with ingredient identification, portion estimation, and often produced wildly inaccurate calorie counts. Cal AI misidentified an apple as tikka masala and underestimated calories by as much as 33%. SnapCalorie offered more accurate initial estimates but still struggled with portion sizes and required manual input to achieve reasonable results, negating the supposed time-saving benefit. Calorie Mama was the worst, essentially requiring manual input for everything, rendering the AI aspect pointless.\n\nThe author argues that these apps don't solve the problem of human error, but rather introduce new inaccuracies. She criticizes the philosophical basis of these tools, which reinforce the idea that precise calorie counting is necessary and beneficial, when research suggests it can be harmful. She suggests that intuitive eating and a focus on general nutrition principles are often more sustainable and psychologically healthy.\n\nDietz concludes that while the apps might offer rough estimates for generic foods, traditional methods like food scales and manual logging remain more reliable for those seeking precision. More importantly, she questions the value of precise calorie counting itself, suggesting that a healthier relationship with food based on listening to one's body is often a better approach.\n",
    "chinese_title": "我用了人工智能卡路里计算应用程序，结果比预期的还要糟糕。",
    "chinese_summary": "梅瑞狄斯·迪茨调查了诸如Cal AI、SnapCalorie和Calorie Mama等人工智能卡路里计数应用，原本期望它们能简化卡路里追踪。然而，她发现它们出人意料地不准确，最终弊大于利。\n\n迪茨发现，这些应用在食材识别、份量估算方面表现不佳，并且经常产生非常不准确的卡路里计数。Cal AI将苹果误识别为印度咖喱鸡块，并低估了高达33%的卡路里。SnapCalorie提供了更准确的初始估算，但仍然在份量大小方面存在问题，并且需要手动输入才能获得合理的结果，从而抵消了本应节省时间的优势。Calorie Mama表现最差，基本上所有内容都需要手动输入，使得人工智能方面毫无意义。\n\n作者认为，这些应用并没有解决人为错误的问题，反而引入了新的误差。她批评了这些工具的哲学基础，即强化了精确卡路里计数是必要且有益的观念，而研究表明这可能是有害的。她认为，直觉饮食和关注一般营养原则通常更可持续且对心理健康更有益。\n\n迪茨总结说，虽然这些应用可能为普通食物提供粗略的估计，但对于那些追求精确度的人来说，食物秤和手动记录等传统方法仍然更可靠。更重要的是，她质疑了精确卡路里计数本身的价值，认为建立在倾听身体基础上的更健康的饮食关系通常是一种更好的方法。"
  },
  {
    "id": "44188214",
    "title": "My first attempt at iOS app development",
    "url": "https://mgx.me/my-first-attempt-at-ios-app-development",
    "summary": "This blog post details the author's first foray into iOS app development, undertaken out of frustration with existing photo management apps. Starting with zero Swift knowledge, the author built a working app for photo management, duplicate finding, and deleting pictures in just three days, aided significantly by AI tools like Cursor and Gemini.\n\nThe author highlights the surprising accessibility of iOS development thanks to readily available native libraries and APIs, while also acknowledging the learning curve associated with ecosystem-specific challenges like code signing and deployment configurations. A specific technical hurdle involved Apple's CLGeocoder behaving differently in China, requiring a workaround.\n\nThe author critiques the common subscription-based pricing models of existing photo management apps, finding them disconnected from the value delivered. They plan to offer their app for a one-time $2.99 fee, avoiding freemium tactics and prioritizing fair pricing. They also observed marketing strategies employed by some app developers, particularly from China, that rely on aggressive advertising and recurring revenue models.\n\nThe author emphasizes the benefits of using AI for coding, particularly for rapid iteration, error understanding, and learning iOS design patterns. However, they wisely caution against using AI for security-sensitive code without proper auditing. They were pleasantly surprised by the app's performance regarding RAM and CPU usage. The project has made them reconsider why they waited so long to try iOS development, emphasizing that with the right tools, building an app is now more accessible than ever. The app is about 90% done, and they intend to polish the user experience before potentially publishing it.\n",
    "chinese_title": "我的首次iOS应用开发尝试",
    "chinese_summary": "本文详细介绍了作者首次尝试 iOS 应用开发的经历，起因是对现有照片管理应用的不满。作者从零 Swift 知识开始，仅用三天时间，在 Cursor 和 Gemini 等 AI 工具的帮助下，构建了一个用于照片管理、查找重复项和删除照片的可用应用。\n\n作者强调了 iOS 开发令人惊讶的可访问性，这得益于易于使用的原生库和 API，同时也承认了与代码签名和部署配置等生态系统特定挑战相关的学习曲线。一个具体的例子是苹果的 CLGeocoder 在中国的表现不同，需要解决。\n\n作者批评了现有照片管理应用常见的订阅式定价模式，认为它们与所提供的价值脱节。他们计划以 2.99 美元的一次性费用提供他们的应用，避免免费增值策略，并优先考虑公平定价。他们还观察到一些应用开发者，特别是来自中国的开发者，采用了依赖于激进广告和循环收入模式的营销策略。\n\n作者强调了使用 AI 进行编码的好处，尤其是在快速迭代、错误理解和学习 iOS 设计模式方面。但是，他们明智地告诫说，未经适当审计，不要将 AI 用于安全敏感代码。他们对应用程序在 RAM 和 CPU 使用率方面的性能感到惊喜。这个项目让他们重新思考为什么他们等待这么久才尝试 iOS 开发，并强调有了合适的工具，构建应用程序现在比以往任何时候都更容易。该应用程序已经完成了大约 90%，他们打算在可能发布之前完善用户体验。"
  },
  {
    "id": "44187765",
    "title": "Panjandrum: The ‘giant firework’ built to break Hitler's Atlantic Wall",
    "url": "https://www.bbc.com/future/article/20250603-the-giant-firework-built-to-break-hitlers-atlantic-wall",
    "summary": "This article details the Panjandrum, a bizarre and ultimately unsuccessful weapon conceived by the British during World War II to breach Hitler's Atlantic Wall. Designed by Nevil Shute Norway, an aeronautical engineer and later renowned novelist, the Panjandrum was essentially a giant, rocket-propelled Catherine wheel intended to deliver a one-tonne explosive charge to the concrete fortifications.\n\nThe concept stemmed from the need to overcome heavily fortified ports along the English Channel, deemed too strong for direct assault. Norway's team calculated the necessary explosive power and devised the wheeled device, powered by cordite rockets, to traverse the beach and detonate against the wall.\n\nDespite its inventive nature, the Panjandrum faced numerous problems during testing. Rockets frequently detached, causing erratic movement and making it difficult to control, resulting in the device careening wildly. The project was ultimately scrapped just months before D-Day, deemed too unreliable for deployment.\n\nWhile the Panjandrum itself was a failure, the article highlights the \"anything-goes\" attitude of British military thinkers at the time and suggests that its concept, of an unmanned weapon delivering a concentrated explosive force, presaged modern drone warfare. Furthermore, the article notes that some have revisited the idea in recent years, attempting to improve the design for peacetime applications. Ultimately, conventional tanks modified with specialized functions proved to be more effective in breaching German defenses during D-Day. Nevil Shute Norway would later become a successful novelist.\n",
    "chinese_title": "潘加德伦：为突破希特勒大西洋壁垒而造的“巨型焰火”",
    "chinese_summary": "本文详细介绍了潘贾德鲁姆（Panjandrum），这是二战期间英国构思的一种奇异但最终失败的武器，旨在突破希特勒的“大西洋壁垒”。 潘贾德鲁姆由航空工程师兼后来的著名小说家内维尔·舒特·挪威设计，本质上是一个巨大的火箭推进式凯瑟琳轮，旨在向混凝土工事运送一吨重的炸药。\n\n这个概念源于需要克服英吉利海峡沿岸防御严密的港口，这些港口被认为过于强大而无法直接攻击。 挪威的团队计算出必要的爆炸威力，并设计出这种轮式装置，该装置由科迪特火箭提供动力，可以穿越海滩并在墙上引爆。\n\n尽管潘贾德鲁姆具有创新性，但在测试过程中遇到了许多问题。 火箭经常脱落，导致不规则运动，难以控制，导致设备疯狂倾斜。 该项目最终在诺曼底登陆日之前的几个月被取消，被认为部署起来太不可靠。\n\n虽然潘贾德鲁姆本身是一个失败之作，但本文突出了当时英国军事思想家“不惜一切代价”的态度，并表明其无人武器运送集中爆炸力的概念预示着现代无人机战争。 此外，文章指出，近年来有人重新审视了这一想法，试图改进设计以用于和平时期的应用。 最终，改装了特殊功能的传统坦克被证明在诺曼底登陆日突破德国防线方面更为有效。 内维尔·舒特·挪威后来成为一位成功的小说家。"
  },
  {
    "id": "44215603",
    "title": "Gaussian integration is cool",
    "url": "https://rohangautam.github.io/blog/chebyshev_gauss/",
    "summary": "This article introduces Gaussian quadrature, a numerical integration technique, focusing on Chebyshev-Gauss quadrature. It explains how Gaussian quadrature approximates definite integrals by evaluating a function at specific points (nodes) with associated weights. Unlike basic integration techniques that can exactly integrate polynomials of degree *n-1* with *n* nodes, Gaussian quadrature can integrate polynomials of degree *2n-1* with the same number of nodes, offering improved accuracy with fewer function evaluations.\n\nThe article then delves into Chebyshev-Gauss quadrature, which uses the roots of Chebyshev polynomials as nodes. This method is particularly suitable for integrals of the form ∫₋₁¹ f(x) / √(1-x²) dx.  The Chebyshev nodes are concentrated at the edges of the integration domain to help counter oscillations. The weights for this method are fixed at *π/n*, where *n* is the number of nodes.\n\nThe author further explains how to adapt Chebyshev-Gauss quadrature for generic functions and arbitrary integration intervals [a, b] by transforming the integral into the required form. The article showcases an interactive marimo notebook where readers can experiment with the number of nodes and compare the accuracy of Chebyshev-Gauss quadrature to a basic integration technique when integrating sin(x) from 0 to π.\n\nFinally, the author shares a real-world application in their `EIV_IGP_jax` library for estimating sea level change rates, using Chebyshev-Gauss quadrature to integrate a gaussian process. The author also addresses previous reader feedback, clarifying aspects of Gaussian quadrature and the differences between Legendre and Chebyshev polynomials in this context.\n",
    "chinese_title": "高斯积分很酷",
    "chinese_summary": "本文介绍了高斯求积，一种数值积分技术，重点是切比雪夫-高斯求积。它解释了高斯求积如何通过在特定点（节点）使用相关权重评估函数来近似定积分。与使用 *n* 个节点可以精确积分 *n-1* 次多项式的基本积分技术不同，高斯求积可以使用相同数量的节点积分 *2n-1* 次多项式，从而以更少的函数评估提供更高的精度。\n\n然后，本文深入研究切比雪夫-高斯求积，它使用切比雪夫多项式的根作为节点。此方法特别适用于 ∫₋₁¹ f(x) / √(1-x²) dx 形式的积分。切比雪夫节点集中在积分域的边缘，以帮助抵消振荡。此方法的权重固定为 *π/n*，其中 *n* 是节点数。\n\n作者进一步解释了如何通过将积分转换为所需的形式，使切比雪夫-高斯求积适用于通用函数和任意积分区间 [a, b]。本文展示了一个交互式的 marimo 笔记本，读者可以在其中试验节点数量，并将切比雪夫-高斯求积的精度与从 0 到 π 积分 sin(x) 时的基本积分技术进行比较。\n\n最后，作者分享了他们在 `EIV_IGP_jax` 库中用于估计海平面变化率的实际应用，使用切比雪夫-高斯求积来积分高斯过程。作者还解决了之前读者的反馈，澄清了高斯求积的各个方面，以及在这种情况下勒让德多项式和切比雪夫多项式之间的差异。"
  },
  {
    "id": "44220583",
    "title": "Analyzing IPv4 Trades with Gnuplot",
    "url": "https://ipv4a-5539ad.gitlab.io/",
    "summary": "This article analyzes IPv4 address trades using Gnuplot, aiming to understand the supply and demand dynamics as the internet transitions to IPv6. The data, sourced from ipv4.global auctions, includes date, number of IPs, total price, and price per IP.\n\nThe analysis explores several aspects:\n\n*   **Real-time analysis:** The script retrieves and displays recent bid information.\n*   **Price Fluctuations:** Initial plots of single IP prices over time are deemed inaccurate due to a lack of volume weighting.\n*   **Price Smoothing:** Attempts are made to smooth the price data to identify trends, including calculating monthly averages.\n*   **Price Distribution:** The distribution of IP prices reveals a multi-modal pattern, with most orders around \\$20 but the bulk of IPs costing closer to \\$50.\n*   **Batch Size Analysis:** The script examines the distribution of batch sizes and how they change over time, observing a surge in demand between 2020 and 2024, correlating with price increases.\n*   **Market Volume:** The analysis explores market volume trends, which closely mirror batch size changes.\n*   **Expensive Batches:** The script identifies that most expensive batches originate from the 2021-2023 period.\n*   **Average Price Calculation:** A method for calculating the actual average price per month is implemented using Gnuplot's \"set table\" and heredoc capabilities to divide total revenue by total IPs traded.\n*   **Future Prediction:** Utilizing a fitted curve on a smoothed price data, the analysis speculates that IPv4 prices could drop to zero by the end of 2026 as IPv6 adoption increases and IPv4 demand diminishes.\n\nThe article uses various Gnuplot features to visualize the data and draw conclusions about the IPv4 market.\n",
    "chinese_title": "使用Gnuplot分析IPv4交易",
    "chinese_summary": "本文利用Gnuplot分析IPv4地址交易，旨在了解互联网向IPv6过渡期间的供需动态。数据来源于ipv4.global拍卖，包括日期、IP数量、总价和每IP价格。\n\n分析探讨了以下几个方面：\n\n*   **实时分析：** 脚本检索并显示最近的投标信息。\n*   **价格波动：** 由于缺乏成交量加权，单个IP价格随时间变化的初始图表被认为不准确。\n*   **价格平滑：** 尝试平滑价格数据以识别趋势，包括计算月度平均值。\n*   **价格分布：** IP价格的分布显示出多峰模式，大多数订单价格在20美元左右，但大部分IP的成本更接近50美元。\n*   **批量大小分析：** 脚本检查批量大小的分布以及它们随时间的变化，观察到2020年至2024年间需求激增，与价格上涨相关。\n*   **市场成交量：** 分析探讨了市场成交量的趋势，这与批量大小的变化密切相关。\n*   **高价批次：** 脚本识别出最昂贵的批次主要来自2021-2023年期间。\n*   **平均价格计算：** 实现了一种使用Gnuplot的“set table”和heredoc功能计算每月实际平均价格的方法，即用总收入除以交易的IP总数。\n*   **未来预测：** 利用平滑价格数据上的拟合曲线，分析推测，随着IPv6采用率的提高和IPv4需求的减少，IPv4价格可能会在2026年底降至零。\n\n本文使用各种Gnuplot功能来可视化数据并得出关于IPv4市场的结论。"
  },
  {
    "id": "44217757",
    "title": "Show HN: Let’s Bend – Open-Source Harmonica Bending Trainer",
    "url": "https://letsbend.de",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "Show HN: Let's Bend – 开源口琴压音训练器",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44183299",
    "title": "How Compiler Explorer Works in 2025",
    "url": "https://xania.org/202506/how-compiler-explorer-works",
    "summary": "Compiler Explorer, initially a small project, now handles over 90 million compilations annually, supporting 81 languages and 4700+ compiler versions. The process involves code input via the Monaco editor, request routing through CloudFront and load balancers, and compilation within isolated \"prisons\" created by nsjail. This sandboxing is critical for security, preventing malicious code from accessing sensitive data or executing arbitrary commands.\n\nA key aspect is managing the massive 4TB of compilers. Compiler versions are never retired to ensure link stability.  They utilize Python and shell scripts for installation and deployment. Squashfs images are built for compilers and mounted over NFS to mitigate latency issues with network file systems, especially crucial for languages with numerous small includes.\n\nCompiler Explorer builds fresh versions of many compilers nightly using GitHub Actions. Support has expanded beyond Linux x86-64 to include Windows, ARM, and GPU instances, all hosted in AWS's us-east-1 region.\n\nThe site is monitored with Grafana, Prometheus, and Loki. Costs are managed through spot instances and caching, and are covered by Patreon supporters, GitHub sponsors, and commercial sponsors.\n\nFuture plans include an AI explanation tool, user accounts for managing short links, and support for more architectures and CPU performance analysis visualization.  The author acknowledges past architectural mistakes, such as relying on a third-party link shortener and the tightly coupled save format, which pose ongoing challenges.\n",
    "chinese_title": "2025年编译器探索器工作原理",
    "chinese_summary": "Compiler Explorer：最初的小项目，如今每年处理超过9000万次编译，支持81种语言和4700多个编译器版本。 该过程涉及通过 Monaco 编辑器输入代码、通过 CloudFront 和负载均衡器路由请求，并在由 nsjail 创建的隔离“监狱”中进行编译。这种沙盒化对于安全性至关重要，可防止恶意代码访问敏感数据或执行任意命令。\n\n一个关键方面是管理巨大的 4TB 编译器。 编译器版本从不退役，以确保链接稳定性。 他们使用 Python 和 shell 脚本进行安装和部署。 为编译器构建 Squashfs 镜像并通过 NFS 挂载，以减轻网络文件系统中的延迟问题，这对于包含大量小型包含文件的语言尤为重要。\n\nCompiler Explorer 每天晚上使用 GitHub Actions 构建许多编译器的最新版本。 支持范围已从 Linux x86-64 扩展到包括 Windows、ARM 和 GPU 实例，所有这些实例都托管在 AWS 的 us-east-1 区域中。\n\n该站点使用 Grafana、Prometheus 和 Loki 进行监控。 成本通过 Spot 实例和缓存进行管理，并由 Patreon 支持者、GitHub 赞助商和商业赞助商承担。\n\n未来的计划包括 AI 解释工具、用于管理短链接的用户帐户以及对更多架构和 CPU 性能分析可视化的支持。 作者承认过去的架构错误，例如依赖第三方链接缩短器和紧密耦合的保存格式，这些错误带来了持续的挑战。"
  },
  {
    "id": "44189088",
    "title": "Generating Pixels One by One",
    "url": "https://tunahansalih.github.io/blog/autoregressive-vision-generation-part-1/",
    "summary": "This article introduces autoregressive image generation models, specifically focusing on building a basic model that predicts pixels one by one. The author, Tuna, explains the core concept of autoregression: predicting the next element in a sequence based on previous elements, using the analogy of keyboard suggestions on phones.\n\nThe article uses MNIST handwritten digits as a dataset and quantizes pixel intensities into discrete \"tokens\" (bins) to treat image generation like language modeling. This involves transforming continuous grayscale values into integer labels representing the bins. The author demonstrates how to load and visualize the quantized data.\n\nThe core of the model is a Multi-Layer Perceptron (MLP) that takes a sequence of previous pixel tokens (represented as one-hot encodings) as input and predicts the next token. The article defines the model architecture (`OneHotPixelPredictor`), including hidden layers, dropout, and an output layer for predicting the probability distribution of possible pixel tokens.\n\nThe article emphasizes the use of context windows to approximate the dependencies between pixels. Instead of considering all previous pixels, the model uses a sliding window of the last *k* pixels. Start tokens are used to handle the beginning of the image where there aren't enough previous pixels. The purpose of this basic model is to establish a framework for future improvements in the image generation quality.\n",
    "chinese_title": "逐个像素生成",
    "chinese_summary": "本文介绍了自回归图像生成模型，重点在于构建一个逐像素预测的基础模型。作者Tuna解释了自回归的核心概念：基于先前的元素预测序列中的下一个元素，并用手机键盘上的建议来类比。\n\n文章使用MNIST手写数字作为数据集，并将像素强度量化为离散的“tokens”（区间），从而将图像生成视为语言建模。这涉及将连续的灰度值转换为代表区间的整数标签。作者演示了如何加载和可视化量化后的数据。\n\n模型的关键是一个多层感知机（MLP），它将先前像素tokens的序列（表示为one-hot编码）作为输入，并预测下一个token。文章定义了模型架构（`OneHotPixelPredictor`），包括隐藏层、dropout和一个用于预测可能像素tokens的概率分布的输出层。\n\n文章强调使用上下文窗口来近似像素之间的依赖关系。模型不是考虑所有先前的像素，而是使用一个由最后*k*个像素组成的滑动窗口。起始tokens用于处理图像的开头，因为那里没有足够的先前像素。这个基础模型的目的是为未来提高图像生成质量建立一个框架。"
  },
  {
    "id": "44186008",
    "title": "Cheap yet ultrapure titanium might enable widespread use in industry (2024)",
    "url": "https://phys.org/news/2024-06-cheap-ultrapure-titanium-metal-enable.amp",
    "summary": "Researchers at the University of Tokyo have developed a cost-effective method for producing ultrapure titanium by efficiently removing oxygen from high-oxygen-concentration titanium ore. This breakthrough addresses the high production costs that have historically limited the widespread use of titanium despite its desirable properties such as high strength, light weight, and chemical resistance.\n\nThe new procedure involves reacting molten titanium with yttrium metal and yttrium trifluoride to remove oxygen down to a level of 0.02% by mass. A key advantage of this method is its ability to process even titanium scrap containing large amounts of oxygen, and the yttrium can be recycled for further use.\n\nThe researchers believe this innovative technology, based on rare-earth metals, could significantly reduce the production cost of titanium, making it more accessible for various industrial applications. While the resulting de-oxygenated titanium contains up to 1% yttrium by mass, which may affect its properties, the researchers are optimistic that solving the yttrium contamination problem will pave the way for straightforward adoption of the method in industrial manufacturing. This advancement represents a significant step towards making high-purity titanium more economically viable and environmentally sustainable.\n",
    "chinese_title": "廉价超纯钛或将促进行业广泛应用 (2024)",
    "chinese_summary": "东京大学的研究人员开发了一种经济高效的方法，通过高效去除高氧浓度钛矿中的氧来生产超纯钛。这一突破解决了钛因其高强度、轻重量和耐化学腐蚀等优良特性而未能得到广泛应用的历史原因，即高昂的生产成本。\n\n新方法包括将熔融钛与钇金属和三氟化钇反应，将氧含量降低至质量的0.02%。该方法的一个关键优势在于它甚至可以处理含有大量氧的钛废料，并且钇可以回收再利用。\n\n研究人员认为，这项基于稀土金属的创新技术可以显著降低钛的生产成本，使其更易于用于各种工业应用。虽然脱氧后的钛含有高达质量1%的钇，这可能会影响其性能，但研究人员乐观地认为，解决钇污染问题将为该方法在工业制造中的直接采用铺平道路。这一进展代表着在使高纯度钛更具经济可行性和环境可持续性方面迈出了重要一步。"
  },
  {
    "id": "44221826",
    "title": "You Weren't Meant to Have a Boss (2008)",
    "url": "https://www.paulgraham.com/boss.html",
    "summary": "Paul Graham's \"You Weren't Meant to Have a Boss\" argues that working for large organizations is unnatural and detrimental, particularly for programmers. He draws an analogy to unhealthy processed foods, comparing large companies to \"high fructose corn syrup\" – seemingly appealing but ultimately harmful.\n\nGraham posits that humans are designed to work in small groups, ideally around 8-20 people, citing research on hunter-gatherer societies. Large companies, however, necessitate hierarchical \"tree\" structures managed by bosses, which limit individual initiative and freedom. This structure forces employees to act as a single unit at higher levels, inversely impacting individual autonomy.\n\nThe article argues that programmers, who thrive on building new things, are particularly stifled in large organizations due to bureaucracy, legacy code, and imposed restrictions. This lack of freedom inhibits creativity and innovation. He suggests that while working for a small company doesn't guarantee freedom, a large company's structure inherently limits it.\n\nGraham advises ambitious programmers to consider starting their own startups or joining small companies where they have greater freedom and can learn more. He notes that Y Combinator's experience shows founders often transform from downtrodden employees to confident individuals when given autonomy. He concludes that the large corporate environment is often toxic to programmers, preventing them from working in a way that's natural and fulfilling.\n",
    "chinese_title": "你不应该有老板 (2008)",
    "chinese_summary": "保罗·格雷厄姆：《你本不该有老板》认为，为大型组织工作是不自然的且有害的，尤其是对程序员而言。他将大型公司比作不健康的加工食品，将它们比作“高果糖玉米糖浆”——看似诱人，但最终有害。\n\n格雷厄姆认为，人类天生适合在小群体中工作，理想情况下是8-20人左右，他引用了对狩猎采集社会的研究。然而，大型公司需要由老板管理的层级“树”状结构，这限制了个人主动性和自由。这种结构迫使员工在高层级上表现得像一个整体，反过来影响了个人的自主性。\n\n文章认为，程序员热衷于创造新事物，但在大型组织中尤其会因官僚主义、遗留代码和强制性限制而受到压制。这种缺乏自由会抑制创造力和创新。他认为，虽然为小公司工作并不能保证自由，但大型公司的结构本身就限制了自由。\n\n格雷厄姆建议有抱负的程序员考虑创办自己的初创公司或加入小公司，在那里他们有更大的自由，可以学到更多东西。他指出，Y Combinator的经验表明，创始人往往在获得自主权后，会从受压迫的员工转变为自信的个体。他总结说，大型企业环境对程序员来说往往是有害的，阻止他们以自然和充实的方式工作。"
  },
  {
    "id": "44188178",
    "title": "Startup Equity 101",
    "url": "https://quarter--mile.com/Startup-Equity-101",
    "summary": "Without the actual content of the \"Startup Equity 101\" article, I can only provide a general summary of what such an article *likely* covers:\n\nThis article, \"Startup Equity 101,\" likely aims to explain the fundamentals of equity compensation in startup companies. It probably defines what equity is - ownership stake in the company represented by stock or options. It's expected to clarify the difference between stock options (the *right* to buy shares at a set price) and actual shares of stock.\n\nThe article likely explains why startups use equity to attract and retain talent, especially when cash compensation may be limited. It probably touches on the concept of vesting, which is a schedule (often over several years) that dictates when employees actually *own* their equity. Common vesting schedules are likely explained.\n\nFurthermore, it likely discusses common stock vs. preferred stock, highlighting that employees typically receive common stock, which is riskier than preferred stock held by investors. The article might also address topics like dilution (when the value of existing shares decreases as the company issues more shares), the importance of understanding your equity grant documents, and resources for further learning about equity compensation. The purpose is likely to empower readers to make informed decisions regarding their equity and understand its potential value and risks.\n",
    "chinese_title": "初创公司股权入门",
    "chinese_summary": "“初创公司股权101”文章（假设内容）可能涵盖的内容概要：\n\n本文“初创公司股权101”旨在解释初创公司股权激励的基本原理。它可能定义股权的概念，即由股票或期权代表的公司所有权。预计会阐明股票期权（以固定价格购买股票的权利）和实际股票之间的区别。\n\n文章可能解释了为什么初创公司使用股权来吸引和留住人才，尤其是在现金补偿可能有限的情况下。它可能涉及归属的概念，即规定员工何时实际拥有其股权的时间表（通常持续数年）。常见的归属时间表可能会被解释。\n\n此外，它可能讨论普通股与优先股，强调员工通常获得普通股，这比投资者持有的优先股风险更高。该文章可能还会涉及诸如稀释（当公司发行更多股票时现有股票的价值下降）之类的主题，理解您的股权授予文件的重要性，以及有关股权激励的进一步学习资源。其目的可能是使读者能够就其股权做出明智的决定，并了解其潜在的价值和风险。"
  },
  {
    "id": "44219519",
    "title": "Building supercomputers for autocrats probably isn't good for democracy",
    "url": "https://helentoner.substack.com/p/supercomputers-for-autocrats",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "为独裁者建造超级计算机可能不利于民主。",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44188839",
    "title": "Tracking Copilot vs. Codex vs. Cursor vs. Devin PR Performance",
    "url": "https://aavetis.github.io/ai-pr-watcher/",
    "summary": "This article presents a comparative analysis of the Pull Request (PR) performance of several AI coding agents: GitHub Copilot, OpenAI Codex, Cursor Agents, Devin, and Codegen. The comparison focuses on three key metrics: Total PRs, Merged PRs, and Success Rate (presumably, the ratio of merged PRs to total PRs).\n\nThe article is structured as a table, showing the numerical values for each metric for each agent (represented by placeholders like `{{COPILOT_TOTAL}}`). Readers can click on each agent to learn more and explore the queries that generated the PRs.\n\nBeyond the table, a historic chart visualizing the performance of each agent over time is displayed. This chart offers different \"View Modes\": \"Complete View\" (showing all three metrics), \"Volume Only\" (likely showing the total number of PRs), and \"Success Rate Only\". Due to potential loading issues, a static version of the interactive chart is shown as a fallback.\n\nIn essence, the article aims to provide a data-driven overview of the effectiveness of different AI coding agents based on their PR contribution and success rate in a real-world software development context.\n",
    "chinese_title": "追踪Copilot、Codex、Cursor和Devin的公关表现",
    "chinese_summary": "本文对几种AI编码助手（GitHub Copilot、OpenAI Codex、Cursor Agents、Devin 和 Codegen）的拉取请求 (PR) 性能进行了比较分析。比较重点关注三个关键指标：PR总数、合并PR数和成功率（大概率是合并PR数与PR总数的比率）。\n\n文章以表格形式呈现，展示了每个助手的各项指标数值（用占位符表示，如`{{COPILOT_TOTAL}}`）。读者可以点击每个助手以了解更多信息并探索生成PR的查询。\n\n表格之外，还展示了一个历史图表，可视化了每个助手随时间的性能表现。该图表提供了不同的“查看模式”：“完整视图”（显示所有三个指标）、“仅数量”（可能显示PR总数）和“仅成功率”。由于可能存在加载问题，静态版本的交互式图表将作为备用显示。\n\n本质上，本文旨在基于不同AI编码助手在实际软件开发环境中PR贡献和成功率，提供一个数据驱动的有效性概述。"
  },
  {
    "id": "44219270",
    "title": "The wire that transforms much of Manhattan into one big, symbolic home (2017)",
    "url": "https://www.atlasobscura.com/articles/eruv-manhattan-invisible-wire-jewish-symbolic-religious-home",
    "summary": "This article explores the function and maintenance of the Manhattan eruv, a nearly invisible wire encircling most of the borough that has been in place, in some form or another, for just over a century. This eruv serves as a symbolic boundary, allowing observant Jews to bypass the Shabbat prohibition against carrying objects between public and private domains. By creating a unified \"home\" across a large area, the eruv permits them to carry keys, push strollers, and assist those who need canes or wheelchairs.\n\nRabbi Moshe Tauber plays a critical role in maintaining the eruv, driving the perimeter of the wire twice a week to identify and repair any breaks, which frequently occur due to construction or weather. Repairs must be completed before sundown on Friday, as even a single break renders the eruv invalid.\n\nThe Manhattan Eruv is funded by the Jewish community and overseen by the Manhattan Eruv Committee, it represents a community effort to maintain a space that supports religious observance. Zachary Levine from the National Building Museum emphasizes the eruv's significance in creating a visual language that defines space and benefits the most vulnerable members of the community, while remaining essentially invisible and unnoticed by the general public. The eruv only \"matters, unless it matters to you,\" highlighting its deeply personal and religious significance for observant Jews.\n",
    "chinese_title": "将曼哈顿变成一个巨大象征家园的电线（2017）",
    "chinese_summary": "本文探讨了曼哈顿“安息日围墙”的功能和维护。这个几乎隐形的铁丝网环绕着该区的大部分区域，已经存在了一个多世纪，并以某种形式存在。这个“安息日围墙”作为一个象征性的边界，允许遵守教规的犹太人绕过安息日禁止在公共和私人领域之间携带物品的禁令。通过在一个大范围内创建一个统一的“家”，这个“安息日围墙”允许他们携带钥匙、推婴儿车和帮助需要拐杖或轮椅的人。\n\nMoshe Tauber 拉比在维护“安息日围墙”方面发挥着关键作用，他每周两次驾车绕行铁丝网的周边，以识别和修复任何断裂，这些断裂通常是由于施工或天气造成的。维修必须在星期五日落之前完成，因为即使是单一的断裂也会使“安息日围墙”失效。\n\n曼哈顿“安息日围墙”由犹太社区资助，并由曼哈顿“安息日围墙”委员会监督，它代表着社区为维护一个支持宗教仪式的空间所做的努力。国家建筑博物馆的 Zachary Levine 强调了“安息日围墙”在创造一种视觉语言方面的重要性，这种视觉语言定义了空间，并使社区中最脆弱的成员受益，同时对普通公众来说基本上是隐形的和不引人注意的。“安息日围墙”只“有意义，除非它对你有意义”，突出了它对遵守教规的犹太人来说深刻的个人和宗教意义。"
  },
  {
    "id": "44197347",
    "title": "Building an AI server on a budget",
    "url": "https://www.informationga.in/blog/building-an-ai-server-on-a-budget",
    "summary": "This article details a step-by-step guide to building an AI server on a budget of $1.3K. The author outlines the rationale for building a personal server, citing unrestricted learning, hands-on operational experience, and potential cost savings for heavy GPU usage. The major limitation is the GPU's VRAM, restricting the scale of experiments.\n\nThe build process is broken down into four key steps: acquiring hardware, assembling hardware, installing the operating system, and installing necessary software tools and libraries.\n\nFor hardware acquisition, the author prioritizes an Nvidia GPU due to its mature software ecosystem, ultimately choosing a used RTX 4070 for its balance of price, memory (12GB VRAM), power consumption, and resale value. Other components like the motherboard, CPU, RAM, SSD, PSU, and case were selected based on budget, performance, and future upgrade potential, utilizing ChatGPT for initial recommendations.\n\nThe assembly process involved carefully installing components into the motherboard and case, with precautions taken against static electricity. Detailed instructions are provided for installing the CPU, fan, RAM, SSD, GPU, and connecting power cables.\n\nThe OS installation involved creating a bootable USB drive with Ubuntu Server 24.04.2 LTS and configuring the system with SSH access. Finally, the author details updating the system and running diagnostic commands to verify the health of the server.\n",
    "chinese_title": "低成本构建AI服务器",
    "chinese_summary": "本文详细介绍了一个以 1300 美元预算构建 AI 服务器的逐步指南。作者阐述了构建个人服务器的理由，包括不受限制的学习、实践操作经验以及重度 GPU 使用的潜在成本节约。主要限制是 GPU 的显存容量，限制了实验规模。\n\n构建过程分为四个关键步骤：获取硬件、组装硬件、安装操作系统以及安装必要的软件工具和库。\n\n在硬件获取方面，作者优先考虑 Nvidia GPU，因为其软件生态系统成熟，最终选择了一块二手 RTX 4070，因为它在价格、内存（12GB 显存）、功耗和转售价值之间取得了平衡。主板、CPU、RAM、SSD、电源和机箱等其他组件的选择基于预算、性能和未来升级潜力，并利用 ChatGPT 进行初步推荐。\n\n组装过程包括小心地将组件安装到主板和机箱中，并采取预防静电的措施。文中提供了安装 CPU、风扇、RAM、SSD、GPU 以及连接电源线的详细说明。\n\n操作系统安装包括创建带有 Ubuntu Server 24.04.2 LTS 的可启动 USB 驱动器，并配置系统以实现 SSH 访问。最后，作者详细介绍了更新系统和运行诊断命令以验证服务器运行状况。"
  },
  {
    "id": "44216630",
    "title": "Binfmtc – binfmt_misc C scripting interface",
    "url": "https://www.netfort.gr.jp/~dancer/software/binfmtc.html.en",
    "summary": "Binfmtc is a tool that allows C programmers to use the C language for scripting tasks traditionally handled by interpreted languages like Perl or Shell. It leverages Linux's binfmt_misc mechanism to compile and execute C scripts on the fly.\n\nBy adding a specific magic keyword (`/*BINFMTC: compile-time options`) to the beginning of a C file and granting it execute permissions, the binfmtc interpreter automatically compiles the script using GCC into a temporary binary and then executes it. This eliminates the need for manual compilation steps and makefiles, making C more accessible for quick scripting tasks.\n\nThe package includes \"real csh,\" an example of utilizing this method for system administration tasks in a C-style shell.\n\nInstallation for Debian systems involves adding a specific repository to `/etc/apt/sources.list` and installing the `binfmtc` package.\n\nFuture development plans included expanding compiler support beyond GCC (gcj, g77, gpc, gnat, gobjc, chill, mono/pnet). The project also has incorporated the `binfmt-support` functionality. The author provides links to alternatives like tcc -run and c repl for similar C scripting experiences.\n",
    "chinese_title": "Binfmtc – binfmt_misc C 脚本接口",
    "chinese_summary": "Binfmtc是一个工具，允许C程序员使用C语言来处理传统上由Perl或Shell等解释型语言处理的脚本任务。它利用Linux的binfmt_misc机制来即时编译和执行C脚本。\n\n通过在C文件开头添加一个特定的魔术关键字(`/*BINFMTC: compile-time options`)并授予其执行权限，binfmtc解释器会自动使用GCC将该脚本编译成一个临时二进制文件并执行它。这消除了手动编译步骤和makefile的需求，使得C语言对于快速脚本任务来说更加易用。\n\n该软件包包含“real csh”，这是利用此方法在C风格的shell中执行系统管理任务的示例。\n\n对于Debian系统的安装，需要将特定的存储库添加到`/etc/apt/sources.list`并安装`binfmtc`软件包。\n\n未来的开发计划包括将编译器支持扩展到GCC之外（gcj, g77, gpc, gnat, gobjc, chill, mono/pnet）。该项目还整合了`binfmt-support`功能。作者提供了类似C脚本体验的替代方案链接，例如tcc -run和c repl。"
  },
  {
    "id": "44219563",
    "title": "tcpulse: A TCP/UDP load generator that provides fine-grained, flow-level control",
    "url": "https://github.com/yuuki/tcpulse",
    "summary": "tcpulse is a Go-based TCP/UDP load generator designed for fine-grained, flow-level control over network connections. It operates in client and server modes, enabling users to simulate real-world network traffic patterns for performance testing, infrastructure validation, and protocol comparison.\n\ntcpulse supports both persistent (long-lived connections) and ephemeral (new connection per request) connection modes, offering precise control over connection establishment and data transfer. Key features include real-time metrics (latency percentiles, throughput, connection counts), rate limiting, multi-target support, and JSON Lines output for easy integration with monitoring tools.\n\nUnlike bandwidth-focused tools like iperf3 and netperf, tcpulse emphasizes load pattern control and experiment reproducibility. It allows users to specify connection generation rates and concurrent connection counts, making it suitable for validating network device and middleware performance under realistic load conditions.\n\nExample use cases include measuring eBPF overhead, verifying load balancer distribution, testing firewall/conntrack table exhaustion, simulating UDP packet rate tolerance for real-time applications, measuring the effect of thread pinning, and validating multi-target infrastructure performance. While tcpulse isn't intended for maximum throughput measurement or high-layer protocol testing, its unique positioning makes it a valuable tool for operational validation and performance regression testing.\n",
    "chinese_title": "tcpulse: 一款提供细粒度流级别控制的 TCP/UDP 负载生成器",
    "chinese_summary": "tcpulse 是一款基于 Go 的 TCP/UDP 负载生成器，旨在对网络连接进行细粒度的、流级别的控制。它以客户端和服务器模式运行，使用户能够模拟真实世界的网络流量模式，用于性能测试、基础设施验证和协议比较。\n\ntcpulse 支持持久连接（长连接）和临时连接（每个请求建立新连接）两种模式，可精确控制连接建立和数据传输。主要特性包括实时指标（延迟百分位数、吞吐量、连接计数）、速率限制、多目标支持和 JSON Lines 输出，便于与监控工具集成。\n\n与 iperf3 和 netperf 等专注于带宽的工具不同，tcpulse 强调负载模式控制和实验可重复性。它允许用户指定连接生成速率和并发连接数，使其适合于在真实负载条件下验证网络设备和中间件的性能。\n\n用例示例包括测量 eBPF 开销、验证负载均衡器分配、测试防火墙/连接跟踪表耗尽、模拟实时应用程序的 UDP 数据包速率容忍度、测量线程绑定的影响以及验证多目标基础设施性能。虽然 tcpulse 并非旨在进行最大吞吐量测量或高层协议测试，但其独特的定位使其成为运营验证和性能回归测试的宝贵工具。"
  },
  {
    "id": "44189966",
    "title": "Efficient mRNA delivery to resting T cells to reverse HIV latency",
    "url": "https://www.nature.com/articles/s41467-025-60001-2",
    "summary": "This article explores a novel approach to HIV latency reversal using mRNA-lipid nanoparticle (LNP) technology. The persistence of latent HIV proviruses in resting CD4+ T cells is a major obstacle to curing HIV. The study hypothesizes that delivering mRNA encoding proteins that can reverse HIV latency via LNPs could activate viral transcription and lead to the elimination of infected cells.\n\nResearchers developed a new LNP formulation called LNP X, which demonstrates unprecedented potency in delivering mRNA to resting CD4+ T cells without causing toxicity or activation. LNP X uses SM-102 as an ionizable lipid and is further modified using ß-sitosterol. Encapsulating mRNA encoding HIV Tat, an activator of HIV transcription, LNP X significantly enhances HIV transcription in ex vivo CD4+ T cells from people living with HIV. It also enables the delivery of CRISPR activation machinery to modulate viral and host gene transcription.\n\nThe superior potency of LNP X is attributed to enhanced protein expression downstream of endosomal escape.\n\nThese findings offer a promising avenue for developing nucleic acid-based T cell therapeutics, particularly for HIV cure strategies focused on latency reversal. The efficient delivery of mRNA to resting T cells using LNP X represents a significant advancement in the field.\n",
    "chinese_title": "高效mRNA递送至静息T细胞以逆转HIV潜伏",
    "chinese_summary": "本文探讨了一种利用mRNA-脂质纳米颗粒(LNP)技术逆转HIV潜伏的新方法。潜伏性HIV前病毒在静止CD4+ T细胞中的持续存在是治愈HIV的主要障碍。该研究假设，通过LNP递送编码能够逆转HIV潜伏的蛋白的mRNA，可以激活病毒转录并导致感染细胞的清除。\n\n研究人员开发了一种名为LNP X的新型LNP配方，该配方在将mRNA递送至静止CD4+ T细胞方面表现出前所未有的效力，且不会引起毒性或激活。LNP X使用SM-102作为可电离脂质，并使用β-谷甾醇进一步修饰。LNP X封装了编码HIV转录激活因子HIV Tat的mRNA，显著增强了来自HIV感染者的离体CD4+ T细胞中的HIV转录。它还能够递送CRISPR激活机制，以调节病毒和宿主基因的转录。\n\nLNP X的卓越效力归因于内体逃逸后的增强的蛋白质表达。\n\n这些发现为开发基于核酸的T细胞疗法提供了一条有前景的途径，特别是对于侧重于潜伏逆转的HIV治愈策略。使用LNP X将mRNA有效地递送至静止T细胞代表了该领域的重大进展。"
  },
  {
    "id": "44217322",
    "title": "Launching the BeOS on Hitachi Flora Prius Systems (1999)",
    "url": "http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/support/guides/hitachi_boot.html",
    "summary": "This document provides a guide for launching the BeOS on Hitachi FLORA Prius systems, specifically the 330J model, which comes pre-installed with both BeOS and Windows 98. The default configuration boots directly into Windows 98, requiring user intervention to access the BeOS.\n\nThe document outlines three methods for booting into the BeOS:\n\n1.  **Using the BeOS Boot Floppy Diskette:** A simple, temporary solution requiring the user to boot from a floppy disk each time they want to use BeOS.\n\n2.  **Launching from the Windows 98 Desktop:** This method involves installing the BeOS Launcher on the Windows 98 system, allowing users to launch BeOS by double-clicking a shortcut icon.\n\n3.  **Choosing an Operating System at Startup (using Bootman):** The recommended approach utilizes Bootman, a boot manager included on the BeOS backup CD-ROM.  Bootman is installed within the BeOS environment and allows the user to select which OS to boot into at startup. The guide provides detailed step-by-step instructions for Bootman installation, configuration, and uninstallation, including creating a rescue disk for restoring the original Master Boot Record (MBR) if needed. It also warns users against installing Bootman if they already have a working boot manager.\nThe document also mentions commercial alternatives to Bootman. It emphasizes that the instructions are specifically for the Hitachi FLORA Prius 330J.\n",
    "chinese_title": "在日立Flora Prius系统上发布BeOS (1999)",
    "chinese_summary": "本文档为在日立FLORA Prius系统（特别是预装了BeOS和Windows 98的330J型号）上启动BeOS提供指南。默认配置直接启动Windows 98，需要用户干预才能访问BeOS。\n\n本文档概述了三种启动BeOS的方法：\n\n1.  **使用BeOS启动软盘：** 一种简单、临时的解决方案，每次想要使用BeOS时都需要从软盘启动。\n\n2.  **从Windows 98桌面启动：** 此方法需要在Windows 98系统上安装BeOS启动器，允许用户通过双击快捷方式图标来启动BeOS。\n\n3.  **在启动时选择操作系统（使用Bootman）：** 推荐的方法是使用Bootman，它是BeOS备份光盘中包含的启动管理器。Bootman安装在BeOS环境中，允许用户在启动时选择要启动的操作系统。本指南提供了Bootman安装、配置和卸载的详细分步说明，包括创建救援磁盘以在需要时恢复原始主引导记录(MBR)。它还警告用户，如果他们已经有一个可以正常工作的启动管理器，则不要安装Bootman。\n\n本文档还提到了Bootman的商业替代品。它强调这些说明专门针对日立FLORA Prius 330J。"
  },
  {
    "id": "44223853",
    "title": "Defiant loyalists paid dearly for choosing wrong side in the American Revolution",
    "url": "https://www.smithsonianmag.com/history/meet-the-defiant-loyalists-who-paid-dearly-for-choosing-the-wrong-side-in-the-american-revolution-180986716/",
    "summary": "This Smithsonian article explores the plight of American Loyalists during and after the American Revolution. Despite the popular image of unified colonists, a significant portion (15-20%) remained loyal to the British Crown, facing severe consequences for their allegiance. These Loyalists, derisively called \"Tories,\" endured violence, ostracism, property confiscation, and exile.\n\nThe article highlights that Loyalists came from diverse backgrounds and were particularly prevalent in New York, Pennsylvania, and the Southern Colonies. Even before independence was declared, refusing loyalty oaths resulted in penalties ranging from ostracism to imprisonment and banishment. Examples of extreme violence against Loyalists, like tarring and feathering, are cited. While outright killings were relatively rare, revolutionaries employed public humiliation and property seizure to undermine Loyalists' social standing.\n\nThe Treaty of Paris, which ended the war, only \"recommended\" restitution of confiscated Loyalist property, allowing states to largely ignore the provision. The article details the animosity toward Loyalists, exemplified by Benjamin Franklin's strained relationship with his Loyalist son, William.\n\nUltimately, while some Loyalists were eventually readmitted into American society, many remained in exile, facing lasting consequences for choosing the \"wrong side.\" The article concludes by noting that even in exile, many Loyalists maintained contact with their families in the new republic and were reconciled in their own way.\n",
    "chinese_title": "反叛效忠者为站错美国独立战争的队付出了惨重代价。",
    "chinese_summary": "史密森尼学会的文章探讨了美国独立战争期间及之后效忠派的困境。尽管人们普遍认为殖民者是团结一致的，但仍有相当一部分人（15-20%）效忠于英国王室，并因此面临严重的后果。这些效忠派，被轻蔑地称为“托利党人”，遭受了暴力、排斥、财产没收和流放。\n\n文章强调，效忠派来自不同的背景，尤其在纽约、宾夕法尼亚和南部殖民地最为普遍。甚至在宣布独立之前，拒绝效忠宣誓就会受到惩罚，从排斥到监禁和驱逐不等。文章引用了针对效忠派的极端暴力行为的例子，比如涂焦油和羽毛。虽然直接杀戮相对罕见，但革命者利用公开羞辱和没收财产来削弱效忠派的社会地位。\n\n结束战争的《巴黎条约》仅“建议”归还被没收的效忠派财产，使得各州可以在很大程度上忽视这一规定。文章详细描述了对效忠派的敌意，本杰明·富兰克林与他效忠派儿子威廉的紧张关系就是一个例证。\n\n最终，虽然一些效忠派最终被重新接纳到美国社会，但许多人仍然流亡，为选择“错误的一方”而面临持久的后果。文章最后指出，即使在流亡中，许多效忠派仍与他们在共和国的家人保持联系，并以自己的方式和解。"
  },
  {
    "id": "44221430",
    "title": "Web designs are getting too complicated",
    "url": "https://websmith.studio/blog/website-designs-are-getting-too-complicated/",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "网页设计变得过于复杂。",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44215726",
    "title": "Focus and Context and LLMs",
    "url": "https://taras.glek.net/posts/focus-and-context-and-llms/",
    "summary": "This article discusses the author's experience with using LLMs for software engineering, arguing against the hype surrounding agentic coding. While LLMs can accomplish complex tasks, they are not autonomous \"ADHD agents on meth\" capable of independently producing useful software.\n\nThe author highlights a project where an LLM successfully built a complete HTTP/2 server, emphasizing that this was achieved through meticulous context management and algorithmic supervision by a skilled engineer. The LLM required constant guidance, strategic context adjustments, and a specific file-based workflow. Tool calling, the basis of much agentic hype, proved unreliable. The author also points out the difficulties LLMs face with structured data like JSON.\n\nThe core argument is that LLM output quality is directly tied to the quality of the context provided. Current agentic approaches are likened to the genetic algorithm hype of the 90s – brute-force solutions that are often too expensive. The author concludes that until better context curation methods are developed, LLMs will primarily be effective in the hands of exceptional engineers who can provide the necessary context and guidance. Ultimately, the author cautions against expecting significant results from poorly equipped individuals feeding mediocre data to LLMs.\n",
    "chinese_title": "专注、语境与大型语言模型",
    "chinese_summary": "本文探讨了作者使用大型语言模型（LLMs）进行软件工程的经验，驳斥了围绕自主编码的炒作。虽然LLMs可以完成复杂的任务，但它们并非能够独立生成有用软件的自主“嗑药多动症代理”。\n\n作者重点介绍了一个LLM成功构建完整HTTP/2服务器的项目，强调这是通过熟练工程师的精心上下文管理和算法监督实现的。LLM需要持续的指导、战略性的上下文调整和特定的基于文件的工作流程。工具调用（许多自主编码炒作的基础）被证明是不可靠的。作者还指出了LLMs在处理JSON等结构化数据方面面临的困难。\n\n核心论点是，LLM的输出质量与提供的上下文质量直接相关。目前的自主方法类似于90年代的遗传算法炒作——通常成本过高的蛮力解决方案。作者的结论是，在开发出更好的上下文管理方法之前，LLMs主要对能够提供必要上下文和指导的卓越工程师有效。最终，作者告诫不要期望装备不足的人向LLMs输入平庸数据能产生显著成果。"
  },
  {
    "id": "44219692",
    "title": "There's not much point in buying Commodore",
    "url": "http://oldvcr.blogspot.com/2025/06/theres-not-much-point-in-buying.html",
    "summary": "This blog post, written by a self-proclaimed Commodore enthusiast with extensive experience and a significant collection, argues against buying the Commodore trademark. The author's credentials include writing for Commodore magazines, owning numerous Commodore systems, and even meeting Jack Tramiel.\n\nThe post stems from a Retro Recipes video detailing how Commodore Corporation BV (CC BV), the current holder of the Commodore trademark, suggested a buyout instead of granting a broad license. The author believes the Commodore brand, once valuable, is now largely worthless outside of a niche retro market. They cite numerous failed attempts to revive the brand after Commodore's bankruptcy, including the disastrous Commodore 64 Web.it, Commodore Gaming PCs, Commodore USA LLC's underpowered \"new\" Commodore computers, and poorly received MP3 players and a smartphone.\n\nThe author acknowledges the success of the C64DTV and \"TheC64\" but highlights that the latter avoids using the Commodore name due to licensing issues. They mention the current production of a licensed 64x case, but question the value added by the Commodore name and the exorbitant fees charged by CC BV.\n\nUltimately, the author warns against \"bloodsuckers\" draining the Commodore name and argues that enthusiasts will buy retro hardware based on its merits, not the brand name. They raise crucial questions about governance and enforcement should the trademark be purchased, particularly regarding community projects, potential cloning, and profit sharing. The author believes leaving the brand to rest in peace is a better strategy than perpetuating tawdry products and enriching the licensor.\n",
    "chinese_title": "买 Commodore 没什么意义。",
    "chinese_summary": "一位自称拥有丰富经验和大量收藏的Commodore爱好者撰写的这篇博文，反对购买Commodore商标。作者的资历包括为Commodore杂志撰稿、拥有大量Commodore系统，甚至会见过Jack Tramiel。\n\n这篇文章源于Retro Recipes的一段视频，该视频详细介绍了Commodore商标的当前持有者Commodore Corporation BV (CC BV) 建议直接收购而非授予广泛的许可。作者认为，Commodore品牌曾经很有价值，但现在除了小众的复古市场之外，几乎毫无价值。他们列举了Commodore破产后无数次复兴该品牌失败的尝试，包括灾难性的Commodore 64 Web.it、Commodore游戏PC、Commodore USA LLC性能不足的“新”Commodore电脑，以及反响不佳的MP3播放器和智能手机。\n\n作者承认C64DTV和“TheC64”的成功，但强调后者由于许可问题避免使用Commodore名称。他们提到目前正在生产获得许可的64x机箱，但质疑Commodore名称所增加的价值以及CC BV收取的过高费用。\n\n最终，作者警告人们不要让“吸血鬼”榨干Commodore名称，并认为爱好者会根据其优点而不是品牌名称购买复古硬件。他们提出了关于购买商标后治理和执行的关键问题，特别是关于社区项目、潜在的克隆和利润分享。作者认为，让品牌安息比延续粗制滥造的产品和让许可方致富更好。"
  },
  {
    "id": "44221907",
    "title": "Show HN: I made CSS-only glitch effect",
    "url": "https://muffinman.io/blog/css-image-glitch/",
    "summary": "This \"Show HN\" post details how the author created a CSS-only image glitch effect, motivated by a desire to make a robotic poet's image visually glitch. The core idea involves slicing the image into strips, randomly displacing them, and altering their colors, all without JavaScript.\n\nThe author explains how they programmatically generated HTML divs representing image strips, each acting as a background with a vertical offset. To achieve glitchy movement, the post highlights a technique to simulate instant jumps using very short CSS keyframes, effectively creating near-vertical transitions in animations.\n\nA Safari browser issue prevented hue-rotation from working within animations unless an initial `hue-rotate(0)` was specified. The author then demonstrates combining transforms and filters (including hue-rotation) in a single animation for the image strips.\n\nTo introduce randomness, JavaScript is used to generate multiple CSS keyframe animation variations, employing CSS variables to control properties like displacement and hue rotation. These values, along with animation duration and delay, are randomly assigned to each strip's inline styles.\n\nFinally, the author incorporated subtle chromatic aberration using blue and red shadows to enhance the corrupted screen effect. The post concludes with a link to the CodePen example and other interesting glitch effect resources.\n",
    "chinese_title": "显示 HN: 我用纯 CSS 实现了故障效果",
    "chinese_summary": "纯CSS实现的图像故障效果"
  },
  {
    "id": "44219755",
    "title": "Poison everywhere: No output from your MCP server is safe",
    "url": "https://www.cyberark.com/resources/threat-research-blog/poison-everywhere-no-output-from-your-mcp-server-is-safe",
    "summary": "This article, titled \"Poison everywhere: No output from your MCP server is safe,\" explores vulnerabilities in the Model Context Protocol (MCP), an open-source project from Anthropic that allows LLMs to interact with real-world tools and services. It builds upon the existing Tool Poisoning Attack (TPA), which involves embedding malicious instructions in tool descriptions.\n\nThe article argues that existing TPA research is too narrowly focused on description fields and introduces the concept of Full-Schema Poisoning (FSP), where the entire tool schema (including function name, parameters, types, etc.) is a potential injection point. Through examples, it demonstrates how malicious content can be injected into various parts of the schema to manipulate LLM behavior.\n\nThe article then introduces a new attack class called Advanced Tool Poisoning Attacks (ATPA), which exploits the LLM's interpretation of tool outputs, particularly dynamic content like error messages. In this scenario, a seemingly benign tool can return a poisoned error message that tricks the LLM into providing sensitive information or performing unintended actions. The article highlights that ATPAs are harder to detect because the malicious behavior is often subtle and masked within a seemingly normal flow.\n",
    "chinese_title": "到处是毒药：你的 MCP 服务器的任何输出都不安全",
    "chinese_summary": "到处是毒药：你的MCP服务器的任何输出都是不安全的\n\n本文题为《到处是毒药：你的MCP服务器的任何输出都是不安全的》，探讨了模型上下文协议(MCP)中的漏洞，MCP是Anthropic的一个开源项目，允许LLM与现实世界的工具和服务进行交互。它建立在现有的工具中毒攻击(TPA)之上，该攻击涉及在工具描述中嵌入恶意指令。\n\n本文认为，现有的TPA研究过于狭隘地关注描述字段，并引入了全模式中毒(FSP)的概念，即整个工具模式（包括函数名、参数、类型等）都是潜在的注入点。通过示例，它展示了如何将恶意内容注入到模式的各个部分以操纵LLM的行为。\n\n本文随后介绍了一种新的攻击类别，称为高级工具中毒攻击(ATPA)，该攻击利用LLM对工具输出的解释，特别是动态内容，如错误消息。在这种情况下，一个看似良性的工具可能会返回一个中毒的错误消息，从而诱骗LLM提供敏感信息或执行非预期的操作。本文强调，ATPA更难检测，因为恶意行为通常很微妙，并且隐藏在看似正常的流程中。"
  },
  {
    "id": "44180533",
    "title": "The time bomb in the tax code that's fueling mass tech layoffs",
    "url": "https://qz.com/tech-layoffs-tax-code-trump-section-174-microsoft-meta-1851783502",
    "summary": "This article argues that a little-noticed change to Section 174 of the U.S. tax code, buried in the 2017 Tax Cuts and Jobs Act, has significantly contributed to mass tech layoffs. For almost 70 years, Section 174 allowed companies to deduct 100% of R&D spending in the year incurred, incentivizing innovation and keeping R&D jobs in the U.S.\n\nThe 2017 tax law, while cutting the corporate tax rate, mandated that companies now amortize R&D expenses over five or 15 years, effectively raising their tax burden. This change, which took effect in 2022, made R&D more expensive and coincided with a drying up of venture funding and rising interest rates.\n\nMajor tech companies like Meta, Microsoft, Google, Amazon, and Salesforce, along with smaller companies like Twilio, Shopify, and Coinbase, subsequently announced significant layoffs, often blaming over-hiring or AI. However, the article suggests that the Section 174 change was a hidden accelerant, impacting the financial logic of R&D investments.\n\nThe impact wasn't limited to tech; it affected any company that had adopted tech-like models of aggressive spending on product and engineering. The change disrupted their ability to use R&D write-offs as a tax shield, leading to unexpected tax bills. While there's a bipartisan push to repeal the change, the layoffs have already happened, and the economic ripple effects are still unfolding. The article concludes that the Section 174 change serves as a cautionary tale about the unintended consequences of tax policy and the importance of understanding its real-world effects.\n",
    "chinese_title": "导致大规模科技裁员的税法定时炸弹",
    "chinese_summary": "本文认为，2017年《减税与就业法案》中一项鲜为人知的美国税法第174条修改，极大地促成了大规模科技裁员。近70年来，第174条允许企业在发生当年扣除100%的研发支出，从而激励创新并将研发岗位留在美国。\n\n2017年的税法在降低企业税率的同时，规定企业现在必须在五年或十五年内摊销研发费用，实际上增加了它们的税负。这一变化于2022年生效，使研发成本更高，并恰逢风险投资枯竭和利率上升。\n\nMeta、微软、谷歌、亚马逊和Salesforce等大型科技公司，以及Twilio、Shopify和Coinbase等规模较小的公司，随后宣布了大规模裁员，通常归咎于过度招聘或人工智能。然而，本文认为，第174条的修改是一个隐藏的加速因素，影响了研发投资的财务逻辑。\n\n这种影响不仅限于科技行业；它影响了所有采用类似科技公司模式，在产品和工程方面进行积极支出的公司。这一变化扰乱了他们利用研发注销作为避税手段的能力，导致了意外的税单。虽然两党都在推动废除这一变化，但裁员已经发生，经济连锁反应仍在展开。本文的结论是，第174条的修改是一个关于税收政策的意外后果以及理解其现实影响的重要性的警示故事。"
  },
  {
    "id": "44221489",
    "title": "Forests offset warming more than thought: study",
    "url": "https://news.ucr.edu/articles/2025/05/29/does-planting-trees-really-help-cool-planet",
    "summary": "This article discusses a new modeling study from the University of California, Riverside, that suggests reforestation can cool the planet more effectively than previously thought, particularly in the tropics. Restoring forests to preindustrial levels could lower global average temperatures by 0.34 degrees Celsius, about one-quarter of the warming already experienced.\n\nThe study highlights that trees, beyond carbon absorption, release biogenic volatile organic compounds (BVOCs) that interact with other gases to reflect sunlight and encourage cloud formation, amplifying their cooling effect. This aspect is often overlooked in climate models.\n\nHowever, the benefits aren't uniform. Tropical forests offer stronger cooling due to efficient carbon absorption and greater BVOC production, with less warming from surface darkening compared to higher latitude forests.\n\nReforestation can also improve regional air quality by reducing atmospheric dust. While increased BVOCs in the tropics could worsen air quality based on particulate matter, they could also improve it based on ozone measurements. The researchers emphasize that even smaller, localized reforestation efforts can significantly impact regional climates.\n\nThe study acknowledges the unlikelihood of restoring forests to their full historical extent due to land-use conflicts, including agriculture and housing. It stresses the need for careful planning and highlights Rwanda as an example where conservation and economic development are aligned.\n\nUltimately, the study concludes that reforestation is a valuable climate solution but should not be seen as a replacement for reducing fossil fuel emissions. Every step toward restoration, regardless of scale, contributes to mitigating climate change.\n",
    "chinese_title": "森林抵消变暖效应超预期：研究",
    "chinese_summary": "加州大学河滨分校的一项新模型研究表明，森林再造比先前认为的更能有效地为地球降温，尤其是在热带地区。将森林恢复到工业化前的水平，可以将全球平均气温降低0.34摄氏度，约占已经历升温幅度的四分之一。\n\n该研究强调，除了吸收碳之外，树木还会释放生物源挥发性有机化合物（BVOCs），这些化合物与其他气体相互作用，反射阳光并促进云的形成，从而增强其冷却效果。这一方面在气候模型中经常被忽视。\n\n然而，这种益处并非均匀分布。由于有效吸收碳和更高的BVOCs产生，热带森林提供更强的冷却效果，与高纬度森林相比，地表变暗产生的升温更少。\n\n森林再造还可以通过减少大气粉尘来改善区域空气质量。虽然热带地区BVOCs的增加可能会因颗粒物而恶化空气质量，但它们也可能因臭氧测量而改善空气质量。研究人员强调，即使是较小规模的局部森林再造努力，也会对区域气候产生重大影响。\n\n该研究承认，由于包括农业和住房在内的土地利用冲突，将森林恢复到其全部历史规模的可能性不大。它强调需要仔细规划，并强调卢旺达是一个保护和经济发展相结合的例子。\n\n最终，该研究得出结论，森林再造是一种有价值的气候解决方案，但不应被视为替代减少化石燃料排放的方案。无论规模大小，每一步的恢复都将有助于减缓气候变化。"
  },
  {
    "id": "44212441",
    "title": "Joining Apple Computer (2018)",
    "url": "https://www.folklore.org/Joining_Apple_Computer.html",
    "summary": "Bill Atkinson's \"Joining Apple Computer\" reflects on his decision to leave his neuroscience PhD program in 1978 to join Apple, a decision he attributes to a persuasive pitch from Steve Jobs. Jobs painted a vision of Apple as a place to \"invent the future\" and make a significant impact on millions of lives.\n\nAtkinson recounts contributing significantly to the Lisa and Macintosh projects. He advocated for the inclusion of a mouse and a white background for the Lisa. He wrote QuickDraw, a core graphics library, the Lisa Window, Event, and Menu Managers (including inventing pull-down menus). His code comprised nearly two-thirds of the original Macintosh ROM. He also created MacPaint, which showcased the creative potential of computers with graphics displays and mice.\n\nAtkinson highlights his close friendship with Jobs, detailing how they collaborated and challenged each other's ideas. Inspired by a personal experience, Atkinson also designed HyperCard, an authoring system for non-programmers.\n\nHe worked at Apple for 12 years, leaving in 1990 to co-found General Magic. He expresses gratitude to Jef Raskin and Steve Jobs for the opportunity to shape the world through his work at Apple.\n",
    "chinese_title": "加入苹果公司 (2018年)",
    "chinese_summary": "比尔·阿特金森的《加入苹果电脑公司》回顾了他1978年离开神经科学博士课程加入苹果的决定，他将这个决定归功于史蒂夫·乔布斯的极具说服力的游说。乔布斯将苹果描绘成一个“创造未来”并对数百万人的生活产生重大影响的地方。\n\n阿特金森回忆了他对Lisa和Macintosh项目的重大贡献。他倡导Lisa包含鼠标和白色背景。他编写了核心图形库QuickDraw，Lisa Window、Event和Menu Managers（包括发明下拉菜单）。他的代码占原始Macintosh ROM的近三分之二。他还创建了MacPaint，它展示了具有图形显示器和鼠标的计算机的创造潜力。\n\n阿特金森强调了他与乔布斯的亲密友谊，详细描述了他们如何合作和挑战彼此的想法。受到个人经历的启发，阿特金森还为非程序员设计了创作系统HyperCard。\n\n他在苹果工作了12年，于1990年离开并共同创立了General Magic。他感谢Jef Raskin和史蒂夫·乔布斯让他有机会通过在苹果的工作来塑造世界。"
  },
  {
    "id": "44218618",
    "title": "Rkyv (archive) is a zero-copy deserialization framework for Rust",
    "url": "https://rkyv.org/rkyv.html",
    "summary": "Rkyv (archive) is a Rust framework focused on zero-copy deserialization. This documentation provides an overview of its motivation, architecture, and key features, serving as a comprehensive learning resource. While not exhaustively detailed like the official documentation, it's a valuable starting point for understanding rkyv.\n\nThe document highlights various resources for learning and support: a Discord server for community assistance, the GitHub repository for source code and issue tracking, and the official documentation for the core `rkyv` library and `rkyv_dyn` crate, which adds trait object support.\n\nThe summary also points to the Rust serialization benchmark, a comparative analysis of various Rust serialization methods, including specialized benchmarks for zero-copy solutions like rkyv. Finally, it lists related \"sister crates\" utilized by rkyv: `rend` (endian-agnostic features), `bytecheck` (validation), `rancor` (error handling), and `ptr_meta` (pointer manipulation). In essence, Rkyv is a powerful tool for efficient data handling in Rust, and the provided resources offer ample support for its adoption and understanding.\n",
    "chinese_title": "Rkyv (archive) 是 Rust 的零拷贝反序列化框架。",
    "chinese_summary": "Rkyv (存档) 是一个专注于零拷贝反序列化的 Rust 框架。本文档概述了其动机、架构和关键特性，作为全面的学习资源。虽然不如官方文档详尽，但它是理解 rkyv 的一个有价值的起点。\n\n文档重点介绍了各种学习和支持资源：用于社区协助的 Discord 服务器、用于源代码和问题跟踪的 GitHub 仓库，以及用于核心 `rkyv` 库和添加 trait object 支持的 `rkyv_dyn` crate 的官方文档。\n\n摘要还指出了 Rust 序列化基准测试，这是一个对各种 Rust 序列化方法进行比较分析的工具，包括对像 rkyv 这样的零拷贝解决方案的专门基准测试。最后，它列出了 rkyv 使用的相关“姊妹 crate”：`rend`（字节序无关功能）、`bytecheck`（验证）、`rancor`（错误处理）和 `ptr_meta`（指针操作）。本质上，Rkyv 是 Rust 中用于高效数据处理的强大工具，提供的资源为其采用和理解提供了充分的支持。"
  },
  {
    "id": "44221450",
    "title": "Kagi Reaches 50k Users",
    "url": "https://kagi.com/stats?stat=members",
    "summary": "Kagi search has reached a milestone of 50,000 members, pioneering the next frontier of search. The service boasts 5,450 families and 194 teams. Kagi recorded 760,600 queries and 10,662 Assistant Threads in the past day. There are 2,047 Orion+ members.\n\nThe statistics page provides a visual graph and daily record of membership growth from May 26th (48,961) to June 9th (50,074).\n\nKagi is celebrating this milestone with a surprise for its members. The fun fact notes that Kagi's user base exceeds the population of 26 countries and inhabited territories and are approaching the population of the Faroe Islands.\n\nThe page then includes information about Kagi's features, keyboard shortcuts, search operators, and query shortcuts and widgets. These features are designed to improve the user experience and allow for more precise and efficient searching.\n",
    "chinese_title": "Kagi用户突破5万",
    "chinese_summary": "Kagi搜索达到50,000会员里程碑，引领搜索的下一个前沿。该服务拥有5,450个家庭和194个团队。过去一天，Kagi记录了760,600次查询和10,662个助手线程。现有2,047名Orion+会员。\n\n统计页面提供了从5月26日（48,961）到6月9日（50,074）的会员增长的可视化图表和每日记录。\n\nKagi正在庆祝这一里程碑，并为会员准备了一份惊喜。有趣的事实指出，Kagi的用户群超过了26个国家和居住地的总人口，并且正在接近法罗群岛的人口。\n\n该页面随后包括有关Kagi的功能、键盘快捷键、搜索运算符以及查询快捷方式和窗口小部件的信息。这些功能旨在改善用户体验，并允许更精确和高效的搜索。"
  },
  {
    "id": "44215197",
    "title": "FAA to eliminate floppy disks used in air traffic control systems",
    "url": "https://www.tomshardware.com/pc-components/storage/the-faa-seeks-to-eliminate-floppy-disk-usage-in-air-traffic-control-systems",
    "summary": "The FAA is planning a major overhaul of the U.S. air traffic control (ATC) system, aiming to replace outdated technology like floppy disks and Windows 95 with modern, secure systems. The current state of the ATC hardware is deemed unsustainable and a risk to national infrastructure. Acting FAA administrator Chris Rocheleau and Transportation Secretary Sean Duffy emphasized the importance of this upgrade, with the aviation industry also advocating for modernization.\n\nThe upgrade faces challenges. The system cannot be shut down for upgrades due to its critical safety role. The new system must be resistant to hacking and vulnerabilities. While the FAA is investing in maintaining the old systems, age will eventually render them unusable. The FAA has issued a Request For Information and plans \"Industry Days\" to gather input from companies. The Transportation Department aims to complete the project in four years, though experts consider this timeline optimistic.\n",
    "chinese_title": "美国联邦航空局将淘汰空中交通管制系统中使用的软盘。",
    "chinese_summary": "美国联邦航空管理局计划对美国空中交通管制 (ATC) 系统进行重大改革，旨在用现代安全的系统取代软盘和 Windows 95 等过时技术。目前 ATC 硬件的状态被认为是不可持续的，并且对国家基础设施构成风险。代理联邦航空局局长克里斯·罗舍洛和交通部长肖恩·达菲强调了此次升级的重要性，航空业也在倡导现代化。\n\n升级面临挑战。由于其关键的安全作用，该系统不能为了升级而关闭。新系统必须能够抵抗黑客攻击和漏洞。虽然联邦航空局正在投资维护旧系统，但老化最终会使其无法使用。联邦航空局已发布信息征询书，并计划举办“行业日”活动，以收集公司的意见。交通部计划在四年内完成该项目，但专家认为这一时间表过于乐观。"
  },
  {
    "id": "44211779",
    "title": "Discovering a JDK Race Condition, and Debugging It in 30 Minutes with Fray",
    "url": "https://aoli.al/blogs/jdk-bug/",
    "summary": "This article details the discovery and debugging of a race condition in the JDK's `ScheduledThreadPoolExecutor` using the Fray concurrency testing tool. The author uncovered a deadlock scenario where a task scheduled before shutdown can become indefinitely blocked, even though the executor is in a terminated state.\n\nThe bug occurs due to a specific interleaving of the `schedule` and `shutdown` methods. The `schedule` method prematurely returns without assigning a worker to the task when the executor is transitioning to the `SHUTDOWN` state, assuming the shutdown process will terminate the task. However, the `shutdown` method can complete before the task is executed, leaving the task in a limbo state.\n\nThe key benefit of using Fray was its ability to deterministically replay the problematic execution, allowing the author to precisely identify the thread interleaving causing the deadlock. Traditional debugging methods failed due to the Heisenbug phenomenon.\n\nThe article includes code snippets of the relevant `ScheduledThreadPoolExecutor` methods and details how to reproduce and replay the bug using Fray's IntelliJ IDEA plugin. The author reported the bug to the JDK team, who ultimately used Fray to reproduce and understand the issue. The article highlights the power of deterministic replay tools like Fray in tackling complex concurrency bugs.\n",
    "chinese_title": "发现JDK竞态条件，并用Fray在30分钟内调试它",
    "chinese_summary": "本文详述了使用Fray并发测试工具在JDK的`ScheduledThreadPoolExecutor`中发现并调试竞争条件的过程。作者发现了一种死锁场景，其中在关闭之前调度的任务可能会无限期阻塞，即使执行器处于终止状态。\n\n该错误是由于`schedule`和`shutdown`方法的一种特定交错引起的。当执行器转换到`SHUTDOWN`状态时，`schedule`方法过早返回，没有为任务分配worker，并假定关闭过程会终止该任务。但是，`shutdown`方法可能在任务执行之前完成，导致任务处于悬而未决的状态。\n\n使用Fray的关键好处是它能够确定性地重现问题执行，从而使作者能够精确地识别导致死锁的线程交错。由于Heisenbug现象，传统的调试方法失败了。\n\n本文包括相关`ScheduledThreadPoolExecutor`方法的代码片段，并详细介绍了如何使用Fray的IntelliJ IDEA插件重现和重播该错误。作者已将该错误报告给JDK团队，该团队最终使用Fray来重现并理解该问题。本文强调了诸如Fray之类的确定性重播工具在解决复杂并发错误方面的强大功能。"
  },
  {
    "id": "44210895",
    "title": "OneText (YC W23) Is Hiring a DevOps/DBA Lead Engineer",
    "url": "https://jobs.ashbyhq.com/one-text/b95952a2-9bc2-4c3a-9da1-3dcc157b4a27",
    "summary": "The article announces that OneText (YC W23), a startup that participated in the Y Combinator Winter 2023 batch, is hiring a DevOps/DBA Lead Engineer. The body of the content contains only the word \"Jobs\" and a statement indicating JavaScript is required to run the application, implying that the job posting itself, with details about the responsibilities, qualifications, and benefits, is likely contained within an interactive application. Without JavaScript enabled, the full job description is inaccessible.\n",
    "chinese_title": "OneText (YC W23) 招聘 DevOps/DBA 首席工程师",
    "chinese_summary": "文章宣布，参加了 Y Combinator 2023 冬季项目的初创公司 OneText (YC W23) 正在招聘一名 DevOps/DBA 首席工程师。内容主体仅包含“Jobs”一词以及JavaScript为运行应用程序所必需的声明，暗示有关职责、资格和福利的完整职位描述可能包含在一个交互式应用程序中。禁用 JavaScript 后，将无法访问完整的职位描述。"
  },
  {
    "id": "44219857",
    "title": "Self-hosted x86 back end is now default in debug mode",
    "url": "https://ziglang.org/devlog/2025/#2025-06-08",
    "summary": "This Zig devlog highlights several significant improvements and new features in the Zig programming language ecosystem. A major update is the self-hosted x86 backend becoming the default in debug mode for x86_64 targets (excluding Windows for now). This change offers significant performance improvements in compilation speed compared to using LLVM. For example, compiling \"hello.zig\" is ~70% faster.\n\nThe post also details updates to the debug allocator, which now supports runtime-known page sizes, enabling Zig to work on Asahi Linux. The new allocator implementation is faster, more memory-efficient, and avoids the need for compile-time known page sizes. A new fast allocator designed for multi-threaded applications in ReleaseFast mode is also introduced, designed to minimize contention.\n\nOther notable updates include improved UBSan error messages for C interop, providing more informative diagnostics for undefined behavior, and the addition of cross-compilation support for FreeBSD 14.0.0+ and NetBSD 10.1+ using `zig cc` or `zig build`.\n\nLoris Cro released a YouTube video introducing the Zig build system, and the official Zig website was updated to use standalone Zine 0.10.0. The 0.14.0 release is imminent, with a focus on getting release notes completed.\n",
    "chinese_title": "调试模式下，自托管x86后端现为默认设置。",
    "chinese_summary": "这篇 Zig 开发日志重点介绍了 Zig 编程语言生态系统中的几项重大改进和新功能。一个主要的更新是自托管的 x86 后端成为 x86_64 目标（目前不包括 Windows）在调试模式下的默认后端。 相比于使用 LLVM，此更改显著提高了编译速度。例如，编译 \"hello.zig\" 的速度提高了约 70%。\n\n该文章还详细介绍了调试分配器的更新，现在支持运行时已知的页面大小，使 Zig 能够在 Asahi Linux 上运行。新的分配器实现速度更快、内存效率更高，并且避免了对编译时已知页面大小的需求。 此外，还引入了一种新的快速分配器，专为 ReleaseFast 模式下的多线程应用程序而设计，旨在最大限度地减少争用。\n\n其他值得注意的更新包括改进了 C 互操作的 UBSan 错误消息，为未定义行为提供更翔实的诊断信息，以及使用 `zig cc` 或 `zig build` 添加了对 FreeBSD 14.0.0+ 和 NetBSD 10.1+ 的交叉编译支持。\n\nLoris Cro 发布了一个 YouTube 视频，介绍了 Zig 构建系统，并且官方 Zig 网站已更新为使用独立的 Zine 0.10.0。 0.14.0 版本即将发布，重点是完成发行说明。"
  },
  {
    "id": "44222556",
    "title": "Lisp Machines: A Cult AI Computer's Boom and Bust [video]",
    "url": "https://www.youtube.com/watch?v=sV7C6Ezl35A",
    "summary": "This appears to be a title and a list of generic YouTube footer links. The title refers to a YouTube video about Lisp Machines, specifically their rise and fall in the field of Artificial Intelligence. However, the \"content\" provided is just standard YouTube legal disclaimers and information.\n\nTherefore, a summary is impossible *without* actually watching the YouTube video itself. Based on the title alone, we can *infer* the video likely discusses:\n\n*   **Lisp Machines:** Specialized computers designed to run the Lisp programming language efficiently, popular in early AI research.\n*   **Boom:** The period when Lisp Machines were considered the cutting edge of AI hardware, perhaps the 1970s and 80s, likely driven by optimism about AI capabilities.\n*   **Bust:** The decline and eventual obsolescence of Lisp Machines, likely due to factors like the rise of cheaper, general-purpose computing hardware, the AI winter, and a shift in AI research focus.\n\nTo get a *real* summary, the actual video needs to be watched.\n",
    "chinese_title": "Lisp机器：一种邪典AI计算机的兴衰[视频]",
    "chinese_summary": "这似乎是一个标题和一些通用的YouTube页脚链接列表。标题指的是一个关于Lisp机器的YouTube视频，特别是它们在人工智能领域的兴衰。然而，所提供的“内容”只是标准的YouTube法律声明和信息。\n\n因此，*不*观看YouTube视频本身，是不可能进行总结的。仅根据标题，我们可以*推断*该视频可能讨论：\n\n*   **Lisp机器：** 专门设计的用于高效运行Lisp编程语言的计算机，在早期的人工智能研究中很受欢迎。\n*   **兴起：** Lisp机器被认为是人工智能硬件前沿的时期，可能是20世纪70年代和80年代，很可能受到对人工智能能力乐观情绪的推动。\n*   **衰落：** Lisp机器的衰落和最终过时，可能是由于诸如更便宜的通用计算硬件的兴起、人工智能寒冬以及人工智能研究重点的转变等因素。\n\n要获得*真正*的总结，需要观看实际的视频。"
  },
  {
    "id": "44215352",
    "title": "The last six months in LLMs, illustrated by pelicans on bicycles",
    "url": "https://simonwillison.net/2025/Jun/6/six-months-in-llms/",
    "summary": "This article presents a lighthearted yet insightful overview of the rapid advancements in Large Language Models (LLMs) over the previous six months (as of June 2025). The author uses the whimsical benchmark of having LLMs generate an SVG image of a pelican riding a bicycle to illustrate the capabilities and limitations of various models.\n\nThe talk covers significant model releases from December 2024 to May 2025, including Amazon's Nova models, Meta's Llama 3.3 70B (which the author could run on their laptop), and DeepSeek's open-weight models. It highlights the fluctuating performance of models like OpenAI's GPT 4.5 (a \"lemon\") versus the impressive cost-effectiveness of GPT 4.1 Nano. The author also discusses the success of OpenAI’s ChatGPT's native multimodal image generation feature (unofficially named “ChatGPT Mischief Buddy”), and the author's concerns over loss of control due to AI memory features. The author covers Anthropic's Claude 4, and Google's Gemini models. The author discusses evaluation of 30 models, via a tool built by Claude, using Elo rankings for the pelican drawings.\n\nThe article concludes by touching on interesting bugs and ethical considerations, such as ChatGPT's sycophancy bug, and the potential for LLMs to \"snitch\" on unethical behavior, evidenced by the SnitchBench benchmark.\n",
    "chinese_title": "大语言模型近半年：鹈鹕骑车图解",
    "chinese_summary": "本文以轻松幽默又不失洞察力的方式概述了大型语言模型（LLMs）在过去六个月（截至2025年6月）的快速发展。作者采用让 LLM 生成鹈鹕骑自行车的 SVG 图像这一异想天开的基准来阐释各种模型的能力和局限性。\n\n本次讨论涵盖了 2024 年 12 月至 2025 年 5 月期间的重要模型发布，包括亚马逊的 Nova 模型、Meta 的 Llama 3.3 70B（作者可以在其笔记本电脑上运行），以及 DeepSeek 的开源模型。文章突出了诸如 OpenAI 的 GPT 4.5（“次品”）等模型的性能波动，以及 GPT 4.1 Nano 令人印象深刻的性价比。作者还讨论了 OpenAI 的 ChatGPT 原生多模态图像生成功能（非正式名称为“ChatGPT 恶作剧伙伴”）的成功，以及作者对由于 AI 记忆功能而导致失去控制的担忧。作者涵盖了 Anthropic 的 Claude 4 和 Google 的 Gemini 模型。作者讨论了使用 Claude 构建的工具，通过 Elo 排名对 30 个模型的鹈鹕绘画进行评估。\n\n文章最后涉及有趣的漏洞和伦理考量，例如 ChatGPT 的谄媚漏洞，以及 LLM “告密”不道德行为的潜力，这已通过 SnitchBench 基准得到证实。"
  },
  {
    "id": "44224830",
    "title": "Falsehoods programmers believe about video stuff (2016)",
    "url": "https://haasn.dev/posts/2016-12-25-falsehoods-programmers-believe-about-%5Bvideo-stuff%5D.html",
    "summary": "This article, \"Falsehoods Programmers Believe About Video Stuff,\" highlights numerous misconceptions held by programmers regarding video decoding, playback, files, image scaling, color spaces, color conversion, video output, displays, and subtitles. The core message is that video handling is far more complex than often assumed, and naive assumptions can lead to poor user experiences.\n\nThe article details how bit-exact decoding doesn't guarantee consistent quality due to hardware API post-processing. It debunks assumptions about timing, seeking, and frame properties, emphasizing the variability in frame rates, timestamps, and seeking capabilities. It exposes misunderstandings related to color representation, including the nuances of RGB, YCbCr, and color space conversion, as well as the pitfalls of assuming standard color spaces and gamma curves.\n\nFurthermore, the document emphasizes that image scaling requires careful consideration beyond basic algorithms and that naive assumptions about display characteristics (refresh rates, color spaces, pixel properties) can result in inaccurate rendering. Finally, the list challenges simplistic views on subtitles, urging developers to handle encoding, color management, and rendering resolution with care. The author implicitly advocates for deeper understanding and rigorous testing to avoid these common pitfalls and deliver a high-quality video experience.\n",
    "chinese_title": "程序员对视频的错误认知 (2016)",
    "chinese_summary": "程序员对视频的误解"
  },
  {
    "id": "44211612",
    "title": "BorgBackup 2 has no server-side append-only anymore",
    "url": "https://github.com/borgbackup/borg/pull/8798",
    "summary": "This GitHub issue discusses the removal of server-side append-only support in BorgBackup 2. The original Borg 1.x offered this feature only for SSH repositories due to the presence of a server-side component enforcing it. However, Borg 2 supports various repository types like fs, sftp, rclone (for cloud providers), s3/b3, and SSH (using similar RPC as Borg 1.x). Only the SSH method has a borg server process that *could* potentially enforce features, but it's not implemented.\n\nThe key takeaway is that append-only functionality in Borg 2 will no longer be handled within Borg itself. Instead, the proposed solution involves leveraging storage-level permissions. Specifically, the idea is to use credentials with \"no-delete\" permissions for `borg create` operations, preventing object deletion and overwriting, effectively creating an append-only setup. `borg compact`, which requires deletion, would use credentials with delete permissions.\n\nA commenter raised concerns about the potential for data corruption or encryption with file edit permissions. Thomas Waldmann clarified that the \"no-delete\" permission also prohibits overwriting. The change has been merged into the master branch, allowing users to test the new approach.\n",
    "chinese_title": "BorgBackup 2 已经不再支持服务器端只追加模式。",
    "chinese_summary": "此 GitHub issue 讨论了在 BorgBackup 2 中移除服务端只追加支持。最初的 Borg 1.x 仅为 SSH 仓库提供此功能，因为存在一个服务端组件来强制执行它。 然而，Borg 2 支持各种仓库类型，如 fs、sftp、rclone（针对云提供商）、s3/b3 和 SSH（使用与 Borg 1.x 类似的 RPC）。 只有 SSH 方法有一个 borg 服务器进程 *可能* 执行这些功能，但它尚未实现。\n\n关键在于，Borg 2 中的只追加功能将不再由 Borg 本身处理。 相反，提议的解决方案涉及利用存储级别的权限。 具体来说，这个想法是为 `borg create` 操作使用具有“no-delete”权限的凭据，防止对象删除和覆盖，从而有效地创建只追加设置。 需要删除操作的 `borg compact` 将使用具有删除权限的凭据。\n\n一位评论员提出了关于使用文件编辑权限进行数据损坏或加密的潜在担忧。 Thomas Waldmann 澄清说，“no-delete”权限也禁止覆盖。 该更改已合并到主分支中，允许用户测试这种新方法。"
  },
  {
    "id": "44214522",
    "title": "<Blink> and <Marquee> (2020)",
    "url": "https://danq.me/2020/11/11/blink-and-marquee/",
    "summary": "This article humorously explores the history and legacy of the `<blink>` and `<marquee>` HTML tags, relics from the 1990s web. The author recounts discovering that younger developers are unfamiliar with these elements.\n\nThe `<blink>` tag, allegedly conceived as a joke by a Netscape engineer as a universally compatible \"fancy\" effect for text-only browsers like Lynx, was introduced in Netscape Navigator 2.0. It was quickly recognized as a design faux pas, used to draw unnecessary attention to elements on personal web pages.\n\nMicrosoft's response to `<blink>` was the `<marquee>` tag in Internet Explorer 2.0, offering control over text scrolling direction and speed. It enabled even more distracting and inaccessible design.\n\nA common practice emerged of nesting `<blink>` within `<marquee>`, aiming to cater to both Netscape's flashing and Internet Explorer's scrolling effects. This practice adhered to Postel's Law, ensuring content remained accessible even for browsers that didn't support these tags.\n\nThe author, an Opera user at the time, largely avoided these elements. He recounts the jarring experience of Netscape 7, which supported both tags, leading to truly awful visual effects.\n\nWhile `<blink>` is now largely extinct, `<marquee>` surprisingly persists in some browsers and polyfills. The author strongly advises against using it, urging readers to indulge in digital nostalgia elsewhere. The article serves as a lighthearted reminder of the web's evolution and the importance of considerate design.\n",
    "chinese_title": "<Blink>和<Marquee> (2020)",
    "chinese_summary": "本文幽默地探讨了 `<blink>` 和 `<marquee>` HTML 标签的历史和遗留问题，这些标签是 20 世纪 90 年代网络的遗物。作者讲述了自己发现年轻的开发者不熟悉这些元素的故事。\n\n据称，`<blink>` 标签是 Netscape 的一位工程师为了给 Lynx 等纯文本浏览器提供通用的“花哨”效果而开的一个玩笑，在 Netscape Navigator 2.0 中被引入。它很快就被认为是设计上的败笔，常被用于不必要地吸引个人网页上元素的注意力。\n\n微软对 `<blink>` 的回应是 Internet Explorer 2.0 中的 `<marquee>` 标签，该标签可以控制文本滚动方向和速度。它使得设计更加分散注意力和难以访问。\n\n一种常见的做法是将 `<blink>` 嵌套在 `<marquee>` 中，旨在同时满足 Netscape 的闪烁效果和 Internet Explorer 的滚动效果。这种做法遵循了 Postel 定律，确保内容对于不支持这些标签的浏览器仍然可以访问。\n\n作者当时是 Opera 用户，在很大程度上避免了使用这些元素。他回忆起 Netscape 7 的令人不快的体验，该版本支持这两个标签，导致了非常糟糕的视觉效果。\n\n虽然 `<blink>` 现在已基本绝迹，但令人惊讶的是，`<marquee>` 在某些浏览器和 polyfill 中仍然存在。作者强烈建议不要使用它，并敦促读者在其他地方沉迷于数字怀旧。本文是对网络发展和周到设计重要性的一次轻松提醒。"
  },
  {
    "id": "44225156",
    "title": "Feline Genetics and Why Orange Cats Are the Most Special",
    "url": "https://hackaday.com/2025/06/09/feline-genetics-and-why-orange-cats-are-the-most-special/",
    "summary": "This article explores the genetics behind orange fur in cats, debunking the myth of them being \"freaks of nature\" and explaining the scientific basis for their unique coloration. Two studies identified the 'O gene,' a mutation near the ARHGAP36 gene on the X chromosome, as the reason for the suppression of eumelanin (dark pigment) and promotion of pheomelanin (orange pigment). A deletion in a section preceding ARHGAP36 leads to its increased expression, which interrupts the eumelanin production pathway.\n\nThe article highlights that most color variation in cats, beyond recessive defects caused by inbreeding, comes down to melanin. While wildcats are rarely orange, the orange mutation has persisted in domestic cats for millennia, likely due to human preference.\n\nThe orange mutation's X-linked nature explains why most orange cats are male (having only one X chromosome). Female cats can display tortoiseshell or calico patterns (orange, black/brown, and sometimes white) due to X-inactivation, where one X chromosome is randomly deactivated in each cell. It's rare for male cats to have these patterns, typically indicating a genetic condition like Klinefelter syndrome or chimerism.\n\nThe article concludes by emphasizing that orange, tortoiseshell, and calico cats are the result of a unique genetic event in cat domestication, making them a special part of feline history.\n",
    "chinese_title": "猫的基因学：为何橘猫最特别",
    "chinese_summary": "本文探讨了猫科动物橙色毛发的遗传学原理，揭穿了它们是“自然界的怪胎”的说法，并解释了其独特颜色的科学基础。两项研究表明，X染色体上ARHGAP36基因附近的“O基因”突变是抑制真黑色素（深色色素）并促进褐黑素（橙色色素）的原因。ARHGAP36基因前一段的缺失导致其表达增加，从而中断了真黑色素的生成途径。\n\n文章强调，猫的大部分颜色变化，除了近亲繁殖引起的隐性缺陷外，都归结为黑色素。虽然野猫很少有橙色，但橙色突变在几千年来一直存在于家猫中，这很可能是由于人类的偏好。\n\n橙色突变的X连锁性质解释了为什么大多数橙色猫是雄性（只有一个X染色体）。雌性猫由于X染色体失活，即每个细胞中一条X染色体随机失活，因此可以表现出玳瑁色或三花色图案（橙色、黑色/棕色，有时还有白色）。雄性猫出现这些图案的情况很少见，通常表明存在克莱恩费尔特综合征或嵌合体等遗传疾病。\n\n文章最后强调，橙色、玳瑁色和三花色猫是猫驯化过程中独特的遗传事件的结果，使它们成为猫科动物历史中特殊的一部分。"
  },
  {
    "id": "44212650",
    "title": "Why Understanding Software Cycle Time Is Messy, Not Magic",
    "url": "https://arxiv.org/abs/2503.05040",
    "summary": "This arXiv preprint titled \"No Silver Bullets: Why Understanding Software Cycle Time is Messy, Not Magic\" by Flournoy et al. explores the complexities of using cycle time as a metric for software development velocity. Analyzing a large dataset of over 55,000 observations across 216 organizations, the authors use Bayesian hierarchical modeling to investigate how factors like coding time, task scoping, and collaboration affect cycle time.\n\nThe study finds statistically significant, albeit modest, associations between cycle time and factors like coding days per week, number of merged pull requests, and degree of collaboration. However, the analysis reveals substantial unexplained variation in cycle time, both between and within individuals. This highlights the limitation of relying solely on single observations of cycle time to assess performance.\n\nThe authors conclude that while common workplace factors do influence cycle time as expected, its inherent variability makes it a noisy signal. Consequently, they advise against using cycle time as the sole basis for individual-focused interventions to improve software delivery velocity. Instead, they advocate for a more holistic, systems-level approach to improving software delivery, recognizing that complex interactions are at play. The paper also showcases methods for analyzing complex operational metrics at scale and warns against potential pitfalls in their use for decision-making.\n",
    "chinese_title": "理解软件周期时间为何是复杂的，而非神奇的",
    "chinese_summary": "Flournoy等人发表的arXiv预印本文章“没有银弹：为何理解软件周期时间是复杂的，而非神奇的”探讨了使用周期时间作为软件开发速度指标的复杂性。作者分析了来自216个组织的超过55,000个观测值的大型数据集，并使用贝叶斯分层模型来研究编码时间、任务范围和协作等因素如何影响周期时间。\n\n该研究发现，周期时间与每周编码天数、合并的拉取请求数量以及协作程度等因素之间存在统计显著但适度的关联。然而，分析显示周期时间存在大量无法解释的变异，无论是在个体之间还是个体内部。这突出了仅依赖周期时间的单一观察值来评估绩效的局限性。\n\n作者得出结论，虽然常见的职场因素确实如预期般影响周期时间，但其内在的变异性使其成为一个嘈杂的信号。因此，他们建议不要将周期时间作为改善软件交付速度的以个人为中心的干预措施的唯一依据。相反，他们提倡一种更全面的、系统层面的方法来改进软件交付，认识到其中存在复杂的交互作用。该论文还展示了大规模分析复杂运营指标的方法，并警告了在决策中使用这些指标的潜在陷阱。"
  },
  {
    "id": "44215667",
    "title": "A look at Cloudflare's AI-coded OAuth library",
    "url": "https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/",
    "summary": "Neil Madden, an OAuth and security expert, reviewed Cloudflare's new OAuth library, which was primarily coded using Anthropic's Claude LLM. While initially impressed with the code's structure and organization, he found several issues that raised concerns about its security and adherence to OAuth standards.\n\nMadden identified inadequate testing, particularly the lack of testing for MUST and MUST NOT requirements in the OAuth specifications, and missing parameter validation. He also highlighted \"YOLO CORS\" settings that effectively disable same-origin policy and the absence of standard security headers. A significant issue was the implementation of the deprecated \"implicit\" grant for public clients and the incorrect implementation of Basic Auth support. Furthermore, he found a bug in token ID generation that resulted in biased output.\n\nWhile praising the design of the encryption implementation for the token store, he emphasized the importance of expert knowledge when working with LLMs, citing an example where Claude produced a flawed security design that would have been easily exploitable.\n\nMadden concluded that while the library isn't a bad first attempt, it's not ready for use due to potential security vulnerabilities and a lack of thorough testing. He argued that building a secure OAuth provider is complex and requires significant expertise, making it an inappropriate domain for relying solely on LLMs. He emphasized the need for experienced developers to carefully review and understand LLM-generated code, as LLMs often produce outputs based on potentially flawed information found online. Ultimately, he expressed a preference for writing critical security components himself to ensure careful consideration and prevent vulnerabilities.\n",
    "chinese_title": "Cloudflare AI 编写的 OAuth 库一览",
    "chinese_summary": "OAuth和安全专家尼尔·马登评估了Cloudflare使用Anthropic的Claude LLM主要编写的新OAuth库。虽然最初他对代码的结构和组织印象深刻，但他发现了一些问题，这些问题引发了对其安全性和OAuth标准合规性的担忧。\n\n马登发现测试不足，尤其是在OAuth规范中缺乏对MUST和MUST NOT要求的测试，以及缺少参数验证。他还强调了实际上禁用了同源策略的“YOLO CORS”设置以及缺少标准安全标头。一个重要的问题是为公共客户端实现了已弃用的“隐式”授权，以及对Basic Auth支持的错误实现。此外，他发现令牌ID生成中存在一个导致偏差输出的错误。\n\n虽然他赞扬了令牌存储的加密实现的设计，但他强调了在使用LLM时专业知识的重要性，并举例说明Claude产生了一个有缺陷的安全设计，该设计很容易被利用。\n\n马登总结说，虽然该库不是一个糟糕的第一次尝试，但由于潜在的安全漏洞和缺乏彻底的测试，它还不能使用。他认为，构建安全的OAuth提供程序非常复杂，需要大量的专业知识，这使得它不适合仅仅依赖LLM。他强调，经验丰富的开发人员需要仔细审查和理解LLM生成的代码，因为LLM经常根据在线发现的可能存在缺陷的信息生成输出。最终，他表示更喜欢自己编写关键的安全组件，以确保仔细考虑并防止漏洞。"
  },
  {
    "id": "44189329",
    "title": "Show HN: Air Lab – A portable and open air quality measuring device",
    "url": "https://networkedartifacts.com/airlab/simulator",
    "summary": "This \"Show HN\" post introduces Air Lab, a portable and open-source device designed for measuring air quality. The title emphasizes its key features: portability and open-source design, suggesting that users can easily transport and modify the device according to their needs. The content, simply stating \"Air Lab Simulator,\" hints at the device's functionality, implying that it simulates air quality conditions or collects data to represent them. While the description is sparse, the core message is that Air Lab is a new tool for air quality monitoring, accessible and adaptable due to its open-source nature and portable design. Further information would be needed to understand the specific sensors used, data output, and target audience.\n",
    "chinese_title": "Show HN: 空气实验室 – 一款便携式开源空气质量测量设备",
    "chinese_summary": "这款“Show HN”帖子介绍了Air Lab，一款用于测量空气质量的便携式开源设备。标题强调了其关键特性：便携性和开源设计，暗示用户可以根据需要轻松运输和修改该设备。内容简洁地声明“Air Lab模拟器”，暗示了该设备的功能，即模拟空气质量条件或收集数据来表示它们。虽然描述简洁，但核心信息是Air Lab是一种新的空气质量监测工具，由于其开源性质和便携式设计，它易于访问和调整。需要更多信息来了解所使用的具体传感器、数据输出和目标受众。"
  },
  {
    "id": "44212845",
    "title": "Coventry Very Light Rail",
    "url": "https://www.coventry.gov.uk/coventry-light-rail",
    "summary": "This is a summary of information about the Coventry Very Light Rail (VLR) project.\n\nThe project encompasses:\n\n*   **Vehicle and Track:** The project includes the development and testing of both the VLR vehicle and its track system.\n*   **On-Road Testing:** There are plans for on-road testing of the VLR.\n*   **Booking Information:** Information is available about bookings related to the VLR project, and a privacy notice outlines how booking data will be handled.\n*   **Newsletter:** There is an option to sign up for a VLR newsletter to receive updates.\n*   **Contact Information:** Contact details for the Coventry VLR project are provided, including a postal address (Coventry City Council, PO Box 7097, Coventry, CV6 9SL) and an email address (CoventryVLR@coventry.gov.uk).",
    "chinese_title": "考文垂超轻轨",
    "chinese_summary": "考文垂超轻轨 (VLR) 项目信息摘要。\n\n该项目包括：\n\n*   **车辆和轨道：** 项目包括VLR车辆及其轨道系统的开发和测试。\n*   **道路测试：** 计划进行VLR的道路测试。\n*   **预订信息：** 提供与VLR项目相关的预订信息，以及概述如何处理预订数据的隐私声明。\n*   **新闻通讯：** 可以订阅VLR新闻通讯以接收最新信息。\n*   **联系方式：** 提供考文垂VLR项目的联系方式，包括邮政地址（Coventry City Council, PO Box 7097, Coventry, CV6 9SL）和电子邮件地址（CoventryVLR@coventry.gov.uk）。"
  },
  {
    "id": "44211417",
    "title": "Field Notes from Shipping Real Code with Claude",
    "url": "https://diwank.space/field-notes-from-shipping-real-code-with-claude",
    "summary": "This article, \"Field Notes from Shipping Real Code with Claude,\" explores how to effectively use AI assistants like Claude in software development to achieve significant productivity gains. It moves beyond the meme of \"vibe-coding\" to present a practical framework for AI-assisted development.\n\nThe author introduces three distinct \"modes\" of vibe-coding: **Playground**, for rapid prototyping and experimentation; **Pair Programming**, for structured development with a strong human-AI collaboration using a `CLAUDE.md` file; and **Production/Monorepo Scale**, which requires rigorous engineering practices and well-defined boundaries.\n\nThe `CLAUDE.md` file is crucial, serving as a central document outlining project conventions, architecture decisions, code style, and critical \"do not do\" rules for the AI.  Anchor comments, denoted with prefixes like `AIDEV-NOTE`, `AIDEV-TODO`, and `AIDEV-QUESTION`, are inline guidance for the AI, providing context and preventing errors. These comments also serve as a form of inline documentation.\n\nThe article emphasizes the importance of good engineering principles, even with AI assistance.  Tests remain sacred, and AI should never modify them or API contracts. The key takeaway is that AI amplifies existing capabilities, but rigorous practices are essential to prevent chaos.  Larger projects should adopt vibe coding incrementally, focusing on individual services or sub-modules and continuously refining the processes to better guide the AI and keep it from making mistakes.\n",
    "chinese_title": "用 Claude 发布真实代码的实地笔记",
    "chinese_summary": "本文《使用Claude交付真实代码的实地笔记》探讨了如何在软件开发中有效利用像Claude这样的人工智能助手，以实现显著的生产力提升。它超越了“随心编码”的梗，提出了一个AI辅助开发的实用框架。\n\n作者介绍了三种不同的“随心编码”模式：**试验场**，用于快速原型设计和实验；**结对编程**，用于结构化开发，通过`CLAUDE.md`文件实现强大的人机协作；以及**生产/单体仓库规模**，这需要严格的工程实践和明确的边界。\n\n`CLAUDE.md`文件至关重要，它作为一份中心文档，概述了项目约定、架构决策、代码风格以及AI的关键“禁止事项”规则。锚定注释，以`AIDEV-NOTE`、`AIDEV-TODO`和`AIDEV-QUESTION`等前缀表示，是为AI提供的内联指导，提供上下文并防止错误。这些注释也作为一种内联文档的形式。\n\n文章强调了即使在人工智能辅助下，良好的工程原则的重要性。测试仍然是神圣的，AI永远不应该修改它们或API契约。关键在于，AI可以放大现有的能力，但严格的实践对于防止混乱至关重要。更大的项目应该逐步采用随心编码，重点关注单个服务或子模块，并不断改进流程，以更好地指导AI并防止其犯错。"
  },
  {
    "id": "44210938",
    "title": "Dolphin Emulator Progress Report: Release 2506",
    "url": "https://dolphin-emu.org/blog/2025/06/04/dolphin-progress-report-release-2506/",
    "summary": "This Dolphin Emulator Progress Report (Release 2506) highlights significant improvements, including audio and frame pacing enhancements, alongside some housekeeping.\n\nA major advancement is the Granule Synthesis Audio System, which addresses audio lag issues during slowdowns without the high latency drawbacks of audio stretching. It \"fills in the gaps\" in the audio stream created by the slowdown, minimizing the effects of audio hitches.\n\nFrame pacing has been significantly improved to provide a smoother gaming experience. These changes involved refined throttling techniques, accounting for variations in analog video timing parameters, and implementing a high-resolution timer on Windows. These improvements result in more consistent frame delivery.\n\nAdditionally, Dolphin now respects game-requested anisotropic filtering when texture filtering is set to \"Default,\" offering a more accurate emulation of the original console's graphical output.\n\nThe report also covers: a hotfix (2503a) for issues with a previous release; bumping the minimum required versions of Windows to 1903 and macOS to Big Sur due to new API requirements.\n\nIt also mentions the addition of Wii Speak emulation and compatibility with \"The Daring Game for Girls.\" High frame rate gaming is introduced but has extremely low compatibility.\n",
    "chinese_title": "海豚模拟器进度报告：发布2506",
    "chinese_summary": "海豚模拟器进度报告（发布版2506）：音频与帧步进显著改进，并进行维护工作\n\n一项重大进展是颗粒合成音频系统，它解决了减速期间的音频延迟问题，且没有音频拉伸带来的高延迟缺点。它“填补”了由减速造成的音频流中的“空白”，从而最大限度地减少了音频故障的影响。\n\n帧步进已得到显著改善，以提供更流畅的游戏体验。这些更改涉及改进的节流技术，考虑了模拟视频定时参数的变化，并在Windows上实现了高分辨率计时器。这些改进带来了更一致的帧交付。\n\n此外，当纹理过滤设置为“默认”时，Dolphin现在尊重游戏请求的各向异性过滤，从而提供更准确的原始控制台图形输出的模拟。\n\n本报告还涵盖：针对先前版本问题的热修复补丁(2503a)；由于新的API要求，将Windows的最低要求版本提升至1903，macOS提升至Big Sur。\n\n报告还提到增加了Wii Speak模拟和对“The Daring Game for Girls”的兼容性。引入了高帧率游戏，但兼容性极低。"
  },
  {
    "id": "44225834",
    "title": "-=:[ WarGames Terminal Fonts ]",
    "url": "https://mw.rat.bz/wgterm/",
    "summary": "This document introduces the \"WarGames Terminal Fonts\" created by Michael Walden, a collection of nine font files designed to replicate the terminal fonts seen in the movie \"WarGames.\" The author meticulously transcribed characters from various on-screen terminals (missile silos, David Lightman's computer, Dr. McKittrick's office, and NORAD) to create a complete 95-character ASCII font.\n\nThe font pack includes three main font variations: Normal (N), Double (D), and Raster (R), each available in .FON (Microsoft Windows bitmapped), .OTF (OpenType), and .TTF (TrueType) formats. \"Normal\" presents the raw bitmap, \"Double\" vertically stretches the font, and \"Raster\" simulates raster lines. The creator acknowledges challenges with creating proper .WOFF web font versions but includes hacked versions with demo files for web use, noting a highlighting issue.\n\nThe document also provides information on installing and using the fonts, recommends a color scheme based on David Lightman's monitor, and includes a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license. It features samples of the fonts, a download link, and links to related content, including on-screen terminal images and transcribed text, showcasing the accuracy of the fonts in replicating the movie's visuals. The author encourages sharing the project on social media.\n",
    "chinese_title": "-=:[ 战争游戏终端字体 ]",
    "chinese_summary": "本文介绍了 Michael Walden 创建的“战争游戏终端字体”，这是一套包含九个字体文件的合集，旨在重现电影《战争游戏》中出现的终端字体。作者一丝不苟地从各种屏幕终端（导弹发射井、David Lightman 的电脑、McKittrick 博士的办公室以及 NORAD）上抄录字符，创建了一个完整的 95 个字符的 ASCII 字体。\n\n该字体包包括三种主要的字体变体：Normal (N)、Double (D) 和 Raster (R)，每种变体都提供 .FON（Microsoft Windows 位图）、.OTF（OpenType）和 .TTF（TrueType）格式。“Normal”呈现原始位图，“Double”垂直拉伸字体，“Raster”模拟光栅线。创建者承认在创建合适的 .WOFF 网络字体版本时面临挑战，但包含了带有演示文件的破解版本以供网络使用，并指出了一个高亮显示问题。\n\n本文档还提供了有关安装和使用字体的信息，推荐了一种基于 David Lightman 监视器的配色方案，并包含 Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International 许可协议。它包含字体示例、下载链接以及相关内容的链接，包括屏幕终端图像和转录文本，展示了字体在重现电影视觉效果方面的准确性。作者鼓励在社交媒体上分享该项目。"
  },
  {
    "id": "44210689",
    "title": "Washington Post's Privacy Tip: Stop Using Chrome, Delete Meta Apps (and Yandex)",
    "url": "https://tech.slashdot.org/story/25/06/07/035249/washington-posts-privacy-tip-stop-using-chrome-delete-metas-apps-and-yandex",
    "summary": "A Washington Post tech columnist advises users to take steps to improve their online privacy, focusing on vulnerabilities in popular web browsers and apps. The article highlights research indicating that Meta (Facebook, Instagram) and Yandex apps were allegedly circumventing Android's privacy protections to harvest user data, regardless of privacy settings.\n\nThe main recommendations are:\n\n*   **Stop using the Chrome browser:** Switch to privacy-focused alternatives like Mozilla Firefox, Brave, or DuckDuckGo's browser, which block common tracking methods. Safari on iPhones and Macs also offers strong privacy protections. While no browser is foolproof, these alternatives offer better privacy features.\n*   **Delete Meta and Yandex apps:** These apps provide the companies with increased access to sensitive information like location, battery level, and connected devices, which websites generally cannot easily obtain. The researchers found Meta and Yandex employed tactics that made them untrustworthy.\n*   **Be aware of Meta's broader tracking:** Even without having the apps or using Facebook/Instagram, Meta might still be collecting data about your web activity.\n\nIn essence, the article urges users to actively protect their privacy by choosing privacy-respecting browsers, removing data-hungry apps, and acknowledging that companies like Meta can still track users even without direct app usage.\n",
    "chinese_title": "华盛顿邮报隐私提示：停止使用 Chrome，删除 Meta 应用（和 Yandex）",
    "chinese_summary": "《华盛顿邮报》科技专栏作家建议用户采取措施提高在线隐私保护，重点关注常用网页浏览器和应用程序的漏洞。文章强调，研究表明Meta（Facebook、Instagram）和Yandex的应用程序涉嫌绕过安卓的隐私保护机制来收集用户数据，无论隐私设置如何。\n\n主要建议包括：\n\n*   **停止使用Chrome浏览器：** 切换到注重隐私的替代品，如Mozilla Firefox、Brave或DuckDuckGo的浏览器，它们可以阻止常见的跟踪方法。iPhone和Mac上的Safari也提供强大的隐私保护。虽然没有哪个浏览器是万无一失的，但这些替代品提供了更好的隐私功能。\n*   **删除Meta和Yandex应用程序：** 这些应用程序让这些公司可以更多地访问敏感信息，如位置、电池电量和连接的设备，而网站通常无法轻易获得这些信息。研究人员发现Meta和Yandex使用的策略使其不可信。\n*   **注意Meta更广泛的追踪行为：** 即使没有安装这些应用程序或使用Facebook/Instagram，Meta可能仍然在收集关于您网络活动的数据。\n\n本质上，文章敦促用户通过选择尊重隐私的浏览器、删除渴求数据的应用程序以及认识到即使不直接使用应用程序，像Meta这样的公司仍然可以追踪用户来积极保护自己的隐私。"
  },
  {
    "id": "44209515",
    "title": "Musk-Trump dispute includes threats to SpaceX contracts",
    "url": "https://spacenews.com/musk-trump-dispute-includes-threats-to-spacex-contracts/",
    "summary": "The article details a public feud between Elon Musk and then-President Trump, triggered by Musk's criticism of a budget reconciliation bill. Trump retaliated by threatening to cancel government contracts with SpaceX, prompting Musk to initially threaten to decommission SpaceX's Dragon spacecraft.\n\nTrump's threat to SpaceX contracts stemmed from Musk's criticism of a budget bill. Musk responded by claiming SpaceX would begin decommissioning Dragon, though he later retracted this statement.\n\nThe potential cancellation of government contracts would significantly impact SpaceX, which projects $1.1 billion in revenue from NASA in 2025, with further revenue from defense contracts. However, the government also heavily relies on SpaceX for launch services, including crew and cargo transport to the ISS, and the development of the U.S. Deorbit Vehicle.\n\nAn industry source dismissed the exchanges as \"bluster.\" NASA stated it would continue to execute the President's vision for space.\n\nThe article also mentions Trump's withdrawal of Jared Isaacman as NASA administrator nominee, claiming Musk recommended him and that Isaacman was a Democrat. Trump stated that Gen. Dan Caine would be involved in selecting a new nominee, despite Caine's lack of space background.\n",
    "chinese_title": "马斯克与特朗普争端包括对SpaceX合同的威胁",
    "chinese_summary": "文章详细描述了埃隆·马斯克与时任总统特朗普之间的一场公开争端，起因是马斯克批评一项预算协调法案。特朗普随即威胁要取消与SpaceX的政府合同，促使马斯克最初威胁要退役SpaceX的龙飞船。\n\n特朗普威胁取消SpaceX合同源于马斯克对一项预算法案的批评。马斯克回应称SpaceX将开始退役龙飞船，但他后来撤回了这一声明。\n\n政府合同的潜在取消将严重影响SpaceX，该公司预计2025年从NASA获得11亿美元的收入，以及来自国防合同的进一步收入。然而，政府也严重依赖SpaceX的发射服务，包括往返国际空间站的宇航员和货物运输，以及美国离轨飞行器的开发。\n\n一位业内人士认为这些交流只是“虚张声势”。NASA表示将继续执行总统的太空愿景。\n\n文章还提到特朗普撤回了贾里德·艾萨克曼的NASA局长提名，声称马斯克推荐了他，并且艾萨克曼是民主党人。特朗普表示，丹·凯恩将军将参与新提名人的选拔，尽管凯恩缺乏太空背景。"
  },
  {
    "id": "44223283",
    "title": "Ex-FCC Chair Ajit Pai is now a wireless lobbyist",
    "url": "https://arstechnica.com/tech-policy/2025/06/ex-fcc-chair-ajit-pai-is-now-a-wireless-lobbyist-and-enemy-of-cable-companies/",
    "summary": "The article discusses the ongoing fight over spectrum allocation, triggered by former FCC Chair Ajit Pai's return to the telecom scene as a lobbyist for the wireless industry group CTIA. Pai advocates for auctioning more spectrum for 5G, arguing the US is falling behind China.\n\nThis stance has ignited opposition from an unusual coalition, Spectrum for the Future, comprised of cable companies like Comcast and Charter, consumer advocacy groups like Public Knowledge, and small ISPs. This group alleges Pai is misrepresenting the facts and that there isn't a spectrum shortage, accusing him of \"hypocrisy.\"\n\nThe conflict centers around the Citizens Broadband Radio Service (CBRS) band (3550-3700 MHz), currently shared between the Department of Defense and non-federal users. Wireless companies like AT&T want to reallocate CBRS for licensed, full-power 5G use, a proposal supported by the Department of Defense. Cable companies heavily rely on CBRS for their growing mobile service offerings and fear being crowded out by high-power mobile signals. They oppose any move that would diminish their access.\n\nThe Department of Defense is proposing to change the license terms for CBRS users to benefit its competitors, which cable companies will likely sue the government for.\n\nSmall ISPs that rely on CBRS to provide rural internet also strongly oppose AT&T's plan, and Senator Maria Cantwell has voiced concerns regarding potential disruptions to naval operations if the CBRS band is reallocated. The debate highlights the complex interplay of industry interests, national security, and consumer access in the allocation of valuable spectrum resources.\n",
    "chinese_title": "前FCC主席阿吉特·帕伊现为无线通信说客",
    "chinese_summary": "文章讨论了关于频谱分配的持续争斗，这场争斗由前联邦通信委员会主席阿吉特·帕伊作为无线行业组织CTIA的游说者重返电信行业而引发。帕伊主张拍卖更多频谱用于5G，声称美国正在落后于中国。\n\n这一立场引发了一个不寻常的联盟——未来频谱（Spectrum for the Future）的反对，该联盟由康卡斯特和特许通讯等有线电视公司、公共知识等消费者权益倡导团体以及小型互联网服务提供商组成。该团体声称帕伊歪曲事实，并不存在频谱短缺，指责他“虚伪”。\n\n冲突的中心是公民宽带无线电服务（CBRS）频段（3550-3700 MHz），目前由国防部和非联邦用户共享。像AT&T这样的无线公司希望重新分配CBRS，用于授权的全功率5G，国防部也支持这一提议。有线电视公司严重依赖CBRS来提供其不断增长的移动服务，并担心被高功率移动信号挤出。他们反对任何会减少他们访问权限的举动。\n\n国防部提议更改CBRS用户的许可条款以使其竞争对手受益，有线电视公司很可能会因此起诉政府。\n\n依赖CBRS提供农村互联网服务的小型互联网服务提供商也强烈反对AT&T的计划，参议员玛丽亚·坎特韦尔对CBRS频段重新分配可能对海军行动造成的干扰表示担忧。这场辩论突显了在宝贵频谱资源分配中，行业利益、国家安全和消费者访问之间复杂的相互作用。"
  },
  {
    "id": "44222809",
    "title": "What DOGE and its affiliates are doing with government systems and data [pdf]",
    "url": "https://oversight.house.gov/wp-content/uploads/2025/06/Schneier-Written-Testimony.pdf",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "DOGE及其关联方如何处理政府系统和数据 [pdf]",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "44210736",
    "title": "My experiment living in a tent in Hong Kong's jungle",
    "url": "https://corentin.trebaol.com/Blog/8.+The+Homelessness+Experiment",
    "summary": "Without having access to the actual article content \"My experiment living in a tent in Hong Kong's jungle,\" I can only offer a generalized summary based on the title and the snippet you provided.\n\nThe article likely documents the experience of Corentin Trebaol, who conducted an experiment to live in a tent in the jungle of Hong Kong. This implies an exploration of themes related to homelessness, survival, and potentially, social commentary on housing issues in Hong Kong.\n\nThe experiment likely involved Trebaol setting up a temporary dwelling in a tent within a Hong Kong jungle environment. The article could detail the practical challenges he faced, such as:\n\n*   **Survival:** Finding food and water, dealing with the climate (humidity, heat, rain), and protecting himself from insects and animals.\n*   **Logistics:** Setting up and maintaining the tent, managing waste, and navigating the jungle terrain.\n*   **Social and Emotional Impact:** Experiencing isolation, coping with the stigma associated with homelessness, and reflecting on the privilege of having a stable home.\n\nThe title suggests a focus on personal experience, while the mention of \"Homelessness Experiment\" indicates a possible intention to raise awareness about the struggles faced by homeless individuals in Hong Kong. The article likely blends a personal narrative with broader social commentary, using Trebaol's experiment as a vehicle to explore the complexities of housing insecurity and the challenges of living without shelter in a densely populated and economically disparate city. It could also discuss potential solutions or insights gained from the experience.\n",
    "chinese_title": "我在香港丛林帐篷里生活的实验",
    "chinese_summary": "在无法获取“我在香港丛林中搭帐篷的实验”这篇文章的实际内容的情况下，我只能根据标题和你提供的片段提供一个概括性的总结。\n\n这篇文章可能记录了Corentin Trebaol在香港丛林中搭帐篷居住的实验经历。 这暗示着对与无家可归、生存以及潜在的、对香港住房问题的社会评论等主题的探索。\n\n该实验可能涉及Trebaol在香港丛林环境中搭建一个临时帐篷住所。 这篇文章可能会详细介绍他所面临的实际挑战，例如：\n\n*   **生存:** 寻找食物和水，应对气候（湿度、高温、雨水）以及保护自己免受昆虫和动物的侵害。\n*   **后勤:** 搭建和维护帐篷，处理废物以及在丛林地形中导航。\n*   **社会和情感影响:** 体验孤独，应对与无家可归相关的耻辱，并反思拥有稳定住所的特权。\n\n标题表明重点在于个人体验，而提到“无家可归实验”表明可能旨在提高人们对香港无家可归者所面临的困境的认识。 这篇文章可能将个人叙述与更广泛的社会评论相结合，利用Trebaol的实验作为载体，探索住房无保障的复杂性以及在人口稠密且经济悬殊的城市中无家可归所面临的挑战。 它还可以讨论从经验中获得的潜在解决方案或见解。"
  },
  {
    "id": "44222022",
    "title": "I tried to make something in America (SmarterEveryDay) [video]",
    "url": "https://www.youtube.com/watch?v=3ZTGwcHQfLY",
    "summary": "This appears to be a truncated YouTube page footer rather than an article about the \"I tried to make something in America (SmarterEveryDay)\" video.\n\nTherefore, there's no article to summarize. The provided text is a standard YouTube copyright notice and legal disclaimer, covering aspects like:\n\n*   **General YouTube Information:** Links to \"About,\" \"Press,\" \"Copyright,\" \"Contact Us,\" \"Creators,\" \"Advertise,\" \"Developers,\" \"Terms,\" \"Privacy,\" and \"Safety.\"\n*   **YouTube Functionality:**  Indicates this is about YouTube functionality testing.\n*   **Copyright and Ownership:** States copyright ownership of Google LLC for the year 2025, and may also include the NFL Sunday Ticket, if applicable.\n\nThe important takeaway is that this text is not related to the content of the SmarterEveryDay video; it's just standard YouTube legal information.\n",
    "chinese_title": "我在美国尝试制作东西 (SmarterEveryDay) [视频]",
    "chinese_summary": "这看起来像是截断的YouTube页面页脚，而不是一篇关于“我尝试在美国制造东西 (SmarterEveryDay)”视频的文章。\n\n因此，没有文章可以总结。提供的文本是标准的YouTube版权声明和法律免责声明，涵盖以下方面：\n\n*   **通用YouTube信息：** 链接到“关于”、“媒体”、“版权”、“联系我们”、“创作者”、“广告”、“开发者”、“条款”、“隐私”和“安全”。\n*   **YouTube功能：** 表明这是关于YouTube功能测试。\n*   **版权和所有权：** 说明Google LLC对2025年拥有版权，并且如果适用，可能还包括NFL Sunday Ticket。\n\n重要的是，这段文字与SmarterEveryDay视频的内容无关；它只是标准的YouTube法律信息。"
  },
  {
    "id": "44205282",
    "title": "Researchers develop ‘transparent paper’ as alternative to plastics",
    "url": "https://japannews.yomiuri.co.jp/science-nature/technology/20250605-259501/",
    "summary": "Japanese researchers at JAMSTEC have developed a biodegradable \"transparent paper\" from cellulose, derived from plant biomass, as a potential replacement for plastics. This new material is thicker than conventional cellulose-based alternatives, making it suitable for containers.\n\nThe process involves dissolving cellulose powder from cotton seed fibers in a lithium bromide-water solution, heating it into a gel, and then shaping and drying it. The resulting material is reportedly as strong as polycarbonate plastic. The paper's transparency stems from the dense packing of nanometer-scale fibers, allowing light to pass through without diffusion. A 0.7mm sheet allows clear visibility up to 100 meters.\n\nTesting showed the paper dissolves in seawater via microbial action, with the rate dependent on depth. While dissolution took longer in the deep ocean due to fewer microbes, the paper largely dissolved within four months at 757 meters.\n\nWhile transparent paper addresses consumer reluctance to buy goods in opaque paper packaging, mass production is needed to bring it to market. Researchers estimate production costs will be three times that of ordinary paper, but with half the CO2 emissions compared to plastic production. An expert notes that the key advantage is its proven biodegradability in the deep sea.\n",
    "chinese_title": "研究人员开发出“透明纸”作为塑料替代品",
    "chinese_summary": "日本海洋研究开发机构（JAMSTEC）的研究人员开发出一种由植物生物质纤维素制成的可生物降解的“透明纸”，有望替代塑料。 这种新材料比传统的纤维素基替代品更厚，适用于制作容器。\n\n该工艺包括将棉籽纤维中的纤维素粉末溶解在溴化锂水溶液中，加热成凝胶，然后进行塑形和干燥。 据报道，所得材料强度与聚碳酸酯塑料相当。 纸张的透明度源于纳米级纤维的密集排列，使光线能够通过而不发生扩散。 0.7毫米厚的纸张能见度可达100米。\n\n测试表明，该纸张在海水中通过微生物作用溶解，溶解速率取决于深度。 虽然由于微生物较少，深海中的溶解时间较长，但纸张在757米深处的大部分在四个月内溶解。\n\n虽然透明纸解决了消费者不愿购买不透明纸质包装商品的问题，但要将其推向市场，还需要大规模生产。 研究人员估计生产成本将是普通纸的三倍，但与塑料生产相比，二氧化碳排放量将减少一半。 一位专家指出，其关键优势在于其在深海中已被证实的生物降解性。"
  },
  {
    "id": "44212446",
    "title": "Convert photos to Atkinson dithering",
    "url": "https://gazs.github.io/canvas-atkinson-dither/",
    "summary": "This document describes a simple tool for converting photos into Atkinson-dithered images. The user interface presents two primary functions: image selection and output options.\n\nFirst, the user is prompted to \"Choose Image...\", implying the user needs to upload or select an image to be processed.\n\nSecond, the document provides options for resizing the image. Predefined sizes are available (50x50, 320x240, 512x384, 640x480, 800x600, and 1024x768), along with an \"Other...\" option, suggesting the user can specify a custom resolution.\n\nFinally, the user can \"Save to Desktop\" after the dithering process is complete, implying the generated image will be saved locally.\n\nIn essence, the tool allows users to upload a photo, resize it according to predefined or custom dimensions, apply Atkinson dithering, and then save the resulting image to their desktop. The main purpose is the conversion of photos using the Atkinson dithering algorithm.\n",
    "chinese_title": "将照片转换为阿特金森抖动",
    "chinese_summary": "本文介绍一个简单的工具，用于将照片转换为Atkinson抖动图像。用户界面提供两个主要功能：图像选择和输出选项。\n\n首先，提示用户“选择图像...”，表明用户需要上传或选择要处理的图像。\n\n其次，文档提供图像大小调整选项。提供预定义尺寸（50x50、320x240、512x384、640x480、800x600和1024x768），以及“其他...”选项，表明用户可以指定自定义分辨率。\n\n最后，用户可以在抖动处理完成后“保存到桌面”，表明生成的图像将保存到本地。\n\n本质上，该工具允许用户上传照片，根据预定义或自定义尺寸调整大小，应用Atkinson抖动，然后将生成的图像保存到桌面。其主要目的是使用Atkinson抖动算法转换照片。"
  },
  {
    "id": "44207063",
    "title": "Reverse Engineering Cursor's LLM Client",
    "url": "https://www.tensorzero.com/blog/reverse-engineering-cursors-llm-client/",
    "summary": "This article details how the authors reverse-engineered Cursor's LLM client using their open-source framework, TensorZero, to observe and experiment with the underlying LLM interactions. They aimed to gain observability into Cursor's inner workings, optimize its performance for individual users, and A/B test different LLM models.\n\nThe authors overcame two main roadblocks: Cursor's reliance on its own servers (initially preventing direct connection to TensorZero) and CORS issues. They bypassed these by setting up a reverse proxy using Ngrok and Nginx to forward requests to their self-hosted TensorZero instance. This allowed them to intercept and analyze the prompts being sent to the LLMs by Cursor.\n\nThey discovered that Cursor uses a relatively short (642 tokens) system prompt to guide the LLM and employs a hierarchical model approach, with a \"less intelligent\" model called the \"apply model\" responsible for making code edits based on the output of the primary LLM.\n\nWith TensorZero in place, they're now able to A/B test different models like Claude 4.0 Sonnet, GPT-4.1, o4 Mini, and Gemini 2.5 Pro, with no noticeable latency. The article highlights the potential for optimizing LLM interactions based on individual user patterns and promises a follow-up post discussing how they collect feedback and evaluate the real-world usage of AI coding assistants.\n",
    "chinese_title": "逆向工程 Cursor 的 LLM 客户端",
    "chinese_summary": "本文详细介绍了作者如何使用他们的开源框架 TensorZero 对 Cursor 的 LLM 客户端进行逆向工程，以观察和实验底层的 LLM 交互。他们的目标是深入了解 Cursor 的内部运作，针对单个用户优化其性能，并对不同的 LLM 模型进行 A/B 测试。\n\n作者克服了两个主要障碍：Cursor 对其自身服务器的依赖（最初阻止了与 TensorZero 的直接连接）以及 CORS 问题。他们通过使用 Ngrok 和 Nginx 设置反向代理来绕过这些问题，将请求转发到他们自托管的 TensorZero 实例。这使他们能够拦截和分析 Cursor 发送给 LLM 的提示。\n\n他们发现 Cursor 使用一个相对较短（642 个 tokens）的系统提示来引导 LLM，并采用分层模型方法，其中一个名为“apply model”（应用模型）的“不太智能”的模型负责根据主 LLM 的输出来进行代码编辑。\n\n有了 TensorZero，他们现在能够对不同的模型（如 Claude 4.0 Sonnet、GPT-4.1、o4 Mini 和 Gemini 2.5 Pro）进行 A/B 测试，而没有明显的延迟。本文强调了基于个人用户模式优化 LLM 交互的潜力，并承诺在后续文章中讨论他们如何收集反馈并评估 AI 编码助手在现实世界中的使用情况。"
  },
  {
    "id": "44210606",
    "title": "Bill Atkinson has died",
    "url": "https://daringfireball.net/linked/2025/06/07/bill-atkinson-rip",
    "summary": "John Gruber's Daring Fireball reports on the passing of Bill Atkinson, a pivotal figure in Apple and computer history, at the age of 74 due to pancreatic cancer. The news came via a family statement on Atkinson's Facebook page.\n\nAtkinson is celebrated for his essential contributions to the original Macintosh team, particularly in overcoming hardware limitations with his ingenious code and algorithms. Gruber highlights his innovative dithering algorithm, which inspired the name of his podcast, Dithering.\n\nBeyond low-level programming, Atkinson is renowned as the creator of MacPaint, a groundbreaking bitmap image editor that Gruber argues directly influenced Photoshop, and HyperCard, which had a profound impact on software design.\n\nGruber emphasizes Atkinson's extraordinary talent, calling him possibly the best computer programmer ever. He recommends reading stories about Atkinson on Andy Hertzfeld's Folklore.org. The article underscores Atkinson's significant and lasting contributions to the world of computing. He is survived by his wife, children, siblings, and his dog, Poppy.\n",
    "chinese_title": "比尔·阿特金森去世了",
    "chinese_summary": "John Gruber的Daring Fireball报道了苹果和计算机历史上的关键人物Bill Atkinson因胰腺癌去世，享年74岁。消息来自Atkinson的Facebook页面上发布的一份家庭声明。\n\nAtkinson因其对最初Macintosh团队的重要贡献而备受赞誉，尤其是在克服硬件限制方面，他凭借巧妙的代码和算法做出了突出贡献。Gruber重点介绍了他的创新抖动算法，这激发了他的播客“Dithering”的名称。\n\n除了底层编程之外，Atkinson还以MacPaint的创作者而闻名，MacPaint是一款开创性的位图图像编辑器，Gruber认为它直接影响了Photoshop，以及对软件设计产生深远影响的HyperCard。\n\nGruber强调了Atkinson的非凡才华，称他可能是有史以来最好的计算机程序员。他建议在Andy Hertzfeld的Folklore.org上阅读关于Atkinson的故事。文章强调了Atkinson对计算机世界的重大而持久的贡献。他的妻子、子女、兄弟姐妹和他的狗 Poppy 仍然健在。"
  },
  {
    "id": "44214481",
    "title": "Knowledge Management in the Age of AI",
    "url": "https://ericgardner.info/notes/knowledge-management-june-2025",
    "summary": "The author reflects on their past experience with Emacs, a powerful but demanding text editor and environment for personal computing, particularly highlighting the benefits of Org-Mode for knowledge management.  They transitioned away from Emacs due to the maintenance burden, but missed the organizational capabilities, especially Org-Mode's features.\n\nThe article then introduces Obsidian, a markdown-based note-taking app, as a potential replacement. Obsidian offers a more user-friendly experience with a robust plugin ecosystem and mobile support. The author outlines their plan to use Obsidian with the PARA (Projects, Areas, Resources, Archive) method for organizing notes and knowledge, aiming for a simple, sustainable system.\n\nThe author justifies this effort in the context of the rise of LLM-based AI like ChatGPT. While acknowledging the convenience of AI assistants, they express concern about the potential for over-reliance and the outsourcing of personal thinking. They advocate for maintaining a personal knowledge base as a way to value one's own thoughts, engage in deliberate thinking, and retain ownership of ideas. The author suggests a future where Obsidian could integrate with AI tools, serving as a personal \"MCP server\" where AI assists without supplanting individual thought and knowledge. The ultimate goal is to stay in control and actively participate in one's own learning and understanding.\n",
    "chinese_title": "人工智能时代的知识管理",
    "chinese_summary": "作者回顾了他们过去使用Emacs的经历，Emacs是一款强大但要求苛刻的文本编辑器和个人计算环境，尤其强调了Org-Mode在知识管理方面的优势。 由于维护负担，他们放弃了Emacs，但怀念其组织功能，特别是Org-Mode的特性。\n\n文章随后介绍了Obsidian，一个基于Markdown的笔记应用程序，作为潜在的替代品。 Obsidian提供更友好的用户体验，拥有强大的插件生态系统和移动支持。 作者概述了他们使用Obsidian结合PARA（项目、领域、资源、存档）方法来组织笔记和知识的计划，旨在建立一个简单、可持续的系统。\n\n作者在ChatGPT等基于LLM的AI兴起的背景下，论证了这项工作的意义。 虽然承认AI助手的便利性，但他们对过度依赖和个人思维外包的可能性表示担忧。 他们提倡维护个人知识库，以此来珍视自己的想法，进行有意识的思考，并保留对思想的所有权。 作者设想了Obsidian未来与AI工具集成的可能性，将其作为个人“MCP服务器”，AI可以在其中提供帮助，而不会取代个人思想和知识。 最终目标是保持控制，并积极参与自己的学习和理解。"
  },
  {
    "id": "44201975",
    "title": "How we decreased GitLab repo backup times from 48 hours to 41 minutes",
    "url": "https://about.gitlab.com/blog/2025/06/05/how-we-decreased-gitlab-repo-backup-times-from-48-hours-to-41-minutes/",
    "summary": "GitLab significantly decreased its repository backup times, from 48 hours to 41 minutes, by addressing a Git scalability issue. The problem stemmed from a 15-year-old Git function with O(N²) complexity used in the `git bundle create` command, which is crucial for GitLab's repository backup functionality. This function, responsible for removing duplicate references, became a major bottleneck as repositories grew larger with millions of references.\n\nGitLab engineers identified the `object_array_remove_duplicates()` function as the culprit using a flame graph analysis. They then contributed a fix upstream to Git, replacing the nested loops with a map data structure, dramatically improving performance from O(N²) to a more efficient mapping.\n\nThe resulting performance gains were substantial, with benchmark testing showing a 6x improvement. For GitLab's largest repository, backup times decreased dramatically. This improvement brings tangible benefits to GitLab customers, enabling nightly backup schedules without impacting performance, minimizing recovery point objectives (RPO), reducing operational overhead, and future-proofing their infrastructure. This enhancement is available to all GitLab customers regardless of their license tier starting with the 18.0 release. GitLab emphasizes its ongoing commitment to performance and its collaborative approach to development by contributing the fix upstream to the broader Git community.\n",
    "chinese_title": "我们如何将 GitLab 仓库备份时间从 48 小时缩短至 41 分钟",
    "chinese_summary": "GitLab 通过解决 Git 扩展性问题，将仓库备份时间从 48 小时大幅缩短至 41 分钟。问题源于 `git bundle create` 命令中使用的一个具有 O(N²) 复杂度的 15 年前的 Git 函数，该命令对于 GitLab 的仓库备份功能至关重要。这个负责删除重复引用的函数，随着拥有数百万引用的仓库越来越大，成为了主要的瓶颈。\n\nGitLab 工程师通过火焰图分析确定 `object_array_remove_duplicates()` 函数是罪魁祸首。然后，他们向上游 Git 贡献了一个修复程序，用 map 数据结构替换了嵌套循环，从而将性能从 O(N²) 大幅提升到更高效的映射。\n\n由此产生的性能提升非常显著，基准测试显示性能提升了 6 倍。对于 GitLab 最大的仓库，备份时间大幅缩短。这一改进为 GitLab 客户带来了实实在在的好处，使其能够在不影响性能的情况下安排夜间备份，最大限度地减少恢复点目标 (RPO)，降低运营开销，并面向未来地保护其基础设施。此增强功能从 18.0 版本开始适用于所有 GitLab 客户，无论其许可级别如何。GitLab 强调其对性能的持续承诺，并通过向上游的更广泛 Git 社区贡献修复程序来体现其协作开发方法。"
  },
  {
    "id": "44223393",
    "title": "Seagate still HAMRing away at the 100 TB disk drive decades later",
    "url": "https://www.theregister.com/2025/06/09/hamr_100_tb_drive_feature/",
    "summary": "This article examines Seagate's long and challenging journey to mass-produce HAMR (heat-assisted magnetic recording) disk drives, aiming for 100 TB capacities. While HAMR promises higher areal densities (more data per platter) than traditional PMR (perpendicular magnetic recording), Seagate has faced significant delays in bringing the technology to market, despite being a HAMR pioneer.\n\nThe article highlights the difficulties in achieving manufacturing yields and reliability needed for mass production and hyperscaler qualification. Seagate's initial predictions for HAMR drive availability were repeatedly missed. Currently, Seagate is shipping 30 TB HAMR drives and 32/36 TB SMR (shingled magnetic recording) drives, with 40+ TB samples delivered and production expected in late 2025 or early 2026. They envision 100 TB drives by 2033.\n\nCompetitors Western Digital and Toshiba have pursued alternative technologies like MAMR (microwave-assisted magnetic recording) and are now developing their own HAMR solutions. WD's move to 11 platters per drive has allowed them to nearly match Seagate's capacity, mitigating Seagate's areal density advantage. Seagate's decision to stick with 10 platters initially for cost control has also impacted its capacity leadership. Seagate anticipates a major shift to HAMR by the end of fiscal year 2026. They also plan to reduce production costs by vertically integrating laser production.\n\nThe author suggests that if competitors face similar HAMR production hurdles, Seagate could gain a significant market advantage. However, Seagate's past forecasting inaccuracies suggest caution.\n",
    "chinese_title": "希捷仍在数十年后努力攻克100TB硬盘",
    "chinese_summary": "本文探讨了希捷公司在量产HAMR（热辅助磁记录）硬盘驱动器以实现100TB容量的漫长而充满挑战的旅程。虽然HAMR承诺比传统PMR（垂直磁记录）更高的面密度（每张盘片更多数据），但尽管希捷是HAMR技术的先驱，但在将该技术推向市场方面却面临着严重的延误。\n\n本文重点介绍了在实现量产和超大规模客户认证所需的制造良率和可靠性方面所遇到的困难。希捷最初对HAMR驱动器上市时间的预测一再落空。目前，希捷正在交付30TB的HAMR驱动器和32/36TB的SMR（叠瓦式磁记录）驱动器，并已交付40TB以上的样品，预计将于2025年末或2026年投产。他们预计到2033年实现100TB的驱动器。\n\n竞争对手西部数据和东芝已经采用了MAMR（微波辅助磁记录）等替代技术，并且现在正在开发自己的HAMR解决方案。西部数据通过在每个驱动器中使用11个盘片，使其容量几乎与希捷的容量相匹配，从而削弱了希捷的面密度优势。希捷最初出于成本控制考虑坚持使用10个盘片的决定也影响了其容量领先地位。希捷预计到2026财年末，HAMR将发生重大转变。他们还计划通过垂直整合激光生产来降低生产成本。\n\n作者认为，如果竞争对手也面临类似的HAMR生产障碍，希捷可能会获得显著的市场优势。然而，希捷过去预测的不准确性表明应谨慎对待。"
  },
  {
    "id": "44221695",
    "title": "Enterprises are getting stuck in AI pilot hell, say Chatterbox Labs execs",
    "url": "https://www.theregister.com/2025/06/08/chatterbox_labs_ai_adoption/",
    "summary": "According to Chatterbox Labs CEO Danny Coleman and CTO Stuart Battersby, enterprises are struggling to move AI projects from pilot phases to full deployment due to security concerns. They argue that only 10% of enterprises have fully adopted AI, hindered by worries about the safety and societal impact of AI technologies.\n\nThe executives emphasize that traditional cybersecurity approaches are insufficient for AI, as infosec teams often lack expertise in the unique vulnerabilities of AI models. They advocate for a continuous, use-case-specific security testing regime, warning against solely relying on the security claims of model and guardrail vendors. Even authorized users can cause damage within AI systems, highlighting the inadequacy of current content safety filters and guardrails.\n\nChatterbox Labs suggests that layered security measures are crucial. While constant testing involves costs, Battersby believes it can ultimately reduce expenses by demonstrating that smaller, more affordable models can be just as secure for specific applications. Coleman points to acquisitions like Cisco's purchase of Robust Intelligence and Palo Alto Networks' acquisition of Protect AI as positive steps towards addressing AI security. The McKinsey report mentioned highlights the growing interest in AI but emphasizes the struggle leaders face in ensuring AI safety in the workplace.\n",
    "chinese_title": "企业深陷AI试点困境，Chatterbox Labs高管表示",
    "chinese_summary": "根据Chatterbox Labs首席执行官Danny Coleman和首席技术官Stuart Battersby的说法，由于安全顾虑，企业正艰难地将人工智能项目从试点阶段推进到全面部署。他们认为，只有10%的企业完全采用了人工智能，原因是担心人工智能技术的安全性和社会影响。\n\n两位高管强调，传统的网络安全方法不足以应对人工智能，因为信息安全团队通常缺乏人工智能模型独特漏洞方面的专业知识。他们提倡一种持续的、针对特定用例的安全测试机制，并警告不要仅仅依赖模型和防护栏供应商的安全声明。即使是授权用户也可能在人工智能系统内造成损害，这突显了当前内容安全过滤器和防护栏的不足。\n\nChatterbox Labs建议，分层安全措施至关重要。虽然持续测试会带来成本，但Battersby认为，通过证明较小、更经济的模型在特定应用中同样安全，最终可以降低成本。Coleman指出，思科收购Robust Intelligence以及Palo Alto Networks收购Protect AI等举措，是解决人工智能安全问题的积极步骤。《麦肯锡报告》也提到，人们对人工智能的兴趣日益浓厚，但同时强调了领导者在确保工作场所人工智能安全方面面临的困难。"
  },
  {
    "id": "44217510",
    "title": "105 Vibe-Coded Tools",
    "url": "https://tools.simonwillison.net/colophon",
    "summary": "This document is a colophon for the website tools.simonwillison.net, detailing the 106 AI-assisted tools available on the site and their development history. It highlights that Claude 3.7 Sonnet was used to generate the descriptions for each tool.\n\nThe colophon then provides a list of tools with brief descriptions and links to the commit messages and LLM transcripts used in their development. Each entry includes the tool's name, a short description of its functionality, a \"code\" link presumably leading to the tool's code repository, and a \"Development history\" section listing commit hashes, dates, and often links to Claude or ChatGPT conversations documenting the AI-assisted development process.\n\nThe tools cover a variety of use cases, including: real-time multi-tab chat, transfer time calculation, date calculation, CSS flexbox experimentation, ICS calendar file generation, annotated presentation creation, SVG to JPEG/PNG conversion, Gemini API JSON rendering, an automatic redirect to llm-prices.com, HTML live preview, Bluesky thread viewing, Markdown to HTML rendering, RTF to HTML conversion, and Gemini API mask and bounding box visualization. The frequent links to LLM conversations show the author's reliance on and documentation of AI in creating these tools.\n",
    "chinese_title": "105种氛围感工具",
    "chinese_summary": "本文档是网站 tools.simonwillison.net 的版本说明，详细介绍了该网站上提供的 106 个 AI 辅助工具及其开发历史。 其中重点介绍了使用 Claude 3.7 Sonnet 生成每个工具的描述。\n\n该版本说明随后提供了一个工具列表，其中包含简要描述以及指向用于其开发的提交消息和 LLM 记录的链接。 每个条目包括工具名称、其功能的简短描述、可能指向工具代码库的“代码”链接，以及列出提交哈希值、日期，并且通常链接到 Claude 或 ChatGPT 对话以记录 AI 辅助开发过程的“开发历史”部分。\n\n这些工具涵盖各种用例，包括：实时多标签聊天、传输时间计算、日期计算、CSS flexbox 实验、ICS 日历文件生成、带注释的演示文稿创建、SVG 到 JPEG/PNG 转换、Gemini API JSON 渲染、自动重定向到 llm-prices.com、HTML 实时预览、Bluesky 帖子查看、Markdown 到 HTML 渲染、RTF 到 HTML 转换以及 Gemini API 遮罩和边界框可视化。 频繁链接到 LLM 对话表明作者在创建这些工具时对 AI 的依赖和记录。"
  },
  {
    "id": "44214960",
    "title": "Fray: A Controlled Concurrency Testing Framework for the JVM",
    "url": "https://github.com/cmu-pasta/fray",
    "summary": "Fray is a concurrency testing tool for Java designed to detect and debug race conditions, deadlocks, and other concurrency-related issues in multithreaded applications. It employs techniques like probabilistic concurrency testing and partial order sampling and offers deterministic replay for debugging specific interleavings.\n\nFray is designed for easy integration with existing testing frameworks. For JUnit 5, tests can be marked with `@ConcurrencyTest` and the class extended with `@ExtendWith(FrayTestExtension.class)`. For other frameworks, the `FrayInTestLauncher` can be used.\n\nFray offers integration with build tools like Gradle and Maven. Gradle integration requires adding the \"org.pastalab.fray.gradle\" plugin. Maven integration involves adding the `fray-plugins-maven` plugin and the `fray-junit` dependency.\n\nThe documentation includes a technical report, usage guide, IDE settings, and a list of bugs found by Fray. Contributions to the project are welcomed, with a contributing guide available.\n\nThe project is supported by the National Science Foundation under Grant No. 2120955 and an Amazon Research Award.\n",
    "chinese_title": "Fray：JVM 的受控并发测试框架",
    "chinese_summary": "Fray 是一款 Java 并发测试工具，旨在检测和调试多线程应用程序中的竞态条件、死锁和其他并发相关问题。它采用概率并发测试和偏序抽样等技术，并提供确定性重放以调试特定交错执行。\n\nFray 旨在轻松集成到现有测试框架中。对于 JUnit 5，测试可以使用 `@ConcurrencyTest` 注解标记，并且类可以扩展 `@ExtendWith(FrayTestExtension.class)`。 对于其他框架，可以使用 `FrayInTestLauncher`。\n\nFray 提供与 Gradle 和 Maven 等构建工具的集成。Gradle 集成需要添加 \"org.pastalab.fray.gradle\" 插件。Maven 集成涉及添加 `fray-plugins-maven` 插件和 `fray-junit` 依赖项。\n\n文档包括技术报告、使用指南、IDE 设置以及 Fray 发现的错误列表。欢迎对项目做出贡献，并提供贡献指南。\n\n该项目由美国国家科学基金会（项目编号 2120955）和亚马逊研究奖资助。"
  },
  {
    "id": "44219660",
    "title": "Dropbox CEO slams RTO mandates, compares them to outdated malls and theaters",
    "url": "https://www.techspot.com/news/108227-dropbox-ceo-slams-return-office-mandates-compares-them.html",
    "summary": "Drew Houston, the CEO of Dropbox, has criticized return-to-office (RTO) mandates, comparing them to forcing people back to outdated malls and movie theaters. He argues that RTO is often a waste of time and resources when employees can effectively work remotely.\n\nDropbox has embraced a \"virtual first\" approach, allowing employees to work from home 90% of the time and attend off-site events the remaining 10%. Houston emphasizes trusting employees and giving them autonomy, believing it unlocks a better future of work.\n\nWhile many employees prefer remote work, research indicates a significant portion would refuse a full-time RTO mandate, even accepting a pay cut for flexibility. However, most executives remain opposed to remote work, citing concerns about productivity and collaboration. Several major companies like EA, Amazon, and Dell are enforcing RTO policies, requiring employees to return to the office for several days a week or face job loss.\n\nCountering the executive perspective, a recent study suggests that the most productive workers thrive with shorter work bursts and longer breaks. The study also argues that hybrid and in-office work models may encourage a healthier work-life balance compared to fully remote arrangements.\n",
    "chinese_title": "Dropbox CEO 抨击重返办公室强制令，将其比作过时的购物中心和剧院",
    "chinese_summary": "Dropbox CEO德鲁·休斯顿批评了重返办公室（RTO）的要求，将其比作强迫人们回到过时的商场和电影院。他认为，当员工可以高效地远程工作时，RTO通常是时间和资源的浪费。\n\nDropbox已经采取了一种“虚拟优先”的方法，允许员工90%的时间在家工作，剩余10%的时间参加线下活动。休斯顿强调信任员工并赋予他们自主权，相信这能开启更好的工作未来。\n\n虽然许多员工更喜欢远程工作，但研究表明，很大一部分人会拒绝全职RTO的要求，甚至愿意接受降薪以换取灵活性。然而，大多数高管仍然反对远程工作，理由是担心生产力和协作问题。包括EA、亚马逊和戴尔在内的几家主要公司正在执行RTO政策，要求员工每周返回办公室几天，否则将面临失业。\n\n与高管的观点相反，最近的一项研究表明，最高效的员工通过较短的工作时间和较长的休息时间来茁壮成长。该研究还认为，与完全远程的安排相比，混合和办公室工作模式可能更有利于更健康的工作与生活平衡。"
  },
  {
    "id": "44205599",
    "title": "Medieval Africans had a unique process for purifying gold with glass (2019)",
    "url": "https://www.atlasobscura.com/articles/medieval-african-gold",
    "summary": "This article discusses a unique gold purification process used by medieval Africans in Tadmekka, Mali, during the 11th century. Archaeologist Sam Nixon's discovery of coin mold fragments and glass shards in 2005 led to the investigation of this method. Scientists have since recreated the process, finding it to be a novel and sophisticated technique using recycled glass to refine gold.\n\nUnlike the European method of cupellation using lead, medieval West Africans mixed gold ore from the river with recycled glass. When heated, the impurities dissolved into the glass, leaving behind the purified gold. Marc Walton and his team replicated this process using gold dust, local sand, and synthetic glass, confirming the effectiveness of the ancient Malian technique. The use of recycled glass demonstrates the ingenuity and resourcefulness of the medieval African craftsmen, who possessed a deep understanding of the properties of gold and glass, using materials from their surroundings to aid their practices. This discovery marks the first archaeological evidence of glass being used in gold refinement, highlighting a previously unknown aspect of medieval African technological expertise.\n",
    "chinese_title": "中世纪非洲人用玻璃提纯黄金的独特工艺 (2019)",
    "chinese_summary": "本文探讨了11世纪马里塔德梅卡的中世纪非洲人使用的一种独特的黄金提纯工艺。考古学家萨姆·尼克松2005年发现的硬币模具碎片和玻璃碎片促成了对这种方法的研究。此后，科学家们重现了这一过程，发现这是一种新颖而精巧的技术，利用回收玻璃来提炼黄金。\n\n与欧洲使用铅的灰吹法不同，中世纪西非人将来自河流的黄金矿石与回收玻璃混合。加热后，杂质溶解在玻璃中，留下提纯后的黄金。马克·沃尔顿和他的团队使用金粉、当地沙子和合成玻璃复制了这一过程，证实了古代马里技术的有效性。回收玻璃的使用展示了中世纪非洲工匠的独创性和足智多谋，他们对黄金和玻璃的特性有着深刻的理解，并利用周围的材料来辅助他们的实践。这一发现标志着首次考古证据表明玻璃被用于黄金提炼，突显了中世纪非洲技术专长中一个以前未知的方面。"
  },
  {
    "id": "44207095",
    "title": "Getting Past Procrastination",
    "url": "https://spectrum.ieee.org/getting-past-procastination",
    "summary": "This article, titled \"Getting Past Procrastination,\" is written by Rahul Pandey, the founder of Taro, a career platform for tech professionals. It focuses on strategies to overcome procrastination and achieve consistent productivity. While the provided content snippet is brief, we can infer that the article will likely explore practical systems and techniques to combat procrastination. Since the article is aimed at tech professionals, the strategies might be tailored to the challenges and workflows common in the tech industry. The \"3 min read\" suggests the article aims to offer concise and actionable advice. In essence, the article promises to provide readers with frameworks for building habits and structures that foster productivity and minimize procrastination.\n",
    "chinese_title": "克服拖延症",
    "chinese_summary": "题为“克服拖延症”的这篇文章由Taro创始人Rahul Pandey撰写，Taro是面向科技专业人士的职业平台。文章重点介绍克服拖延症和实现持续生产力的方法。虽然提供的内容摘要很简短，但我们可以推断，这篇文章很可能会探讨克服拖延症的实用系统和技巧。由于该文章面向科技专业人士，因此这些策略可能针对科技行业常见的挑战和工作流程量身定制。“3分钟阅读”表明该文章旨在提供简洁且可操作的建议。本质上，这篇文章承诺为读者提供构建习惯和结构的框架，以促进生产力并最大限度地减少拖延症。"
  },
  {
    "id": "44209833",
    "title": "Hate Radio (2011)",
    "url": "https://rwandanstories.org/genocide/hate_radio.html",
    "summary": "The article \"Hate Radio\" (2011) on rwandanstories.org details the pivotal role Radio Télévision Libre des Mille Collines (RTLM) played in inciting and facilitating the Rwandan genocide in 1994. RTLM, rather than acting as a neutral news source, deliberately fueled ethnic hatred and violence against the Tutsi population.\n\nThe radio station, controlled by extremist Hutu elites, broadcast dehumanizing propaganda, referring to Tutsis as \"cockroaches\" and blaming them for Rwanda's problems. This rhetoric created an atmosphere of fear and mistrust, effectively preparing the Hutu population to participate in the genocide.\n\nCrucially, RTLM didn't just spew hatred; it actively identified and located Tutsi individuals and their allies, broadcasting their names and addresses to the public. This information enabled Interahamwe militia and ordinary citizens to track down and murder Tutsis with horrifying efficiency. The radio became a direct instrument of extermination.\n\nThe article highlights the station's manipulative tactics, using popular music and humor to disguise its deadly message and reach a wide audience. It emphasizes that RTLM was a carefully orchestrated campaign of propaganda designed to achieve the systematic elimination of the Tutsi population. The article concludes by emphasizing the devastating impact of RTLM, illustrating how radio can be weaponized to incite genocide and underscores the importance of combating hate speech and propaganda to prevent future atrocities.\n",
    "chinese_title": "仇恨电台 (2011)",
    "chinese_summary": "关于卢旺达故事网站(rwandanstories.org)上题为《仇恨电台》(2011)的文章，详细描述了自由卢旺达千山电台（RTLM）在煽动和促成1994年卢旺达种族大屠杀中所扮演的关键角色。RTLM非但没有充当一个中立的新闻来源，反而蓄意煽动针对图西族人民的种族仇恨和暴力。\n\n这个由极端胡图族精英控制的电台，播放贬低人格的宣传，将图西族人称为“蟑螂”，并将卢旺达的问题归咎于他们。这种言论营造了一种恐惧和不信任的氛围，有效地使胡图族人民准备参与种族灭绝。\n\n至关重要的是，RTLM不仅仅是散布仇恨；它还积极识别和定位图西族个人及其盟友，向公众广播他们的姓名和地址。这些信息使联攻派民兵和普通公民能够以令人发指的效率追踪和谋杀图西族人。该电台成为了一个直接的灭绝工具。\n\n这篇文章强调了该电台的操纵手段，利用流行音乐和幽默来掩盖其致命的信息，并覆盖广泛的受众。它强调RTLM是一场精心策划的宣传活动，旨在系统地消灭图西族人口。文章最后强调了RTLM的破坏性影响，说明了如何将广播武器化以煽动种族灭绝，并强调了打击仇恨言论和宣传以防止未来暴行的重要性。"
  },
  {
    "id": "44201762",
    "title": "Too Many Open Files",
    "url": "https://mattrighetti.com/2025/06/04/too-many-files-open",
    "summary": "This article details the author's experience troubleshooting a \"Too many open files\" error encountered while running Rust tests. The author explains that file descriptors (fds) are positive integers used by the OS kernel to identify open files, including regular files, directories, pipes, sockets, and devices. Every Unix process starts with three standard fds: stdin (0), stdout (1), and stderr (2).\n\nThe article then describes how to inspect open file descriptors using commands like `ls /dev/fd` (macOS), `ls /proc/<pid>/fd` (Linux), and `lsof`. The author explains the difference between `kern.maxfiles` (system-wide limit), `kern.maxfilesperproc` (per-process hard limit), and `ulimit -n` (shell's soft limit) for open file descriptors.\n\nThe author hypothesized that the \"Too many open files\" error occurred because `cargo test` was exceeding the shell's soft limit (256). A monitoring script was created to track the number of open file descriptors for the `cargo test` process, confirming that the error occurred when the number of open files approached the soft limit.\n\nThe solution was to increase the shell's soft limit using `ulimit -n 8192`. After raising the limit, the tests ran successfully, demonstrating that the problem was indeed caused by the default soft limit. The article concludes by emphasizing the importance of understanding file descriptors for troubleshooting similar issues in Unix-like systems.\n",
    "chinese_title": "打开的文件过多",
    "chinese_summary": "本文详细介绍了作者在运行 Rust 测试时遇到的 \"Too many open files\" 错误的排查经验。作者解释说，文件描述符 (fds) 是操作系统内核用来标识打开文件的正整数，包括普通文件、目录、管道、套接字和设备。每个 Unix 进程都以三个标准 fds 开始：stdin (0)、stdout (1) 和 stderr (2)。\n\n然后，本文描述了如何使用诸如 `ls /dev/fd` (macOS)、`ls /proc/<pid>/fd` (Linux) 和 `lsof` 等命令来检查打开的文件描述符。作者解释了 `kern.maxfiles` (系统范围限制)、`kern.maxfilesperproc` (每个进程的硬限制) 和 `ulimit -n` (shell 的软限制) 对于打开文件描述符的区别。\n\n作者推测 \"Too many open files\" 错误的发生是因为 `cargo test` 超出了 shell 的软限制 (256)。创建了一个监控脚本来跟踪 `cargo test` 进程打开的文件描述符数量，证实了当打开的文件数量接近软限制时发生了错误。\n\n解决方案是使用 `ulimit -n 8192` 增加 shell 的软限制。提高限制后，测试成功运行，表明问题确实是由默认的软限制引起的。文章最后强调了理解文件描述符对于在类 Unix 系统中排除类似问题的重要性。"
  },
  {
    "id": "44208060",
    "title": "Low-Level Optimization with Zig",
    "url": "https://alloc.dev/2025/06/07/zig_optimization",
    "summary": "This article explores low-level optimization and highlights Zig's suitability for achieving it. It argues that while compilers are good at optimization, developers must understand the compiler's limitations and provide it with sufficient information about program intent. Verbose languages like Zig, with explicit details like alignment and array sizes, enable better compiler reasoning and optimization, leading to more performant code.\n\nThe article emphasizes Zig's \"comptime\" feature, a form of metaprogramming similar to macros, but more seamlessly integrated into the language. Comptime allows code to be executed at compile-time, generating constants, structures, and even specialized code based on compile-time known data. This allows for significant optimizations, such as unrolling loops and pre-calculating values.\n\nThe article provides an example of string comparison, demonstrating how comptime can generate highly optimized assembly code when one of the strings is known at compile-time.  It also covers runtime-known data at comptime, where the procedure generated at compile-time is dispatched for simple cases, and dynamically dispatched to a runtime implementation for everything else.\n\nThe author concludes that Zig's comptime is a powerful tool for writing performant code and avoids the complexities associated with other languages' metaprogramming approaches. Ultimately, the article champions the idea of choosing tools based on their usefulness rather than engaging in unproductive \"language wars.\"\n",
    "chinese_title": "使用 Zig 进行底层优化",
    "chinese_summary": "本文探讨了底层优化，并强调了Zig在实现底层优化方面的适用性。文章认为，虽然编译器擅长优化，但开发者必须了解编译器的局限性，并为编译器提供足够的关于程序意图的信息。像Zig这样具有显式细节（如对齐和数组大小）的冗长语言，可以使编译器更好地进行推理和优化，从而产生更高性能的代码。\n\n文章强调了Zig的“comptime”特性，这是一种类似于宏的元编程形式，但更无缝地集成到语言中。Comptime允许代码在编译时执行，生成常量、结构，甚至基于编译时已知数据的专用代码。这允许进行显著的优化，例如展开循环和预先计算值。\n\n文章提供了一个字符串比较的例子，演示了当其中一个字符串在编译时已知时，comptime如何生成高度优化的汇编代码。文章还介绍了在编译时处理运行时已知数据的方法，即为简单情况调度编译时生成的过程，并为其他所有情况动态调度到运行时实现。\n\n作者总结说，Zig的comptime是编写高性能代码的强大工具，并避免了与其他语言的元编程方法相关的复杂性。最终，文章提倡根据工具的实用性来选择工具，而不是参与无谓的“语言战争”。"
  },
  {
    "id": "44220571",
    "title": "Unlocking the Motorola G23 (and some words on Motorola)",
    "url": "https://shomy.is-a.dev/blog/article/unlocking-the-motorola-g23",
    "summary": "This article details the arduous process of unlocking the bootloader of the Motorola G23, a device initially believed to be unlockable. The author, Shomy, chronicles the journey alongside a team of enthusiasts, including DiabloSat and R0rt1z2 (Roger), spanning from early 2024 to early 2025.\n\nThe initial attempts involved exploring methods used for previous Motorola phones, like the G22, and experimenting with mtkclient and firmware extraction from the official rescue software (RSA). These efforts were initially unsuccessful due to BROM being blocked and patched preloader issues.\n\nThe breakthrough came with decompiling the bootloader (lk.img) and discovering that the device could be unlocked with a specific key.  After reverse-engineering the key generation algorithm, the team was able to create a Python script to generate the correct key based on the device's SOC ID, successfully unlocking the bootloader.\n\nThe team then focused on booting TWRP and testing GSIs. Roger created \"Chouchou,\" a custom bootloader, to protect against relocking and prevent flashing of potentially bricking partitions.  DiabloSat also created a debloated version of the firmware.\n\nThe article highlights the exploitative nature of Motorola's software. System apps in the stock firmware completely locked users from using their device. Most notably PAKS and SysDLL.\n\nThe article concludes with a warning against buying Motorola phones due to their restrictive practices, ads, and artificially imposed limitations, particularly on lower-end models. It praises the team's success in unlocking the G23, finally granting users full control over their devices.\n",
    "chinese_title": "解锁摩托罗拉G23 (以及关于摩托罗拉的一些话)",
    "chinese_summary": "本文详细介绍了摩托罗拉G23解锁引导加载器的艰辛过程，这款设备最初被认为无法解锁。作者Shomy记录了与DiabloSat和R0rt1z2 (Roger)等爱好者团队从2024年初到2025年初的探索历程。\n\n最初的尝试包括探索用于之前摩托罗拉手机（如G22）的方法，并尝试使用mtkclient和从官方救援软件(RSA)中提取固件。由于BROM被阻止和预加载器问题，这些努力最初并未成功。\n\n突破来自于反编译引导加载器(lk.img)，并发现该设备可以用特定的密钥解锁。在逆向工程密钥生成算法后，该团队成功创建了一个Python脚本，根据设备的SOC ID生成正确的密钥，从而成功解锁了引导加载器。\n\n该团队随后专注于启动TWRP和测试GSIs。Roger创建了一个名为“Chouchou”的自定义引导加载器，以防止重新锁定并阻止刷入可能导致设备变砖的分区。DiabloSat还创建了一个精简版的固件。\n\n本文突出了摩托罗拉软件的剥削性质。股票固件中的系统应用程序完全阻止用户使用他们的设备。最值得注意的是PAKS和SysDLL。\n\n本文最后警告不要购买摩托罗拉手机，因为它们具有限制性做法、广告和人为施加的限制，尤其是在低端型号上。文章赞扬了该团队在解锁G23方面的成功，最终授予用户对其设备的完全控制权。"
  },
  {
    "id": "44217693",
    "title": "Nginx Restic Back End",
    "url": "https://www.grepular.com/Nginx_Restic_Backend",
    "summary": "This article describes how to use Nginx as a backend for the Restic backup tool, offering an alternative to the dedicated Rest Server. The author highlights the benefits of leveraging an existing Nginx setup instead of introducing new software.\n\nThe core idea is to configure Nginx to act as a REST API compatible with Restic's requirements. The author presents two Nginx virtual host configurations: one for append-only backups performed by the hosts themselves and another for administrative tasks like pruning, allowing deletion and greater access.\n\nThe append-only configuration restricts hosts from deleting or overwriting backup data, enhancing security in case of host compromise. The administrative vhost grants full access but is intended to be used from a secured, separate host.\n\nThe Nginx configurations utilize regular expressions and custom logic to handle Restic API requests, including writing (using the DAV module and a proxy to handle POST requests), deleting, and listing objects. The LUA module is used to modify HTTP response codes and format directory listings to be compatible with Restic's expected JSON format.\n\nThe author discusses security considerations, acknowledging the potential risks associated with compromised hosts or the backup server and suggests improvements by potentially making the Restic client compatible. He also uses a Lithuanian VPS Host named Time4VPS to host these backups.\n",
    "chinese_title": "Nginx Restic 后端",
    "chinese_summary": "本文介绍了如何使用 Nginx 作为 Restic 备份工具的后端，以此替代专用的 Rest Server。作者强调了利用现有 Nginx 设置而非引入新软件的优势。\n\n核心思想是配置 Nginx 以充当与 Restic 要求兼容的 REST API。作者展示了两个 Nginx 虚拟主机配置：一个用于主机自身执行的仅追加备份，另一个用于修剪等管理任务，允许删除和更大的访问权限。\n\n仅追加配置限制主机删除或覆盖备份数据，从而在主机遭到入侵时增强安全性。管理 vhost 授予完全访问权限，但旨在从安全的、单独的主机使用。\n\nNginx 配置利用正则表达式和自定义逻辑来处理 Restic API 请求，包括写入（使用 DAV 模块和代理来处理 POST 请求）、删除和列出对象。LUA 模块用于修改 HTTP 响应代码并将目录列表格式化为与 Restic 期望的 JSON 格式兼容。\n\n作者讨论了安全考虑因素，承认与受损主机或备份服务器相关的潜在风险，并建议通过使 Restic 客户端兼容来改进。他还使用名为 Time4VPS 的立陶宛 VPS 主机来托管这些备份。"
  },
  {
    "id": "44208968",
    "title": "Why We're Moving on from Nix",
    "url": "https://blog.railway.com/p/introducing-railpack",
    "summary": "Railway is replacing Nixpacks with a new builder called Railpack, based on lessons learned from building 14 million apps. While Nixpacks worked well for many, its limitations hindered scaling to a larger user base.\n\nThe core problem with Nixpacks stemmed from Nix's commit-based package versioning, which was difficult to manage and maintain, especially for supporting granular versions of languages like Node and Python. Updating package versions often led to unexpected build failures for existing projects.\n\nAdditionally, Nixpacks resulted in large image sizes due to a monolithic `/nix/store` layer and offered limited control over caching, leading to frequent cache invalidation and slower deploys.\n\nRailpack addresses these issues through:\n\n*   **Granular Versioning:** Supports `major.minor.patch` versioning for packages.\n*   **Smaller Builds:** Achieves significant image size reductions (38-77%).\n*   **Better Caching:** Interfaces directly with BuildKit for precise layer control and improved cache hits.\n\nRailpack uses a custom BuildKit LLB + Frontend, Mise for version resolution and package installation, and improved secret environment variable management. The build process is split into Analyze, Plan, and Generate stages, creating a parallel BuildKit build graph. This allows for efficient layer caching and precise image construction.\n\nRailpack unlocks support for static sites (Vite, Astro, CRA, Angular), tight integration with Railway UI, support for the latest language versions, and optimized caching across environments. It's currently in Beta and supports Node, Python, Go, Php, and Static HTML. Railpack is open source and documented at railpack.com.\n",
    "chinese_title": "我们为何放弃 Nix",
    "chinese_summary": "Railway 使用 Railpack 取代 Nixpacks，基于构建 1400 万个应用的经验教训。虽然 Nixpacks 对许多人来说运行良好，但其局限性阻碍了扩展到更大的用户群。\n\nNixpacks 的核心问题源于 Nix 基于提交的软件包版本控制，这难以管理和维护，尤其是在支持 Node 和 Python 等语言的细粒度版本时。更新软件包版本通常会导致现有项目的意外构建失败。\n\n此外，由于单片式的 `/nix/store` 层，Nixpacks 导致了大型镜像尺寸，并且对缓存的控制有限，导致频繁的缓存失效和较慢的部署。\n\nRailpack 通过以下方式解决了这些问题：\n\n*   **细粒度版本控制：** 支持软件包的 `major.minor.patch` 版本控制。\n*   **更小的构建：** 实现显著的镜像尺寸缩减 (38-77%)。\n*   **更好的缓存：** 直接与 BuildKit 交互，实现精确的图层控制并提高缓存命中率。\n\nRailpack 使用自定义的 BuildKit LLB + Frontend、Mise 用于版本解析和软件包安装，以及改进的密钥环境变量管理。构建过程分为分析、计划和生成阶段，创建并行的 BuildKit 构建图。这允许高效的图层缓存和精确的镜像构建。\n\nRailpack 实现了对静态站点（Vite、Astro、CRA、Angular）的支持，与 Railway UI 的紧密集成，对最新语言版本的支持，以及跨环境的优化缓存。它目前处于 Beta 版，支持 Node、Python、Go、Php 和静态 HTML。Railpack 是开源的，文档位于 railpack.com。"
  },
  {
    "id": "44209497",
    "title": "What was Radiant AI, anyway?",
    "url": "https://blog.paavo.me/radiant-ai/",
    "summary": "This article delves into the history and reality of \"Radiant AI,\" a promised revolutionary feature in Bethesda's *The Elder Scrolls IV: Oblivion*. The author aims to clarify what Radiant AI was meant to be, what it actually was in the released game, and its evolution in subsequent Bethesda titles.\n\nThe article begins by highlighting *Morrowind*'s shortcomings regarding NPC behavior and contrasts it with the ambitious promises of *Oblivion*'s Radiant AI system. Pre-release hype, fueled by magazine articles and the E3 2005 demo, painted a picture of dynamic NPCs with independent schedules, motivations, and interactions, making their own choices based on the world around them. Todd Howard described NPCs that had needs and desires.\n\nThe author then examines the specifics, including character attributes, AI packages, schedules, and low-level AI processing. Key quotes from Bethesda's announcements, interviews, and the E3 demo are analyzed to compare the promises with the reality of *Oblivion*'s NPC behavior. The article touches on the concept of GOAP (Goal-Oriented Action Planning) as a possible influence and contrast it with Radiant AI.\n\nThe piece promises to further explore how Radiant AI changed before Oblivion’s release and after. It will trace its influence (or lack thereof) in later Bethesda games like Fallout 3, Skyrim (with Radiant Story), Fallout 4, and Starfield.\n",
    "chinese_title": "Radiant AI 到底是什么？",
    "chinese_summary": "本文深入探讨Bethesda《上古卷轴IV：湮没》中备受期待的革命性功能“光辉AI”的历史和现实。作者旨在阐明光辉AI的最初设想、游戏发布后的实际表现，以及其在Bethesda后续作品中的演变。\n\n文章首先强调了《晨风》在NPC行为方面的不足，并将其与《湮没》光辉AI系统的宏伟承诺进行对比。在杂志文章和2005年E3展演示的推动下，发布前的宣传描绘了一幅动态NPC的画面，这些NPC拥有独立的日程安排、动机和互动，并根据周围的世界做出自己的选择。陶德·霍华德描述了拥有需求和欲望的NPC。\n\n随后，作者研究了具体细节，包括角色属性、AI包、日程安排和底层AI处理。分析了Bethesda在公告、采访和E3演示中的关键引言，以比较承诺与《湮没》NPC行为的现实。文章还探讨了GOAP（面向目标的行动规划）的概念，作为一种可能的参考和与光辉AI的对比。\n\n文章承诺进一步探索光辉AI在《湮没》发布前后发生的变化。它将追溯其在后来的Bethesda游戏中（如《辐射3》、《天际》（含光辉故事）、《辐射4》和《星空》）的影响（或缺乏影响）。"
  },
  {
    "id": "44203732",
    "title": "Workhorse LLMs: Why Open Source Models Dominate Closed Source for Batch Tasks",
    "url": "https://sutro.sh/blog/workhorse-llms-why-open-source-models-win-for-batch-tasks",
    "summary": "This Sutro Components blog post argues that open-source LLMs often outperform and are more cost-effective than closed-source models for common \"workhorse\" tasks like classification, summarization, and data extraction. While closed-source models lead in cutting-edge capabilities, open-source alternatives offer better price-to-performance ratios for tasks not requiring PhD-level reasoning.\n\nThe article highlights the Intelligence Index as a weighted average benchmark for comparing models and introduces a \"performance-to-cost ratio\" metric. It then compares the performance and cost of various LLMs, including Gemini 2.5 Flash, GPT-4o-mini, Claude 3.5 Haiku, Qwen3 series, Llama 3 series, and Gemma 3 series. The analysis shows that open-source models, especially when using batch inference providers like Sutro, can offer 2x-10x the price/performance of their closed-source counterparts.\n\nThe article provides a conversion chart, offering specific open-source replacements for common closed-source models and estimates cost savings that teams can see if they switch. It suggests that, while some models may require slight prompting adjustments for performance parity, the cost savings can be substantial, especially when leveraging batch APIs. The conclusion emphasizes that businesses can significantly benefit by focusing on the cost-to-performance ratio and embracing open-source models for routine LLM tasks to maximize performance and minimize expenses.\n",
    "chinese_title": "主力大语言模型：为何开源模型在批量任务中胜过闭源模型",
    "chinese_summary": "这篇Sutro Components博客文章认为，对于常见的“主力”任务，如分类、总结和数据提取，开源LLM通常优于且更具成本效益，相比于闭源模型。虽然闭源模型在尖端能力方面领先，但对于不需要博士级别推理的任务，开源替代方案提供了更高的性价比。\n\n文章重点介绍了智能指数，这是一个用于比较模型的加权平均基准，并引入了“性能成本比”指标。然后，它比较了各种LLM的性能和成本，包括Gemini 2.5 Flash、GPT-4o-mini、Claude 3.5 Haiku、Qwen3系列、Llama 3系列和Gemma 3系列。分析表明，开源模型，尤其是在使用像Sutro这样的批量推理提供商时，可以提供比其闭源同类产品高2到10倍的性价比。\n\n文章提供了一个转换图表，为常见的闭源模型提供了具体的开源替代方案，并估算了团队如果转换可以节省的成本。文章建议，虽然某些模型可能需要稍作提示调整以实现性能均等，但成本节省可能非常可观，尤其是在利用批量API时。结论强调，企业可以通过关注成本与性能比，并采用开源模型来完成日常LLM任务，从而最大限度地提高性能并最大限度地降低费用，从而获得显著收益。"
  },
  {
    "id": "44213313",
    "title": "Reinforcement Learning to Train Large Language Models to Explain Human Decisions",
    "url": "https://arxiv.org/abs/2505.11614",
    "summary": "This arXiv article (arXiv:2505.11614) presents a novel approach to cognitive modeling using reinforcement learning to train large language models (LLMs) to explain human decision-making, specifically in the context of risky choices. Authored by Jian-Qiao Zhu, Hanbo Xie, Dilip Arumugam, Robert C. Wilson, and Thomas L. Griffiths, the paper addresses a central challenge in cognitive modeling: creating models that not only predict human behavior accurately but also provide interpretable explanations of the underlying cognitive processes.\n\nThe authors leverage the capabilities of pretrained LLMs, aiming to create \"dual-purpose\" cognitive models capable of both accurate prediction and natural language explanations. Their key innovation is the use of reinforcement learning with outcome-based rewards to guide LLMs in generating explicit reasoning traces that justify and explain human risky choices. The paper claims that this method yields both high-quality explanations and strong quantitative predictions of human decisions.\n\nIn essence, the researchers are using reinforcement learning to fine-tune LLMs to produce human-understandable justifications for choices, effectively bridging the gap between predictive accuracy and interpretability in cognitive models. The paper is categorized under Artificial Intelligence (cs.AI) and Computation and Language (cs.CL).\n",
    "chinese_title": "使用强化学习训练大型语言模型来解释人类决策",
    "chinese_summary": "这篇 arXiv 文章 (arXiv:2505.11614) 提出了一种认知建模的新方法，该方法利用强化学习训练大型语言模型 (LLM)，以解释人类决策，尤其是在风险选择的背景下。该论文由 Jian-Qiao Zhu、Hanbo Xie、Dilip Arumugam、Robert C. Wilson 和 Thomas L. Griffiths 撰写，旨在解决认知建模中的一个核心挑战：创建不仅能准确预测人类行为，而且还能提供对潜在认知过程的可解释解释的模型。\n\n作者利用预训练 LLM 的能力，旨在创建能够同时进行准确预测和自然语言解释的“双重用途”认知模型。他们的主要创新是使用基于结果的奖励的强化学习来指导 LLM 生成明确的推理轨迹，以证明和解释人类的风险选择。该论文声称，这种方法既能产生高质量的解释，又能对人类决策进行强有力的定量预测。\n\n本质上，研究人员正在使用强化学习来微调 LLM，使其产生人类可以理解的选择理由，从而有效地弥合认知模型中预测准确性和可解释性之间的差距。该论文被归类为人工智能 (cs.AI) 和计算与语言 (cs.CL) 领域。"
  }
]