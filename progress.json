[
  {
    "id": "43719211",
    "title": "Top OpenAI Catastrophic Risk Official Steps Down Abruptly",
    "url": "https://garrisonlovely.substack.com/p/breaking-top-openai-catastrophic",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "OpenAI顶级灾难风险官员突然辞职",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43716058",
    "title": "An Intro to DeepSeek's Distributed File System",
    "url": "https://maknee.github.io/blog/2025/3FS-Performance-Journal-1/",
    "summary": "This article introduces DeepSeek's open-source distributed file system, 3FS (Fire-Flyer File System). It explains the concept of distributed file systems, highlighting their ability to abstract away the complexities of data fragmentation across multiple machines, making it appear as a single local file system to the user. The advantages of distributed file systems include massive data serving capacity, high throughput, fault tolerance, and redundancy.\n\n3FS comprises four main node types: Meta (manages metadata), Mgmtd (manages cluster configuration and node discovery), Storage (holds actual file data), and Client (communicates with other nodes). The article details the functions of each node, including Mgmtd's role in node registration and configuration, Meta's handling of file operations and metadata storage using FoundationDB, and Storage's use of a ChunkEngine (written in Rust) to manage physical storage by breaking files into chunks and storing metadata in LevelDB.\n\nA significant aspect of 3FS is its use of CRAQ (Chain Replication with Apportioned Queries) for strong consistency and fault tolerance. CRAQ ensures data is replicated across a chain of nodes, with writes propagated sequentially and reads served from either clean or dirty data, with the tail always having the most recent data.\n\nThe article concludes by comparing 3FS to other distributed file systems, emphasizing the importance of real-world applicability, tuning flexibility, and practical implementation details. The author outlines plans for future blog posts to benchmark 3FS performance, identify bottlenecks, and compare it to existing systems. Finally, the post provides links to design notes, technical documentation, and an academic paper with more in-depth information.\n",
    "chinese_title": "DeepSeek分布式文件系统入门",
    "chinese_summary": "本文介绍DeepSeek的开源分布式文件系统3FS（Fire-Flyer File System）。它阐述了分布式文件系统的概念，强调了其将数据碎片化分布在多台机器上的复杂性抽象化，从而使用户感觉就像在使用单个本地文件系统。分布式文件系统的优势包括海量数据服务能力、高吞吐量、容错性和冗余性。\n\n3FS由四种主要节点类型组成：Meta（管理元数据）、Mgmtd（管理集群配置和节点发现）、Storage（存储实际文件数据）和Client（与其他节点通信）。本文详细介绍了每个节点的功能，包括Mgmtd在节点注册和配置中的作用，Meta使用FoundationDB处理文件操作和元数据存储，以及Storage使用ChunkEngine（用Rust编写）通过将文件分成块并将元数据存储在LevelDB中来管理物理存储。\n\n3FS的一个重要方面是它使用CRAQ（具有分配查询的链式复制）来实现强一致性和容错。CRAQ确保数据复制到一系列节点上，写入操作按顺序传播，读取操作可以从干净或脏数据中获取，并且尾节点始终具有最新的数据。\n\n文章最后将3FS与其他分布式文件系统进行比较，强调了实际应用性、调优灵活性和实际实现细节的重要性。作者概述了未来博客文章的计划，以对3FS性能进行基准测试，找出瓶颈，并将其与现有系统进行比较。最后，该文章提供了指向设计说明、技术文档和学术论文的链接，其中包含更深入的信息。"
  },
  {
    "id": "43716526",
    "title": "Unauthenticated Remote Code Execution in Erlang/OTP SSH",
    "url": "https://nvd.nist.gov/vuln/detail/CVE-2025-32433",
    "summary": "CVE-2025-32433 describes an unauthenticated remote code execution (RCE) vulnerability in Erlang/OTP's SSH server. Versions prior to OTP-27.3.3, OTP-26.2.5.11, and OTP-25.3.2.20 are affected. An attacker can exploit a flaw in SSH protocol message handling to gain unauthorized access and execute arbitrary commands without needing valid credentials.\n\nThe vulnerability is rated as CRITICAL by GitHub, Inc., with a CVSS 3.1 score of 10.0 and a vector of CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H. This indicates that the vulnerability is network exploitable, requires no user interaction or privileges, has low attack complexity, and can result in a complete compromise of confidentiality, integrity, and availability of the affected system.\n\nPatches are available in versions OTP-27.3.3, OTP-26.2.5.11, and OTP-25.3.2.20. A temporary workaround is to disable the SSH server or block access using firewall rules. The vulnerability is due to missing authentication for a critical function (CWE-306). Further details and code commits related to the fix can be found on the linked GitHub resources.\n",
    "chinese_title": "Erlang/OTP SSH 中未经身份验证的远程代码执行",
    "chinese_summary": "CVE-2025-32433 描述了 Erlang/OTP 的 SSH 服务器中的一个未经身份验证的远程代码执行 (RCE) 漏洞。受影响的版本包括 OTP-27.3.3 之前的版本、OTP-26.2.5.11 之前的版本以及 OTP-25.3.2.20 之前的版本。攻击者可以利用 SSH 协议消息处理中的缺陷，在无需有效凭据的情况下获得未授权访问权限并执行任意命令。\n\nGitHub, Inc. 将此漏洞评级为 CRITICAL（严重），CVSS 3.1 评分为 10.0，向量为 CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H。这表明该漏洞可通过网络利用，无需用户交互或权限，攻击复杂度低，并可能导致受影响系统的机密性、完整性和可用性完全受损。\n\n补丁已在 OTP-27.3.3、OTP-26.2.5.11 和 OTP-25.3.2.20 版本中提供。临时的解决方案是禁用 SSH 服务器或使用防火墙规则阻止访问。此漏洞是由于关键功能缺少身份验证 (CWE-306) 导致的。更多详细信息和与修复相关的代码提交可以在链接的 GitHub 资源中找到。"
  },
  {
    "id": "43717705",
    "title": "Google Is a Monopolist in Online Advertising Tech, Judge Says",
    "url": "https://www.nytimes.com/2025/04/17/technology/google-ad-tech-antitrust-ruling.html",
    "summary": "A federal judge has ruled that Google illegally maintained a monopoly in certain online advertising technology, specifically the tools used by online publishers to host ad space and the software facilitating ad transactions. Judge Leonie Brinkema of the U.S. District Court for the Eastern District of Virginia found that Google violated the Sherman Antitrust Act, determining the company's actions harmed competitors, publishers, and ultimately consumers.\n\nThe lawsuit, brought by the Justice Department and a group of states, argued that Google's dominance allowed it to inflate prices and take a larger cut of each ad sale. The government specifically targeted three aspects of the online ad market: publisher tools, advertiser tools, and the ad transaction software. While the judge sided with the government on Google's monopoly over publisher tools and the transaction software, she dismissed the claim that Google monopolized the advertiser tools market. The ruling adds to Google's existing legal challenges and has the potential to significantly alter the company's power within the internet advertising ecosystem.\n",
    "chinese_title": "谷歌是线上广告技术领域的垄断者，法官表示",
    "chinese_summary": "联邦法官裁定谷歌非法垄断部分在线广告技术市场"
  },
  {
    "id": "43678144",
    "title": "Making Software",
    "url": "https://www.makingsoftware.com/",
    "summary": "\"Making Software\" is a book aimed at curious individuals who want to understand how everyday technologies work, without being a technical expert. It's not a tutorial or guide but rather a manual explaining the underlying mechanisms of things like touch screens, image blurring, vector graphics, and more.\n\nThe book addresses the increasing gap between our technology usage and our understanding of it. It aims to provide a deeper, though not necessarily actionable, knowledge of how things function, which can be beneficial in problem-solving or simply for intellectual curiosity. The book uses illustrations and diagrams to ease comprehension.\n\nThe table of contents reveals the broad scope of topics covered, including pixels and color, fonts and vectors, 3D and shaders, AI and ML, compression and data, networking and the web, and compilers and interpreters. It will also explore more specific examples like regular expressions, QR codes, and quantum computing.\n\nThe book will initially be released digitally, with a potential print run later. A pre-order option offers access to chapters as they are written and allows readers to suggest topics. While the price is yet to be determined, some content will be free, especially for those on the mailing list.\n",
    "chinese_title": "软件制作",
    "chinese_summary": "《软件制作》一书面向那些对日常技术如何运作充满好奇心，但又不是技术专家的读者。它不是教程或指南，而是一本解释触摸屏、图像模糊、矢量图形等底层机制的手册。\n\n本书旨在弥合我们对技术的使用与理解之间日益扩大的差距。它旨在提供对事物如何运作的更深入（但不一定是可操作的）的知识，这有助于解决问题或满足纯粹的求知欲。本书使用插图和图表来方便理解。\n\n目录揭示了本书涵盖的广泛主题，包括像素和颜色、字体和矢量、3D和着色器、人工智能和机器学习、压缩和数据、网络和Web、以及编译器和解释器。它还将探讨更具体的例子，如正则表达式、二维码和量子计算。\n\n本书最初将以数字形式发布，之后可能会进行印刷。预购选项允许读者在章节撰写时访问它们，并允许读者提出主题建议。虽然价格尚未确定，但某些内容将是免费的，特别是对于那些在邮件列表中的人。"
  },
  {
    "id": "43717377",
    "title": "Stainless steel strengthened: Twisting creates submicron 'anti-crash wall'",
    "url": "https://techxplore.com/news/2025-04-stainless-steel-technique-submicron-anti.html",
    "summary": "This article from Tech Xplore, published April 12, 2025, reports on a new method for strengthening stainless steel developed by researchers from the Chinese Academy of Sciences, Shandong University, and the Georgia Institute of Technology. The study, published in the journal *Science*, details a twisting technique that dramatically improves the metal's resistance to metal fatigue and cycle creep.\n\nThe innovative method involves repeatedly twisting 304 austenitic stainless steel, creating a spatially graded cellular structure that forms a submicron-scale, three-dimensional \"anti-crash wall.\" Microscopic analysis revealed an ultra-fine, sub-10 nanometer, coherent lamellar structure that effectively slows dislocation by preventing stacking faults. This \"anti-crash wall\" functions like a spring, absorbing impacts and making the metal's ability to resist cycle creep more uniform.\n\nTesting showed that the treated stainless steel experienced a 2.6-fold increase in strength and a reduction in strain due to ratcheting by two to four orders of magnitude compared to untreated steel. The researchers claim this improvement could potentially make products made from the treated steel up to 10,000 times more resistant to fatigue, opening up possibilities for specialized applications in industries like aerospace.\n",
    "chinese_title": "不锈钢强化：扭转产生亚微米级“防撞墙”",
    "chinese_summary": "发表于2025年4月12日Tech Xplore上的一篇文章报道了中国科学院、山东大学和佐治亚理工学院的研究人员开发的一种新型不锈钢强化方法。该研究发表在《科学》杂志上，详细介绍了一种扭转技术，该技术显著提高了金属的抗金属疲劳和循环蠕变能力。\n\n这种创新方法包括重复扭转304奥氏体不锈钢，创造一种空间梯度蜂窝结构，形成亚微米级的三维“防撞墙”。显微分析显示，超细的、小于10纳米的相干层状结构有效地通过阻止堆垛层错来减缓位错运动。这种“防撞墙”像弹簧一样，吸收冲击力，使金属的抗循环蠕变能力更加均匀。\n\n测试表明，与未处理的钢相比，处理后的不锈钢强度提高了2.6倍，棘轮效应引起的应变减少了2到4个数量级。研究人员声称，这种改进可能会使由处理后的钢制成的产品抗疲劳能力提高多达10,000倍，为航空航天等行业的专业应用开辟了可能性。"
  },
  {
    "id": "43719522",
    "title": "EasyPost (YC S13) Is Hiring",
    "url": "https://www.easypost.com/careers",
    "summary": "EasyPost (YC S13) is actively hiring, seeking approachable, dynamic, inventive, intelligent, and reliable candidates to help define the future of shipping. They are looking for problem solvers who can collaborate, ask challenging questions, explore new solutions, and take accountability.\n\nThe company emphasizes their focus on modern, flexible technology to improve the customer experience of shipping, envisioning a future with same-day shipping and reduced environmental waste. They highlight a culture of adaptability, simplicity, and inclusivity.\n\nEasyPost prides itself on being an engineering-first company with a pragmatic approach to software development. They offer a fun, passionate, and entrepreneurial environment with diverse experience across the team. Key technological features include CI/CD inspired workflows, small services over monoliths, strong engineering tooling and developer support, and a culture of blamelessness.\n\nThey offer benefits and perks like medical, dental, and vision plans, flexible time-off, stock option opportunities, cross-functional learning, and monthly virtual events. The article also includes a warning about recruitment scams impersonating EasyPost and urges applicants to be cautious and verify any suspicious job offers through official channels.\n",
    "chinese_title": "EasyPost (YC S13) 正在招聘",
    "chinese_summary": "EasyPost (YC S13) 积极招聘，寻找平易近人、充满活力、富有创造力、才智过人且值得信赖的候选人，共同定义航运的未来。他们正在寻找能够协作、提出挑战性问题、探索新解决方案并承担责任的问题解决者。\n\n该公司强调他们专注于现代、灵活的技术，以改善航运的客户体验，展望实现当日送达和减少环境浪费的未来。他们强调一种适应性强、简单和包容的文化。\n\nEasyPost 以其工程至上的公司理念和务实的软件开发方法而自豪。他们提供一个有趣、充满激情和创业精神的环境，团队拥有多样化的经验。关键技术特性包括受 CI/CD 启发的Workflow、小型服务而非单体应用、强大的工程工具和开发者支持，以及一种不咎责任的文化。\n\n他们提供医疗、牙科和视力保险计划、弹性休假、股票期权机会、跨职能学习和每月虚拟活动等福利和津贴。文章还警告存在冒充 EasyPost 的招聘诈骗，并敦促申请人保持警惕，并通过官方渠道验证任何可疑的职位邀请。"
  },
  {
    "id": "43719447",
    "title": "Show HN: AgentAPI – HTTP API for Claude Code, Goose, Aider, and Codex",
    "url": "https://github.com/coder/agentapi",
    "summary": "AgentAPI is an HTTP API that allows programmatic control of coding agents like Claude Code, Goose, Aider, and Codex. It addresses the challenge of interacting with these agents through their terminal-based interfaces, offering a unified way to build chat interfaces, create multi-agent systems, and automate code review processes.\n\nThe tool can be installed via pre-built binaries or built from source using Go. It provides CLI commands for running an agent server (`agentapi server`) and attaching to a running agent's terminal session (`agentapi attach`). The server exposes an OpenAPI schema and documentation UI.\n\nKey features include:\n\n*   **API Endpoints:** `/messages` (get history), `/message` (send message), `/status` (get status), `/events` (SSE stream).\n*   **Terminal Emulation:** Translates API calls into terminal keystrokes.\n*   **Message Parsing:** Splits terminal output into user and agent messages, removing unwanted TUI elements.\n*   **Agent Compatibility:** Works with Claude Code, Goose, Aider, and Codex, with flexibility to adapt to future TUI updates.\n\nThe long-term vision is for AgentAPI to either become obsolete in favor of standardized official SDKs or to serve as a universal adapter if agents continue to use proprietary APIs. Future features under consideration include supporting the MCP and Agent2Agent protocols.\n",
    "chinese_title": "展示 HN: AgentAPI – Claude Code、Goose、Aider 和 Codex 的 HTTP API",
    "chinese_summary": "AgentAPI 是一个 HTTP API，它允许对 Claude Code、Goose、Aider 和 Codex 等编码代理进行编程控制。它解决了通过基于终端的界面与这些代理交互的难题，提供了一种统一的方式来构建聊天界面、创建多代理系统和自动化代码审查流程。\n\n该工具可以通过预构建的二进制文件安装，也可以使用 Go 从源代码构建。它提供了 CLI 命令来运行代理服务器 (`agentapi server`) 和连接到正在运行的代理的终端会话 (`agentapi attach`)。该服务器公开了一个 OpenAPI 模式和文档 UI。\n\n主要功能包括：\n\n*   **API 端点：** `/messages` (获取历史记录), `/message` (发送消息), `/status` (获取状态), `/events` (SSE 流).\n*   **终端模拟：** 将 API 调用转换为终端击键。\n*   **消息解析：** 将终端输出拆分为用户和代理消息，删除不需要的 TUI 元素。\n*   **代理兼容性：** 适用于 Claude Code、Goose、Aider 和 Codex，并具有适应未来 TUI 更新的灵活性。\n\nAgentAPI 的长期愿景是，要么因标准化官方 SDK 的出现而变得过时，要么在代理继续使用专有 API 的情况下，充当通用适配器。正在考虑的未来功能包括支持 MCP 和 Agent2Agent 协议。"
  },
  {
    "id": "43717606",
    "title": "HDR‑Infused Emoji",
    "url": "https://sharpletters.net/2025/04/16/hdr-emoji/",
    "summary": "This article explains how to create HDR (High Dynamic Range) emoji for use in Slack. The author notes that these HDR emoji render with enhanced brightness, making them visually striking, especially on hardware that supports HDR displays.\n\nThe HDR emoji creation process involves using `imagemagick` to manipulate an image. Specifically, the script performs the following:\n\n1.  Adjusts the image's color space to RGB.\n2.  Applies auto-gamma correction.\n3.  Multiplies and powers the image values to increase brightness. The multiplication factor needs tweaking depending on the source image.\n4.  Converts the color space back to sRGB.\n5.  Adjusts the color depth to 16 bits.\n6.  Applies the 2020\\_profile.icc color profile.\n\nThe article highlights that HDR emoji support is not universal. It works well in Chrome and Slack but is largely incompatible with Safari and Android devices. Users are advised to test the emoji in Slack to verify their rendering on different platforms. A key requirement is having the `2020_profile.icc` file in the working directory where the `imagemagick` script is executed.\n",
    "chinese_title": "HDR加持的表情符号",
    "chinese_summary": "本文解释了如何在Slack中创建HDR（高动态范围）表情符号。作者指出，这些HDR表情符号以增强的亮度渲染，使其在视觉上引人注目，尤其是在支持HDR显示的硬件上。\n\nHDR表情符号的创建过程涉及使用`imagemagick`来处理图像。具体来说，该脚本执行以下操作：\n\n1. 将图像的色彩空间调整为RGB。\n2. 应用自动伽马校正。\n3. 乘以并幂运算图像值以增加亮度。乘法因子需要根据源图像进行调整。\n4. 将色彩空间转换回sRGB。\n5. 将颜色深度调整为16位。\n6. 应用2020\\_profile.icc颜色配置文件。\n\n文章强调HDR表情符号的支持并不普遍。它在Chrome和Slack中运行良好，但在很大程度上与Safari和Android设备不兼容。建议用户在Slack中测试表情符号，以验证它们在不同平台上的渲染效果。一个关键要求是在执行`imagemagick`脚本的工作目录中拥有`2020_profile.icc`文件。"
  },
  {
    "id": "43711957",
    "title": "Zoom outage caused by accidental 'shutting down' of the zoom.us domain",
    "url": "https://status.zoom.us/incidents/pw9r9vnq5rvk",
    "summary": "On April 16, 2025, Zoom experienced an outage affecting multiple services, including Zoom Meetings, Zoom Phone, Zoom Contact Center, and the Zoom website. The root cause was a communication error between Zoom's domain registrar, Markmonitor, and GoDaddy Registry. This error led to GoDaddy Registry mistakenly blocking the zoom.us domain, rendering it unavailable between 2:25 P.M. and 4:12 P.M. ET.\n\nZoom, Markmonitor, and GoDaddy acted swiftly to identify and resolve the issue, restoring service to the zoom.us domain. Zoom clarified that the outage was not due to any product failure, security breach, network issue, or a Distributed Denial of Service (DDoS) attack.\n\nFollowing the restoration, Zoom advised users experiencing connection issues to flush their DNS cache. Instructions were provided for both Windows and Mac users to perform this action. GoDaddy and Markmonitor are collaborating to prevent similar incidents from occurring in the future.\n",
    "chinese_title": "Zoom宕机因意外“关闭”zoom.us域名导致。",
    "chinese_summary": "2025年4月16日，Zoom遭遇中断，影响了包括Zoom Meetings、Zoom Phone、Zoom Contact Center和Zoom网站在内的多项服务。根本原因是Zoom的域名注册商Markmonitor与GoDaddy Registry之间发生通信错误。此错误导致GoDaddy Registry错误地屏蔽了zoom.us域名，使其在东部时间下午2:25至下午4:12之间无法访问。\n\nZoom、Markmonitor和GoDaddy迅速采取行动，确定并解决了问题，恢复了zoom.us域名的服务。Zoom澄清说，中断并非由于任何产品故障、安全漏洞、网络问题或分布式拒绝服务(DDoS)攻击所致。\n\n恢复后，Zoom建议遇到连接问题的用户刷新其DNS缓存，并为Windows和Mac用户提供了执行此操作的说明。GoDaddy和Markmonitor正在合作以防止未来发生类似事件。"
  },
  {
    "id": "43691230",
    "title": "MCP Run Python",
    "url": "https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python",
    "summary": "This article introduces `@pydantic/mcp-run-python`, a Model Context Protocol (MCP) server that enables the execution of Python code within a sandboxed environment using Pyodide and Deno. This isolation prevents the code from directly interacting with the host operating system. The server is designed to integrate with PydanticAI and other tools utilizing the MCP.\n\nTo run the server, the article provides a Deno command with specific flags to allow network access and read/write permissions to a local `node_modules` directory, necessary for Pyodide to download and cache Python libraries. It also specifies the `node_modules-dir=auto` flag to automatically manage the local `node_modules` directory.\n\nTwo MCP transport options are presented: `stdio` for local subprocess execution and `sse` for running the server as an HTTP server, allowing local or remote connections. The `warmup` option runs a basic Python script to pre-download and cache the Python standard library, also serving as a server functionality test.\n\nThe article includes a code example demonstrating how to use `@pydantic/mcp-run-python` with PydanticAI. It showcases the integration with `MCPServerStdio`, setting up a PydanticAI Agent to execute a Python script through the sandboxed server. The example ultimately calculates the number of days between two dates using Python code executed within the MCP server.\n",
    "chinese_title": "MCP运行Python",
    "chinese_summary": "本文介绍了`@pydantic/mcp-run-python`，一个模型上下文协议(MCP)服务器，它使用Pyodide和Deno在沙箱环境中执行Python代码。这种隔离防止了代码直接与主机操作系统交互。该服务器旨在与PydanticAI和其他使用MCP的工具集成。\n\n为了运行服务器，本文提供了一个Deno命令，其中包含允许网络访问以及对本地`node_modules`目录进行读/写权限的特定标志，这对于Pyodide下载和缓存Python库是必需的。它还指定了`node_modules-dir=auto`标志来自动管理本地`node_modules`目录。\n\n文章介绍了两种MCP传输选项：`stdio`用于本地子进程执行，`sse`用于将服务器作为HTTP服务器运行，允许本地或远程连接。`warmup`选项运行一个基本的Python脚本来预先下载和缓存Python标准库，同时也作为服务器功能测试。\n\n本文包含一个代码示例，演示了如何将`@pydantic/mcp-run-python`与PydanticAI一起使用。它展示了与`MCPServerStdio`的集成，设置了一个PydanticAI Agent来通过沙箱服务器执行Python脚本。该示例最终使用在MCP服务器中执行的Python代码计算两个日期之间的天数。"
  },
  {
    "id": "43714619",
    "title": "Why Japan's \"Weakest Samurai Warlord\" Is Still Admired to This Day",
    "url": "https://www.tokyoweekender.com/art_and_culture/japanese-culture/oda-ujiharu-the-weakest-samurai-warlord/",
    "summary": "This article explores the paradoxical admiration for Oda Ujiharu, a daimyo from Japan's Sengoku period known as the \"weakest samurai warlord\" due to his repeated losses of Oda Castle. Despite his military shortcomings, particularly in strategy, Ujiharu remains a figure of respect.\n\nThe article highlights Ujiharu's lineage, connecting him to prominent figures of the Kamakura and Ashikaga shogunates, though this held little sway during the turbulent Sengoku period. He lost Oda Castle nine times to various powerful clans like Hojo, Yuki, Satake, and Uesugi, but crucially, he always fought to reclaim it. This resilience earned him the moniker \"The Phoenix,\" challenging the \"weakest\" label.\n\nWhile his military decisions were often baffling, researchers suggest his willingness to fight on open ground rather than endure sieges may have stemmed from a desire to protect his people. Ujiharu also demonstrated significant diplomatic skills, forming alliances and switching sides strategically. His strong connection with his retainers and farmers, who remained fiercely loyal despite his defeats, further contributes to his enduring appeal.\n\nUltimately, Ujiharu's story is one of perseverance and resilience. He eventually lost his lands to Toyotomi Hideyoshi for delaying his pledge of fealty, but avoided the tragic fate of Oda Nobunaga. Despite his reputation, Oda Ujiharu's unwavering spirit and the loyalty he inspired explain why he's admired to this day.\n",
    "chinese_title": "为什么日本“最弱武士领主”至今仍受敬仰",
    "chinese_summary": "对“最弱武将”小田氏治的矛盾性敬佩：韧性与复兴"
  },
  {
    "id": "43692746",
    "title": "Ultrafast Optical Detector",
    "url": "https://www.tdk.com/en/about_tdk/innovation/spin-photo-detector/index.html",
    "summary": "TDK has announced the development of the world's first \"Spin Photo Detector,\" a groundbreaking technology poised to revolutionize photoelectric conversion, particularly for AI applications. This detector leverages magnetic tunnel junction (MTJ) elements, unlike traditional semiconductor-based light detectors, to achieve ultrafast light detection across a broad wavelength range, from near-infrared to visible light.\n\nKey advantages of the Spin Photo Detector include its potential for 10x faster data transmission speeds, contributing to faster data processing and reduced power consumption in AI systems. Furthermore, the technology is versatile, allowing for integration onto various boards and devices.\n\nTDK envisions applications for this innovation in data centers, optical communication and interconnect for generative AI, and augmented/virtual reality (AR/VR). The company's press release and featured stories article provide further details.\n",
    "chinese_title": "超快光探测器",
    "chinese_summary": "TDK发布全球首款“自旋光电探测器”，有望革新光电转换技术，尤其适用于人工智能应用。该探测器采用磁性隧道结（MTJ）元件，与传统半导体光电探测器不同，可在近红外到可见光的宽波长范围内实现超快光检测。\n\n自旋光电探测器的主要优势包括其数据传输速度有望提高10倍，从而加快人工智能系统中的数据处理速度并降低功耗。此外，该技术用途广泛，可集成到各种板卡和设备上。\n\nTDK设想该创新技术可应用于数据中心、生成式人工智能的光通信和互连以及增强/虚拟现实（AR/VR）领域。该公司的媒体新闻稿和专题报道文章提供了更多详细信息。"
  },
  {
    "id": "43679065",
    "title": "The Second Half",
    "url": "https://ysymyth.github.io/The-Second-Half/",
    "summary": "This article, \"The Second Half,\" argues that AI is entering a new era, shifting its focus from developing new training methods and models (\"solving problems\") to defining the right problems to solve and how to measure real progress (\"defining problems\"). The author claims that reinforcement learning (RL), powered by language pre-training and reasoning, has finally generalized, creating a \"recipe\" that can tackle a wide range of tasks.\n\nThe first half of AI focused on breakthroughs in training methods and models, evaluated primarily through benchmark performance. This was successful because methods were harder and more generally applicable than tasks. Now, this \"recipe\" has become so effective that it diminishes the need for novel methods and quickly solves new benchmarks.\n\nThe author argues that the second half demands a fundamental rethinking of evaluation. Existing evaluation setups, like automatic and independent task runs, don't mirror real-world utility where AI agents interact with humans in sequential tasks. This leads to the \"utility problem,\" where AI excels in benchmarks but hasn't drastically impacted the economy.\n\nThe future game involves developing novel evaluation setups and tasks that reflect real-world utility, solving them using the existing recipe or augmenting it with novel components. This shift requires questioning fundamental assumptions and focusing on building useful products, leading to potentially greater impact and innovation than the incremental improvements seen in the first half. Essentially, the focus is shifting from academic advancement to real-world application and value creation.\n",
    "chinese_title": "下半场",
    "chinese_summary": "第二篇章：人工智能正步入新纪元，重心从开发新的训练方法和模型（“解决问题”）转向定义需要解决的正确问题以及如何衡量实际进展（“定义问题”）。作者认为，由语言预训练和推理驱动的强化学习 (RL) 终于实现了泛化，创造出了一种能够解决各种任务的“配方”。\n\n人工智能的上半场侧重于训练方法和模型的突破，主要通过基准性能进行评估。之所以成功，是因为方法比任务更难，适用性更广。如今，这种“配方”变得非常有效，降低了对新方法的需求，并能快速解决新的基准问题。\n\n作者认为，下半场需要从根本上重新思考评估方式。现有的评估设置，例如自动和独立的任务运行，并不能反映现实世界的效用，即人工智能代理在顺序任务中与人类互动。这导致了“效用问题”，即人工智能在基准测试中表现出色，但尚未对经济产生重大影响。\n\n未来的游戏包括开发反映现实世界效用的新型评估设置和任务，并使用现有配方解决它们或用新的组件来增强它。这种转变需要质疑基本假设，并专注于构建有用的产品，从而带来比上半场中看到的增量改进更大的影响和创新。本质上，重点正在从学术进步转向现实世界的应用和价值创造。"
  },
  {
    "id": "43678138",
    "title": "Adipose tissue retains an epigenetic memory of obesity after weight loss",
    "url": "https://www.nature.com/articles/s41586-024-08165-7",
    "summary": "This study investigates the molecular mechanisms behind the difficulty of maintaining weight loss, focusing on the concept of an \"obesogenic memory\" in adipose tissue. Researchers used single-nucleus RNA sequencing (snRNA-seq) to analyze adipose tissue from humans after bariatric surgery-induced weight loss and from mice after diet-induced weight loss.\n\nThe key findings are:\n\n*   **Human adipose tissue retains transcriptional changes after significant weight loss.** snRNA-seq revealed that even after weight loss, many genes differentially expressed during obesity remained deregulated in adipocytes, adipocyte progenitor cells (APCs), and endothelial cells. These retained changes were linked to downregulated pathways involved in adipocyte metabolism and function, and upregulated pathways linked to fibrosis and apoptosis.\n*   **Mouse adipocytes exhibit an epigenetic obesogenic memory.** The study found long-term persistent epigenetic alterations in mouse adipocytes after weight loss.\n*   **Obesogenic memory leads to accelerated weight regain.** Mice with this \"memory\" showed faster rebound weight gain when re-exposed to a high-fat diet. The epigenetic memory could explain future transcriptional deregulation in adipocytes in response to further high-fat diet feeding.\n*   **Transcriptional changes persist WL induced (partial) remodelling of epiAT.** After WL, only a few mild metabolic impartments persisted, including glucose intolerance in HC mice, hyperinsulinemia and slight liver steatosis in HHC mice and a notable decrease in epiAT depot size after WL in both groups.\n\nIn conclusion, the study provides evidence for an obesogenic memory, largely driven by stable epigenetic changes in adipocytes and potentially other cell types, that primes cells for pathological responses in an obesogenic environment, contributing to the yo-yo dieting effect. Targeting these changes could potentially improve long-term weight management strategies.\n",
    "chinese_title": "脂肪组织在减肥后保留了肥胖的表观遗传记忆",
    "chinese_summary": "本研究调查了维持减肥困难背后的分子机制，重点关注脂肪组织中的“致肥胖记忆”概念。研究人员利用单细胞核RNA测序 (snRNA-seq) 分析了接受过减肥手术的人类和饮食诱导减肥的小鼠的脂肪组织。\n\n主要发现如下：\n\n*   **人类脂肪组织在显著减肥后保留了转录变化。** snRNA-seq 显示，即使在减肥后，肥胖期间差异表达的许多基因在脂肪细胞、脂肪细胞祖细胞 (APCs) 和内皮细胞中仍然失调。这些保留的变化与脂肪细胞代谢和功能相关的通路下调以及与纤维化和细胞凋亡相关的通路上调有关。\n*   **小鼠脂肪细胞表现出表观遗传的致肥胖记忆。** 研究发现，小鼠脂肪细胞在减肥后存在长期持续的表观遗传改变。\n*   **致肥胖记忆导致体重快速反弹。** 具有这种“记忆”的小鼠在再次暴露于高脂肪饮食时表现出更快的反弹性体重增加。这种表观遗传记忆可以解释脂肪细胞在未来对进一步高脂肪饮食的反应中出现的转录失调。\n*   **体重减轻诱导的(部分) epiAT重塑后，转录变化持续存在。** 体重减轻后，只有少数轻微的代谢损伤持续存在，包括HC小鼠的葡萄糖不耐受，HHC小鼠的高胰岛素血症和轻微的肝脏脂肪变性，以及两组小鼠体重减轻后epiAT储存库大小的显著减少。\n\n总之，该研究为致肥胖记忆提供了证据，这种记忆主要由脂肪细胞和潜在的其他细胞类型的稳定表观遗传变化驱动，使细胞为在致肥胖环境中的病理反应做好准备，从而导致溜溜球节食效应。针对这些变化可能有助于改善长期体重管理策略。"
  },
  {
    "id": "43713524",
    "title": "Passing planes and other whoosh sounds",
    "url": "https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html",
    "summary": "This article explores the \"whoosh\" sound often heard when a plane passes overhead, arguing it's not solely due to the Doppler effect. While the Doppler effect explains the descending pitch of the engine, the article focuses on a broader, breathier sound where the pitch initially decreases and then increases after the plane passes.\n\nThe author identifies this sound as being caused by comb filtering, a phenomenon where two slightly delayed copies of the same sound interfere with each other, creating moving peaks and valleys in the frequency spectrum. The author hypothesizes that this delay is due to a ground echo - the listener hears both the direct sound from the plane and a delayed reflection from the ground.\n\nThe cepstrum is used to analyze the delay time, revealing a sweeping peak that corresponds to the perceived pitch change. Calculations based on the listener's height and the distance to the ground support the idea that the echo delay falls within the observed range (4-9 milliseconds when the plane is overhead, with closer to 4ms at an angle).\n\nThe article further explains that the \"whoosh\" sound isn't limited to planes, requiring a structured sound, a nearby reflective surface, and movement. Examples include waterfalls reflecting off walls and sounds near motorway barriers. The author encourages readers to experiment with creating the effect themselves and includes an interactive JavaScript plot to visualize the relationship between plane position, listener position, and the resulting time delay.\n",
    "chinese_title": "飞机的轰鸣和其他嗖嗖声",
    "chinese_summary": "本文探讨了飞机飞过头顶时常听到的“呼啸”声，认为它不仅仅是多普勒效应造成的。虽然多普勒效应解释了发动机音调的降低，但本文侧重于一种更广泛、更气息化的声音，这种声音的音调首先降低，然后在飞机经过后又升高。\n\n作者认为这种声音是由梳状滤波引起的，梳状滤波是一种现象，其中同一声音的两个略有延迟的副本相互干扰，在频谱中产生移动的峰谷。作者假设这种延迟是由于地面回声造成的——听者既听到来自飞机的直接声音，也听到来自地面的延迟反射。\n\n倒谱被用于分析延迟时间，揭示了一个与感知到的音调变化相对应的扫动峰值。基于听者的高度和到地面的距离的计算支持了这样的观点，即回声延迟落在观测到的范围内（当飞机在头顶时为4-9毫秒，成角度时接近4毫秒）。\n\n文章进一步解释说，“呼啸”声并不局限于飞机，它需要结构化的声音、附近的反射表面和运动。例子包括瀑布反射墙壁的声音以及高速公路护栏附近的声音。作者鼓励读者自己尝试创造这种效果，并包含一个交互式 JavaScript 图，以可视化飞机位置、听者位置和由此产生的时间延迟之间的关系。"
  },
  {
    "id": "43697717",
    "title": "AI as Normal Technology",
    "url": "https://knightcolumbia.org/content/ai-as-normal-technology",
    "summary": "This article argues that AI should be viewed as \"normal technology,\" akin to electricity or the internet, rather than a separate, superintelligent entity. The authors present this view as a description of current AI, a prediction for its foreseeable future, and a prescription for how it should be treated. They reject technological determinism and emphasize the slow, uncertain nature of technology adoption, drawing lessons from past technological revolutions.\n\nThe article is divided into four parts. Part I explains why transformative impacts will be slow (on the timescale of decades) due to the different speeds of AI methods, applications, and adoption. Part II discusses a human-AI division of labor where humans retain control, with an increasing proportion of jobs focused on AI control. Part III examines AI risks (accidents, arms races, misuse, misalignment) and argues that a \"normal technology\" perspective leads to different mitigation strategies compared to viewing AI as human-like. Part IV advocates for reducing uncertainty and fostering resilience in AI policy, cautioning against drastic interventions based on superintelligence fears.\n\nThe authors highlight that AI diffusion in safety-critical areas is particularly slow due to regulatory oversight and the need for interpretable models. They also note that even outside safety-critical areas, AI adoption is limited by the speed of human, organizational, and institutional change. They predict that slow diffusion will continue in high-consequence tasks and emphasize the importance of adapting regulations as new areas for AI application emerge.\n",
    "chinese_title": "人工智能作为普通技术",
    "chinese_summary": "本文认为，应将人工智能视为“普通技术”，类似于电力或互联网，而非独立、超智能的实体。作者将此观点作为对当前人工智能的描述、对其可预见的未来的预测以及对其应如何对待的建议。他们反对技术决定论，并强调技术采纳的缓慢和不确定性，从过去的技术革命中汲取经验教训。\n\n本文分为四个部分。第一部分解释了为何变革性影响会很慢（以数十年为单位），因为人工智能方法、应用和采纳的速度各不相同。第二部分讨论了人机分工，其中人类保留控制权，越来越多的工作集中在人工智能控制上。第三部分考察了人工智能的风险（事故、军备竞赛、滥用、未对齐），并认为与将人工智能视为类人相比，“普通技术”的视角会导致不同的缓解策略。第四部分主张减少人工智能政策的不确定性并培养韧性，告诫不要基于对超智能的恐惧而采取激烈的干预措施。\n\n作者强调，由于监管监督和对可解释模型的需求，人工智能在安全关键领域的扩散尤其缓慢。他们还指出，即使在安全关键领域之外，人工智能的采用也受到人类、组织和制度变革速度的限制。他们预测，在高后果任务中的缓慢扩散将持续下去，并强调随着人工智能应用新领域的出现，调整法规的重要性。"
  },
  {
    "id": "43714041",
    "title": "The Halting Problem is a terrible example of NP-Harder",
    "url": "https://buttondown.com/hillelwayne/archive/the-halting-problem-is-a-terrible-example-of-np/",
    "summary": "The author argues that using the Halting Problem (HALT) as the primary example of a problem harder than NP-complete is a poor choice. While technically correct (HALT is undecidable), the author finds it inelegant and confusing. They point out that NP only requires polynomial-time verification for \"yes\" instances, and a \"yes\" instance of HALT (\"it halts in N steps\") *can* be verified. The complication arises from demonstrating that this verification process exceeds polynomial time due to the busy beaver function's uncomputability.\n\nThe author desires a more intuitive example, but notes that many problems definitively harder than NP require significant theoretical background. They propose an alternative based on a token moving on a multi-dimensional grid. Determining if a sequence of moves can reach a target point in this grid starts at PSPACE-complete and escalates dramatically with increasing dimensions, becoming EXPSPACE-complete, then TOWER-complete, and eventually ACKERMANN-complete. This problem, while significantly harder than NP, remains decidable and easily explainable, offering a clearer illustration of \"NP-harder\" than the Halting Problem. The author also mentions the alternate definition of NP (solvable by a non-deterministic Turing Machine in polynomial time) as a reason why HALT cannot be in NP.\n",
    "chinese_title": "停机问题是NP-难的一个糟糕例子",
    "chinese_summary": "作者认为，将停机问题（HALT）作为比NP完全问题更难的主要例子是一个糟糕的选择。虽然技术上正确（HALT是不可判定的），但作者觉得它不够简洁且容易混淆。他们指出，NP仅要求对“是”实例进行多项式时间验证，而HALT的“是”实例（“它在N步内停止”） *可以* 被验证。复杂之处在于证明此验证过程超出多项式时间，原因是忙碌海狸函数的不可计算性。\n\n作者希望有一个更直观的例子，但指出许多确定比NP难的问题需要大量的理论背景。他们提出了一个基于在多维网格上移动令牌的替代方案。确定一系列移动能否到达此网格中的目标点，其难度从PSPACE完全开始，并随着维数的增加而急剧升级，变为EXPSPACE完全，然后是TOWER完全，最终变为ACKERMANN完全。这个问题虽然比NP难得多，但仍然是可判定的并且容易解释，提供了一个比停机问题更清晰的“比NP更难”的说明。作者还提到NP的另一种定义（可以用非确定性图灵机在多项式时间内解决）是HALT不能属于NP的原因。"
  },
  {
    "id": "43714004",
    "title": "BitNet b1.58 2B4T Technical Report",
    "url": "https://arxiv.org/abs/2504.12285",
    "summary": "This technical report introduces BitNet b1.58 2B4T, the first open-source 1-bit Large Language Model (LLM) with 2 billion parameters. The model was trained on a massive corpus of 4 trillion tokens and evaluated across a range of benchmarks including language understanding, mathematical reasoning, coding, and conversational ability.\n\nThe key finding is that BitNet b1.58 2B4T achieves performance comparable to leading open-weight, full-precision LLMs of similar size. However, it offers significant advantages in computational efficiency. These advantages include a substantially reduced memory footprint, lower energy consumption, and decreased decoding latency.\n\nTo promote further research and adoption, the authors are releasing the model weights on Hugging Face, along with open-source inference implementations for both GPU and CPU architectures. The article also includes links to various resources related to the paper, such as code repositories, demos, and bibliographic tools. This paper is a work in progress.\n",
    "chinese_title": "BitNet b1.58 2B4T 技术报告",
    "chinese_summary": "本技术报告介绍了BitNet b1.58 2B4T，首个拥有20亿参数的开源1比特大型语言模型(LLM)。该模型在包含4万亿tokens的大规模语料库上进行训练，并在包括语言理解、数学推理、编码和对话能力等一系列基准上进行了评估。\n\n主要发现是，BitNet b1.58 2B4T的性能与同等规模的领先开源、全精度LLM相当。然而，它在计算效率方面具有显著优势，包括大幅减少的内存占用、更低的能耗以及更低的解码延迟。\n\n为了促进进一步的研究和应用，作者将在Hugging Face上发布模型权重，以及针对GPU和CPU架构的开源推理实现。文章还包含了与该论文相关的各种资源链接，例如代码仓库、演示和参考文献工具。本文是一项正在进行中的工作。"
  },
  {
    "id": "43714902",
    "title": "Building an AI That Watches Rugby",
    "url": "https://nickjones.tech/ai-watching-rugby/",
    "summary": "This article details the author's project to build an AI system that can \"watch\" rugby games and generate richer, more contextual data than traditional event feeds provide. The goal is to understand the \"why\" behind the on-field action, capturing nuances like referee explanations, scrum dominance, and other unquantified aspects of the game.\n\nThe author experimented with OpenAI's vision model to extract the score and game clock from screenshots of the broadcast. Initially, a full-resolution screenshot was used, but the cost was reduced by cropping the image to focus solely on the scoreboard. The author also explored alternatives like image differencing and OCR, but found the LLM approach provided the most reliable results.\n\nFurthermore, the author used OpenAI's Whisper to transcribe audio from the broadcast, capturing commentary and referee audio to provide even more context. This enabled the AI to identify events missed in the official stats, like impressive player performances or penalties.\n\nWhile still a prototype, the project demonstrates the potential to use AI to generate in-depth rugby data, enabling the Gainline app to provide a richer, more immersive second-screen experience for fans. The author acknowledges the challenges of scaling the system and the ethical considerations of AI-driven sports analysis, but remains optimistic about the future potential of AI in sports broadcasting and data analysis.\n",
    "chinese_title": "构建一个观看橄榄球比赛的AI",
    "chinese_summary": "本文详细介绍了作者构建一个AI系统的项目，该系统能够“观看”橄榄球比赛，并生成比传统事件流提供的数据更丰富、更具上下文的数据。其目标是理解场上动作背后的“原因”，捕捉裁判的解释、争球优势以及比赛中其他无法量化的方面等细微之处。\n\n作者尝试使用OpenAI的视觉模型从广播截图中提取比分和比赛计时器。最初，使用了全分辨率截图，但通过裁剪图像以仅关注记分牌来降低了成本。作者还探索了图像差异和OCR等替代方案，但发现LLM方法提供了最可靠的结果。\n\n此外，作者使用OpenAI的Whisper转录广播中的音频，捕捉解说和裁判音频，以提供更多上下文。这使得AI能够识别官方统计数据中遗漏的事件，例如令人印象深刻的球员表现或处罚。\n\n虽然仍是一个原型，但该项目展示了使用AI生成深入橄榄球数据的潜力，使Gainline应用程序能够为球迷提供更丰富、更具沉浸感的第二屏幕体验。作者承认扩展该系统所面临的挑战以及AI驱动的体育分析的伦理考量，但对AI在体育广播和数据分析中的未来潜力仍然持乐观态度。"
  },
  {
    "id": "43706037",
    "title": "Darwin's children drew all over the “On the Origin of Species” manuscript (2014)",
    "url": "https://theappendix.net/posts/2014/02/darwins-children-drew-vegetable-battles-on-the-origin-of-species",
    "summary": "This article, published on Darwin Day 2014, explores the surprisingly personal side of Charles Darwin's work by showcasing drawings and doodles found within his manuscripts and family belongings.  The author highlights the digitization efforts of projects like Darwin Online and the Darwin Manuscripts Project, which allow access to these intimate historical artifacts.\n\nThe article focuses on drawings attributed to Darwin's children, including a fantastical \"Battle of the Fruit and Vegetable Soldiers\" on the back of an \"On the Origin of Species\" manuscript page, nature sketches reflecting the family's observational skills, and a child's-eye view of the Darwin home, possibly depicting Darwin's famous \"sandwalk.\"\n\nThe author also delves into Emma Darwin's diaries, showcasing her own artistic talent through sketches and doodles. The diaries also bear the marks of the Darwin children's playful defacement, reminding readers of the family life surrounding Darwin's scientific pursuits.\n\nAn update to the article includes a touching note about Annie Darwin, Charles's deceased daughter, and a box of her mementos, including needlepoint flowers. The author connects Annie's death to Darwin's personal life and the potential impact it had on his scientific thought and declining faith. The article ultimately argues that understanding the personal lives of historical figures is crucial for a more complete and human understanding of their work and legacy.\n",
    "chinese_title": "达尔文的孩子们在《物种起源》手稿上乱涂乱画（2014）",
    "chinese_summary": "本文发表于2014年达尔文日，通过展示查尔斯·达尔文手稿和家庭物品中发现的绘画和涂鸦，探索了达尔文作品中令人惊讶的个人一面。作者重点介绍了达尔文在线和达尔文手稿项目等数字化工作，这些项目允许人们访问这些私密的历史文物。\n\n文章重点介绍了据说是达尔文孩子们的画作，包括在《物种起源》手稿背面上的奇幻“水果蔬菜士兵之战”、反映家庭观察能力的自然素描，以及儿童眼中达尔文的家，可能描绘了达尔文著名的“沙道”。\n\n作者还深入研究了艾玛·达尔文的日记，展示了她通过素描和涂鸦所展现的艺术才华。日记也留下了达尔文孩子们顽皮破坏的痕迹，提醒读者达尔文科学研究周围的家庭生活。\n\n文章的更新内容包括关于查尔斯已故女儿安妮·达尔文的一段感人笔记，以及一盒她的纪念品，包括针绣花朵。作者将安妮的去世与达尔文的个人生活以及它可能对他的科学思想和信仰衰退产生的影响联系起来。文章最终认为，理解历史人物的个人生活对于更完整和人性化地理解他们的工作和遗产至关重要。"
  },
  {
    "id": "43716293",
    "title": "Scientists find strongest evidence yet of life on an alien planet",
    "url": "https://www.reuters.com/science/scientists-find-strongest-evidence-yet-life-an-alien-planet-2025-04-16/",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "科学家发现迄今为止外星生命的最有力证据",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43715235",
    "title": "Cutting down Rust compile times from 30 to 2 minutes with one thousand crates",
    "url": "https://www.feldera.com/blog/cutting-down-rust-compile-times-from-30-to-2-minutes-with-one-thousand-crates",
    "summary": "Feldera, a platform that compiles SQL into Rust code, significantly reduced its Rust compile times from 30 minutes to 2 minutes by splitting a large, single crate into over 1,000 smaller crates. Previously, compiling complex SQL programs generated ~100k lines of Rust code, resulting in long compilation times despite using a powerful machine with 64 cores. Profiling revealed that LLVM passes and codegen, which are single-threaded, were the bottlenecks, leaving most cores idle.\n\nThe solution involved modifying the SQL-to-Rust compiler to generate many small, interconnected crates instead of one large crate. Each SQL operator became its own crate, exporting a function to build a piece of the dataflow.  Crate names were based on a hash of their Rust code, enabling efficient incremental builds. When the SQL code changes slightly, only the corresponding crates with modified hashes are recompiled, leveraging cached artifacts for unchanged crates.\n\nThis approach fully utilized all CPU cores, dramatically reducing compilation time.  While initially concerned about the overhead of many crates, the authors found the parallelization benefits outweighed the drawbacks. They acknowledge remaining mysteries, as the observed speedup wasn't linear despite full CPU utilization, hinting at potential bottlenecks like hardware resource contention or file system limitations. Despite these remaining mysteries, splitting their Rust into thousands of crates resulted in an enormous improvement in compilation time for their customers.\n",
    "chinese_title": "使用一千个 crate 将 Rust 编译时间从 30 分钟缩短到 2 分钟",
    "chinese_summary": "Feldera 通过将大型单代码仓库拆分为 1000 多个小型代码仓库，显著缩短了 Rust 编译时间，从 30 分钟降至 2 分钟。 之前，编译复杂的 SQL 程序会生成约 10 万行 Rust 代码，即使使用拥有 64 个内核的强大机器，也会导致编译时间过长。 分析显示，LLVM 传递和代码生成是单线程的瓶颈，导致大多数内核处于空闲状态。\n\n该解决方案涉及修改 SQL 到 Rust 的编译器，以生成许多小型、相互连接的代码仓库，而不是一个大型代码仓库。 每个 SQL 运算符都变成自己的代码仓库，导出一个函数来构建数据流的一部分。 代码仓库名称基于其 Rust 代码的哈希值，从而实现高效的增量构建。 当 SQL 代码略有更改时，只会重新编译具有修改后的哈希值的相应代码仓库，从而利用未更改代码仓库的缓存工件。\n\n这种方法充分利用了所有 CPU 内核，大大缩短了编译时间。 虽然最初担心许多代码仓库的开销，但作者发现并行化的好处超过了缺点。 他们承认仍然存在一些谜团，因为尽管 CPU 使用率很高，但观察到的加速并不是线性的，这暗示了潜在的瓶颈，例如硬件资源争用或文件系统限制。 尽管存在这些未解之谜，但将他们的 Rust 代码拆分成数千个代码仓库，极大地改善了客户的编译时间。"
  },
  {
    "id": "43713140",
    "title": "Differentiable Programming from Scratch",
    "url": "https://thenumb.at/Autodiff/",
    "summary": "This article, \"Differentiable Programming from Scratch,\" introduces differentiable programming, its increasing relevance beyond machine learning, and various techniques for differentiating code. It starts with a calculus review, focusing on derivatives, gradients, directional derivatives, and the chain rule. It emphasizes the importance of viewing derivatives as mappings between vectors.\n\nThe article then discusses optimization via gradient descent, explaining its iterative process, the role of the learning rate, and potential pitfalls like local minima and divergence. It highlights the importance of regularization techniques.\n\nThe core of the article delves into different approaches to differentiating code: numerical, symbolic, and automatic differentiation. Numerical differentiation, while simple to implement via finite differences, is computationally expensive for high-dimensional inputs and provides only approximations. Symbolic differentiation uses a domain-specific language with known differentiation rules, but the resulting derivative expression can become very large.\n",
    "chinese_title": "从零开始的可微编程",
    "chinese_summary": "本文《从零开始的可微编程》介绍了可微编程，及其在机器学习以外领域日益增长的相关性，并阐述了区分代码的各种技术。文章首先回顾了微积分，重点关注导数、梯度、方向导数和链式法则。它强调了将导数视为向量之间映射的重要性。\n\n文章随后讨论了通过梯度下降进行优化，解释了它的迭代过程、学习率的作用，以及诸如局部最小值和发散等潜在陷阱。文章强调了正则化技术的重要性。\n\n文章的核心深入探讨了区分代码的不同方法：数值微分、符号微分和自动微分。数值微分虽然通过有限差分易于实现，但对于高维输入而言，计算成本很高，并且只能提供近似值。符号微分使用具有已知微分规则的特定领域语言，但生成的导数表达式可能会变得非常大。"
  },
  {
    "id": "43708025",
    "title": "OpenAI Codex CLI: Lightweight coding agent that runs in your terminal",
    "url": "https://github.com/openai/codex",
    "summary": "OpenAI Codex CLI is a lightweight, open-source coding agent that runs in your terminal, leveraging ChatGPT-level reasoning to interact with and modify your code. It allows developers to use natural language prompts to automate tasks such as refactoring, generating tests, updating documentation, and identifying vulnerabilities.\n\nKey features include:\n\n*   **Terminal-based interaction:** Built for developers who prefer working in the terminal.\n*   **Code Execution:** Can run code, manipulate files, and install dependencies within a secure sandbox.\n*   **Flexible Approval Modes:** Offers varying levels of autonomy via the `--approval-mode` flag: Suggest, Auto Edit, and Full Auto. Full Auto runs commands network-disabled and directory-sandboxed for security.\n*   **Multimodal Input:** Accepts screenshots and diagrams.\n*   **Customizable Instructions:** Supports personal and project-specific instructions through Markdown files.\n*   **Non-interactive Mode:** Can be used in CI/CD pipelines.\n*   **Security:** Utilizes platform-specific sandboxing (Apple Seatbelt on macOS, Docker on Linux) and requires explicit approval for potentially risky actions.\n\nThe CLI requires Node.js 22+ and Git (optional). Installation is via npm. Configuration is done through `~/.codex/config.yaml` and supports customizing model preferences and defining custom instructions.\n\nOpenAI is offering funding opportunities for open-source projects utilizing Codex CLI. Contributions are welcome, with guidelines emphasizing focused changes, test coverage, documentation, and atomic commits.\n",
    "chinese_title": "OpenAI Codex CLI：轻量级终端编码助手",
    "chinese_summary": "OpenAI Codex CLI 是一个轻量级的开源编码助手，可在您的终端中运行，利用 ChatGPT 级别的推理能力与您的代码进行交互和修改。它允许开发人员使用自然语言提示来自动化任务，例如重构、生成测试、更新文档和识别漏洞。\n\n主要功能包括：\n\n* **基于终端的交互：** 专为喜欢在终端中工作的开发人员而构建。\n* **代码执行：** 可以在安全的沙盒中运行代码、操作文件和安装依赖项。\n* **灵活的批准模式：** 通过 `--approval-mode` 标志提供不同级别的自主权：建议、自动编辑和完全自动。完全自动模式运行命令时禁用网络并进行目录沙盒化，以确保安全。\n* **多模态输入：** 接受屏幕截图和图表。\n* **可自定义的指令：** 通过 Markdown 文件支持个人和项目特定的指令。\n* **非交互模式：** 可在 CI/CD 管道中使用。\n* **安全性：** 利用平台特定的沙盒技术（macOS 上的 Apple Seatbelt，Linux 上的 Docker），并且需要明确批准才能执行潜在的风险操作。\n\n该 CLI 需要 Node.js 22+ 和 Git（可选）。安装通过 npm 进行。配置通过 `~/.codex/config.yaml` 完成，并支持自定义模型偏好和定义自定义指令。\n\nOpenAI 正在为使用 Codex CLI 的开源项目提供资金机会。欢迎贡献，指南强调重点明确的更改、测试覆盖率、文档和原子提交。"
  },
  {
    "id": "43682207",
    "title": "A type-safe, intuitive Go SDK for building MCP servers with ease and confidence",
    "url": "https://github.com/ktr0731/go-mcp",
    "summary": "`go-mcp` is a Go SDK designed to simplify the development of Model Context Protocol (MCP) servers. It offers a type-safe and intuitive interface for building servers with features like tools, logging, and prompts.\n\nKey benefits include:\n\n*   **Type Safety:** Code generation enforces static typing, preventing runtime errors.\n*   **Intuitive API:** A Go-idiomatic interface simplifies server development.\n*   **Developer-Friendly:** Designed for ease of use.\n\nThe quick start guide demonstrates how to create an MCP server by defining server capabilities, tools using Go structs and descriptions, generating code with `mcpgen`, and implementing the server logic. An example directory structure and runnable code snippets are provided.\n\nSupported features include ping, tools, prompts, resource subscription, update notifications, logging, and cancellation. Features under development include batching, streamable HTTP transport, and progress notifications. Dynamic prompt and tool changes are intentionally excluded due to Go's limitations with dynamic typing. Contributions are welcomed under the MIT License.\n",
    "chinese_title": "用于轻松自信地构建MCP服务器的类型安全、直观的Go SDK",
    "chinese_summary": "`go-mcp` 是一个 Go SDK，旨在简化模型上下文协议 (MCP) 服务器的开发。它提供了一个类型安全且直观的接口，用于构建具有工具、日志和提示等功能的服务器。\n\n主要优势包括：\n\n*   **类型安全：** 代码生成强制静态类型，防止运行时错误。\n*   **直观 API：** Go 语言风格的接口简化了服务器开发。\n*   **开发者友好：** 设计易于使用。\n\n快速入门指南演示了如何通过定义服务器功能、使用 Go 结构体和描述定义工具、使用 `mcpgen` 生成代码以及实现服务器逻辑来创建 MCP 服务器。提供了示例目录结构和可运行的代码片段。\n\n支持的功能包括 ping、工具、提示、资源订阅、更新通知、日志记录和取消。正在开发的功能包括批处理、可流式传输的 HTTP 传输和进度通知。由于 Go 在动态类型方面的限制，有意排除了动态提示和工具更改。欢迎在 MIT 许可证下贡献代码。"
  },
  {
    "id": "43716939",
    "title": "This 'College Protester' Isn't Real. It's an AI-Powered Undercover Bot for Cops",
    "url": "https://www.wired.com/story/massive-blue-overwatch-ai-personas-police-suspects/",
    "summary": "This article exposes Massive Blue, a company selling AI-powered \"Overwatch\" technology to U.S. police departments near the Mexican border. Overwatch uses AI-generated online personas to infiltrate and gather intelligence on \"college protesters,\" \"radicalized\" activists, and suspected traffickers. These personas, complete with detailed backstories and AI-generated images, engage suspects on social media and messaging apps, attempting to generate evidence.\n\nLaw enforcement agencies in Arizona and Texas are paying significant sums for this unproven technology, citing its potential to combat human trafficking. However, concerns are raised about its effectiveness, potential for First Amendment violations by targeting protesters, and the ill-defined problems it aims to solve. Examples include personas designed to resemble lonely divorced women interested in activism, young people from Yemen, and even underage children.\n\nCritics like Dave Maass from the Electronic Frontier Foundation question the purpose and ethical implications of these AI-driven undercover operations. While Massive Blue claims its goal is to bring traffickers to justice and protect victims, specific details about its operations and arrest outcomes are scarce. Law enforcement agencies are secretive about the technology, and some have admitted it hasn't yet led to any arrests. Furthermore, concerns are mounting that the AI could be used beyond trafficking investigations into immigration and protest movements.\n",
    "chinese_title": "这个“大学抗议者”不是真人，而是警方用于卧底的人工智能机器人。",
    "chinese_summary": "本文揭露了“巨蓝”公司向美墨边境附近的美国警察部门出售人工智能驱动的“守望者”技术。“守望者”利用人工智能生成的网络身份，渗透并收集“大学抗议者”、“激进化”的活动人士和疑似人口贩运者的情报。这些人物角色拥有详细的背景故事和人工智能生成的图像，他们在社交媒体和通讯应用上与嫌疑人互动，试图获取证据。\n\n亚利桑那州和德克萨斯州的执法机构正为此未经证实的技术支付巨额资金，理由是其具有打击人口贩运的潜力。然而，人们对其有效性、通过针对抗议者而可能违反第一修正案，以及其旨在解决的定义不清的问题表示担忧。例子包括旨在模仿对激进主义感兴趣的孤独离异女性、来自也门的年轻人，甚至未成年儿童的角色。\n\n电子前沿基金会的戴夫·马斯等批评人士质疑这些人工智能驱动的卧底行动的目的和伦理影响。“巨蓝”公司声称其目标是将人口贩运者绳之以法并保护受害者，但关于其行动和逮捕结果的具体细节却很少。执法机构对这项技术讳莫如深，一些机构承认该技术尚未促成任何逮捕行动。此外，人们越来越担心人工智能可能会被用于贩运调查之外的移民和抗议活动中。"
  },
  {
    "id": "43710576",
    "title": "Show HN: Plandex v2 – open source AI coding agent for large projects and tasks",
    "url": "https://github.com/plandex-ai/plandex",
    "summary": "Plandex v2 is an open-source, terminal-based AI coding agent designed for managing large coding tasks and real-world projects. It supports up to 2M tokens of context and can index directories with 20M+ tokens using tree-sitter. Key features include a diff review sandbox, controlled command execution for debugging, and the ability to combine models from Anthropic, OpenAI, Google, and open-source providers.\n\nPlandex is adaptable, offering both full autonomy for tasks like loading files, planning, implementation, command execution, and debugging, as well as fine-grained control for developers. It's built to handle large projects with smart context management, reliable file edits, and fast project map generation.\n\nIt supports configurable autonomy, automated debugging of terminal commands and browser applications, and offers a project-aware chat mode for brainstorming. It prioritizes correctness with syntax and logic validation and features version control, Git integration (including commit message generation), and cost-saving context caching.\n\nInstallation is simple with a one-line CLI install. Hosting options include Plandex Cloud (with integrated models or BYO API key) and self-hosted/local mode using Docker. To get started, users `cd` into a project directory and run `plandex` or `pdx`. The REPL interface provides help text and prompts the user to switch between chat and tell modes for idea fleshing and detailed planning, respectively. Documentation, a Discord server, and community contribution are encouraged.\n",
    "chinese_title": "Show HN: Plandex v2 – 大型项目及任务的开源AI编码代理",
    "chinese_summary": "Plandex v2 是一款开源的、基于终端的 AI 编码代理，旨在管理大型编码任务和真实项目。它支持高达 200 万 tokens 的上下文，并可以使用 tree-sitter 索引包含 2000 万以上 tokens 的目录。主要功能包括差异审查沙箱、用于调试的受控命令执行，以及结合 Anthropic、OpenAI、Google 和开源供应商的模型的能力。\n\nPlandex 具有适应性，既为加载文件、规划、实施、命令执行和调试等任务提供完全自主性，也为开发人员提供精细控制。它专为处理大型项目而构建，具有智能上下文管理、可靠的文件编辑和快速的项目地图生成功能。\n\n它支持可配置的自主性、终端命令和浏览器应用程序的自动调试，并提供用于头脑风暴的项目感知聊天模式。它通过语法和逻辑验证来优先考虑正确性，并具有版本控制、Git 集成（包括提交消息生成）和节省成本的上下文缓存功能。\n\n安装非常简单，只需一行 CLI 命令即可安装。托管选项包括 Plandex Cloud（带有集成模型或 BYO API 密钥）以及使用 Docker 的自托管/本地模式。要开始使用，用户 `cd` 进入项目目录并运行 `plandex` 或 `pdx`。REPL 界面提供帮助文本，并提示用户在聊天模式和讲述模式之间切换，分别用于完善想法和进行详细规划。我们鼓励查阅文档，加入 Discord 服务器并参与社区贡献。"
  },
  {
    "id": "43679906",
    "title": "Concurrency in Haskell: Fast, Simple, Correct",
    "url": "https://bitbashing.io/haskell-concurrency.html",
    "summary": "This article champions Haskell's approach to concurrency, arguing it offers a fast, simple, and correct solution compared to traditional threading or continuation passing. It starts by highlighting the need for concurrency to utilize multi-core processors and manage slow I/O operations. While alternatives like Node.js with event-driven I/O exist, they can lead to debugging challenges.\n\nHaskell uses green threads managed by its runtime, combining the benefits of threads and event-driven I/O. The `forkIO` function spawns threads, and the `async` package provides control through promises (`Async a`), enabling waiting (`wait`) and cancellation (`cancel`). The article introduces higher-level abstractions like `concurrently`, `race`, and `mapConcurrently` that simplify concurrent task management by automatically handling thread cancellation and failure propagation.\n\nThe real magic lies in STM (Software Transactional Memory), which uses special types like `TVar` and `TBQueue` along with the `atomically` function to ensure atomic read/write operations. This eliminates the need for explicit mutexes and avoids common concurrency issues like deadlocks and race conditions. A key example is a closeable queue (`TBCQueue`) where read and write operations are atomically coordinated with an \"open\" flag using `retry` for blocking operations, showcasing STM's power and ease of use. The author argues that STM, like Rust's memory safety features, eliminates entire categories of concurrency bugs.\n",
    "chinese_title": "Haskell中的并发：快速、简单、正确",
    "chinese_summary": "本文推崇Haskell的并发处理方式，认为与传统线程或续传传递相比，它提供了一种快速、简单且正确的解决方案。文章首先强调了利用多核处理器和管理慢速I/O操作对并发的需求。虽然存在像Node.js这样使用事件驱动I/O的替代方案，但它们可能会导致调试难题。\n\nHaskell使用由其运行时管理的绿色线程，结合了线程和事件驱动I/O的优点。`forkIO`函数产生线程，`async`包通过promises（`Async a`）提供控制，可以等待（`wait`）和取消（`cancel`）。文章介绍了更高级的抽象，如`concurrently`、`race`和`mapConcurrently`，它们通过自动处理线程取消和故障传播，简化了并发任务管理。\n\n真正的魔力在于STM（软件事务内存），它使用诸如`TVar`和`TBQueue`等特殊类型以及`atomically`函数来确保原子读/写操作。这消除了对显式互斥锁的需求，并避免了诸如死锁和竞争条件等常见的并发问题。一个关键示例是可关闭队列（`TBCQueue`），其中读写操作与“打开”标志进行原子协调，使用`retry`进行阻塞操作，展示了STM的强大功能和易用性。作者认为，STM就像Rust的内存安全特性一样，消除了整个类别的并发错误。"
  },
  {
    "id": "43714594",
    "title": "Advanced Shell Scripting with Bash (2006) [pdf]",
    "url": "http://uniforumchicago.org/slides/bash1.pdf",
    "summary": "This document, titled \"Advanced Shell Scripting with Bash (2006)\", appears to be a corrupted or incomplete PDF file. The content consists primarily of encoded data, likely the compressed representation of text, images, and formatting instructions that constitute a PDF document.  There is no readily discernible human-readable text within the provided snippet that would allow for understanding its subject matter, intended audience, or learning objectives. Therefore, it's impossible to summarize the article's content. The presence of \"/ProcSet [ /PDF /Text ]\" suggests it intended to include text elements, while \"/ImageB /ImageC /ImageI\" point to potential inclusion of bitmap, color, and indexed images. The \"Advanced Shell Scripting with Bash (2006)\" title indicates the subject matter, but without proper rendering, the document's actual content remains inaccessible. It is, essentially, data without the decoder, so any 'summary' would be speculation based on the title alone.\n",
    "chinese_title": "Bash高级Shell脚本编程 (2006) [pdf]",
    "chinese_summary": "这份名为“Bash高级Shell脚本编程（2006）”的文档，似乎是一个损坏或不完整的PDF文件。其内容主要由编码数据组成，可能是构成PDF文档的文本、图像和格式指令的压缩表示。在提供的片段中，没有任何容易辨认的人类可读文本可以让我们理解其主题、目标受众或学习目标。因此，无法总结文章的内容。“/ProcSet [ /PDF /Text ]”的存在表明它打算包含文本元素，而“/ImageB /ImageC /ImageI”则指向可能包含位图、彩色和索引图像。“Bash高级Shell脚本编程（2006）”这个标题表明了主题，但如果没有正确的渲染，文档的实际内容仍然无法访问。本质上，它是没有解码器的数据，所以任何“摘要”都将是仅基于标题的推测。"
  },
  {
    "id": "43680715",
    "title": "Scientists pioneer chemical process to repurpose rubber waste",
    "url": "https://phys.org/news/2025-03-cleaner-future-scientists-chemical-repurpose.html",
    "summary": "This article details a new chemical process developed by scientists at UNC-Chapel Hill for repurposing rubber waste, specifically from discarded tires. The method offers a sustainable alternative to traditional recycling methods like pyrolysis, which generates harmful byproducts.\n\nLed by Dr. Aleksandr Zhukhovitskiy, the research introduces a two-step process involving C–H amination and a polymer rearrangement strategy. This breaks down the complex, cross-linked structure of rubber into soluble, amine-functionalized materials suitable for creating epoxy resins. The process is conducted under mild conditions (35–50°C) in aqueous media, making it more environmentally friendly and cost-effective compared to methods requiring extreme temperatures or expensive catalysts.\n\nTesting showed significant molecular weight reduction in model polymers and complete breakdown of used rubber within six hours. The resulting materials can be used to produce epoxy resins with similar strengths to commercial, petroleum-based resins.\n\nThe researchers also evaluated the environmental impact using the Environmental Impact Factor (E-factor). While the overall E-factor was high due to solvent use, the simple E-factor was much lower, indicating potential for improvement by optimizing solvent systems and reaction conditions. This research offers a promising approach for transforming rubber waste into valuable materials, reducing landfill reliance and minimizing environmental harm.\n",
    "chinese_title": "科学家开创橡胶废料再利用化学工艺",
    "chinese_summary": "本文详细介绍了北卡罗来纳大学教堂山分校的科学家开发的一种新的化学工艺，用于再利用橡胶废料，特别是废弃轮胎。该方法为热解等产生有害副产品的传统回收方法提供了一种可持续的替代方案。\n\n该研究由 Aleksandr Zhukhovitskiy 博士领导，介绍了一种涉及 C–H 胺化和聚合物重排策略的两步工艺。该工艺将橡胶复杂的交联结构分解成可溶的、胺基功能化的材料，适用于制造环氧树脂。该过程在温和的条件（35-50°C）下在水性介质中进行，与需要极端温度或昂贵催化剂的方法相比，更环保且更具成本效益。\n\n测试表明，模型聚合物的分子量显著降低，并且使用过的橡胶在六小时内完全分解。所得材料可用于生产强度与商业石油基树脂相似的环氧树脂。\n\n研究人员还使用环境影响因子（E-factor）评估了环境影响。虽然由于溶剂的使用，总体E-factor 较高，但简单E-factor 较低得多，表明可以通过优化溶剂系统和反应条件来改进。这项研究为将橡胶废料转化为有价值的材料、减少对垃圾填埋场的依赖并最大限度地减少环境危害提供了一种有希望的方法。"
  },
  {
    "id": "43676690",
    "title": "How refrigeration changed our food",
    "url": "https://www.nytimes.com/2024/06/24/books/review/frostbite-nicola-twilley.html",
    "summary": "Sallie Tisdale's review of Nicola Twilley's \"Frostbite\" explores the profound impact of refrigeration on our food system and beyond. Twilley delves into the complex \"cold chain,\" using the supermarket banana as an example of the intricate network of refrigeration required to bring tropical fruit to consumers year-round.\n\nThe review highlights how refrigeration has transformed food production, consumption, and even the environment. In the 19th century, refrigerated rail cars eliminated urban slaughterhouses, leading to increased meat consumption and vast changes in land use, including the decline of bison and displacement of Native Americans.\n\nThe advent of the home refrigerator, a relatively recent innovation, further revolutionized how and what we eat. Twilley argues that refrigeration has not only redesigned our plates but also reshaped our bodies, homes, cities, landscapes, and the global atmosphere. While the cold chain offers consumers endless abundance, the review hints at a potential cost, suggesting that flavor may be sacrificed in the pursuit of year-round availability and widespread distribution.\n",
    "chinese_title": "制冷如何改变了我们的食物",
    "chinese_summary": "萨莉·蒂斯代尔对尼古拉·特威利的《冻伤》的评论探讨了冷藏技术对我们的食物系统及其他领域的深刻影响。特威利深入研究了复杂的“冷链”，并以超市的香蕉为例，说明了将热带水果全年带给消费者所需的错综复杂的冷藏网络。\n\n该评论强调了冷藏如何改变了食品生产、消费，甚至环境。19世纪，冷藏铁路车厢消除了城市屠宰场，导致肉类消费增加，土地利用发生巨大变化，包括野牛数量下降和美洲原住民流离失所。\n\n家用冰箱的出现，这项相对较新的创新，进一步彻底改变了我们的饮食方式和内容。特威利认为，冷藏不仅重新设计了我们的餐盘，还重塑了我们的身体、家园、城市、景观和全球大气。虽然冷链为消费者提供了无尽的丰富，但该评论暗示了潜在的代价，表明为了追求全年供应和广泛分销，风味可能会被牺牲。"
  },
  {
    "id": "43707021",
    "title": "Damn Vulnerable MCP Server",
    "url": "https://github.com/harishsg993010/damn-vulnerable-MCP-server",
    "summary": "DVMCP, or Damn Vulnerable Model Context Protocol, is an educational project designed to highlight security vulnerabilities in MCP implementations. MCP is a standardized protocol allowing applications to provide context to Large Language Models (LLMs) in a structured manner.\n\nDVMCP contains 10 challenges across three difficulty levels (easy, medium, hard) demonstrating various attack vectors, including prompt injection, tool poisoning, excessive permissions, rug pull attacks, tool shadowing, indirect prompt injection, token theft, malicious code execution, remote access control, and multi-vector attacks.\n\nThe project includes a vulnerable MCP server, documentation, and solution guides. It recommends using Docker for a stable environment. CLINE (VSCode Extension) is suggested as a recommended MCP client.\n\nThe project aims to educate security researchers, developers, and AI safety professionals about potential security issues in MCP implementations and how to mitigate them. It emphasizes the importance of security best practices when implementing MCP servers and is licensed under the MIT License. It was created by Harish Santhanalakshmi Ganesan using cursor IDE and Manus AI.\n",
    "chinese_title": "该死的漏洞百出的MCP服务器",
    "chinese_summary": "DVMCP（即 Damn Vulnerable Model Context Protocol，易受攻击的模型上下文协议）是一个旨在突出 MCP 实现中安全漏洞的教育项目。 MCP 是一种标准化协议，允许应用程序以结构化方式向大型语言模型 (LLM) 提供上下文。\n\nDVMCP 包含 10 个挑战，分为三个难度级别（简单、中等、困难），展示了各种攻击媒介，包括提示注入、工具中毒、过度权限、Rug Pull 攻击、工具阴影、间接提示注入、令牌盗窃、恶意代码执行、远程访问控制和多向量攻击。\n\n该项目包括一个易受攻击的 MCP 服务器、文档和解决方案指南。建议使用 Docker 以获得稳定的环境。 推荐使用 CLINE (VSCode Extension) 作为推荐的 MCP 客户端。\n\n该项目旨在教育安全研究人员、开发人员和 AI 安全专业人员了解 MCP 实现中潜在的安全问题以及如何缓解这些问题。它强调了在实现 MCP 服务器时安全最佳实践的重要性，并采用 MIT 许可证。它由 Harish Santhanalakshmi Ganesan 使用 cursor IDE 和 Manus AI 创建。"
  },
  {
    "id": "43699271",
    "title": "12-factor Agents: Patterns of reliable LLM applications",
    "url": "https://github.com/humanlayer/12-factor-agents",
    "summary": "Dex, an AI agent hacker, introduces \"12-Factor Agents,\" a set of principles for building reliable LLM-powered applications that are suitable for production environments. He observed that many \"AI Agents\" are mostly deterministic code with strategic LLM integrations, unlike the \"prompt-tool loop\" paradigm often associated with agent frameworks. Dex argues that truly effective agents rely more on conventional software engineering practices.\n\nThe article outlines a journey from traditional software development represented by directed acyclic graphs (DAGs) managed by orchestrators like Airflow, to the initial promise of agents that could autonomously navigate tasks without pre-defined DAGs, relying on LLMs to determine the path. This \"agent loop\" involves the LLM determining the next step, deterministic code executing the tool, and the result being fed back into the context window. However, this approach often falls short in practice.\n\nThe core argument is that integrating modular agent concepts into existing products is more effective than relying solely on full-fledged frameworks. Dex outlines 12 factors covering key aspects of building robust LLM applications, including:\n\n*   Natural Language to Tool Calls\n*   Prompt and Context Window Ownership\n*   Treating Tools as Structured Outputs\n*   Unifying Execution and Business State\n*   Launch/Pause/Resume Capabilities\n*   Human-in-the-Loop via Tool Calls\n*   Control Flow Management\n*   Error Handling\n*   Agent Focus and Size\n*   Triggering and User Accessibility\n*   Stateless Reducer Architecture.\n\nThe article is a practical guide, aiming to help software engineers build high-quality AI-powered features for customers by incorporating elements of agent design into existing products.\n",
    "chinese_title": "12要素代理：可靠LLM应用模式",
    "chinese_summary": "AI智能体黑客Dex提出“十二要素智能体”，一套用于构建可靠的、适用于生产环境的LLM驱动应用程序的原则。他观察到，许多“AI智能体”主要由具有战略性LLM集成的确定性代码组成，这与通常与智能体框架相关的“提示-工具循环”范式不同。Dex认为，真正有效的智能体更依赖于传统的软件工程实践。\n\n文章概述了一个从传统软件开发（以由Airflow等编排器管理的有向无环图(DAG)为代表）到智能体的最初承诺（即无需预定义的DAG，依靠LLM来确定路径，自主导航任务）的演变过程。这种“智能体循环”涉及LLM确定下一步，确定性代码执行工具，以及将结果反馈到上下文窗口。然而，这种方法在实践中常常不尽如人意。\n\n核心论点是，将模块化智能体概念集成到现有产品中比仅仅依赖于完整的框架更有效。Dex概述了涵盖构建强大LLM应用程序的关键方面的12个要素，包括：\n\n*   自然语言到工具调用\n*   提示和上下文窗口所有权\n*   将工具视为结构化输出\n*   统一执行和业务状态\n*   启动/暂停/恢复能力\n*   通过工具调用实现人机协作\n*   控制流管理\n*   错误处理\n*   智能体关注点和规模\n*   触发和用户可访问性\n*   无状态Reducer架构。\n\n这篇文章是一篇实用指南，旨在通过将智能体设计的元素融入现有产品中，帮助软件工程师为客户构建高质量的AI驱动功能。"
  },
  {
    "id": "43704430",
    "title": "CVE Foundation",
    "url": "https://www.thecvefoundation.org/home",
    "summary": "The CVE Foundation has been launched to secure the future of the Common Vulnerabilities and Exposures (CVE) Program, a key part of global cybersecurity for 25 years. This action was prompted by the U.S. government's decision not to renew its contract with MITRE for managing the program.\n\nPreviously, the CVE Program was a U.S. government-funded initiative, leading to concerns about its sustainability and neutrality. The CVE Foundation aims to address this by becoming a dedicated, non-profit organization focused solely on the CVE program's mission: delivering high-quality vulnerability identification and maintaining the integrity of CVE data for global defenders.\n\nAccording to Kent Landfield, an officer of the Foundation, CVE is essential to the cybersecurity ecosystem. The formation of the CVE Foundation seeks to remove a single point of failure in vulnerability management and ensure the CVE Program is a trusted, community-driven initiative that reflects the global nature of the threat landscape. More information regarding the Foundation's structure, transition plans, and opportunities for community involvement will be released soon.\n",
    "chinese_title": "CVE基金会",
    "chinese_summary": "CVE基金会成立，保障通用漏洞披露 (CVE) 项目的未来。该项目作为全球网络安全的重要组成部分已走过 25 年。此次行动的起因是美国政府决定不再续签与 MITRE 公司的合同，后者负责管理该项目。\n\n此前，CVE 项目是一项由美国政府资助的倡议，这引发了人们对其可持续性和中立性的担忧。CVE 基金会旨在通过成为一个专注的非营利组织来解决这个问题，该组织的目标完全专注于 CVE 项目的使命：提供高质量的漏洞识别，并为全球防御者维护 CVE 数据的完整性。\n\n据该基金会官员肯特·兰德菲尔德称，CVE 对于网络安全生态系统至关重要。 CVE 基金会的成立旨在消除漏洞管理中的单一故障点，并确保 CVE 项目成为一个值得信赖、社区驱动的倡议，反映了全球威胁形势的本质。有关基金会的结构、过渡计划以及社区参与机会的更多信息即将发布。"
  },
  {
    "id": "43714203",
    "title": "“Most promising signs yet” of alien life on a planet beyond our Solar System",
    "url": "https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide",
    "summary": "Astronomers using the James Webb Space Telescope have detected promising \"biosignatures\" – dimethyl sulfide and dimethyl disulfide – in the atmosphere of exoplanet K2-18b, a planet 124 lightyears away located within its star's habitable zone. These chemicals, primarily produced by marine organisms on Earth, could potentially indicate the presence of life.\n\nK2-18b is a \"Hycean\" planet, suggesting it has a liquid ocean and a hydrogen-rich atmosphere. While previous studies found methane and carbon dioxide in K2-18b's atmosphere, this latest research offers stronger evidence of dimethyl sulfide and dimethyl disulfide, detected with different instruments on the Webb telescope.\n\nThe team remains cautious, acknowledging that other, non-biological processes could potentially explain the presence of these chemicals. The detection currently stands at a \"three-sigma\" level of statistical significance, falling short of the \"five-sigma\" threshold required for a confirmed scientific discovery.\n\nScientists analyze exoplanet atmospheres by studying starlight passing through them during a transit, which leaves chemical fingerprints. The concentrations of dimethyl sulfide and dimethyl disulfide on K2-18b are significantly higher than on Earth, aligning with theoretical predictions for Hycean worlds. Further research is crucial to determine if these molecules can be produced non-biologically at the observed levels. While acknowledging the need for skepticism and further testing, researchers believe this discovery represents a significant step toward answering the question of whether we are alone in the universe.\n",
    "chinese_title": "太阳系外行星发现外星生命“最具希望的迹象”",
    "chinese_summary": "天文学家使用詹姆斯·韦伯太空望远镜在系外行星K2-18b的大气层中探测到有希望的“生物特征”——二甲基硫醚和二甲基二硫醚。该行星距离地球124光年，位于其恒星的宜居带内。这些化学物质主要由地球上的海洋生物产生，可能暗示着生命的存在。\n\nK2-18b是一颗“海洋”行星，表明它拥有液态海洋和富氢大气层。虽然之前的研究在K2-18b的大气层中发现了甲烷和二氧化碳，但这项最新的研究提供了更强的证据表明存在二甲基硫醚和二甲基二硫醚，这些物质是用韦伯望远镜上的不同仪器探测到的。\n\n该团队仍然保持谨慎，承认其他非生物过程也可能解释这些化学物质的存在。目前的探测结果具有“三西格玛”的统计显著性，低于确认为科学发现所需的“五西格玛”阈值。\n\n科学家通过研究恒星光在凌日期间穿过系外行星大气层的情况来分析其大气层，这会留下化学指纹。K2-18b上二甲基硫醚和二甲基二硫醚的浓度明显高于地球，与海洋世界的理论预测相符。进一步的研究对于确定这些分子是否能在观察到的水平上非生物地产生至关重要。在承认需要保持怀疑态度和进一步测试的同时，研究人员认为这项发现代表着在回答“我们在宇宙中是否孤独”这个问题上迈出了重要一步。"
  },
  {
    "id": "43711001",
    "title": "How a Forgotten Battle Created a More Peaceful World",
    "url": "https://worldhistory.substack.com/p/how-a-forgotten-battle-created-a",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "一场被遗忘的战役如何创造了一个更和平的世界",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43715030",
    "title": "Erlang Solutions' Blog round-up",
    "url": "https://www.erlang-solutions.com/blog/erlang-solutions-blog-round-up/",
    "summary": "Erlang Solutions' blog roundup covers a range of important topics in the tech world, aiming to inform businesses and tech enthusiasts. The articles highlight the transformative power of big data in healthcare, emphasizing predictive health trends, precision medicine, and data security using technologies like Erlang, Elixir, and SAFE.\n\nThe blog also explores the growing importance of digital wallets, detailing their benefits like improved security, cost savings, and global access, while also acknowledging associated challenges. Another article presents key takeaways from a survey on Women in BEAM, addressing representation gaps and the importance of role models within the Elixir community.\n\nFurthermore, the roundup offers practical tips for boosting IoT business security, including strong passwords, data encryption, regular audits, team training, and disabling unused features. Finally, it tackles DORA compliance for fintech businesses, explaining the Act's impact and outlining steps for building resilient and compliant operations. Erlang Solutions aims to simplify complex tech topics for their audience and invites further discussion.\n",
    "chinese_title": "Erlang Solutions博客精选",
    "chinese_summary": "Erlang Solutions博客综述涵盖了科技界一系列重要议题，旨在为企业和科技爱好者提供资讯。文章重点介绍了大数据在医疗保健领域的变革力量，强调使用Erlang、Elixir和SAFE等技术的预测性健康趋势、精准医疗和数据安全。\n\n该博客还探讨了数字钱包日益增长的重要性，详细介绍了其优势，如提高安全性、节省成本和全球访问，同时也承认了相关的挑战。另一篇文章介绍了关于“BEAM中的女性”调查的主要结论，讨论了代表性差距以及Elixir社区内榜样的重要性。\n\n此外，该综述还提供了提高物联网业务安全性的实用技巧，包括强密码、数据加密、定期审计、团队培训以及禁用未使用的功能。最后，它还探讨了金融科技企业的DORA合规性问题，解释了该法案的影响，并概述了构建弹性和合规运营的步骤。Erlang Solutions旨在为受众简化复杂的技术话题，并邀请进一步讨论。"
  },
  {
    "id": "43674892",
    "title": "Clowning Around: On the Principles of Clowning",
    "url": "https://funnyhow.substack.com/p/clowning-around-",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "小丑表演：小丑艺术原理",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43709770",
    "title": "Man who built ISP instead of paying Comcast expands to hundreds of homes (2022)",
    "url": "https://arstechnica.com/tech-policy/2022/08/man-who-built-isp-instead-of-paying-comcast-50k-expands-to-hundreds-of-homes/",
    "summary": "Jared Mauch, a Michigan man, is expanding his fiber-to-the-home ISP, Washtenaw Fiber Properties LLC, thanks to $2.6 million in government funding from the American Rescue Plan. Frustrated with the lack of good broadband options from AT&T and Comcast (Comcast quoted him $50,000 to extend its network), Mauch initially built his own network to serve his home and a few neighbors.\n\nNow, with the government grant, he's extending his 14-mile fiber network by an additional 38 miles, aiming to reach nearly 600 properties in Washtenaw County, going beyond the 417 required by his contract. He offers symmetrical 100Mbps service for $55/month and 1Gbps for $79/month, both with unlimited data and no hidden fees, along with participation in the FCC's Affordable Connectivity Program.\n\nMauch, who works as a network architect at Akamai, aims to complete half the project by the end of 2023 and the rest by the end of 2024, well ahead of the 2026 deadline.  Despite facing rising equipment costs, he has invested in equipment like an industrial air compressor. The county is touting this as a \"historic\" broadband investment and selected three other ISPs, including Comcast and Charter, for other areas. Mauch has become a local celebrity, even being saved in neighbors' phones as \"fiber cable guy,\" and provides a crucial service to a previously underserved rural community.\n",
    "chinese_title": "自己建ISP不付康卡斯特费用男子，将其服务扩展到数百户家庭 (2022)",
    "chinese_summary": "密歇根男子Jared Mauch凭借《美国救援计划》提供的260万美元政府资助，正在扩展他的光纤到户ISP，Washtenaw光纤地产有限责任公司。Mauch对AT&T和Comcast提供的宽带服务选择不足感到失望（Comcast报价5万美元才肯扩展网络），最初他自建网络，仅为自己家和几个邻居提供服务。\n\n现在，有了政府资助，他将把14英里的光纤网络再扩展38英里，目标是覆盖Washtenaw县近600处房产，超出合同要求的417处。他提供对称的100Mbps服务，每月55美元；1Gbps服务，每月79美元，两者都提供无限流量，没有隐藏费用，并且参与FCC的经济适用连接计划。\n\n在Akamai担任网络架构师的Mauch计划在2023年底前完成项目的一半，并在2024年底前完成剩余部分，远早于2026年的截止日期。尽管面临设备成本上涨，他还是投资了工业空气压缩机等设备。该县将此誉为“历史性的”宽带投资，并选择了包括Comcast和Charter在内的其他三家ISP来覆盖其他地区。Mauch已成为当地名人，甚至被邻居保存在电话里，备注为“光纤电缆人”，并为以前服务不足的农村社区提供了至关重要的服务。"
  },
  {
    "id": "43692677",
    "title": "America underestimates the difficulty of bringing manufacturing back",
    "url": "https://www.molsonhart.com/blog/america-underestimates-the-difficulty-of-bringing-manufacturing-back",
    "summary": "Molson Hart argues that recent tariffs imposed by the US government to bring manufacturing back to America are misguided and likely to fail. He provides 14 reasons, primarily centering on the fact that the US has underestimated the complexity and difficulty of reshoring manufacturing.\n\nKey reasons include that the tariffs aren't high enough to offset the existing cost advantages of manufacturing in countries like China, where robust industrial supply chains, established know-how, and a strong work ethic prevail. He asserts the US industrial supply chain is weak, and critical components are predominantly produced in Asia.\n\nHart criticizes the US workforce, citing issues such as work ethic and basic skills deficiencies compared to Chinese labor. He also highlights the lack of sufficient infrastructure, like reliable electricity and adequate transportation, to support a significant increase in domestic manufacturing.\n\nHe points out the long lead times required to build factories and establish efficient production, coupled with the uncertainty and complexity surrounding the tariffs, which are freezing business investment. Ultimately, he argues that many Americans are not willing or prepared for the demanding nature of manufacturing work, and the labor pool is already relatively tight.\n",
    "chinese_title": "美国低估了制造业回流的难度。",
    "chinese_summary": "莫尔森·哈特认为，美国政府为将制造业迁回美国而征收的最新关税是错误的，并且很可能会失败。 他提出了 14 个理由，主要集中在美国低估了制造业回流的复杂性和难度这一事实上。\n\n关键原因包括关税不足以抵消在中国等国家制造业的现有成本优势，这些国家拥有强大的工业供应链、成熟的专业知识和强大的职业道德。 他断言，美国的工业供应链薄弱，关键部件主要在亚洲生产。\n\n哈特批评了美国的劳动力，指出与中国劳动力相比，美国劳动力存在职业道德和基本技能不足等问题。 他还强调缺乏足够的基础设施，例如可靠的电力和充足的运输，来支持国内制造业的显著增长。\n\n他指出，建造工厂和建立高效生产需要很长的交付周期，再加上围绕关税的不确定性和复杂性，导致商业投资停滞不前。 最终，他认为许多美国人不愿意或没有准备好从事要求苛刻的制造业工作，而且劳动力市场已经相对紧张。"
  },
  {
    "id": "43678533",
    "title": "Query Engines: Push vs. Pull (2021)",
    "url": "https://justinjaffray.com/query-engines-push-vs.-pull/",
    "summary": "This article explores the \"push\" vs. \"pull\" execution models in query engines, aiming to clarify their differences and practical implications.\n\n**Pull-based (Volcano/Iterator) engines** are consumer-driven; operators produce rows only when requested by downstream operators. The article provides a basic Javascript implementation.\n\n**Push-based (Reactive/Stream) engines** are producer-driven; operators push data downstream when available. A Javascript implementation of a push-based engine is provided.\n\nThe article addresses two key questions raised by Snowflake's SIGMOD paper:\n\n1.  **DAG-shaped plans:** Push-based systems handle directed acyclic graphs (DAGs) more efficiently than pull-based systems, which are traditionally tree-structured. SQL's `WITH` clause and query planner optimizations can benefit from DAGs. Pull-based systems face challenges in scheduling and managing the lifetime of intermediate results in DAGs, potentially requiring unbounded buffering. Push-based systems decouple scheduling from output requests, allowing operators to force consumers to process rows and eliminating the need for extensive buffering.\n\n2.  **Cache efficiency:** While the Snowflake paper suggests push-based systems improve cache efficiency, the author argues that benefits stem more from query compilation to machine code (e.g., using LLVM) rather than the push model itself. Compiling a push-based query can result in more straightforward, easily unrolled code.\n\nThe article concludes that while introductory database materials focus on the iterator (pull) model, modern analytic systems increasingly explore the push model. The \"best\" choice depends on the specific needs of the query engine. Boundary impedance mismatch and algorithmic suitability were mentioned as considerations.\n",
    "chinese_title": "查询引擎：推送与拉取 (2021)",
    "chinese_summary": "本文探讨查询引擎中的“推”与“拉”执行模型，旨在阐明它们的差异和实际意义。\n\n**基于拉取（火山/迭代器）的引擎**是消费者驱动的；算子只有在下游算子请求时才生成行。本文提供了一个基本的 Javascript 实现。\n\n**基于推送（反应式/流式）的引擎**是生产者驱动的；算子在数据可用时向下游推送数据。提供了一个基于推送引擎的 Javascript 实现。\n\n本文探讨了 Snowflake 的 SIGMOD 论文提出的两个关键问题：\n\n1. **DAG 形计划：** 基于推送的系统比基于拉取的系统更有效地处理有向无环图 (DAG)，而基于拉取的系统传统上是树状结构的。SQL 的 `WITH` 子句和查询计划器优化可以受益于 DAG。基于拉取的系统在 DAG 中调度和管理中间结果的生命周期方面面临挑战，可能需要无限缓冲。基于推送的系统将调度与输出请求分离，允许算子强制消费者处理行，从而消除对大量缓冲的需求。\n\n2. **缓存效率：** 虽然 Snowflake 的论文表明基于推送的系统提高了缓存效率，但作者认为，其优势更多地源于将查询编译为机器代码（例如，使用 LLVM），而不是推送模型本身。编译基于推送的查询可以产生更直接、更容易展开的代码。\n\n本文总结道，虽然入门数据库材料侧重于迭代器（拉取）模型，但现代分析系统越来越多地探索推送模型。“最佳”选择取决于查询引擎的特定需求。边界阻抗不匹配和算法适用性被提及为考虑因素。"
  },
  {
    "id": "43690828",
    "title": "eInk Mode: Making web pages easier to read",
    "url": "https://jackscogito.blogspot.com/2025/04/e-ink-mode-making-web-pages-easier-to.html",
    "summary": "This article introduces \"Eink Mode,\" a web browsing mode designed to optimize website viewing on E Ink devices like e-readers and monitors, mimicking the experience of reading a physical book. Eink Mode presents web content in a paginated format, accessible through tapping the screen's left or right side for navigation, similar to turning pages. It prioritizes content presentation by minimizing UI elements.\n\nThe article details Eink Mode's features and operation. Users can enter Eink mode by clicking the eink icon or swiping left to right on the webpage. The mode supports rich gesture controls like swiping up/down to jump to the top/bottom of the page and keyboard shortcuts for desktop users.\n\nA key feature is preventing accidental clicks on hyperlinks and images, requiring a long-press to activate them. Users can also adjust text size using a two-finger pinch gesture, ensuring no text is cut off. Another feature is the ability to jump to the table of contents.\n\nEink Mode offers a highlight annotation tool, accessible via swipe or keyboard shortcut, with multiple colors selectable through multi-finger taps or keyboard commands. A floating action button provides access to highlighter colors and a \"notebook\" of highlighted content. This notebook compiles all highlighted passages, categorized by color, and can be saved as a PDF with links to the original webpage for note-taking and archiving. The article concludes by mentioning cross-page highlighting capability.\n",
    "chinese_title": "eInk模式：让网页更易读",
    "chinese_summary": "本文介绍了“墨水屏模式”，这是一种网页浏览模式，旨在优化在如电子阅读器和显示器等墨水屏设备上浏览网站的体验，模仿阅读实体书籍的感觉。墨水屏模式以分页格式呈现网页内容，通过点击屏幕左侧或右侧进行导航，类似于翻页。它通过最小化用户界面元素来优先呈现内容。\n\n本文详细介绍了墨水屏模式的功能和操作。用户可以通过点击墨水屏图标或在网页上从左向右滑动来进入墨水屏模式。该模式支持丰富的姿势控制，例如向上/向下滑动跳到页面顶部/底部，以及为桌面用户提供的键盘快捷键。\n\n一个关键功能是防止意外点击超链接和图像，需要长按才能激活它们。用户还可以使用双指捏合手势调整文本大小，确保没有文本被截断。另一个功能是跳转到目录。\n\n墨水屏模式提供高亮注释工具，可以通过滑动或键盘快捷键访问，可以通过多指轻敲或键盘命令选择多种颜色。一个浮动操作按钮提供对高亮颜色的访问和突出显示内容的“笔记本”。这个笔记本编译所有突出显示的段落，按颜色分类，并且可以保存为PDF文件，其中包含指向原始网页的链接，用于笔记和存档。文章最后提到跨页高亮功能。"
  },
  {
    "id": "43707719",
    "title": "OpenAI o3 and o4-mini",
    "url": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "OpenAI o3 和 o4-mini",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43691334",
    "title": "4chan Sharty Hack And Janitor Email Leak",
    "url": "https://knowyourmeme.com/memes/events/april-2025-4chan-sharty-hack-and-janitor-email-leak",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "4chan 沙提駭客與清潔工電郵洩露",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43714023",
    "title": "WordPress Feature API",
    "url": "https://github.com/Automattic/wp-feature-api",
    "summary": "The WordPress Feature API is a system designed to standardize and expose WordPress functionality for use by both servers, clients, and AI systems like LLMs. It provides a unified registry of WordPress features, leveraging existing functionality like REST endpoints, making them more discoverable and accessible. The API utilizes the MCP specification, tailored for WordPress's dual server and client nature, enabling features to be used on both the backend and frontend. While not implementing a full MCP server, the feature registry can be used by one if available.\n\nThe project is structured as a monorepo with packages including: a client-side SDK (`@wp-feature-api/client`) for interacting with the feature registry; a library (`@wp-feature-api/client-features`) containing standard client-side features; and a demo plugin (`wp-feature-api-demo`) showcasing API usage.\n\nA key aspect is the ability to filter features based on properties, keywords, categories, eligibility callbacks, and context matching, ensuring that the most relevant tools are available for specific user intents and contexts. Installation involves cloning the repository, installing dependencies with `npm run setup`, and building the packages with `npm run build`. The demo can be run using `@wordpress/env` and activating both the main \"WordPress Feature API\" plugin and the \"wp-feature-api-demo\" plugin. The API promotes a generic interface for functionality within WordPress beyond just LLM consumption.\n",
    "chinese_title": "WordPress 功能 API",
    "chinese_summary": "WordPress功能API是一个旨在标准化和暴露WordPress功能的系统，供服务器、客户端和人工智能系统（如LLM）使用。它提供了一个统一的WordPress功能注册表，利用现有的REST端点等功能，使其更易于发现和访问。该API采用MCP规范，专为WordPress的双服务器和客户端特性量身定制，使功能可以在后端和前端使用。虽然没有实现完整的MCP服务器，但功能注册表可以被现有的MCP服务器使用。\n\n该项目结构为一个单一代码仓库，包含多个包，其中包括：用于与功能注册表交互的客户端SDK（`@wp-feature-api/client`）；包含标准客户端功能的库（`@wp-feature-api/client-features`）；以及展示API用法的演示插件（`wp-feature-api-demo`）。\n\n一个关键方面是能够基于属性、关键字、类别、资格回调和上下文匹配来过滤功能，确保为特定用户意图和上下文提供最相关的工具。安装包括克隆存储库，使用`npm run setup`安装依赖项，以及使用`npm run build`构建包。可以使用`@wordpress/env`运行演示，并激活主“WordPress Feature API”插件和“wp-feature-api-demo”插件。该API旨在为WordPress中超越LLM消费的功能提供一个通用接口。"
  },
  {
    "id": "43676254",
    "title": "Breaking the Llama Community License",
    "url": "https://notes.victor.earth/youre-probably-breaking-the-llama-community-license/",
    "summary": "This article delves into potential violations of the Llama Community License Agreement, focusing on aspects often overlooked by the AI community. It highlights the discrepancy between Llama's marketing as \"open source\" and the reality of its restrictive license terms.\n\nThe author argues that simply using or distributing Llama materials, regardless of clicking \"I Accept,\" binds users to the agreement. Key violations include failing to prominently display \"Built with Llama\" on websites or products utilizing the model or its derivatives, a requirement introduced in Llama 3.x licenses. Prominent platforms like Ollama and Openrouter.ai are cited as potential violators.\n\nThe article also points out the naming convention stipulated by the license, requiring all fine-tuned models derived from Llama to begin with \"Llama-\", a rule widely ignored. Examples like \"Hermes 3\" are given as violations. NVIDIA's \"Llama-3.3-Nemotron-Super-49B-v1\" is highlighted as adhering to the licensing terms.\n\nFinally, the author discusses the \"Acceptable Use Policy,\" specifically the obligation to disclose any known dangers of an AI system built with Llama, including biases and factual inaccuracies. The author stresses the ambiguity of \"appropriate disclosure.\"\n\nThe author concludes by speculating on the reasons behind the widespread disregard for the license, suggesting possible ignorance, calculated risk-taking, or separate agreements with Meta. The piece underscores the importance of carefully reviewing the Llama Community License for anyone distributing or using Llama-based products, as Meta retains the option to enforce these terms in the future.\n",
    "chinese_title": "违反Llama社区许可协议",
    "chinese_summary": "本文深入探讨Llama社区许可协议的潜在违规行为，重点关注人工智能社区经常忽略的方面。文章突出了Llama被宣传为“开源”与其实际限制性许可条款之间的差异。\n\n作者认为，仅仅使用或分发Llama材料，无论是否点击“我接受”，都会使使用者受到协议的约束。主要违规行为包括未在网站或产品上显著显示“Built with Llama”（使用Llama构建），该要求在Llama 3.x许可中引入。Ollama和Openrouter.ai等知名平台被列为潜在的违规者。\n\n文章还指出许可规定的命名规范，要求所有从Llama衍生的微调模型都以“Llama-”开头，这一规则被广泛忽视。例如，“Hermes 3”被认为是违规行为。 NVIDIA的“Llama-3.3-Nemotron-Super-49B-v1”被强调为符合许可条款。\n\n最后，作者讨论了“可接受使用政策”，特别是披露使用Llama构建的AI系统的任何已知危险（包括偏见和事实错误）的义务。作者强调了“适当披露”的模糊性。\n\n作者最后推测了广泛无视许可的原因，提出了可能的无知、精打细算的冒险或与Meta达成的单独协议。文章强调，对于任何分发或使用基于Llama产品的个人来说，仔细审查Llama社区许可至关重要，因为Meta保留在未来执行这些条款的权利。"
  },
  {
    "id": "43705824",
    "title": "A high-throughput parser for the Zig programming language",
    "url": "https://github.com/Validark/Accelerated-Zig-Parser",
    "summary": "This article details the development of a high-throughput tokenizer and parser for the Zig programming language, aiming for significant performance improvements over the mainline Zig tokenizer. The project explores two tokenizer implementations: one using bitstrings to skip continuation-character matching and another employing vector compression to find all token extents simultaneously.\n\nPerformance benchmarks demonstrate substantial gains.  One version showed a 2.75x speed increase and a 2.47x reduction in memory usage compared to the legacy tokenizer in a test environment. The author outlines design principles for high performance: SIMD (Single Instruction, Multiple Data) for parallel processing of bytes, and SWAR (SIMD Within A Register) techniques. These techniques are used for identifying identifiers, keywords, whitespace, and comments.\n\nThe design also emphasizes reducing unpredictable branches by using perfect hash functions for keyword and operator identification.  The author leverages Zig's comptime execution feature for automated management of dummy operators/keywords in hashing schemes. Additional optimizations include allocating the upper-bound memory for tokens and using sentinels at file boundaries to simplify code and remove bounds checking. The work addresses memory consumption by storing token lengths instead of start indices, further compressing the data.\n",
    "chinese_title": "Zig编程语言的高吞吐量解析器",
    "chinese_summary": "本文详细介绍了 Zig 编程语言的高吞吐量词法分析器和语法分析器的开发，旨在显著提高性能，超越主线 Zig 词法分析器。该项目探索了两种词法分析器实现：一种使用位串来跳过延续字符匹配，另一种采用向量压缩来同时查找所有 token 范围。\n\n性能基准测试表明了显著的提升。在一个测试环境中，一个版本相比于旧版词法分析器，速度提高了 2.75 倍，内存使用量减少了 2.47 倍。作者概述了高性能的设计原则：SIMD（单指令多数据）用于字节的并行处理，以及 SWAR（寄存器内的 SIMD）技术。这些技术被用于识别标识符、关键字、空格和注释。\n\n该设计还强调通过使用完美哈希函数进行关键字和运算符识别来减少不可预测的分支。作者利用 Zig 的编译时执行特性来自动管理哈希方案中的虚拟运算符/关键字。其他优化包括为 token 分配上限内存，并在文件边界使用哨兵来简化代码并消除边界检查。该工作通过存储 token 长度而不是起始索引来解决内存消耗问题，从而进一步压缩数据。"
  },
  {
    "id": "43716160",
    "title": "How Meta AI Staff Deemed More Than 7M Books to Have No \"Economic Value\"",
    "url": "https://www.vanityfair.com/news/story/meta-ai-lawsuit",
    "summary": "This article details the copyright lawsuit, Richard Kadrey et al. v. Meta Platforms, over Meta's use of millions of pirated books to train its Llama AI model. The plaintiffs, prominent authors including Andrew Sean Greer, Junot Díaz, and Sarah Silverman, allege that Meta infringed on their copyrights by using illegal databases like LibGen and Z-Library to obtain the books without permission or payment.\n\nMeta defends its actions under \"fair use,\" arguing that its LLM project is \"highly transformative,\" and that using copyrighted material is vital for open-source AI development. They also argue that individual books have negligible economic value in training the AI, as the contribution of any single book is minimal. This argument is central to their fair use claim.\n\nThe lawsuit sheds light on Meta's internal deliberations regarding the use of pirated materials, with some employees expressing concerns about the ethical and legal implications. Internal communications reveal that Meta researchers sought as much long-form writing as possible, including books of all genres, while also attempting to remove copyright pages.\n\nThe article also touches on Meta's failed preliminary discussions with publishers regarding licensing fees, citing the complexities and costs of negotiating with millions of authors.  Former Meta lawyer Mark Lemley believes copyright law should focus on AI's output, not the training data.\n\nThe case, one of many copyright lawsuits against AI companies, raises fundamental questions about the value of art and literature in the age of generative AI and whether the large language models should be allowed to ingest copyrighted works to produce their outputs.\n",
    "chinese_title": "Meta AI 如何认定超过 700 万本书籍没有“经济价值”",
    "chinese_summary": "本文详细介绍了 Richard Kadrey 等人诉 Meta Platforms 的版权诉讼，该诉讼涉及 Meta 使用数百万盗版书籍来训练其 Llama AI 模型。原告包括 Andrew Sean Greer、Junot Díaz 和 Sarah Silverman 等著名作家，他们声称 Meta 未经许可或支付费用，使用 LibGen 和 Z-Library 等非法数据库获取书籍，侵犯了他们的版权。\n\nMeta 辩称其行为属于“合理使用”，认为其 LLM 项目具有“高度转化性”，并且使用受版权保护的材料对于开源 AI 的开发至关重要。他们还辩称，单本书籍在训练 AI 方面的经济价值微不足道，因为任何单本书籍的贡献都极小。这一论点是其合理使用主张的核心。\n\n该诉讼揭示了 Meta 内部对使用盗版材料的讨论，一些员工对其中的伦理和法律影响表示担忧。内部沟通显示，Meta 研究人员寻求尽可能多的长篇写作，包括所有类型的书籍，同时也试图删除版权页。\n\n文章还提到了 Meta 与出版商就许可费进行的初步讨论失败，理由是与数百万作者谈判的复杂性和成本。Meta 前律师 Mark Lemley 认为，版权法应侧重于 AI 的输出，而不是训练数据。\n\n该案件是针对 AI 公司的众多版权诉讼之一，提出了关于生成式 AI 时代艺术和文学的价值，以及大型语言模型是否应被允许摄取受版权保护的作品以产生其输出的根本问题。"
  },
  {
    "id": "43670921",
    "title": "In Two Moves, AlphaGo and Lee Sedol Redefined the Future (2016)",
    "url": "https://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future/",
    "summary": "This article recounts the historic Go match between Lee Sedol, a world champion, and AlphaGo, Google's AI system. AlphaGo's victory marked a significant milestone, demonstrating the rapid advancement of AI, particularly in complex strategic games.\n\nThe article highlights two pivotal moves: AlphaGo's Move 37 in Game Two, a move so unusual that even experts initially considered it a mistake, and Lee Sedol's Move 78 in Game Four, dubbed \"God's Touch\" for its brilliance and unexpectedness. Both moves were deemed to have a one-in-ten-thousand probability of being played.\n\nThe significance of these moves lies not just in their unexpected nature, but in what they reveal about the future of human-machine interaction. AlphaGo's victory showcases the potential of AI to surpass human capabilities in certain domains. However, Lee Sedol's \"God's Touch\" underscored that human intuition and creativity remain invaluable.\n\nThe author argues that the future isn't about humans versus machines, but rather humans *with* machines. By learning from AI, humans can expand their own understanding and abilities. Go player Fan Hui's ranking skyrocketed and Lee Sedol himself stated that AlphaGo opened his eyes to new possibilities in the game. The article concludes that the integration of human and artificial intelligence will lead to advancements neither could achieve alone.\n",
    "chinese_title": "两步棋，AlphaGo与李世乭重新定义未来 (2016)",
    "chinese_summary": "本文回顾了围棋世界冠军李世石与谷歌人工智能系统AlphaGo之间具有历史意义的围棋对弈。AlphaGo的胜利标志着一个重要的里程碑，展示了人工智能的快速发展，尤其是在复杂战略游戏领域。\n\n本文重点介绍了两个关键的落子：AlphaGo在第二局中的第37手，这一步棋非常不寻常，甚至专家最初都认为这是一个错误；以及李世石在第四局中的第78手，因其精妙和出人意料而被誉为“神之一手”。据说这两步棋的落子概率都只有万分之一。\n\n这些落子的意义不仅在于其出人意料的性质，还在于它们揭示了人机交互的未来。AlphaGo的胜利展示了人工智能在某些领域超越人类能力的潜力。然而，李世石的“神之一手”强调了人类的直觉和创造力仍然是无价的。\n\n作者认为，未来不是人与机器的对立，而是人与机器的合作。通过向人工智能学习，人类可以扩展自己的理解和能力。围棋棋手樊麾的排名飙升，李世石本人也表示AlphaGo让他对围棋有了新的认识。文章总结说，人类智能和人工智能的融合将带来双方都无法单独实现的进步。"
  },
  {
    "id": "43716665",
    "title": "TikTok Is Harming Children at an Industrial Scale",
    "url": "https://www.afterbabel.com/p/industrial-scale-harm-tiktok",
    "summary": "This article, \"TikTok Is Harming Children at an Industrial Scale,\" argues that TikTok is causing significant harm to children and young adults. The authors, Jon Haidt and Zach Rausch, draw primarily from legal briefs filed by 14 state Attorneys General in lawsuits against TikTok, citing internal reports, memos, and employee statements.\n\nThe article organizes the evidence into five clusters of harm: addictive and compulsive use, depression and anxiety, exposure to porn, violence and drugs, sexual exploitation and CSAM. TikTok insiders acknowledge these harms but often prioritize engagement metrics over user well-being. The article highlights TikTok's awareness of its addictive algorithm, its manipulative design features (like infinite scrolling and constant notifications), and the vulnerability of young users to these tactics.\n\nThe authors also point out TikTok's ineffective parental controls and poor content moderation, citing internal studies that reveal high leakage rates of harmful content like normalization of pedophilia and minor sexual solicitation. The piece aims to inform parents about the business practices of TikTok, showcasing how the company is aware of its negative impact on children's mental health and development but continues to prioritize growth and engagement regardless. Ultimately, the authors suggest that the potential ban of TikTok in the U.S. should be welcomed due to the widespread harm it inflicts on children.\n",
    "chinese_title": "TikTok正以工业规模危害儿童",
    "chinese_summary": "TikTok正以工业规模危害儿童\n本文《TikTok正以工业规模危害儿童》认为，TikTok正在对儿童和年轻人造成重大危害。作者乔恩·海特和扎克·劳施主要引用了14个州的总检察长在针对TikTok的诉讼中提交的法律摘要，其中引用了内部报告、备忘录和员工声明。\n\n文章将证据归纳为五类危害：成瘾和强迫性使用、抑郁和焦虑、接触色情内容、暴力和毒品、性剥削和儿童性虐待材料。TikTok内部人士承认这些危害，但通常将参与度指标置于用户福祉之上。文章强调了TikTok对其成瘾算法、操纵性设计功能（如无限滚动和持续通知）以及年轻用户对此类策略的脆弱性的认知。\n\n作者还指出，TikTok的家长控制功能无效，内容审核不力，并引用内部研究表明，有害内容的泄露率很高，例如恋童癖正常化和未成年人性招揽。本文旨在告知家长TikTok的商业行为，展示该公司如何意识到其对儿童心理健康和发展的负面影响，但仍然优先考虑增长和参与度。最终，作者认为，由于TikTok对儿童造成广泛的危害，美国应欢迎潜在的TikTok禁令。"
  },
  {
    "id": "43714533",
    "title": "Show HN: Startup Success Calculator",
    "url": "https://app.tactyqal.com",
    "summary": "This \"Show HN: Startup Success Calculator\" post likely points to a tool or resource aimed at helping founders assess their startup's potential for success. The title suggests a calculator, which implies an interactive tool leveraging metrics and signals to predict or estimate the likelihood of success. Because the content is simply \"startup-success-signal,\" it is impossible to know the specifics of the tool without access to the linked resource. However, we can infer the following based on the title:\n\n*   **Purpose:** The tool aims to provide an indication of a startup's chances of succeeding.\n*   **Method:** It likely uses a calculator format, suggesting input fields for various startup metrics or characteristics (e.g., market size, team experience, funding).\n*   **Output:** The output is probably a score, percentage, or qualitative assessment (e.g., \"high potential,\" \"moderate risk\") indicating the likelihood of success.\n*   **Target Audience:** The tool is designed for startup founders, investors, and potentially mentors seeking a quantifiable or structured way to evaluate startup potential.\n\nIn essence, this post highlights a new resource designed to help assess startup success, presumably through a calculative or formulaic approach. More information is needed to understand the specific factors considered and the underlying algorithm used by the \"calculator.\"\n",
    "chinese_title": "展示HN：初创公司成功计算器",
    "chinese_summary": "“Show HN：创业成功计算器”帖子可能指向一个旨在帮助创始人评估其创业成功潜力的工具或资源。 标题表明是一个计算器，这意味着一个利用指标和信号来预测或估计成功可能性的互动工具。由于内容仅为“startup-success-signal”，因此在没有访问链接资源的情况下，不可能了解该工具的具体细节。 但是，我们可以根据标题推断出以下内容：\n\n*   **目的：** 该工具旨在提供有关创业公司成功几率的指示。\n*   **方法：** 它可能使用计算器格式，表明存在用于各种创业公司指标或特征（例如，市场规模、团队经验、资金）的输入字段。\n*   **输出：** 输出可能是一个分数、百分比或定性评估（例如，“高潜力”、“中等风险”），表明成功的可能性。\n*   **目标受众：** 该工具专为寻求以可量化或结构化方式评估创业公司潜力的创业公司创始人、投资者，以及潜在的导师而设计。\n\n本质上，这篇文章突出了一个新的资源，旨在帮助评估创业成功，大概是通过计算或公式化方法。 需要更多信息来了解“计算器”考虑的具体因素和使用的底层算法。"
  },
  {
    "id": "43693900",
    "title": "TLS certificate lifetimes will officially reduce to 47 days",
    "url": "https://www.digicert.com/blog/tls-certificate-lifetimes-will-officially-reduce-to-47-days",
    "summary": "This DigiCert blog post discusses the CA/Browser Forum's decision to reduce the maximum lifetime of TLS certificates to 47 days by March 15, 2029, with incremental reductions beginning in March 2026. This change is driven by concerns about the trustworthiness of certificate information over time and the unreliability of certificate revocation systems.\n\nThe rollout schedule is as follows:\n\n*   **Until March 15, 2026:** 398-day maximum lifetime and validation reuse period.\n*   **March 15, 2026:** 200-day maximum lifetime and validation reuse period, SII validation reuse reduced to 398 days.\n*   **March 15, 2027:** 100-day maximum lifetime and validation reuse period.\n*   **March 15, 2029:** 47-day maximum lifetime, 10-day validation reuse period.\n\nApple, who proposed the change, argues that shorter lifetimes necessitate automation for effective certificate lifecycle management and mitigate the risks associated with revoked certificates. The reduced validation reuse period highlights the need for frequent revalidation.\n\nDigiCert emphasizes that shorter certificate lifetimes will not increase costs for customers with annual subscriptions. They anticipate a move towards automation and offer solutions like Trust Lifecycle Manager and CertCentral, including ACME support, to facilitate this transition. The company encourages readers to explore automation options to manage certificate lifecycles efficiently.\n",
    "chinese_title": "TLS证书有效期将正式缩短至47天",
    "chinese_summary": "DigiCert博客：TLS证书最长有效期将于2029年缩短至47天\n\n该DigiCert博客文章讨论了CA/浏览器论坛决定于2029年3月15日前将TLS证书的最长有效期缩短至47天，并从2026年3月开始逐步缩短。此变更的原因是人们担心证书信息随着时间的推移而失去可信度，以及证书吊销系统不可靠。\n\n推出时间表如下：\n\n*   **2026年3月15日前：** 最长有效期和验证重用期为398天。\n*   **2026年3月15日：** 最长有效期和验证重用期为200天，SII验证重用期缩短至398天。\n*   **2027年3月15日：** 最长有效期和验证重用期为100天。\n*   **2029年3月15日：** 最长有效期为47天，验证重用期为10天。\n\n苹果公司提出了这项变更，他们认为更短的有效期要求必须实现自动化才能有效地管理证书生命周期，并降低与吊销证书相关的风险。 缩短的验证重用期突显了频繁重新验证的必要性。\n\nDigiCert强调，更短的证书有效期不会增加年度订阅客户的成本。 他们预计将转向自动化，并提供Trust Lifecycle Manager和CertCentral等解决方案（包括ACME支持）来促进这一过渡。 该公司鼓励读者探索自动化选项，以有效管理证书生命周期。"
  },
  {
    "id": "43705649",
    "title": "Dirty tricks 6502 programmers use (2019)",
    "url": "https://nurpax.github.io/posts/2019-08-18-dirty-tricks-6502-programmers-use.html",
    "summary": "This article explores the dirty tricks 6502 programmers used in a Commodore 64 coding competition to draw two diagonal lines using the fewest bytes possible. The article analyzes the submissions and details the techniques used for optimization.\n\nThe core challenge involves manipulating screen and color RAM to draw the lines. Initial approaches involve direct memory writes and unrolled loops, but these prove inefficient. The article then delves into several \"dirty tricks\" to reduce code size:\n\n*   **Scrolling:** Instead of calculating memory addresses for each pixel, the code draws on the last screen row and uses a ROM routine (`JSR $E8EA`) to scroll the entire screen upwards, saving address calculation overhead.\n*   **Self-Modifying Code (SMC):** Replacing redundant code sequences with self-modifying code reduces the overall byte count.\n*   **Exploiting Power-On State:** Making assumptions about register values and memory contents at program start saves initialization bytes. Specifically, leveraging zero-page memory ($d5, $22) to avoid explicit loading of constants.\n*   **Smaller Startup:** Eliminating the BASIC startup sequence using stack manipulation or BASIC warm reset vector overwrites allows the program to execute directly.\n*   **Unconventional Control Flow:** Restructuring control flow and utilizing conditional branches instead of absolute jumps minimizes branching code size. Moving the scroll action to the top of the loop reduces overhead of skipping the last frame.\n*   **Bitpacked Line Drawing:** Packing the line pattern into an 8-bit constant saves the overhead of incrementing the line counter.\n\nThe winning entry achieved 34 bytes by combining these tricks, highlighting the importance of memory exploitation and instruction-level optimization for minimizing code size on the 6502.\n",
    "chinese_title": "6502程序员使用的脏技巧 (2019)",
    "chinese_summary": "本文探讨了Commodore 64编程竞赛中，6502程序员为了用最少字节绘制两条对角线而使用的各种“肮脏”技巧。文章分析了提交的作品，并详细介绍了用于优化的技术。\n\n核心挑战在于操纵屏幕和颜色RAM来绘制线条。最初的方法涉及直接内存写入和展开循环，但这些方法效率不高。然后，文章深入研究了几种减少代码大小的“肮脏”技巧：\n\n*   **滚动：** 代码不是为每个像素计算内存地址，而是在屏幕的最后一行绘制，并使用ROM例程(`JSR $E8EA`)向上滚动整个屏幕，从而节省了地址计算的开销。\n*   **自修改代码 (SMC)：** 用自修改代码替换冗余的代码序列可以减少总字节数。\n*   **利用开机状态：** 假设程序启动时的寄存器值和内存内容，从而节省初始化字节。具体来说，利用零页内存（$d5, $22）来避免显式加载常量。\n*   **更小的启动：** 使用堆栈操作或BASIC热启动向量覆盖来消除BASIC启动序列，使程序可以直接执行。\n*   **非常规控制流：** 重构控制流并利用条件分支而不是绝对跳转可以最大限度地减少分支代码的大小。将滚动操作移动到循环的顶部可减少跳过最后一帧的开销。\n*   **位压缩线条绘制：** 将线条模式打包成一个8位常量，可以节省递增线条计数器的开销。\n\n获胜作品通过结合这些技巧实现了34字节，突出了内存利用和指令级优化对于最小化6502上的代码大小的重要性。"
  },
  {
    "id": "43703623",
    "title": "An Introduction to Stochastic Calculus (2022)",
    "url": "https://bjlkeng.io/posts/an-introduction-to-stochastic-calculus/",
    "summary": "This article serves as an introduction to stochastic calculus, an extension of standard calculus used to analyze stochastic processes. It's motivated by the need to model physical and financial phenomena involving randomness, often represented by stochastic differential equations. A key challenge arises from noise terms, particularly \"white noise,\" which are theoretical constructs with properties like uncorrelated fluctuations and infinite variance, making traditional integration difficult.\n\nThe article then delves into the measure-theoretic definition of probability, probability spaces, and random variables to provide the rigorous foundation needed for understanding stochastic calculus. It covers concepts like sigma-algebras, measurable spaces, and probability measures, emphasizing their importance when dealing with uncountable infinities, which are common in continuous-time stochastic processes.\n\nThe article outlines the structure of stochastic processes, including definitions, examples (like the Bernoulli process), and concepts like adapted processes and the Wiener process. It further explores Itô calculus, a specific type of stochastic calculus used for Brownian motion, covering Itô processes, Itô integrals, and Itô's Lemma. Finally, it discusses applications of stochastic calculus, particularly in the Black-Scholes-Merton model for options pricing and the Langevin equation for modeling stochastic phenomena. The article aims to provide a blend of intuition, rigor, and examples to facilitate understanding of this complex subject.\n",
    "chinese_title": "随机微积分导论 (2022)",
    "chinese_summary": "本文旨在介绍随机微积分，它是标准微积分的扩展，用于分析随机过程。其动机是需要对涉及随机性的物理和金融现象进行建模，这些现象通常由随机微分方程表示。一个关键挑战来自噪声项，特别是“白噪声”，这是一种具有非相关波动和无限方差等属性的理论构造，使得传统积分变得困难。\n\n然后，本文深入探讨概率的测度论定义、概率空间和随机变量，为理解随机微积分提供所需的严格基础。它涵盖了诸如σ-代数、可测空间和概率测度等概念，强调了它们在处理连续时间随机过程中常见的不可数无穷时的重要性。\n\n本文概述了随机过程的结构，包括定义、示例（如伯努利过程）以及诸如适应过程和维纳过程等概念。它进一步探讨了伊藤微积分，这是一种用于布朗运动的特定类型的随机微积分，涵盖了伊藤过程、伊藤积分和伊藤引理。最后，它讨论了随机微积分的应用，特别是在期权定价的布莱克-斯科尔斯-莫顿模型和用于模拟随机现象的朗之万方程中。本文旨在提供直觉、严谨和示例的结合，以促进对这一复杂主题的理解。"
  },
  {
    "id": "43714476",
    "title": "The Atari 1200XL Fiasco",
    "url": "https://www.goto10retro.com/p/the-atari-1200xl-fiasco",
    "summary": "This article discusses the Atari 1200XL, a short-lived computer intended to replace the Atari 800 and compete with the Commodore 64. Released in early 1983, it boasted a sleek new design, 64K of RAM, and several keyboard improvements, including function keys and a Help key.\n\nHowever, the 1200XL was a commercial failure due to two key issues: compatibility and price. The updated ROM caused incompatibility with popular software like Letter Perfect, upsetting users. Furthermore, its $800 price tag was significantly higher than the Commodore 64, making it unattractive to consumers. Other issues included lack of built-in BASIC, and a lack of +12V power on the SIO port.\n\nThe failure of the 1200XL led to increased sales of the cheaper and more compatible Atari 800. Atari quickly discontinued the 1200XL in June 1983, replacing it with the more successful 600XL and 800XL.\n\nDespite its initial failure, the Atari 1200XL is now a highly sought-after collectible due to its rarity. Its keyboard is well-regarded, and modifications can address its hardware compatibility issues. Software compatibility is less of a concern today, with workarounds available for older programs. While larger than its successors and lacking built-in BASIC, the 1200XL remains a fascinating piece of Atari history.\n",
    "chinese_title": "雅达利1200XL惨败",
    "chinese_summary": "本文讨论了雅达利1200XL，这是一款旨在取代雅达利800并与Commodore 64竞争的短命电脑。它于1983年初发布，拥有时尚的新设计、64K内存以及多项键盘改进，包括功能键和帮助键。\n\n然而，1200XL因兼容性和价格这两个关键问题而商业上失败。更新后的ROM导致与流行软件（如Letter Perfect）不兼容，令用户不满。此外，其800美元的售价远高于Commodore 64，使其对消费者缺乏吸引力。其他问题包括缺少内置BASIC以及SIO端口缺少+12V电源。\n\n1200XL的失败导致更便宜且更兼容的雅达利800销量增加。雅达利于1983年6月迅速停产了1200XL，并用更成功的600XL和800XL取而代之。\n\n尽管最初失败，但雅达利1200XL现在因其稀有性而成为备受追捧的收藏品。它的键盘备受好评，并且可以通过修改来解决其硬件兼容性问题。如今，软件兼容性已不再是问题，因为旧程序有可用的解决方法。虽然比其后继者更大且缺少内置BASIC，但1200XL仍然是雅达利历史上令人着迷的一部分。"
  },
  {
    "id": "43669540",
    "title": "Nix Trigonometric Math Library from Ground Zero",
    "url": "https://lantian.pub/en/article/modify-computer/nix-trigonometric-math-library-from-zero.lantian/",
    "summary": "This article details the author's journey to create a pure Nix implementation of trigonometric functions to calculate network latency between their VPS nodes, using the Haversine formula based on latitude and longitude coordinates. The initial approach using Python's `geopy` was slow due to Nix creating isolated build environments for each calculation.\n\nThe author then develops a Nix library from scratch, implementing:\n\n*   **sin, cos, tan:** Using Taylor expansions, optimized by calculating each expansion term iteratively to avoid precision loss, and terminating when the term falls below a specified accuracy threshold. Cosine is derived from sine, and tangent from sine and cosine.\n*   **arctan:**  Taylor expansion proves too slow.  An approximation is used instead: the arctangent function is approximated using polynomial regression on the interval [0,1], with other ranges mapped to this interval using arctangent identities.\n*   **sqrt:**  Implemented using the Newtonian method for iterative approximation.\n\nFinally, the Haversine formula is implemented using these functions to calculate distances, and then theoretical network latency based on light speed. The author provides code snippets for each function and includes a link to their GitHub repository (xddxdd/nix-math) containing the complete library. The article concludes by demonstrating how to use the library in a Nix Flake. The goal is achieved: calculating approximate network latency without relying on external tools like Python, resulting in faster and more reproducible Nix builds.\n",
    "chinese_title": "从零开始的Nix三角函数数学库",
    "chinese_summary": "本文详细介绍了作者使用纯Nix实现三角函数，以计算其VPS节点间网络延迟的历程。该方法基于经纬度坐标，并使用Haversine公式。最初使用Python的`geopy`库由于Nix为每次计算创建隔离的构建环境而速度缓慢。\n\n随后，作者从头开始开发了一个Nix库，实现了：\n\n*   **sin, cos, tan:** 使用泰勒展开，通过迭代计算每个展开项来优化，以避免精度损失，并在该项低于指定的精度阈值时终止。余弦从正弦派生，正切从正弦和余弦派生。\n*   **arctan:** 泰勒展开被证明太慢。因此采用了一种近似方法：反正切函数使用多项式回归在[0,1]区间上进行近似，其他范围使用反正切恒等式映射到此区间。\n*   **sqrt:** 使用牛顿法实现迭代近似。\n\n最后，使用这些函数实现Haversine公式来计算距离，然后基于光速计算理论网络延迟。作者提供了每个函数的代码片段，并包含一个指向其GitHub存储库 (xddxdd/nix-math) 的链接，其中包含完整的库。文章最后演示了如何在Nix Flake中使用该库。目标已实现：无需依赖Python等外部工具即可计算近似网络延迟，从而实现更快、更可重现的Nix构建。"
  },
  {
    "id": "43713877",
    "title": "Sniffle: A sniffer for Bluetooth 5 and 4.x LE",
    "url": "https://github.com/nccgroup/Sniffle",
    "summary": "Sniffle is a Bluetooth 5 and 4.x (LE) sniffer utilizing TI CC1352/CC26x2 hardware. It boasts features like support for BT5 PHY modes, extended advertising, channel selection algorithms, and the ability to sniff advertisements on all three primary channels for improved reliability.\n\n**Key Features:**\n\n*   Supports Bluetooth 5 and 4.x LE.\n*   BT5/4.2 extended length packets.\n*   BT5 Channel Selection Algorithms.\n*   BT5 PHY modes.\n*   Advertisement filtering by MAC, RSSI, IRK, or string.\n*   BT5 extended advertising (non-periodic).\n*   Captures advertisements from a target MAC on all three primary channels.\n*   PCAP export (Ubertooth compatible) and Wireshark plugin.\n*   Extensible Python host-side software.\n\n**Hardware Requirements:**\n\nSeveral TI Launchpad boards are supported, including CC26x2R, CC2652RB, CC1352R, CC1352P, CC2652R7, CC1352P7, CC2651P3 and CC1354P10 as well as the SONOFF CC2652P USB Dongle Plus and EC Catsniffer V3.\n\n**Software Requirements:**\n\nARM GNU Toolchain, TI SimpleLink Low Power F2 SDK, TI DSLite Programmer, and Python 3.9+ with PySerial are required. Firmware can be built from source or prebuilt binaries can be flashed using UniFlash/DSLite.\n\n**Installation:**\n\nInstructions are provided for installing GCC, the TI SDK, DSLite, and flashing firmware onto various supported devices (TI Launchpads, SONOFF dongle, Catsniffer V3). Specific instructions for each device type should be followed carefully.\n\n**Usage:**\n\nThe `sniff_receiver.py` script provides command-line options for specifying the serial port, baud rate, advertising channel, RSSI filter, MAC address filter, IRK filter, string filter, and output file. It also supports active/passive scanning, extended advertising capture, and CRC error capture. Instructions are provided on utilizing MAC/IRK filtering to hop along with advertisements and have reliable connection sniffing.\n",
    "chinese_title": "嗅嗅：一款针对蓝牙5和4.x LE的嗅探器",
    "chinese_summary": "Sniffle：基于TI CC1352/CC26x2硬件的蓝牙5和4.x(LE)嗅探器。支持BT5 PHY模式、扩展广播、信道选择算法，并可在所有三个主要信道上嗅探广播，以提高可靠性。\n\n**主要特性：**\n\n*   支持蓝牙5和4.x LE。\n*   BT5/4.2扩展长度数据包。\n*   BT5信道选择算法。\n*   BT5 PHY模式。\n*   通过MAC、RSSI、IRK或字符串进行广播过滤。\n*   BT5扩展广播（非周期性）。\n*   捕获目标MAC在所有三个主要信道上的广播。\n*   PCAP导出（兼容Ubertooth）和Wireshark插件。\n*   可扩展的Python主机端软件。\n\n**硬件\n\n支持多种TI Launchpad开发板，包括CC26x2R、CC2652RB、CC1352R、CC1352P、CC2652R7、CC1352P7、CC2651P3和CC1354P10，以及SONOFF CC2652P USB Dongle Plus和EC Catsniffer V3。\n\n**软件\n\n需要ARM GNU工具链、TI SimpleLink Low Power F2 SDK、TI DSLite Programmer和带有PySerial的Python 3.9+。固件可以从源代码构建，也可以使用UniFlash/DSLite刷入预编译的二进制文件。\n\n**安装：**\n\n提供了安装GCC、TI SDK、DSLite以及将固件刷入各种支持设备（TI Launchpad、SONOFF dongle、Catsniffer V3）的说明。应仔细遵循每种设备类型的具体说明。\n\n**用法：**\n\n`sniff_receiver.py`脚本提供了命令行选项，用于指定串口、波特率、广播信道、RSSI滤波器、MAC地址滤波器、IRK滤波器、字符串滤波器和输出文件。它还支持主动/被动扫描、扩展广播捕获和CRC错误捕获。提供了有关利用MAC/IRK过滤来跟随广播并进行可靠的连接嗅探的说明。"
  },
  {
    "id": "43705796",
    "title": "Science, the Endless Frontier (1945) [pdf]",
    "url": "https://nsf-gov-resources.nsf.gov/2023-04/EndlessFrontier75th_w.pdf",
    "summary": "I am unable to directly analyze the content of the PDF file to provide a comprehensive summary of \"Science, the Endless Frontier (1945)\". The provided text appears to be the raw, encoded content of the PDF, rather than the actual readable text of the report.\n\nHowever, based on the title and historical context, I can infer the likely key points of the report:\n\n\"Science, the Endless Frontier\" (1945), written by Vannevar Bush in response to a request from President Franklin D. Roosevelt, is a landmark document advocating for government funding of scientific research in the United States.\n\n**Likely Key Points:**\n\n*   **Post-War Need for Science:** The report likely argued that the scientific advancements made during World War II should be continued and applied to peacetime needs.\n*   **Government Funding is Crucial:** It advocated for federal government support of basic scientific research, emphasizing that such research is essential for long-term economic growth, public health, and national security.\n*   **Importance of Basic Research:** The report probably stressed the distinction between basic research (fundamental inquiry) and applied research (practical applications) and argued for prioritizing basic research as the foundation for future innovations.\n*   **Supporting Education & Training:** It likely highlighted the importance of educating and training future generations of scientists and engineers.\n*   **Decentralized Administration:** The report possibly recommended that government funding should be administered through decentralized institutions like universities, rather than directly by government agencies, to ensure academic freedom and foster creativity.\n*   **Impact:** The report's recommendations significantly influenced the development of the U.S. science and technology policy, leading to the establishment of the National Science Foundation (NSF) and shaping the model for government support of scientific research that persists to this day.\n",
    "chinese_title": "科学：无尽的前沿 (1945) [pdf]",
    "chinese_summary": "我无法直接分析PDF文件的内容，从而提供对《科学：无尽的前沿》（1945）的全面总结。提供的文本似乎是PDF的原始编码内容，而不是报告的实际可读文本。\n\n然而，根据标题和历史背景，我可以推断出报告可能的主要观点：\n\n《科学：无尽的前沿》（1945）由范内瓦·布什应富兰克林·D·罗斯福总统的要求撰写，是一份具有里程碑意义的文件，倡导政府资助美国的科学研究。\n\n**可能的主要观点：**\n\n*   **战后对科学的需求：** 该报告可能认为，二战期间取得的科学进步应继续并应用于和平时期的需求。\n*   **政府资助至关重要：** 它倡导联邦政府支持基础科学研究，强调这种研究对于长期经济增长、公共卫生和国家安全至关重要。\n*   **基础研究的重要性：** 该报告可能强调了基础研究（基础探究）和应用研究（实际应用）之间的区别，并主张优先发展基础研究，将其作为未来创新的基础。\n*   **支持教育和培训：** 它可能强调了教育和培训未来一代科学家和工程师的重要性。\n*   **分散式管理：** 该报告可能建议，政府资助应通过大学等分散式机构进行管理，而不是直接由政府机构管理，以确保学术自由并培养创造力。\n*   **影响：** 该报告的建议对美国科技政策的发展产生了重大影响，促成了国家科学基金会（NSF）的成立，并塑造了沿用至今的政府支持科学研究的模式。"
  },
  {
    "id": "43711706",
    "title": "Jellyfin as a Spotify alternative",
    "url": "https://coppolaemilio.com/entries/i-left-spotify-what-happened-next/",
    "summary": "Emi chronicles their journey away from Spotify, detailing the frustrations of finding a suitable replacement for local music playback. Initially, they were disappointed with traditional music players like Winamp, VLC, and Foobar2000, finding them clunky and difficult to use. They even attempted building a custom web-based music player, but ran into limitations with offline access. Apple Music served as a temporary solution, but the storage limitations and persistent ads were dissatisfying.\n\nUltimately, Emi discovered Jellyfin, an open-source media server solution, through a Jeff Geerling video. Jellyfin offered all the features they desired, including streaming and offline playback capabilities via dedicated apps like Finamp. While self-hosting was initially a concern, Emi found it surprisingly easy to set up, even using an old computer as a home server.\n\nThe positive experience with Jellyfin led Emi to embrace self-hosting further, adding Immich (a Google Photos alternative) to their setup. The author encourages readers to explore self-hosting as a way to gain more control over their digital content and access it from anywhere. They envision a future where individuals rely less on centralized services and more on personally managed solutions for their media. The article concludes with a call to action to try self-hosting, emphasizing its accessibility and potential benefits.\n",
    "chinese_title": "Jellyfin：Spotify的替代方案",
    "chinese_summary": "Emi 记录了他们离开 Spotify 的旅程，详细描述了寻找合适的本地音乐播放替代品的挫败感。起初，他们对 Winamp、VLC 和 Foobar2000 等传统音乐播放器感到失望，觉得它们笨重且难以使用。他们甚至尝试构建一个自定义的基于 Web 的音乐播放器，但遇到了离线访问的限制。Apple Music 曾作为临时解决方案，但存储限制和持续不断的广告令人不满。\n\n最终，Emi 通过 Jeff Geerling 的视频发现了 Jellyfin，一个开源媒体服务器解决方案。Jellyfin 提供了他们想要的所有功能，包括流媒体和通过 Finamp 等专用应用程序进行离线播放的功能。虽然自托管最初是一个令人担忧的问题，但 Emi 发现设置起来出奇地容易，甚至使用一台旧电脑作为家庭服务器。\n\nJellyfin 的积极体验促使 Emi 进一步拥抱自托管，并将 Immich（一个 Google 相册替代品）添加到他们的设置中。作者鼓励读者探索自托管，以此来更好地控制他们的数字内容并从任何地方访问它。他们设想了一个未来，个人将减少对集中式服务的依赖，更多地依赖于个人管理的媒体解决方案。文章最后呼吁大家尝试自托管，强调它的可访问性和潜在好处。"
  },
  {
    "id": "43658089",
    "title": "Googler... ex-Googler",
    "url": "https://nerdy.dev/ex-googler",
    "summary": "Adam, a former Google employee, expresses his shock and anger after his role at Google was unexpectedly eliminated. He emphasizes that he was told his termination wasn't based on performance and that he could potentially find another role within Google, yet his access to company resources was immediately revoked, making him feel unwelcome.\n\nHe highlights the ironic timing of the layoff, occurring while he was at a Chrome team-building offsite, actively contributing to innovative projects. He laments the loss of opportunities he was anticipating, including speaking engagements at Google I/O and his involvement in various Google projects related to CSS and web developer tools.\n\nAdam lists a significant number of responsibilities and contributions that are now lost, including his membership in the CSS Working Group, Developer Office Hours, and access to important codebases. He also acknowledges the likely loss of relationships he cultivated over years.\n\nHe conveys feelings of betrayal, lack of appreciation, shame, and anger, stating he feels like a disposable \"cog\" within a large corporation. He provides contact information on Bluesky and a personal email address for those who wish to reach out, but anticipates potential delays in responding due to the overwhelming nature of the situation.\n",
    "chinese_title": "谷歌人...前谷歌人",
    "chinese_summary": "前谷歌员工亚当对其在谷歌的角色被意外取消表示震惊和愤怒。他强调，他被告知解雇并非基于绩效，并且他有可能在谷歌内部找到另一个职位，但他的公司资源访问权限却立即被撤销，这让他感到不受欢迎。\n\n他强调了裁员的时机具有讽刺意味，发生在他参加Chrome团队建设活动，并积极为创新项目做出贡献之时。他感叹失去了他所期待的机会，包括在Google I/O上的演讲以及他参与的与CSS和Web开发者工具相关的各种Google项目。\n\n亚当列举了大量现在已失去的职责和贡献，包括他作为CSS工作组成员、开发者办公时间以及对重要代码库的访问权限。他还承认，他多年来建立的关系也可能失去。\n\n他表达了背叛、缺乏赏识、羞耻和愤怒的感觉，声称自己感觉像一个大型公司里可随意丢弃的“齿轮”。他提供了Bluesky上的联系方式和一个个人电子邮件地址，供那些想联系他的人使用，但他预计由于情况过于复杂，回复可能会延迟。"
  },
  {
    "id": "43700633",
    "title": "Markov Chain Monte Carlo Without All the Bullshit (2015)",
    "url": "https://www.jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/",
    "summary": "This article, \"Markov Chain Monte Carlo Without All the Bullshit,\" aims to explain MCMC methods in a clear, jargon-free manner. It criticizes the overly complex language often used in statistical explanations of MCMC.\n\nThe core problem MCMC solves is efficiently sampling from a complex probability distribution, D, when only black-box access to the probability function p(x) is available. This means you can input an element 'x' and get its probability p(x), but you don't know the underlying process generating 'x'. The article illustrates this with an example of estimating probabilities of baby names. A naive approach of random generation and probability-based coin flips is inefficient due to the potentially exponential size of the sample space.\n\nMCMC uses a Markov chain (a random walk on a graph) to address this. The key is to construct a graph where the stationary distribution (the long-term probability of being at a given vertex) matches the desired probability distribution D. The article explains the stationary distribution theorem and conditions like strong connectivity required for it to hold. The transition probabilities between vertices are represented by a matrix, A, enabling linear algebra techniques.\n\nThe article then describes the Metropolis-Hastings algorithm, a method for constructing a Markov chain with the desired stationary distribution. It involves placing elements of the sample space, X, on a lattice and adding edges to neighboring points. The transition probabilities between these points are then carefully defined based on the black-box access to p(x).  The goal is to create a random walk that converges quickly to the stationary distribution, enabling efficient sampling from D.\n",
    "chinese_title": "没有废话的马尔可夫链蒙特卡洛 (2015)",
    "chinese_summary": "本文《去伪存真的马尔可夫链蒙特卡洛法》旨在以清晰、通俗易懂的方式解释MCMC方法。 它批评了统计学对MCMC的解释中经常使用的过于复杂的术语。\n\nMCMC解决的核心问题是，当只有黑盒访问概率函数p(x)时，如何有效地从复杂的概率分布D中采样。 这意味着您可以输入一个元素“x”并获得其概率p(x)，但您不知道生成“x”的底层过程。 文章用估计婴儿名字概率的例子来说明这一点。 由于样本空间可能呈指数级增长，因此随机生成和基于概率的抛硬币这种幼稚的方法效率低下。\n\nMCMC使用马尔可夫链（图上的随机游走）来解决这个问题。 关键是构建一个图，其中平稳分布（位于给定顶点的长期概率）与所需的概率分布D相匹配。 文章解释了平稳分布定理以及使其成立所需的诸如强连通性之类的条件。 顶点之间的转移概率由矩阵A表示，从而可以使用线性代数技术。\n\n然后，文章描述了 Metropolis-Hastings 算法，这是一种构建具有所需平稳分布的马尔可夫链的方法。 它涉及将样本空间X的元素放置在格子上，并向相邻点添加边。 然后，基于对p(x)的黑盒访问，仔细定义这些点之间的转移概率。 目标是创建一个快速收敛到平稳分布的随机游走，从而能够有效地从D中采样。"
  },
  {
    "id": "43677862",
    "title": "Demolishing the Fry's Electronics in Burbank",
    "url": "https://www.latimes.com/00000196-230a-d4c4-abd7-fb5a95770000-123",
    "summary": "In April 2025, the Fry's Electronics store in Burbank, California, known for its iconic spaceship design, was demolished. The store, which had been a landmark since its opening in 1995, closed its doors in 2021. Rebecca Castillo, prompted by a post on social media, visited the site and witnessed the demolition. While the spaceship facade could not be saved, the demolition crew managed to preserve one alien relic from the building's interior. The lot, located at the corner of Hollywood Way and Vanowen Street, is planned for redevelopment into a large apartment complex with approximately 800 units. The article is written by Rebecca Castillo, a video creator and special projects lead for the Los Angeles Times, who is a Southern California native and alumna of Swarthmore College and USC.\n",
    "chinese_title": "拆除伯班克Fry's电子商店",
    "chinese_summary": "2025年4月，位于加州伯班克、以标志性宇宙飞船设计著称的Fry's Electronics商店被拆除。这家自1995年开业以来一直是地标的商店于2021年关闭。受社交媒体帖子的启发，丽贝卡·卡斯蒂略参观了现场并目睹了拆除过程。虽然宇宙飞船外观未能保留，但拆除人员设法保存了一件来自建筑内部的外星文物。该地块位于好莱坞路和凡诺文街的拐角处，计划重新开发成一个拥有约800个单元的大型公寓综合体。本文由洛杉矶时报的视频创作者和特殊项目负责人丽贝卡·卡斯蒂略撰写，她是南加州本地人，也是斯沃斯莫尔学院和南加州大学的校友。"
  },
  {
    "id": "43705144",
    "title": "Show HN: We Put Chromium on a Unikernel (OSS Apache 2.0)",
    "url": "https://github.com/onkernel/kernel-images",
    "summary": "This \"Show HN\" post introduces a project that puts the Chromium browser on a unikernel, offering a sandboxed and ready-to-use browser environment for automated workflows, AI agent development, and custom tools. The project provides both Docker and unikernel implementations.\n\nKey features include a pre-configured Chrome browser compatible with Chrome DevTools-based frameworks like Playwright and Puppeteer, GUI access via noVNC for visual monitoring, and integration with Anthropic's Computer Use agent loop. The unikernel implementation offers unique benefits like automated standby mode for resource conservation, state snapshotting for session reuse, and extremely fast cold restarts.\n\nThe project aims to enable automated browser-based tasks, development of AI agents leveraging browsers, and the creation of custom applications requiring controlled browser environments. The post includes quickstart guides for both the unikernel and Docker versions, a demo video, and invites contributions. It also mentions that the team is hiring backend engineers and provides contact information for inquiries. Finally, it directs users to GitHub issues for support and a waitlist and Discord for learning more about hosted services.\n",
    "chinese_title": "Show HN: 我们在Unikernel上运行了Chromium (开源 Apache 2.0)",
    "chinese_summary": "此“Show HN”帖子介绍了一个将 Chromium 浏览器置于 unikernel 之上的项目，为自动化工作流程、AI 代理开发和自定义工具提供了一个沙盒化且即用的浏览器环境。该项目提供 Docker 和 unikernel 两种实现。\n\n主要功能包括一个与 Chrome DevTools 框架（如 Playwright 和 Puppeteer）兼容的预配置 Chrome 浏览器，通过 noVNC 进行 GUI 访问以实现可视化监控，以及与 Anthropic 的 Computer Use 代理循环集成。unikernel 实现提供独特的优势，例如用于资源节约的自动待机模式、用于会话重用的状态快照以及极快的冷启动。\n\n该项目旨在支持基于浏览器的自动化任务、利用浏览器的 AI 代理开发以及创建需要受控浏览器环境的自定义应用程序。该帖子包括 unikernel 和 Docker 版本的快速入门指南、演示视频，并邀请大家贡献代码。帖子还提到团队正在招聘后端工程师，并提供联系方式以供咨询。最后，帖子引导用户前往 GitHub Issues 获取支持，并引导用户加入候补名单和 Discord 以了解有关托管服务的更多信息。"
  },
  {
    "id": "43704853",
    "title": "Herb: Powerful and seamless HTML-aware ERB parsing and tooling",
    "url": "https://herb-tools.dev/",
    "summary": "Herb is presented as a tool providing powerful and seamless parsing and tooling for ERB (Embedded Ruby) templates, specifically highlighting its HTML-awareness. This means Herb can intelligently understand and navigate the HTML structure interwoven with the Ruby code within ERB files. The key benefit of this HTML-awareness is more accurate and precise parsing, ensuring that the tool can correctly interpret and process both the HTML markup and the embedded Ruby code within the ERB template. Essentially, Herb offers a way to handle ERB files in a more sophisticated and accurate manner than traditional methods by understanding the context of the HTML tags and attributes.\n",
    "chinese_title": "Herb: 强大且无缝的 HTML 感知 ERB 解析与工具",
    "chinese_summary": "Herb：一款强大且无缝的ERB模板解析与工具，尤其擅长HTML感知。这意味着Herb能智能地理解和解析ERB文件中交织的HTML结构与Ruby代码。HTML感知的关键优势在于更准确和精确的解析，确保工具能够正确地解释和处理ERB模板中的HTML标记和嵌入的Ruby代码。本质上，Herb通过理解HTML标签和属性的上下文，提供了一种比传统方法更复杂和准确的处理ERB文件的方式。"
  },
  {
    "id": "43677122",
    "title": "Fibonacci Hashing: The Optimization That the World Forgot",
    "url": "https://probablydance.com/2018/06/16/fibonacci-hashing-the-optimization-that-the-world-forgot-or-a-better-alternative-to-integer-modulo/",
    "summary": "Malte Skarupke's article highlights the surprisingly overlooked optimization technique of Fibonacci hashing for hash tables. He argues that Fibonacci hashing is superior to the commonly used integer modulo operation for mapping hash values to table slots, yet it's largely ignored in major implementations like `std::unordered_map`.\n\nThe article explains that integer modulo is slow and susceptible to patterns in input data. Straightforward modulo implementations are slow, while the faster \"binary and\" approach (used when table size is a power of two) discards upper bits, potentially leading to collisions if the hash function isn't carefully designed.\n\nFibonacci hashing, on the other hand, is faster (integer multiplication followed by a shift) and better at mixing input patterns, effectively providing a second hashing step. This makes it more robust against problematic data patterns. The technique leverages the golden ratio to evenly distribute hash values across the table.\n\nThe author benchmarks various `unordered_map` implementations, demonstrating that `ska::unordered_map`, which utilizes Fibonacci hashing, can be significantly faster (up to twice as fast) than standard implementations. The article posits that the historical prevalence of integer modulo in Knuth's \"The Art of Computer Programming\" may have contributed to its continued use despite its drawbacks. He advocates for widespread adoption of Fibonacci hashing to improve hash table performance.\n",
    "chinese_title": "斐波那契散列：被世界遗忘的优化",
    "chinese_summary": "Malte Skarupke 的文章强调了斐波那契哈希这种令人惊讶地被忽视的哈希表优化技术。他认为，对于将哈希值映射到表槽，斐波那契哈希优于常用的整数取模运算，但它在像 `std::unordered_map` 这样的主要实现中却基本被忽略了。\n\n文章解释说，整数取模速度慢且容易受到输入数据模式的影响。直接的取模实现速度较慢，而更快的“二进制与”方法（在表大小为 2 的幂时使用）会丢弃高位，如果哈希函数没有经过仔细设计，可能会导致冲突。\n\n另一方面，斐波那契哈希速度更快（整数乘法后跟移位），并且更擅长混合输入模式，有效地提供了第二个哈希步骤。这使其对有问题的的数据模式更具鲁棒性。该技术利用黄金比例在整个表中均匀分布哈希值。\n\n作者对各种 `unordered_map` 实现进行了基准测试，表明使用斐波那契哈希的 `ska::unordered_map` 可以比标准实现快得多（高达两倍）。文章认为，Knuth 的“计算机程序设计艺术”中整数取模的历史流行可能导致了它尽管存在缺点但仍被继续使用。他倡导广泛采用斐波那契哈希以提高哈希表性能。"
  },
  {
    "id": "43678909",
    "title": "Fun with -fsanitize=undefined and Picolibc",
    "url": "https://keithp.com/blogs/sanitizer-fun/",
    "summary": "This article details the author's experience enabling and using the `-fsanitize=undefined` flag in GCC and Clang with the Picolibc library to detect undefined behavior and implementation-defined behavior in C code.\n\nThe author describes the process of implementing sanitizer handlers in Picolibc to support both trap-on-error and handler modes, allowing for debugging of identified issues. A significant portion of the work involved addressing harmless instances of undefined behavior, such as pointer arithmetic beyond array bounds and signed arithmetic overflow, often leading to cleaner code.\n\nThe article highlights the challenges of dealing with signed integer shifts due to the C standard's ambiguity, especially the lack of an arithmetic right shift operator. The author provides custom macros `lsl` and `asr` to handle left and right shifts respectively, ensuring correct behavior across different compilers and architectures.\n\nDespite initial expectations, the sanitizer uncovered eight actual bugs within Picolibc, ranging from incorrect input validation in locale functions to memory corruption issues in `memcpy` and errors in floating-point conversions.\n\nFinally, the author suggests extending sanitizers to detect other common programming mistakes, such as unsigned integer overflows in memory allocation, which currently go unnoticed. The author recommends using the undefined behavior sanitizers as a valuable tool for improving C code quality and reliability.\n",
    "chinese_title": "用-fsanitize=undefined和Picolibc的乐趣",
    "chinese_summary": "本文详细介绍了作者在使用GCC和Clang时，通过Picolibc库启用并使用`-fsanitize=undefined`标志来检测C代码中未定义行为和实现定义行为的经验。\n\n作者描述了在Picolibc中实现消毒器处理程序以支持trap-on-error和handler模式的过程，从而能够调试已识别的问题。大部分工作涉及处理无害的未定义行为实例，例如超出数组边界的指针算术和有符号算术溢出，这通常会带来更清晰的代码。\n\n文章强调了处理有符号整数移位的挑战，这是由于C标准的模糊性，特别是缺乏算术右移运算符。作者提供了自定义宏`lsl`和`asr`来分别处理左移和右移，确保在不同的编译器和架构中都能正确运行。\n\n尽管最初的预期，消毒器还是发现了Picolibc中的八个实际错误，从区域设置函数中不正确的输入验证到`memcpy`中的内存损坏问题以及浮点转换中的错误。\n\n最后，作者建议扩展消毒器以检测其他常见的编程错误，例如内存分配中无符号整数溢出，这些错误目前未被发现。作者建议使用未定义行为消毒器作为提高C代码质量和可靠性的宝贵工具。"
  },
  {
    "id": "43690289",
    "title": "Show HN: Unsure Calculator – back-of-a-napkin probabilistic calculator",
    "url": "https://filiph.github.io/unsure/",
    "summary": "Filip Hracek introduces \"Unsure Calculator,\" a probabilistic calculator designed to handle calculations with uncertain numbers expressed as ranges (e.g., 4~6). The tool aims to simplify statistical reasoning for a broader audience by providing a user-friendly interface for inputting ranges representing a 95% confidence interval.\n\nThe calculator employs the Monte Carlo method to perform numerous calculations based on the provided ranges, offering a more realistic and nuanced result compared to using single, arbitrary numbers. The author illustrates its utility through a personal example of evaluating a job offer, demonstrating how it can provide a range of possible outcomes and associated probabilities, aiding in informed decision-making. A second example uses the Drake equation to illustrate the tool's use in estimating uncertain variables, such as the number of potentially communicative civilizations in the galaxy.\n\nThe author suggests various other use cases, including business viability assessments, income estimations, and investment return calculations. While acknowledging the limitations of this early version (slow computation, simple normal distribution assumption, basic UI, and brittle formula parsing), he hopes it will be a valuable tool for quick, back-of-the-napkin estimations. He provides a link to the GitHub repository for contributions and a link to a more recent notebook version of the app for power users.\n",
    "chinese_title": "Show HN: 不确定计算器 – 草稿纸上的概率计算器",
    "chinese_summary": "Filip Hracek推出“不确定计算器”，这是一款概率计算器，旨在处理以范围表示（例如，4~6）的不确定数字的计算。该工具旨在通过提供一个用户友好的界面来输入代表95%置信区间的范围，从而简化更广泛受众的统计推理。\n\n该计算器采用蒙特卡洛方法，基于提供的范围进行大量计算，与使用单个任意数字相比，提供了更真实和细致的结果。作者通过评估一份工作邀请的个人案例来说明其效用，展示了它如何提供一系列可能的Outcome和相关概率，从而帮助做出明智的决策。第二个例子使用德雷克方程来说明该工具在估计不确定变量（例如，银河系中潜在的通信文明的数量）方面的用途。\n\n作者建议了其他各种用例，包括商业可行性评估、收入估算和投资回报计算。虽然承认这个早期版本的局限性（计算速度慢、简单的正态分布假设、基本的用户界面和脆弱的公式解析），但他希望它能成为快速、草稿式估算的宝贵工具。他提供了一个指向GitHub存储库的链接，以供贡献，以及一个指向更近期的笔记本版本应用程序的链接，供高级用户使用。"
  },
  {
    "id": "43714900",
    "title": "Google used AI to suspend over 39M ad accounts suspected of fraud",
    "url": "https://techcrunch.com/2025/04/16/google-used-ai-to-suspend-over-39m-ad-accounts-committing-fraud/",
    "summary": "In 2024, Google significantly ramped up its fight against ad fraud, suspending 39.2 million advertiser accounts, a threefold increase from the previous year. This crackdown was largely fueled by the use of Large Language Models (LLMs) and AI to detect fraudulent activity, such as business impersonation and illegitimate payment details, allowing Google to suspend accounts before ads even ran.\n\nGoogle implemented over 50 LLM enhancements and introduced over 30 ad policy updates last year. This also included countermeasures against deepfake ad scams, leading to a 90% drop in reported deepfake ads after 700,000 offending accounts were suspended.\n\nThe U.S. saw the highest number of suspensions (39.2 million accounts) and the removal of 1.8 billion ads, followed by India with 2.9 million account suspensions and 247.4 million ad removals. Scam-related violations resulted in 5 million account suspensions, with almost half a billion scam ads removed overall.\n\nWhile Google blocked 5.1 billion ads and removed 1.3 billion pages in 2024, these numbers are lower than 2023, which Google attributes to improvements in early detection and prevention. The company also verified over 8,900 new election advertisers and removed 10.7 million election ads during a major election year.\n\nTo address concerns about fair application of rules, Google offers an appeal process with human reviews and is working to improve transparency in its messaging to advertisers regarding suspension rationales.\n",
    "chinese_title": "谷歌利用人工智能暂停了超过3900万个涉嫌欺诈的广告账户。",
    "chinese_summary": "2024年，谷歌大幅加强了打击广告欺诈的力度，暂停了3920万个广告商账户，比上一年增加了两倍。此次打击主要得益于使用大型语言模型（LLM）和人工智能来检测欺诈活动，例如商业冒充和非法支付详情，从而使谷歌能够在广告投放前暂停账户。\n\n去年，谷歌实施了超过50项LLM增强功能，并推出了超过30项广告政策更新。 这还包括针对深度伪造广告诈骗的反制措施，在暂停了70万个违规账户后，报告的深度伪造广告下降了90%。\n\n美国被暂停账户数量最多（3920万个账户），并删除了18亿个广告，其次是印度，暂停了290万个账户并删除了2.474亿个广告。 与诈骗相关的违规行为导致500万个账户被暂停，总体上删除了近5亿个诈骗广告。\n\n虽然谷歌在2024年拦截了51亿个广告并删除了13亿个页面，但这些数字低于2023年，谷歌将其归因于早期检测和预防的改进。该公司还在一个重要的选举年验证了超过8900名新的选举广告商，并删除了1070万个选举广告。\n\n为了解决对公平应用规则的担忧，谷歌提供人工审核的上诉流程，并正在努力提高其向广告商发布的有关暂停理由的信息透明度。"
  },
  {
    "id": "43703682",
    "title": "A Postmortem of a Startup",
    "url": "https://buildwithtract.com/",
    "summary": "Tract, a startup aiming to address Britain's housing crisis by improving the planning permission process, ultimately failed after nearly two years despite raising £744,000 in pre-seed funding. Founded in May 2023, they explored various business models, including a site-sourcing tool (Tract Source), a free land appraisal tool (Attract), becoming tech-enabled land promoters, and an AI-powered planning document platform (Tract Editor).\n\nThe postmortem highlights the difficulty of selling software to a conservative industry, the operational complexities of land promotion, and a low willingness to pay for helpful tools. The founders also realized the British property market's fragmentation and conservatism limited venture-backed disruption.\n\nKey lessons learned include the importance of a larger, more receptive market like the US, focusing on market quality, staying lean until proving revenue, being aggressively commercial from day one, and prioritizing customer learning. Specific errors include overestimating the British market, raising venture capital for an unsuitable model, prioritizing technology over business development, building the team too early, and not focusing on revenue generation.\n\nUltimately, Tract ceased operations in March 2025, returning capital to investors. The founders, Jamie Rumbelow and Henry Dashwood, share their experience as a case study with the goal of codifying learnings, documenting their journey, explaining the resources spent, and achieving closure. They emphasize the failure ultimately lay with their own decisions, while also acknowledging external factors and expressing gratitude to their supporters.\n",
    "chinese_title": "一家创业公司的验尸报告",
    "chinese_summary": "名为Tract的初创公司，旨在通过改善规划许可流程来解决英国的住房危机，但在获得74.4万英镑种子前融资后，经过近两年的努力，最终失败。该公司于2023年5月成立，探索了各种商业模式，包括场地搜寻工具（Tract Source）、免费土地评估工具（Attract）、成为技术赋能的土地推广商以及人工智能驱动的规划文件平台（Tract Editor）。\n\n事后分析突显了向保守行业销售软件的难度、土地推广的运营复杂性以及对实用工具的低支付意愿。创始人还意识到英国房地产市场的分散性和保守性限制了风险投资支持的颠覆。\n\n主要经验教训包括：更大的、更具接受度的市场（如美国）的重要性、关注市场质量、在证明收入之前保持精简、从一开始就积极进行商业活动以及优先考虑客户学习。具体错误包括高估英国市场、为不合适的模式筹集风险投资、优先考虑技术而非业务发展、过早地组建团队以及没有专注于创收。\n\n最终，Tract于2025年3月停止运营，并将资金返还给投资者。创始人Jamie Rumbelow和Henry Dashwood分享他们的经验，作为一个案例研究，目的是整理经验教训、记录他们的旅程、解释花费的资源并实现结束。他们强调，失败最终在于他们自己的决定，同时也承认外部因素并对他们的支持者表示感谢。"
  },
  {
    "id": "43706118",
    "title": "Future Chips Will Be Hotter Than Ever",
    "url": "https://spectrum.ieee.org/hot-chips",
    "summary": "This article discusses the growing challenge of heat dissipation in future chips due to increasing transistor density and the end of Dennard scaling, which previously kept power consumption in check. As chips become more compact and powerful, traditional cooling methods like air and liquid cooling are becoming insufficient for technologies like nanosheet transistors and CFETs, potentially leading to thermal runaway in data centers.\n\nThe article explores alternative cooling techniques, such as microfluidic cooling and immersion cooling, but notes that relying solely on cooling is impractical, especially for mobile devices and due to infrastructure costs in data centers. It then delves into system-level solutions like thermal sensors and thermal sprinting, which involve dynamically adjusting voltage, frequency, or core usage to manage heat, but these can impact performance.\n\nA promising strategy is using the backside of the wafer to improve power delivery through technologies like backside power-delivery networks (BSPDNs), backside capacitors, and backside integrated voltage regulators (IVRs). These could reduce voltage requirements and heat generation. However, the article cautions that these technologies can introduce new thermal problems, such as increased hot spots due to the thinned silicon substrate.\n\nThe article concludes by advocating for a holistic approach to chip design, called system technology co-optimization (STCO), that considers the interplay between systems, physical design, and process technology. This involves using advanced thermal analysis tools during early design stages and fostering collaboration between specialists across different engineering domains. The authors stress the importance of addressing heat issues early in the chip design process to avoid performance-impacting software solutions later on.\n",
    "chinese_title": "未来芯片将比以往更热",
    "chinese_summary": "本文探讨了未来芯片中日益严峻的散热挑战，其原因是晶体管密度不断增加以及此前用于控制功耗的登纳德缩放定律的终结。随着芯片变得更加紧凑和强大，传统的空气和液体冷却方法已不足以满足纳米片晶体管和互补场效应晶体管(CFET)等技术的需求，可能导致数据中心发生热失控。\n\n本文探讨了微流体冷却和浸没式冷却等替代冷却技术，但也指出，仅依靠冷却是不切实际的，尤其是在移动设备中，以及由于数据中心的基础设施成本问题。 然后，本文深入研究了系统级解决方案，如热传感器和热敏加速，这些解决方案涉及动态调整电压、频率或核心使用量来管理热量，但这些可能会影响性能。\n\n一种有前景的策略是利用晶圆背面，通过背面供电网络（BSPDN）、背面电容器和背面集成电压调节器（IVR）等技术来改善功率传输。这些技术可以降低电压需求和热量产生。然而，本文警告说，这些技术可能会引入新的热问题，例如由于硅基板变薄而导致的热点增加。\n\n本文最后倡导采用一种整体的芯片设计方法，称为系统技术协同优化（STCO），该方法考虑了系统、物理设计和工艺技术之间的相互作用。 这涉及在早期设计阶段使用先进的热分析工具，并促进不同工程领域专家之间的合作。作者强调在芯片设计过程的早期解决散热问题的重要性，以避免后期采用影响性能的软件解决方案。"
  },
  {
    "id": "43688131",
    "title": "Miscellaneous Mathematical Symbols",
    "url": "https://www.johndcook.com/blog/2025/04/14/miscellaneous-mathematical-symbols/",
    "summary": "This blog post explores the \"Miscellaneous Mathematical Symbols\" Unicode block, highlighting its collection of primarily obscure symbols. The author notes that while some symbols may seem obscure, they likely have routine usage within specific fields.\n\nThe post focuses on a few examples:\n\n*   **Perpendicular Symbol (⟂):** While technically a variation of the \"false\" symbol (⊥), it's used to denote perpendicularity and sometimes relative primality in number theory.\n*   **Geometric Algebra Symbols (⟑, ⟇):** These symbols represent the geometric product (dot-wedge product) and the dual operator (geometric antiproduct) in geometric algebra, notably promoted by Eric Lengyel.\n*   **Database Join Symbols:**  The blog mentions that the Unicode block includes symbols for left, right and full outer database joins, complementing the bowtie symbol (⨝) for inner joins found in another block.\n*   **Angle Brackets (⟨, ⟩):** These Unicode characters correspond to the LaTeX commands \\langle and \\rangle, and the author recalls using them in a previous post on the Gram matrix.\n\nThe overall theme emphasizes the breadth and depth of Unicode and its inclusion of niche mathematical notation, even if the author's own familiarity with them varies. The post also includes links to other posts related to mathematical notation.\n",
    "chinese_title": "杂项数学符号",
    "chinese_summary": "这篇博文探讨了“杂项数学符号”Unicode区段，着重介绍了其中主要是一些晦涩符号的集合。作者指出，虽然一些符号可能看起来很冷门，但它们可能在特定领域内有常规用途。\n\n博文重点介绍了几个例子：\n\n*   **垂直符号 (⟂):** 虽然技术上是“假”符号 (⊥) 的变体，但它用于表示垂直，有时用于数论中的互质。\n*   **几何代数符号 (⟑, ⟇):** 这些符号表示几何代数中的几何积（点-楔积）和对偶算子（几何反积），尤其受到 Eric Lengyel 的推广。\n*   **数据库连接符号:** 博文提到，Unicode 区段包含左连接、右连接和完全外部连接的符号，补充了另一个区段中的内连接弓形符号 (⨝)。\n*   **角括号 (⟨, ⟩):** 这些 Unicode 字符对应于 LaTeX 命令 \\langle 和 \\rangle，作者回忆起在之前一篇关于格拉姆矩阵的博文中使用了它们。\n\n总而言之，主题强调了 Unicode 的广度和深度，以及它对小众数学符号的收录，即使作者自己对它们的熟悉程度有所不同。该博文还包含指向其他与数学符号相关的博文的链接。"
  },
  {
    "id": "43659814",
    "title": "A Ford executive who kept score of colleagues' verbal flubs",
    "url": "https://www.wsj.com/lifestyle/ford-motor-mike-obrien-malaprops-6e560520",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "一个记录同事口头失误的福特高管",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43704904",
    "title": "Kermit: A typeface for kids",
    "url": "https://microsoft.design/articles/introducing-kermit-a-typeface-for-kids/",
    "summary": "This article introduces Kermit, a new typeface designed by Underware to help children, especially those with dyslexia, improve their reading comprehension and enjoyment. Recognizing that reading can be challenging, particularly for the estimated 1 in 10 people with dyslexia, the designers aimed to create a font that is friendly, approachable, and scientifically informed.\n\nKermit features a large x-height, thick strokes, generous spacing, and familiar letter shapes to maximize legibility. Beyond basic readability, Kermit explores innovative ways to represent prosody (vocal inflections) typographically, using boldness for volume, width for duration, and vertical shifts for pitch. This approach aims to enhance expressiveness and comprehension, even for those with hearing impairments.\n\nThe article also delves into research suggesting that dyslexia may involve visuo-spatial processing issues. To address this, Underware created an animated version of Kermit where letters draw themselves. Using Variable Font technology and a novel mathematical approach called Higher Order Interpolation (HOI), they achieved smooth, natural-looking animation. The hope is that this animation strengthens the high road signal in dyslexic brains, improving letter order comprehension and word recognition.\n\nKermit is presented as more than just a typeface; it's a platform for exploring and implementing science-based methods to make reading more accessible and enjoyable for all children. The basic styles are currently available with the full set of styles coming soon.\n",
    "chinese_title": "科米特：一款儿童字体",
    "chinese_summary": "本文介绍了 Kermit，这是一款由 Underware 设计的全新字体，旨在帮助儿童（尤其是患有阅读障碍的儿童）提高阅读理解能力和乐趣。 鉴于阅读可能具有挑战性，尤其是对于估计占人口十分之一的阅读障碍患者，设计师的目标是创造一种友好、平易近人且具有科学依据的字体。\n\nKermit 具有较大的 x 高度、较粗的笔画、较大的间距和熟悉的字母形状，以最大限度地提高可读性。 除了基本的可读性之外，Kermit 还探索了以排版方式表示韵律（语调）的创新方法，使用粗体表示音量，宽度表示持续时间，垂直偏移表示音高。 这种方法旨在增强表达力和理解力，即使对于听力障碍者也是如此。\n\n本文还深入探讨了研究表明阅读障碍可能涉及视觉空间处理问题。 为了解决这个问题，Underware 创建了 Kermit 的动画版本，其中字母会自行绘制。 他们使用可变字体技术和一种名为高阶插值 (HOI) 的新型数学方法，实现了平滑、自然的动画效果。 希望这种动画能够加强阅读障碍大脑中的高级通路信号，从而提高字母顺序理解和单词识别能力。\n\nKermit 不仅仅是一种字体；它是一个探索和实施基于科学的方法的平台，旨在让所有儿童都能更轻松、更愉快地阅读。 基本样式目前可用，全套样式即将推出。"
  },
  {
    "id": "43679831",
    "title": "Four Kinds of Optimisation (2023)",
    "url": "https://tratt.net/laurie/blog/2023/four_kinds_of_optimisation.html",
    "summary": "Laurence Tratt's \"Four Kinds of Optimisation\" challenges the common assumptions about performance improvement in software. He argues that both identifying performance bottlenecks and knowing how to fix them are often more complex than we think, advocating for rigorous profiling and a nuanced understanding of available solutions.\n\nTratt outlines four main approaches to optimization:\n\n1.  **Use a better algorithm:** Requires understanding the context, inputs, and trade-offs between best, average, and worst-case performance. He cautions against assuming theoretical performance translates to real-world speed and highlights the risk of introducing bugs when implementing complex algorithms.\n2.  **Use a better data-structure:** Demands careful thought and measurement. He suggests using existing data structure libraries and optimizing struct/class size, reducing pointer chasing, and improving memory locality.\n3.  **Use a lower-level system:** Advocates for exploring alternative language implementations (e.g., PyPy for Python) and compiler optimizations before rewriting code in languages like Rust. This often provides substantial performance gains with less effort and risk.\n4.  **Accept a less precise solution:** Involves techniques like local search for complex problems with vast solution spaces. It can also mean deliberately accepting approximate or probabilistic answers (e.g., fast inverse square root or Bloom filters) for speed gains.\n\nThe article emphasizes that selecting the right optimization strategy involves trade-offs and a deep understanding of the software's behavior, data, and context.\n",
    "chinese_title": "四种优化 (2023)",
    "chinese_summary": "劳伦斯·特拉特的《四种优化》挑战了软件性能改进方面的常见假设。他认为，识别性能瓶颈和知道如何修复它们通常比我们想象的要复杂得多，并提倡严格的性能剖析和对可用解决方案的细致理解。\n\n特拉特概述了四种主要的优化方法：\n\n1.  **使用更好的算法：** 需要理解上下文、输入以及最佳、平均和最坏情况性能之间的权衡。他告诫不要假设理论性能会转化为实际速度，并强调了实现复杂算法时引入错误的风险。\n2.  **使用更好的数据结构：** 需要仔细思考和测量。他建议使用现有的数据结构库，并优化结构体/类的大小、减少指针追踪以及改善内存局部性。\n3.  **使用更底层的系统：** 提倡在用Rust等语言重写代码之前，探索替代的语言实现（例如，Python的PyPy）和编译器优化。这通常能以更少的努力和风险提供显著的性能提升。\n4.  **接受不太精确的解决方案：** 涉及针对具有巨大解空间复杂问题的局部搜索等技术。它也可能意味着为了提高速度而故意接受近似或概率性答案（例如，快速平方根倒数或布隆过滤器）。\n\n这篇文章强调，选择正确的优化策略涉及权衡以及对软件行为、数据和上下文的深入理解。"
  },
  {
    "id": "43711393",
    "title": "The Promise of Rust",
    "url": "https://fasterthanli.me/articles/the-promise-of-rust",
    "summary": "The article \"The Promise of Rust\" explores Rust's unique approach to memory management and its implications compared to other popular languages like JavaScript and Go. The author, fasterthanlime, highlights how Rust's ownership and borrowing system enforces memory safety, preventing issues like dangling pointers and data races at compile time.\n\nThe article demonstrates Rust's move semantics, where ownership of data is transferred when a variable is passed to a function. Unlike JavaScript, which automatically passes primitive types by value, Rust requires explicit cloning or borrowing to allow multiple uses of data without ownership transfer. This forces developers to be aware of memory implications and prevents unexpected heap allocations. The author critiques JavaScript's lack of clear \"by value\" or \"by reference\" semantics, and the limitations of methods like `JSON.parse(JSON.stringify(o))` for deep cloning and `Object.freeze()` for preventing mutation.\n\nThe author argues that while Rust's strictness can be initially challenging, it ultimately leads to more robust and predictable code. The compiler's informative error messages act as a teaching tool, guiding developers toward efficient and safe memory management. The article suggests that understanding these concepts is crucial for developers, even those coming from garbage-collected languages, especially when dealing with native extensions or performance-sensitive code. The remainder of the article is exclusive to sponsors and subscribers.\n",
    "chinese_title": "Rust 的前景",
    "chinese_summary": "文章《Rust的承诺》探讨了Rust独特的内存管理方法及其与JavaScript和Go等其他流行语言相比的意义。作者fasterthanlime强调了Rust的所有权和借用系统如何强制执行内存安全，从而在编译时防止悬挂指针和数据竞争等问题。\n\n文章展示了Rust的移动语义，即当变量传递给函数时，数据的所有权会被转移。与自动按值传递原始类型的JavaScript不同，Rust需要显式克隆或借用才能允许多次使用数据而无需转移所有权。这迫使开发者意识到内存影响并防止意外的堆分配。作者批评了JavaScript缺乏清晰的“按值”或“按引用”语义，以及像`JSON.parse(JSON.stringify(o))`用于深度克隆和`Object.freeze()`用于防止突变等方法的局限性。\n\n作者认为，虽然Rust的严格性最初可能具有挑战性，但最终会产生更健壮和可预测的代码。编译器提供的信息丰富的错误消息充当了一种教学工具，引导开发者进行高效且安全的内存管理。文章表明，理解这些概念对于开发者至关重要，即使是来自垃圾回收语言的开发者，尤其是在处理原生扩展或对性能敏感的代码时。文章的剩余部分仅对赞助商和订阅者开放。"
  },
  {
    "id": "43715220",
    "title": "British soldiers take down drone swarm with radio wave weapon",
    "url": "https://www.gov.uk/government/news/british-soldiers-take-down-drone-swarm-in-groundbreaking-use-of-radio-wave-weapon",
    "summary": "British soldiers successfully neutralized drone swarms using a new UK-developed Radiofrequency Directed Energy Weapon (RF DEW) in recent trials. This groundbreaking technology disrupts or damages drone electronics with radio waves, effectively causing them to crash. The trial, the British Army's largest counter-drone swarm exercise, saw over 100 drones tracked, engaged, and defeated.\n\nThe RF DEW demonstrator, developed by a consortium led by Thales UK, can neutralize multiple targets simultaneously with near-instant effect and is effective up to 1km. It's estimated to cost only 10p per shot, offering a potentially cost-effective alternative to missile-based air defense. The UK government has invested over £40 million in RF DEW research, supporting 135 skilled jobs across the UK.\n\nThe development is driven by the increasing use of drone swarms in modern warfare, exemplified by their frequent use in Ukraine. The UK aims to increase its investment in novel technologies, spending at least 10% of MOD's equipment procurement budget on them from 2025-26.\n\nAccording to Sgt Mayers, the first British soldier to use the weapon, the RF DEW is quick to learn and easy to use. Thales MD Nigel MacVean stated Thales is proud to continue the research and development in this sector alongside the UK government.\n",
    "chinese_title": "英国士兵用无线电波武器击落无人机群",
    "chinese_summary": "英军成功使用新型射频定向能武器摧毁无人机群"
  },
  {
    "id": "43709042",
    "title": "RakuAST Grant Report",
    "url": "https://niner.name/blog/rakuast_grant_report/index.html",
    "summary": "This report details the progress and challenges of the RakuAST project, a rewrite of the Raku compiler frontend. The goal was to replace the old frontend with a new, AST-based one capable of handling the complexities of the Raku language.\n\nWhile initial infrastructure was in place, implementing Raku's advanced features, like various method call types and compile-time code execution, proved difficult. The biggest challenge was determining the correct order of declarations, definitions, type setup, and code generation, as this order was undocumented and crucial for successful compilation.\n\nThe project faced a \"long tail\" of special cases, compile-time checks, and error handling, leading to over 900 commits, far exceeding the initial estimate of 200. Bootstrapping the compiler, i.e., compiling it with itself, presented further challenges due to circular dependencies and the need to access internal object attributes directly. The standard library, with its advanced Raku code, revealed deficiencies not covered by spec tests. Many spec tests were also found to be incomplete, incorrect, or dependent on specific error behaviors of the old frontend, requiring adjustments.\n\nDespite the project's complexity and intimidating codebase, contributions from Elizabeth Mattijsen, John Haltiwanger, Vadim Belman, Jimmy Zhuo, and Daniel Green were crucial to its progress.\n",
    "chinese_title": "RakuAST资助报告",
    "chinese_summary": "本报告详细介绍了RakuAST项目的进展和挑战，该项目是对Raku编译器前端的重写。目标是用一种新的、基于AST的前端来取代旧的前端，使其能够处理Raku语言的复杂性。\n\n虽然最初的基础设施已经就位，但实现Raku的高级特性，如各种方法调用类型和编译时代码执行，被证明是困难的。最大的挑战是确定声明、定义、类型设置和代码生成的正确顺序，因为这个顺序没有文档记录，并且对于成功编译至关重要。\n\n该项目面临着大量特殊情况、编译时检查和错误处理的“长尾”，导致了超过900次的提交，远远超过了最初估计的200次。由于循环依赖关系和直接访问内部对象属性的需求，引导编译器（即用自身编译它）提出了进一步的挑战。标准库及其高级Raku代码揭示了规范测试未涵盖的缺陷。还发现许多规范测试是不完整的、不正确的或依赖于旧前端的特定错误行为，需要进行调整。\n\n尽管该项目非常复杂且代码库令人望而生畏，但Elizabeth Mattijsen、John Haltiwanger、Vadim Belman、Jimmy Zhuo和Daniel Green的贡献对于项目的进展至关重要。"
  },
  {
    "id": "43692089",
    "title": "Chroma: Ubisoft's internal tool used to simulate color-blindness",
    "url": "https://github.com/ubisoft/Chroma",
    "summary": "Ubisoft's Chroma is an internal tool designed to simulate different types of color blindness (Protanopia, Deuteranopia, and Tritanopia) for testing and improving accessibility in their games. Chroma allows developers to see how their games appear to players with color vision deficiencies.\n\nKey features of Chroma include real-time color simulation on a single monitor, compatibility with all games regardless of engine, high performance (up to 60 FPS), accurate results, simulation of all major color blind forms, live gameplay screen capture and simulation, easy screenshot logging, and a user-friendly interface. It is noted as a unique solution due to its ability to capture and simulate live gameplay.\n\nThe article also addresses a known issue during the CMake process related to an outdated CPPWinRT library. The suggested solution is to install the Microsoft.Windows.CppWinRT NuGet package or update the CPPWinRT library, with the recommendation of using Visual Studio 2022 to avoid the issue altogether. The article also points to where you can find more details and download the official Chroma logo.\n",
    "chinese_title": "Chroma：育碧用于模拟色盲的内部工具",
    "chinese_summary": "育碧Chroma：一款内部工具，用于模拟不同类型的色盲（红色盲、绿色盲和蓝色盲），以测试和提高其游戏的可访问性。Chroma使开发人员能够了解他们的游戏对色觉障碍玩家的呈现效果。\n\nChroma的主要功能包括：在单个显示器上进行实时色彩模拟、与所有游戏（不限引擎）的兼容性、高性能（高达60 FPS）、准确的结果、所有主要色盲形式的模拟、实时游戏画面捕获和模拟、便捷的屏幕截图记录以及用户友好的界面。由于其捕获和模拟实时游戏画面的能力，Chroma被认为是一种独特的解决方案。\n\n本文还提到CMake过程中一个与过时的CPPWinRT库相关的已知问题。建议的解决方案是安装Microsoft.Windows.CppWinRT NuGet包或更新CPPWinRT库，并建议使用Visual Studio 2022以完全避免此问题。本文还指出了您可以找到更多详细信息和下载官方Chroma徽标的位置。"
  },
  {
    "id": "43662339",
    "title": "Fake images that fooled the world",
    "url": "https://www.theguardian.com/artanddesign/2025/apr/12/28-fake-images-that-fooled-the-world",
    "summary": "Jonathan Freedland's article explores the long history of manipulated photographs and their impact, arguing that the phenomenon is not a modern invention of AI deepfakes but has existed since the dawn of photography. The article highlights various examples, from political propaganda like superimposing Lincoln's head onto another body or cropping out Mussolini's horse handler to create a stronger image, to instances where images were altered to make a subject appear more threatening, like the OJ Simpson Time magazine cover.\n\nThe article also touches on instances where the motivation for fakery is less clear, such as the posed image of Robert Capa's falling soldier or the prankster's photo on the World Trade Center roof. The piece emphasizes that fake images proliferate because they often show viewers what they want to believe, fulfilling fantasies or confirming existing biases.\n\nSpecific examples discussed include Yves Klein's \"Leap into the Void,\" the Princess of Wales' edited family photograph, the Patterson-Gimlin bigfoot film, Jonas Bendiksen's \"The Book of Veles,\" and Billy Meier's UFO images. The author argues that these images demonstrate how easily people can be deceived if the presentation aligns with their expectations and desires. Ultimately, the article underscores that a photograph's power to persuade is based on our inherent trust in its veracity, a trust that has been exploited throughout history.\n",
    "chinese_title": "欺骗世界的假照片",
    "chinese_summary": "乔纳森·弗里德兰的文章探讨了照片造假的悠久历史及其影响，指出这种现象并非人工智能深度伪造的现代发明，而是自摄影术诞生之初就已存在。文章列举了各种例子，从政治宣传（例如将林肯的头像叠加在另一人的身体上，或裁剪掉墨索里尼的马夫以创造更强大的形象），到为了让拍摄对象显得更具威胁性而篡改图像的案例，例如《时代》杂志的辛普森封面。\n\n文章还涉及了造假动机不太明确的案例，例如罗伯特·卡帕的“倒下的士兵”摆拍照片，以及恶作剧者在世贸中心屋顶上的照片。文章强调，虚假图像之所以泛滥，是因为它们通常向观众展示他们想相信的东西，满足幻想或证实既有偏见。\n\n文章讨论的具体例子包括伊夫·克莱因的“纵身入虚空”，威尔士王妃编辑过的家庭照片，帕特森-吉姆林大脚怪电影，乔纳斯·本迪克森的“维莱斯之书”以及比利·迈耶的UFO图像。作者认为，这些图像表明，如果呈现方式符合人们的期望和愿望，人们就很容易被欺骗。最终，文章强调，照片的说服力是建立在我们对照片真实性的固有信任之上的，而这种信任在历史上一直被利用。"
  },
  {
    "id": "43711227",
    "title": "Microsoft researchers developed a hyper-efficient AI model that can run on CPUs",
    "url": "https://techcrunch.com/2025/04/16/microsoft-researchers-say-theyve-developed-a-hyper-efficient-ai-model-that-can-run-on-cpus/",
    "summary": "Microsoft researchers have developed BitNet b1.58 2B4T, a hyper-efficient AI model that can run on CPUs, including Apple's M2. This \"bitnet,\" the largest of its kind, uses quantized weights limited to -1, 0, and 1, making it memory and computationally efficient. Trained on a massive dataset, it boasts 2 billion parameters and outperforms traditional models of similar size on benchmarks like GSM8K and PIQA, surpassing Meta's Llama 3.2 1B, Google's Gemma 3 1B, and Alibaba's Qwen 2.5 1.5B.\n\nBitNet b1.58 2B4T is also notably faster than comparable models, sometimes twice as fast, while using less memory. However, this performance depends on Microsoft's custom framework, bitnet.cpp, which currently lacks GPU support, a major drawback given the dominance of GPUs in AI infrastructure. While bitnets offer potential for resource-constrained devices, compatibility remains a significant challenge. The model is openly available under an MIT license.\n",
    "chinese_title": "微软研究人员开发出一种可在 CPU 上运行的超高效 AI 模型。",
    "chinese_summary": "微软研究人员开发出BitNet b1.58 2B4T，一种可在CPU（包括Apple M2）上运行的超高效AI模型。这种“位网络”是同类中最大的，使用量化权重，仅限于-1、0和1，从而使其在内存和计算方面都非常高效。它在海量数据集上训练，拥有20亿个参数，并在GSM8K和PIQA等基准测试中优于类似规模的传统模型，超越了Meta的Llama 3.2 1B、Google的Gemma 3 1B和阿里巴巴的Qwen 2.5 1.5B。\n\nBitNet b1.58 2B4T也明显快于同类模型，有时速度快两倍，同时使用更少的内存。然而，这种性能取决于微软的自定义框架bitnet.cpp，该框架目前缺乏GPU支持，鉴于GPU在AI基础设施中的主导地位，这是一个主要缺点。虽然位网络为资源受限的设备提供了潜力，但兼容性仍然是一个重大挑战。该模型在MIT许可下公开提供。"
  },
  {
    "id": "43705632",
    "title": "Reproducing Hacker News writing style fingerprinting",
    "url": "https://antirez.com/news/150",
    "summary": "This article likely details an attempt to recreate or verify techniques for identifying authors on Hacker News based on their writing style, often referred to as \"writing style fingerprinting.\"\n\nThe core concept involves analyzing various linguistic features in a user's comments to create a unique profile or \"fingerprint.\" These features can include:\n\n*   **Lexical choices:** Common words, phrases, and specific terminology used.\n*   **Syntactic patterns:** Sentence structure, grammar preferences, and common grammatical errors.\n*   **Punctuation and formatting:** Use of commas, parentheses, emphasis, and code formatting.\n*   **Content themes and arguments:** Recurring topics discussed, favored viewpoints, and argumentation styles.\n\nThe reproduction effort would likely involve:\n\n*   **Data collection:** Gathering a dataset of comments from various Hacker News users.\n*   **Feature extraction:** Developing or utilizing methods to extract the relevant linguistic features from the collected data.\n*   **Model training:** Building a model (often a machine learning classifier) that can learn to associate writing styles with specific authors based on these features.\n*   **Evaluation:** Testing the model's ability to accurately identify the author of new, unseen comments based on their writing style.\n\nThe goal of reproducing these techniques is to understand the effectiveness and limitations of writing style fingerprinting on platforms like Hacker News. It may explore factors influencing accuracy, such as the size of the dataset, the number of features used, and the sophistication of the model. The article might also discuss ethical implications related to privacy and anonymity.\n",
    "chinese_title": "重现Hacker News写作风格指纹识别",
    "chinese_summary": "本文可能详述了一项尝试，旨在重现或验证基于写作风格识别 Hacker News 用户身份的技术，通常称为“写作风格指纹识别”。\n\n其核心概念包括分析用户评论中的各种语言特征，以创建独特的个人资料或“指纹”。这些特征可能包括：\n\n*   **词汇选择：** 常用的词语、短语以及特定术语。\n*   **句法模式：** 句子结构、语法偏好以及常见的语法错误。\n*   **标点符号和格式：** 逗号、括号、强调以及代码格式的使用。\n*   **内容主题和论点：** 反复讨论的主题、偏爱的观点以及论证风格。\n\n该重现工作可能涉及：\n\n*   **数据收集：** 收集来自各种 Hacker News 用户的评论数据集。\n*   **特征提取：** 开发或利用方法从收集的数据中提取相关的语言特征。\n*   **模型训练：** 构建一个模型（通常是机器学习分类器），该模型可以学习根据这些特征将写作风格与特定作者联系起来。\n*   **评估：** 测试该模型根据写作风格准确识别新的、未见过的评论作者身份的能力。\n\n重现这些技术的目的是了解写作风格指纹识别在 Hacker News 等平台上的有效性和局限性。它可能探讨影响准确性的因素，例如数据集的大小、使用的特征数量以及模型的复杂程度。文章可能还会讨论与隐私和匿名相关的伦理影响。"
  },
  {
    "id": "43696334",
    "title": "The last RadioShack in Maryland is closing",
    "url": "https://marylandmatters.org/2025/04/14/end-of-an-era-the-last-radioshack-in-maryland-is-closing-its-doors/",
    "summary": "Unable to access the article link.\n",
    "chinese_title": "马里兰州最后一家无线电小屋即将关闭。",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "43693326",
    "title": "Hacking the Postgres wire protocol",
    "url": "https://pgdog.dev/blog/hacking-postgres-wire-protocol",
    "summary": "This article introduces PgDog, a network proxy designed for sharding Postgres databases without requiring application code changes. PgDog intercepts and manipulates the Postgres wire protocol to route queries to the appropriate shards. It supports both the simple and extended query protocols. For the simple protocol, PgDog parses SQL queries to identify read/write intent and extract sharding keys using `pg_query`, a Rust library that leverages Postgres's own SQL parsing code. For the extended protocol (prepared statements), PgDog caches parsed queries and uses `Bind` messages to determine sharding key values.\n\nA crucial aspect is the sharding function, which PgDog adopts directly from Postgres' declarative partitions (hash-based) to ensure consistency across different data access methods. It extracts parameters from SQL queries to determine shard placement, handling various `WHERE` clause complexities, and even INSERT statements.\n\nFor cross-shard queries, PgDog manages Postgres' message sequence (`RowDescription`, `DataRow`, `CommandComplete`, `ReadyForQuery`) by consolidating `RowDescription`, summing row counts in `CommandComplete`, and handling `DataRow` messages by either buffering for ordered results or streaming immediately for unordered results. It also manipulates client messages for distributed `COPY` commands, ensuring each shard receives complete rows for efficient ingestion. PgDog aims for linear scalability in data ingestion and is built using Tokio for concurrency and parallel processing. The next step involves applying similar techniques to logical replication streams.\n",
    "chinese_title": "入侵Postgres线协议",
    "chinese_summary": "本文介绍 PgDog，一个网络代理，旨在对 Postgres 数据库进行分片，而无需更改应用程序代码。PgDog 拦截并操作 Postgres 线协议，将查询路由到适当的分片。它支持简单查询协议和扩展查询协议。对于简单协议，PgDog 解析 SQL 查询，以识别读/写意图并使用 `pg_query`（一个利用 Postgres 自身 SQL 解析代码的 Rust 库）提取分片键。对于扩展协议（预处理语句），PgDog 缓存解析后的查询，并使用 `Bind` 消息来确定分片键值。\n\n一个关键方面是分片函数，PgDog 直接采用 Postgres 声明式分区（基于哈希）中的分片函数，以确保不同数据访问方法之间的一致性。它从 SQL 查询中提取参数以确定分片位置，处理各种 `WHERE` 子句的复杂性，甚至 INSERT 语句。\n\n对于跨分片查询，PgDog 管理 Postgres 的消息序列（`RowDescription`、`DataRow`、`CommandComplete`、`ReadyForQuery`），通过合并 `RowDescription`、在 `CommandComplete` 中求和行数，以及处理 `DataRow` 消息（通过缓冲以获得有序结果或立即流式传输以获得无序结果）。它还操作客户端消息以进行分布式 `COPY` 命令，确保每个分片接收完整的行以进行高效摄取。PgDog 旨在实现数据摄取中的线性可扩展性，并使用 Tokio 构建以实现并发和并行处理。下一步涉及将类似的技术应用于逻辑复制流。"
  },
  {
    "id": "43716632",
    "title": "TSMC says it will build 'independent' chip hub in U.S.",
    "url": "https://asia.nikkei.com/Business/Tech/Semiconductors/TSMC-says-it-will-build-independent-chip-hub-in-U.S.",
    "summary": "Taiwan Semiconductor Manufacturing Co. (TSMC) intends to produce 30% of the world's most advanced 2-nanometer chips in Arizona, contributing to the U.S.'s goal of establishing an \"independent\" chip hub. According to TSMC Chairman and CEO C.C. Wei, the company is not currently involved in any discussions regarding joint ventures, technology licensing, or technology transfer with other chipmakers, specifically addressing rumors of a partnership with Intel. This statement comes amidst challenges such as rising U.S. tariffs and tighter controls on AI chip exports, which TSMC is actively navigating. The article emphasizes TSMC's commitment to supporting the U.S. chip industry while maintaining its technological independence and safeguarding its intellectual property.\n",
    "chinese_title": "台积电称将在美国建立“独立”芯片中心。",
    "chinese_summary": "台积电计划在亚利桑那州生产全球30%的最先进的2纳米芯片，助力美国建立“独立”芯片中心的目标。据台积电董事长兼首席执行官魏哲家表示，该公司目前未参与任何关于合资企业、技术许可或技术转让的讨论，特别是针对与英特尔合作的传言。发表此声明之际，正值美国关税上涨和人工智能芯片出口管制收紧等挑战，台积电正在积极应对这些挑战。文章强调了台积电在支持美国芯片产业的同时，保持其技术独立性和保护其知识产权的承诺。"
  },
  {
    "id": "43706706",
    "title": "Attention K-Mart Shoppers",
    "url": "https://archive.org/details/attentionkmartshoppers",
    "summary": "This short text fragment presents a peculiar combination: the nostalgic phrase \"Attention K-Mart Shoppers\" paired with information about the Internet Archive. The core takeaway is that the user is being redirected to a lite version of archive.org.\n\nHere's a breakdown:\n\n*   **\"Attention K-Mart Shoppers\":** This is a classic phrase often associated with public address announcements in K-Mart stores, evoking a sense of retail and consumerism from a bygone era. Its inclusion here is likely meant to be attention-grabbing and perhaps subtly humorous or ironic.\n\n*   **Internet Archive:** This identifies the Internet Archive, a well-known digital library that provides access to free and borrowable texts, movies, music, and the Wayback Machine (a tool for archiving and accessing archived web pages).\n\n*   **Redirecting to a lite version of archive.org:** This explains the current action taking place. The user is being automatically moved to a simplified, possibly more efficient, version of the Internet Archive website. This might be due to network conditions, device capabilities, or user preferences.\n\nIn essence, the text is a brief notice that blends an old-school retail announcement with a digital redirect. It highlights the presence of the Internet Archive while indicating a user is being sent to a lighter, potentially faster-loading version of the website.\n",
    "chinese_title": "K玛特顾客请注意",
    "chinese_summary": "注意 K-Mart 顾客：您将被重定向到 archive.org 的简化版。"
  },
  {
    "id": "43715513",
    "title": "Why are two TX senators trying to wrest a Space Shuttle from the Smithsonian?",
    "url": "https://arstechnica.com/space/2025/04/why-are-two-texas-senators-trying-to-wrest-a-space-shuttle-from-the-smithsonian/",
    "summary": "Two Texas Senators, John Cornyn and Ted Cruz, introduced the \"Bring the Space Shuttle Home Act\" to move the Space Shuttle Discovery from the Smithsonian's National Air and Space Museum to Houston. The article argues this is a politically motivated, impractical, and costly endeavor.\n\nHouston, despite its strong ties to the Space Shuttle program, didn't secure a shuttle when they were distributed 15 years ago due to a weak proposal and concerns about preserving the vehicle. Moving Discovery now would be incredibly expensive (estimated at $1 billion), potentially damage the shuttle, and require extensive work to refurbish a Shuttle Carrier Aircraft.\n\nThe article suggests the bill is primarily for political messaging, specifically to bolster Cornyn's reelection campaign against a strong primary challenger. Cornyn aims to portray himself as a fighter for Texas interests against Washington DC.\n\nNeither Space Center Houston nor NASA was consulted before the bill was filed. NASA is particularly unwilling to participate due to the complexity and cost of reactivating a Shuttle Carrier Aircraft. The article emphasizes that the Smithsonian houses Discovery, the most historically significant shuttle, for good reason, highlighting its importance as a national treasure. The author concludes that the proposed move is a \"colossally stupid idea\" that would waste taxpayer money and risk damaging a crucial piece of space history.\n",
    "chinese_title": "为什么两位德州参议员想从史密森尼学会夺取一架航天飞机？",
    "chinese_summary": "两位德克萨斯州参议员约翰·科宁和特德·克鲁兹提出了“将航天飞机带回家法案”，旨在将“发现号”航天飞机从史密森尼国家航空航天博物馆移至休斯顿。文章认为，这是一项出于政治动机、不切实际且代价高昂的举措。\n\n休斯顿虽然与航天飞机计划有着密切的联系，但在15年前分配航天飞机时，由于提案薄弱以及对保存航天飞机的担忧，并未获得一架。现在移动“发现号”将耗资巨大（估计为10亿美元），可能损坏航天飞机，并且需要大量工作来翻新航天飞机运输机。\n\n文章认为，该法案主要用于政治宣传，特别是为了支持科宁对抗一位强大的党内挑战者的连任竞选。科宁旨在将自己塑造成一位对抗华盛顿特区，为德克萨斯州利益而战的斗士。\n\n在提交该法案之前，休斯顿太空中心和美国国家航空航天局均未被咨询。由于重新启动航天飞机运输机的复杂性和成本，美国国家航空航天局尤其不愿意参与。文章强调，史密森尼博物馆收藏着最具历史意义的“发现号”航天飞机是有充分理由的，并强调了它作为国家珍宝的重要性。作者的结论是，拟议的搬迁是一个“极其愚蠢的主意”，会浪费纳税人的钱，并有损坏太空历史重要组成部分的风险。"
  },
  {
    "id": "43713239",
    "title": "Tired of Oh-my-ZSH bloat, built my own minimal dotfiles with just what I need",
    "url": "https://github.com/cassiozen/dotfiles",
    "summary": "Cassio Zen's dotfiles offer a lightweight, dependency-free ZSH configuration for macOS, designed to avoid the bloat often associated with frameworks like Oh-my-ZSH. The setup prioritizes essential features and customization.\n\nKey features include a minimal ZSH prompt displaying Git branch and status, enhanced tab completion with menu selection, arrow key history search, and convenient directory navigation aliases. Git functionality is enhanced with aliases for common commands, improved logging tools like `git lol` and `git graph`, and streamlined branch management via `git publish`, `git unpublish`, and `git cleanup`. Quality of life improvements include automatic stashing during rebases, a default branch set to `main`, and a global `.gitignore` configuration.\n\nInstallation involves cloning the repository (ideally to `~/.dotfiles`) and running the `bootstrap.sh` script. Users are strongly advised to fork the repository and review the configuration files before using them, as the settings are specific to Cassio Zen's preferences. Updates are performed by navigating to the `.dotfiles` directory and re-sourcing `bootstrap.sh`. Local customizations can be added in `~/.gitconfig.local` and `~/.zshrc.local` files, allowing users to tailor the setup further without modifying the core dotfiles.\n",
    "chinese_title": "受够了Oh-my-ZSH的臃肿，我自己构建了极简的、只包含所需功能的点文件。",
    "chinese_summary": "Cassio Zen 的 dotfiles 提供了一个轻量级、无依赖的 macOS ZSH 配置，旨在避免通常与 Oh-my-ZSH 等框架相关的臃肿。该设置优先考虑基本功能和自定义。\n\n主要功能包括：一个显示 Git 分支和状态的极简 ZSH 提示符，增强的带菜单选择的 Tab 补全，箭头键历史记录搜索，以及方便的目录导航别名。Git 功能通过常用命令的别名、改进的日志工具（如 `git lol` 和 `git graph`）以及简化的分支管理（通过 `git publish`、`git unpublish` 和 `git cleanup`）得到增强。生活质量方面的改进包括：rebase 期间的自动储藏，设置为 `main` 的默认分支，以及全局的 `.gitignore` 配置。\n\n安装过程包括克隆存储库（最好到 `~/.dotfiles`）并运行 `bootstrap.sh` 脚本。强烈建议用户在使用前 fork 存储库并查看配置文件，因为这些设置是针对 Cassio Zen 的个人偏好而设计的。更新通过导航到 `.dotfiles` 目录并重新运行 `bootstrap.sh` 来执行。本地自定义可以添加到 `~/.gitconfig.local` 和 `~/.zshrc.local` 文件中，允许用户进一步定制设置，而无需修改核心 dotfiles。"
  },
  {
    "id": "43710761",
    "title": "\"Vivarium\": The keeper of a lab's animals stumbles onto a secret [fiction]",
    "url": "https://jsomers.net/vivarium/",
    "summary": "In James Somers' \"Vivarium,\" the keeper of lab animals at a university stumbles upon a troubling secret within the sterile walls of his workplace. The keeper, who dedicates his life to the mice used in experiments, works odd hours, isolated from the university's daytime bustle and increasingly estranged from normal life. He finds solace in the routine care of the animals, despite the often cruel experiments they endure.\n\nThe story centers on the \"Becker experiment,\" where mice are deliberately kept alive despite severe suffering, pushing the boundaries of ethical treatment. The keeper becomes increasingly disturbed by the postdoc's insistence on prolonging the lives of the suffering mice, even when euthanasia is clearly warranted.\n\nOne night, faced with euthanizing the last two mice from the Becker experiment, the keeper hatches a plan. He finds the female (Anna K) vibrant, making the prospect of her inevitable demise even more upsetting. He sedates Anna K and intends to trick the postdoc into believing she is already too sick to continue, thus sparing her further suffering. His deception works, and the postdoc is led to believe that both mice are beyond saving. The keeper's ethical dilemma underscores the conflict between scientific progress and animal welfare, and the story highlights the dehumanizing effect of scientific abstraction, where animals are reduced to mere subjects, and scientists are blind to the individual suffering they endure.\n",
    "chinese_title": "饲养员：实验室动物管理员偶然发现一个秘密[小说]",
    "chinese_summary": "在詹姆斯·萨默斯的小说《动物饲养所》中，一所大学的实验动物管理员在他的工作场所的无菌墙壁内偶然发现了一个令人不安的秘密。 这位管理员将毕生精力都奉献给了实验用的小鼠，他工作时间不规律，与大学白天的喧嚣隔绝，并且与正常生活越来越疏远。 尽管这些动物忍受着往往是残酷的实验，但他还是从日常的照顾中找到了慰藉。\n\n故事围绕着“贝克尔实验”展开，在这个实验中，尽管小鼠遭受严重的痛苦，但仍被故意保持存活，从而突破了伦理治疗的界限。 管理员越来越不安，因为博士后坚持要延长受苦小鼠的生命，即使安乐死显然是必要的。\n\n一天晚上，面对对贝克尔实验中最后两只小鼠实施安乐死的任务，管理员萌生了一个计划。 他发现雌鼠（安娜·K）充满活力，这使得她不可避免的死亡前景更加令人不安。 他给安娜·K注射了镇静剂，并打算欺骗博士后，让他相信她已经病得太重，无法继续实验，从而免除她进一步的痛苦。 他的欺骗奏效了，博士后被误导，认为这两只小鼠都已经无法挽救。 管理员的伦理困境突显了科学进步与动物福利之间的冲突，并且这个故事突出了科学抽象的非人化影响，在这种影响下，动物被简化为单纯的实验对象，而科学家们却对它们所遭受的个体痛苦视而不见。"
  },
  {
    "id": "43678590",
    "title": "JSLinux",
    "url": "https://www.bellard.org/jslinux/",
    "summary": "JSLinux is a web-based emulator that allows users to run various operating systems directly within their web browser. It offers multiple emulated systems, including different versions of Linux (Alpine, Buildroot, Fedora), Windows 2000, and FreeDOS. These systems can be accessed and operated without requiring any local installation.\n\nThe platform provides console and graphical (X Window) interfaces for the Linux distributions, enabling users to interact with a simulated operating system environment. Each system has a corresponding link that launches it directly in the browser. Some systems feature specific instructions, such as using the right mouse button to access menus.\n\nUsers should also be aware of disclaimers and warnings related to certain operating systems, such as potential longer boot times. The platform is developed by Fabrice Bellard and includes links to news, a VM list, an FAQ, and technical notes for further information.\n",
    "chinese_title": "JSLinux",
    "chinese_summary": "JSLinux是一个基于网络的模拟器，允许用户直接在网页浏览器中运行各种操作系统。它提供多个模拟系统，包括不同版本的Linux（Alpine、Buildroot、Fedora）、Windows 2000和FreeDOS。这些系统无需任何本地安装即可访问和操作。\n\n该平台为Linux发行版提供控制台和图形（X Window）界面，使用户能够与模拟的操作系统环境交互。每个系统都有一个相应的链接，可以直接在浏览器中启动它。某些系统具有特定的说明，例如使用鼠标右键访问菜单。\n\n用户还应注意与某些操作系统相关的免责声明和警告，例如可能较长的启动时间。该平台由Fabrice Bellard开发，并包含新闻、虚拟机列表、常见问题解答和技术说明的链接，以获取更多信息。"
  },
  {
    "id": "43710986",
    "title": "Kotlin 101: Type Classes Quickly Explained",
    "url": "https://rockthejvm.com/articles/kotlin-101-type-classes",
    "summary": "This article provides a practical introduction to type classes in Kotlin using data validation as an example. It addresses the challenge of validating different data types (DTOs) with reusable and generic code, leveraging the Arrow Kt library and Kotlin's context receivers.\n\nThe article starts by highlighting the limitations of traditional object-oriented approaches, such as direct subtyping, which can violate the Single Responsibility Principle and make code less maintainable, especially when dealing with external or auto-generated types.\n\nIt then introduces type classes as a functional programming solution. It defines a `ValidatorScope<T>` interface, with `T.validate()` as an extension function, allowing validation logic to be decoupled from the DTOs. This enables ad-hoc polymorphism and avoids modifying the DTO classes themselves.\n\nThe article also discusses dispatcher receivers, limiting the visibility of the validate extension function through a `ValidatorScope`, making the extension function context-dependent. Furthermore, the use of `with` functions and context receivers is explained to further improve the code and provide cleaner syntax. It also mentions the limitations around automatic discovery of type classes, a feature present in languages like Scala and Haskell.\n\nFinally, it briefly touches upon how type classes can be used recursively, expanding the validation framework to incorporate the specific validation rules for the DTO fields, setting the stage for further explanation in the subsequent section (which is not present in the given text).\n",
    "chinese_title": "Kotlin 101：类型类快速讲解",
    "chinese_summary": "本文以数据验证为例，对 Kotlin 中的类型类进行了实用介绍。它解决了使用可重用和通用代码验证不同数据类型（DTO）的挑战，利用了 Arrow Kt 库和 Kotlin 的上下文接收者。\n\n文章首先强调了传统面向对象方法的局限性，例如直接子类型化，这可能违反单一职责原则并使代码的可维护性降低，尤其是在处理外部或自动生成的类型时。\n\n然后，它介绍了类型类作为一种函数式编程解决方案。它定义了一个 `ValidatorScope<T>` 接口，其中 `T.validate()` 作为一个扩展函数，允许验证逻辑与 DTO 解耦。这实现了特设多态性，并避免了修改 DTO 类本身。\n\n文章还讨论了分发器接收器，通过 `ValidatorScope` 限制 validate 扩展函数的可见性，使扩展函数具有上下文相关性。此外，还解释了 `with` 函数和上下文接收器的使用，以进一步改进代码并提供更简洁的语法。文章还提到了围绕类型类自动发现的限制，这是 Scala 和 Haskell 等语言中存在的功能。\n\n最后，它简要地提到了如何递归地使用类型类，扩展验证框架以纳入 DTO 字段的特定验证规则，为后续章节（在给定的文本中不存在）中的进一步解释奠定了基础。"
  },
  {
    "id": "43704596",
    "title": "How Nintendo bled Atari games to death",
    "url": "https://thereader.mitpress.mit.edu/how-nintendo-bled-atari-games-to-death/",
    "summary": "Julien Mailland's article examines the legal battle between Nintendo and Atari Games (operating as Tengen) concerning unauthorized NES game cartridges. Atari, wanting to avoid Nintendo's restrictive licensing terms, reverse-engineered the NES's lock-out chip (10NES) and created its own, the \"Rabbit.\"\n\nNintendo sued, arguing that Atari's temporary copying of the 10NES code during the reverse-engineering process constituted copyright infringement. While courts initially ruled that intermediate copying for reverse-engineering could be considered fair use, a crucial twist emerged. Atari's lawyers had fraudulently obtained the 10NES code from the Copyright Office by falsely claiming Nintendo was suing them.\n\nThe court invoked the \"unclean hands\" doctrine, stating that because Atari obtained the code through deception, it couldn't claim the fair use defense. This ruling effectively barred Atari from manufacturing NES games. Nintendo, with its stronger legal position, \"bled Atari to death,\" leading to the demise of the Tengen brand.\n\nThe article emphasizes the importance of legal strategies and ethical conduct in shaping the video game industry, illustrating how legal battles can be as significant as engineering innovations or artistic visions. The case also highlights the legal precedents established regarding reverse-engineering, influencing the retro-gaming market and the development of hardware emulators. It showcases how Nintendo's legal team, rather than purely game design, secured its dominance.\n",
    "chinese_title": "任天堂如何扼杀了雅达利游戏",
    "chinese_summary": "任天堂与雅达利（腾根）关于未经授权的NES游戏卡带的法律战"
  },
  {
    "id": "43681132",
    "title": "A protein folding mystery solved: Study explains core packing fractions",
    "url": "https://phys.org/news/2025-03-protein-mystery-core-fractions.html",
    "summary": "This article discusses a Yale University study published in PRX Life that sheds light on the protein folding process. Researchers, led by Corey O'Hern, analyzed the core packing fractions of globular proteins in the Protein Data Bank, finding that they consistently packed to 55%, meaning 55% of the core's space was occupied by atoms.\n\nThe study answers the question of why this packing fraction is consistent and why it's 55%. The researchers concluded that the protein cores jam or rigidify, preventing further compression. Unlike spherical objects which jam at 64%, the complex, elongated, and bumpy shapes of amino acids cause them to jam at a lower packing fraction.\n\nThe findings suggest that manipulating folding conditions like solvent, pressure, or temperature could potentially lead to denser packing and different protein structures, even with the same amino acid sequence. This could open new avenues for protein design, beyond just manipulating amino acid sequences, for applications like drug therapeutics and biomaterials.\n\nFurthermore, high-pressure studies mimicking deep ocean hydrothermal vent conditions have shown protein core packing fractions can increase to 58-60%, which relates to the origins of life. The research, led by Ph.D. candidate Alex Grigas, highlights the potential for designing proteins with novel structures and functions by altering folding conditions.\n",
    "chinese_title": "一个蛋白质折叠谜团解开：研究解释核心堆积率",
    "chinese_summary": "本文探讨了发表在PRX Life上的一项耶鲁大学研究，该研究阐明了蛋白质折叠过程。在Corey O'Hern的带领下，研究人员分析了蛋白质数据库中球状蛋白质的核心堆积密度，发现它们始终以55%的密度堆积，这意味着核心空间中有55%被原子占据。\n\n该研究解答了为什么这种堆积密度是一致的以及为什么是55%的问题。研究人员得出结论，蛋白质核心会发生堵塞或刚性化，从而阻止进一步压缩。与球形物体在64%时发生堵塞不同，氨基酸复杂、细长和凹凸不平的形状导致它们在较低的堆积密度下发生堵塞。\n\n研究结果表明，操纵诸如溶剂、压力或温度等折叠条件，有可能导致更密集的堆积和不同的蛋白质结构，即使使用相同的氨基酸序列。这可能为蛋白质设计开辟新的途径，超越仅仅操纵氨基酸序列，用于药物治疗和生物材料等应用。\n\n此外，模拟深海热液喷口条件的高压研究表明，蛋白质核心堆积密度可增加到58-60%，这与生命的起源有关。在博士候选人Alex Grigas的带领下，该研究强调了通过改变折叠条件来设计具有新结构和功能的蛋白质的潜力。"
  },
  {
    "id": "43679764",
    "title": "Unix files have (at least) two sizes",
    "url": "https://utcc.utoronto.ca/~cks/space/blog/unix/UnixFilesTwoSizes",
    "summary": "Chris Siebenmann's blog (\"Wandering Thoughts\") is blocking older browsers due to a surge in crawling activity, especially from bots pretending to be old Chrome versions. This is a precaution to reduce the server load caused by crawlers gathering data for LLM training and other purposes.\n\nIf a user sees this message, it's likely because their browser is flagged as suspicious due to its age. If the user believes this is an error, they are encouraged to contact Siebenmann with their browser details and User-Agent string.\n\nA specific issue is highlighted regarding archive services like archive.today, archive.ph, and archive.is. These services are often indistinguishable from malicious crawlers because they use old Chrome User-Agent values, crawl from widely distributed IP addresses, and sometimes even use falsified reverse DNS entries mimicking Googlebot. Siebenmann recommends using archive.org instead, as it is a better-behaved archival crawler. He implemented this blocking measure in early 2025 to combat high-volume, suspicious crawling.\n",
    "chinese_title": "Unix文件至少有两个大小。",
    "chinese_summary": "由于爬虫活动激增，尤其是伪装成旧版 Chrome 的机器人，Chris Siebenmann 的博客 (\"Wandering Thoughts\") 正在屏蔽较旧的浏览器。这是一种预防措施，旨在减少为 LLM 训练和其他目的收集数据的爬虫造成的服务器负载。\n\n如果用户看到此消息，很可能是因为他们的浏览器因版本过旧而被标记为可疑。如果用户认为这是一个错误，建议他们联系 Siebenmann 并提供其浏览器详细信息和 User-Agent 字符串。\n\n一个具体的问题是关于 archive.today、archive.ph 和 archive.is 等归档服务。这些服务通常与恶意爬虫无法区分，因为它们使用旧的 Chrome User-Agent 值，从广泛分布的 IP 地址进行爬取，甚至有时会使用伪造的反向 DNS 条目来模仿 Googlebot。Siebenmann 建议使用 archive.org，因为它是一个行为更好的归档爬虫。他于 2025 年初实施了这项屏蔽措施，以打击高流量、可疑的爬虫活动。"
  },
  {
    "id": "43714959",
    "title": "Development on Apple Silicon with UTM",
    "url": "https://rkiselenko.dev/blog/development-on-mac-with-utm/development-on-mac-with-lima/",
    "summary": "This article details how to create Linux development environments on Apple Silicon Macs using UTM virtual machines and cloud-init scripts. The process involves installing UTM and cdrtools, downloading appropriate cloud images for either Fedora or Ubuntu (both aarch64 and x86_64 are covered), and crafting a cloud-init script (user-data) to automate the installation of essential development tools (git, jq, go, docker, etc.), configure user settings, and set up SSH access.\n\nThe cloud-init script is packaged into an init.iso using mkisofs. A new UTM VM is then created, configured to either emulate (x86_64) or virtualize (aarch64), UEFI boot is disabled for Fedora, and the Fedora or Ubuntu cloud image is added as a VirtIO drive. The init.iso is also added as a VirtIO drive for initial setup.\n\nAfter starting the VM, the cloud-init script executes, configuring the system. The default username/password (fedora/password) allows initial login. Once initialization completes, the VM is powered off, and the init.iso drive is removed. Logs can be checked using `sudo cat /var/log/cloud-init-output.log`. For Apple Silicon VMs (aarch64), choose Virtualize and use arm64 images. The Ubuntu process is similar but doesn't require disabling UEFI boot and the `.img.xz` image must be extracted.\n",
    "chinese_title": "使用UTM在Apple Silicon上进行开发",
    "chinese_summary": "本文详细介绍了如何使用UTM虚拟机和cloud-init脚本在Apple Silicon Mac上创建Linux开发环境。该过程包括安装UTM和cdrtools，下载适用于Fedora或Ubuntu的云镜像（涵盖aarch64和x86_64架构），以及编写cloud-init脚本（user-data）以自动安装必要的开发工具（git、jq、go、docker等），配置用户设置并设置SSH访问。\n\ncloud-init脚本使用mkisofs打包成init.iso。然后创建一个新的UTM虚拟机，配置为模拟（x86_64）或虚拟化（aarch64），对于Fedora禁用UEFI启动，并将Fedora或Ubuntu云镜像添加为VirtIO驱动器。init.iso也作为VirtIO驱动器添加，用于初始设置。\n\n启动虚拟机后，cloud-init脚本执行，配置系统。默认用户名/密码（fedora/password）允许初始登录。初始化完成后，虚拟机断电，并移除init.iso驱动器。可以使用`sudo cat /var/log/cloud-init-output.log`查看日志。对于Apple Silicon虚拟机（aarch64），选择虚拟化并使用arm64镜像。Ubuntu过程类似，但不需要禁用UEFI启动，且`.img.xz`镜像必须解压。"
  },
  {
    "id": "43715069",
    "title": "Clean energy projects prioritised for grid connections",
    "url": "https://www.gov.uk/government/news/clean-energy-projects-prioritised-for-grid-connections",
    "summary": "The UK government is prioritizing clean energy projects for grid connections to accelerate the transition to clean energy, stimulate economic growth, and enhance energy security. Ofgem is expected to approve a plan drafted by the National Energy System Operator (NESO) to reform grid connections, unlocking an estimated £40 billion of mainly private investment annually.\n\nThe reforms aim to eliminate delays caused by \"zombie\" projects that hold up the queue, prioritizing businesses driving growth, particularly in sectors like data centers, AI, wind, and solar. This move aims to expedite the connection of renewable energy projects, reducing reliance on volatile global fossil fuel markets and lowering energy bills. Since July 2024, £43.7 billion of private investment has been announced in UK clean energy industries, highlighting the growing momentum.\n\nEnergy Secretary Ed Miliband emphasized the UK's commitment to becoming a safe haven for clean energy investment. The plan supports a \"muscular industrial policy\" focused on British industry. Ofgem CEO Jonathan Brearley noted that the reforms will streamline processes, consign \"zombie projects\" to the past, and supercharge clean power ambitions. NESO COO Kayte O'Neill highlighted the close collaboration across the energy industry in developing the plan. The reforms are projected to save billpayers £5 billion by avoiding unnecessary grid reinforcement.\n",
    "chinese_title": "清洁能源项目并网优先",
    "chinese_summary": "英国政府正优先考虑清洁能源项目的电网连接，以加速向清洁能源的转型，刺激经济增长并增强能源安全。英国天然气电力市场管理局(Ofgem)预计将批准国家能源系统运营商(NESO)起草的电网连接改革计划，从而每年释放估计400亿英镑的主要来自私人投资。\n\n这些改革旨在消除因阻碍队列的“僵尸”项目造成的延误，优先考虑推动增长的企业，尤其是在数据中心、人工智能、风能和太阳能等领域。此举旨在加速可再生能源项目的连接，减少对动荡的全球化石燃料市场的依赖并降低能源费用。自2024年7月以来，英国清洁能源产业已宣布了437亿英镑的私人投资，突显了日益增长的势头。\n\n能源大臣埃德·米利班德强调了英国致力于成为清洁能源投资安全港的承诺。该计划支持一项以英国工业为中心的“强有力的产业政策”。英国天然气电力市场管理局首席执行官乔纳森·布雷尔利指出，这些改革将简化流程，将“僵尸项目”送入历史，并为清洁能源雄心壮志提供强大动力。国家能源系统运营商首席运营官凯特·奥尼尔强调了能源行业在制定该计划中的密切合作。预计这些改革将通过避免不必要的电网加固为账单支付者节省50亿英镑。"
  },
  {
    "id": "43711339",
    "title": "Show HN: I built a deep learning engine from scratch in Python",
    "url": "https://github.com/whitegra/dolphin",
    "summary": "Dolphin is a Python deep learning engine built from scratch, eschewing libraries like NumPy and PyTorch for complete transparency and control. It aims to provide a clear and expressive platform for understanding the inner workings of transformers and automatic differentiation.\n\nKey features include:\n\n*   **Symbolic Autodiff Engine:** A custom Tensor class supporting 1D, 2D, and 3D tensors, tracking computation graphs and gradients, and implementing backpropagation.\n*   **Pure Python Transformer Stack:** Implementing multi-head self-attention, layer normalization, GELU activations, feedforward layers, and residual connections.\n*   **Zero-Dependency Machine Learning System:** Operates solely with vanilla Python, requiring no external libraries.\n*   **Modular Structure:** Organized into modules for tensors, transformers, activations, layers, and optimizers (SGD, Adam, Momentum).\n\nA complete example (`DolphinTest01.py`) demonstrates the framework's capabilities, including text preprocessing, transformer-based sequence modeling, end-to-end training, and text generation, all without external libraries.\n\nDolphin is intended for educational purposes, research, and exploring the fundamentals of deep learning without relying on black-box abstractions. It requires Python 3.7+ and is licensed under the MIT License.\n",
    "chinese_title": "Show HN: 我用 Python 从零开始构建了一个深度学习引擎",
    "chinese_summary": "Dolphin：一个纯Python实现的深度学习引擎，从零开始构建，摒弃了NumPy和PyTorch等库，以实现完全的透明性和控制。它旨在提供一个清晰且富有表现力的平台，用于理解Transformer和自动微分的内部运作原理。\n\n主要特性包括：\n\n*   **符号自动微分引擎：** 一个自定义的Tensor类，支持1D、2D和3D张量，跟踪计算图和梯度，并实现反向传播。\n*   **纯Python Transformer栈：** 实现多头自注意力、层归一化、GELU激活函数、前馈层和残差连接。\n*   **零依赖机器学习系统：** 仅使用原生Python运行，无需任何外部库。\n*   **模块化结构：** 组织成张量、Transformer、激活函数、层和优化器（SGD、Adam、动量）等模块。\n\n完整的示例（`DolphinTest01.py`）展示了该框架的功能，包括文本预处理、基于Transformer的序列建模、端到端训练和文本生成，所有这些都不依赖于外部库。\n\nDolphin旨在用于教育、研究和探索深度学习的基础知识，无需依赖黑盒抽象。它需要Python 3.7+版本，并采用MIT许可证。"
  },
  {
    "id": "43692390",
    "title": "CT scans could cause 5% of cancers, study finds; experts note uncertainty",
    "url": "https://arstechnica.com/health/2025/04/ct-scans-could-cause-5-of-cancers-study-finds-experts-note-uncertainty/",
    "summary": "This article discusses a new study published in JAMA Internal Medicine estimating that CT scans could be linked to approximately 5% of all cancers diagnosed annually in the US, based on data from 93 million scans performed in 2023. The researchers estimate that this translates to 103,000 future cancers, putting CT scans on par with risk factors like alcohol consumption and obesity. Lung and colon cancers were the most common types estimated to result from CT scans, with abdomen and pelvis scans being the most frequently linked.\n\nWhile the study suggests judicious use of CT scans and optimized doses, experts emphasize uncertainty in the modeling and caution against avoiding necessary scans. They argue that the benefits of diagnosis and treatment generally outweigh the small increased risk, estimating only a 0.1% increase in lifetime cancer risk per scan. The article also mentions a 35% increase in CT scan usage since 2007, raising concerns about potential overuse. Doctors are encouraged to consider alternative imaging options like ultrasounds and MRIs, and involve patients in the decision-making process.\n",
    "chinese_title": "CT扫描可能导致5%的癌症，研究发现；专家指出不确定性。",
    "chinese_summary": "基于JAMA内科学发表的一项新研究，该文章探讨了基于2023年进行的9300万次扫描的数据，CT扫描可能与美国每年诊断的约5%的癌症相关。 研究人员估计，这相当于未来将有103,000例癌症，使CT扫描与酒精消费和肥胖等风险因素相当。 肺癌和结肠癌是估计由CT扫描引起的最常见的癌症类型，其中腹部和盆腔扫描是最常见的相关扫描。\n\n虽然该研究建议谨慎使用CT扫描并优化剂量，但专家强调建模中的不确定性，并警告不要避免必要的扫描。 他们认为，诊断和治疗的益处通常大于小的风险增加，估计每次扫描仅增加0.1%的终生癌症风险。 文章还提到自2007年以来CT扫描的使用量增加了35%，引发了对潜在过度使用的担忧。 鼓励医生考虑替代成像选择，如超声波和MRI，并让患者参与决策过程。"
  },
  {
    "id": "43714133",
    "title": "'Why would he take such a risk?' My censor and me",
    "url": "https://www.theguardian.com/news/2025/apr/17/why-would-he-take-such-risk-my-censor-and-me-weibo-china",
    "summary": "Murong Xuecun's article explores the paradox of censorship in China through the story of Liu Lipeng, a Weibo censor who defied his duty to assist the author. In 2013, Liu, disillusioned with his job of deleting content deemed critical of the Communist Party, began to \"total pass\" large volumes of posts, allowing them to be seen by millions.\n\nLiu also used a personal Weibo account, \"Ordinary Fascist,\" to anonymously criticize the government. He assisted banned users, like Jenny Ho, by secretly restoring their accounts. He further collected internal \"shift handover files,\" detailing censorship orders, seeing them as important historical records.\n\nThe author, Murong Xuecun, a popular Weibo user, had his account cancelled after posting critical comments. Xuecun had a \"Weibo gatekeeper,\" Jia Jia, who would gently censor his posts and warn him of sensitive topics. After his account was banned, Liu, on his last day of work, accessed Xuecun's account details and anonymously sent screenshots of the censorship order to one of Murong Xuecun's contacts, Yu Dayou. Xuecun received the screenshots and knew why he was censored. Liu's actions highlight the complexities and contradictions within China's censorship system, raising the question of why someone would take such a risk to help someone they don't know. While Liu downplays the risk, claiming termination was the worst outcome, the article emphasizes the potential danger of his actions.\n",
    "chinese_title": "他为何要冒如此风险？我的审查者和我",
    "chinese_summary": "慕容雪村的文章通过刘力朋的故事探讨了中国审查制度的悖论。刘力朋是一名微博审查员，但他违背职责帮助了作者。 2013年，刘力朋对删除批评共产党的内容的工作感到幻灭，开始“全部通过”大量帖子，让数百万人看到。\n\n刘力朋还使用个人微博账号“普通法西斯”匿名批评政府。他还通过秘密恢复被禁用户的账户来帮助他们，例如珍妮·何。此外，他收集了内部“交班文件”，详细记录了审查命令，认为这些文件是重要的历史记录。\n\n作者慕容雪村是一位受欢迎的微博用户，因发表批评性评论而被取消账户。雪村有一位“微博守门员”贾葭，他会温和地审查他的帖子并警告他敏感话题。账户被封禁后，刘力朋在最后一天工作时，访问了雪村的账户详细信息，并将审查命令的截图匿名发送给了慕容雪村的联系人之一余大有。 雪村收到了截图，并知道了自己被审查的原因。刘力朋的行为突显了中国审查制度的复杂性和矛盾性，提出了一个问题：为什么有人会冒如此大的风险去帮助一个他们不认识的人。虽然刘力朋淡化了风险，声称最坏的结果是被解雇，但文章强调了他的行为可能带来的潜在危险。"
  },
  {
    "id": "43708726",
    "title": "Terak Museum",
    "url": "https://www.threedee.com/jcm/terak/index.html",
    "summary": "The Terak Museum, located within the Jefferson Computer Museum, is dedicated to the Terak, an early personal computer from the late 1970s and early 1980s. The site provides information about the Terak's history, specifications, and influence on computing.\n\nThe Terak, based on the PDP-11 processor, was known for its graphics capabilities, use in teaching Pascal, and adoption of the UCSD P-System. It featured a bitmapped display and user-defined character fonts, making it suitable for diverse applications from CAD to language learning. The museum details its features, including its memory-mapped graphics, programmable sound, and available operating systems like UCSD P-System and RT-11. Pricing information from 1981 is provided to illustrate the system's cost at the time.\n\nThe Terak's significance in computing history is highlighted, particularly its role in early graphical user interfaces, computer-aided design with the T-Square software, and its indirect influence on the Macintosh's MacPaint. The museum also notes its use in developing the Cornell Program Synthesizer (an early IDE) and its presence in \"termcap\" files as a smart terminal.\n\nThe website also features the author's collection of Terak hardware, software, and documentation, including factory photos and converted bitmap images. The author also expresses a desire to create a Terak emulator. The site encourages visitors to share information about Terak hardware and software, offering to provide a home for orphaned items. Information about the UCSD P-System and disk archive tools are also provided.\n",
    "chinese_title": "特拉克博物馆",
    "chinese_summary": "泰拉克博物馆： 位于杰斐逊电脑博物馆内，致力于展示20世纪70年代末至80年代初的早期个人电脑泰拉克。本网站提供有关泰拉克的历史、规格以及对计算领域的影响的信息。\n\n泰拉克基于PDP-11处理器，以其图形功能、在Pascal教学中的应用以及对UCSD P-System的采用而闻名。 它具有位图显示和用户定义的字符字体，使其适用于从CAD到语言学习的各种应用。 博物馆详细介绍了其功能，包括内存映射图形、可编程声音以及可用的操作系统，如UCSD P-System和RT-11。 1981年的定价信息用于说明当时该系统的成本。\n\n强调了泰拉克在计算机历史上的重要性，特别是它在早期图形用户界面、使用T-Square软件的计算机辅助设计以及对Macintosh的MacPaint的间接影响方面的作用。 博物馆还提到它在开发康奈尔程序合成器（一个早期的IDE）中的应用以及它作为智能终端存在于“termcap”文件中。\n\n该网站还收录了作者收藏的泰拉克硬件、软件和文档，包括工厂照片和转换后的位图图像。 作者还表达了创建泰拉克模拟器的愿望。 该网站鼓励访问者分享有关泰拉克硬件和软件的信息，并表示愿意为遗弃的物品提供家园。 还提供了有关UCSD P-System和磁盘归档工具的信息。"
  }
]